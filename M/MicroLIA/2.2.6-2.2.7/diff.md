# Comparing `tmp/MicroLIA-2.2.6.tar.gz` & `tmp/MicroLIA-2.2.7.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "MicroLIA-2.2.6.tar", last modified: Fri May 26 01:23:17 2023, max compression
+gzip compressed data, was "MicroLIA-2.2.7.tar", last modified: Mon Jun 26 12:42:25 2023, max compression
```

## Comparing `MicroLIA-2.2.6.tar` & `MicroLIA-2.2.7.tar`

### file list

```diff
@@ -1,33 +1,38 @@
-drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-05-26 01:23:17.460978 MicroLIA-2.2.6/
--rwxr-xr-x   0 daniel     (501) staff       (20)    35141 2022-10-18 03:09:36.000000 MicroLIA-2.2.6/LICENSE.txt
--rw-r--r--   0 daniel     (501) staff       (20)       24 2023-05-22 20:39:52.000000 MicroLIA-2.2.6/MANIFEST.in
-drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-05-26 01:23:17.438046 MicroLIA-2.2.6/MicroLIA/
--rwxr-xr-x   0 daniel     (501) staff       (20)      365 2022-08-12 15:04:07.000000 MicroLIA-2.2.6/MicroLIA/__init__.py
--rw-r--r--   0 daniel     (501) staff       (20)   172657 2023-04-16 16:18:23.000000 MicroLIA-2.2.6/MicroLIA/cnn_model.py
-drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-05-26 01:23:17.453413 MicroLIA-2.2.6/MicroLIA/data/
--rwxr-xr-x   0 daniel     (501) staff       (20)  1384833 2022-07-17 06:13:15.000000 MicroLIA-2.2.6/MicroLIA/data/Miras_vo.xml
-drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-05-26 01:23:17.459089 MicroLIA-2.2.6/MicroLIA/data/Sesar2010/
--rw-r--r--   0 daniel     (501) staff       (20)   172713 2023-05-22 18:52:51.000000 MicroLIA-2.2.6/MicroLIA/data/Sesar2010/RRLyr_ugriz_templates.tar.gz
--rwxr-xr-x   0 daniel     (501) staff       (20)      365 2023-05-26 00:06:44.000000 MicroLIA-2.2.6/MicroLIA/data/Sesar2010/__init__.py
--rwxr-xr-x   0 daniel     (501) staff       (20)      365 2023-05-26 00:06:30.000000 MicroLIA-2.2.6/MicroLIA/data/__init__.py
--rw-r--r--   0 daniel     (501) staff       (20)    36126 2023-04-14 06:02:09.000000 MicroLIA-2.2.6/MicroLIA/data_augmentation.py
--rw-r--r--   0 daniel     (501) staff       (20)    12888 2023-04-14 06:05:32.000000 MicroLIA-2.2.6/MicroLIA/data_processing.py
--rw-r--r--   0 daniel     (501) staff       (20)    54677 2023-04-14 06:20:00.000000 MicroLIA-2.2.6/MicroLIA/ensemble_model.py
--rwxr-xr-x   0 daniel     (501) staff       (20)     5250 2023-03-30 05:00:56.000000 MicroLIA-2.2.6/MicroLIA/extract_features.py
--rwxr-xr-x   0 daniel     (501) staff       (20)   117151 2023-03-30 03:46:20.000000 MicroLIA-2.2.6/MicroLIA/features.py
--rwxr-xr-x   0 daniel     (501) staff       (20)     2719 2023-03-19 23:16:44.000000 MicroLIA-2.2.6/MicroLIA/noise_models.py
--rw-r--r--   0 daniel     (501) staff       (20)   130007 2023-04-14 05:58:12.000000 MicroLIA-2.2.6/MicroLIA/optimization.py
--rwxr-xr-x   0 daniel     (501) staff       (20)     4419 2023-02-26 05:00:18.000000 MicroLIA-2.2.6/MicroLIA/quality_check.py
--rwxr-xr-x   0 daniel     (501) staff       (20)    42330 2023-05-26 01:20:23.000000 MicroLIA-2.2.6/MicroLIA/simulate.py
--rwxr-xr-x   0 daniel     (501) staff       (20)    25956 2023-05-22 21:13:10.000000 MicroLIA-2.2.6/MicroLIA/training_set.py
-drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-05-26 01:23:17.445111 MicroLIA-2.2.6/MicroLIA.egg-info/
--rw-r--r--   0 daniel     (501) staff       (20)      572 2023-05-26 01:23:17.000000 MicroLIA-2.2.6/MicroLIA.egg-info/PKG-INFO
--rw-r--r--   0 daniel     (501) staff       (20)      658 2023-05-26 01:23:17.000000 MicroLIA-2.2.6/MicroLIA.egg-info/SOURCES.txt
--rw-r--r--   0 daniel     (501) staff       (20)        1 2023-05-26 01:23:17.000000 MicroLIA-2.2.6/MicroLIA.egg-info/dependency_links.txt
--rw-r--r--   0 daniel     (501) staff       (20)      193 2023-05-26 01:23:17.000000 MicroLIA-2.2.6/MicroLIA.egg-info/requires.txt
--rw-r--r--   0 daniel     (501) staff       (20)        9 2023-05-26 01:23:17.000000 MicroLIA-2.2.6/MicroLIA.egg-info/top_level.txt
--rw-r--r--   0 daniel     (501) staff       (20)      572 2023-05-26 01:23:17.460332 MicroLIA-2.2.6/PKG-INFO
--rwxr-xr-x   0 daniel     (501) staff       (20)     2641 2022-10-18 03:09:36.000000 MicroLIA-2.2.6/README.md
--rw-r--r--   0 daniel     (501) staff       (20)      456 2023-05-22 20:31:54.000000 MicroLIA-2.2.6/pyproject.toml
--rw-r--r--   0 daniel     (501) staff       (20)       38 2023-05-26 01:23:17.461636 MicroLIA-2.2.6/setup.cfg
--rwxr-xr-x   0 daniel     (501) staff       (20)     1201 2023-05-26 01:20:48.000000 MicroLIA-2.2.6/setup.py
+drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-06-26 12:42:25.713405 MicroLIA-2.2.7/
+-rwxr-xr-x   0 daniel     (501) staff       (20)    35141 2022-10-18 03:09:36.000000 MicroLIA-2.2.7/LICENSE.txt
+-rw-r--r--   0 daniel     (501) staff       (20)       24 2023-05-22 20:39:52.000000 MicroLIA-2.2.7/MANIFEST.in
+drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-06-26 12:42:25.680486 MicroLIA-2.2.7/MicroLIA/
+-rwxr-xr-x   0 daniel     (501) staff       (20)      365 2022-08-12 15:04:07.000000 MicroLIA-2.2.7/MicroLIA/__init__.py
+-rw-r--r--   0 daniel     (501) staff       (20)   222741 2023-06-26 05:48:00.000000 MicroLIA-2.2.7/MicroLIA/cnn_model.py
+drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-06-26 12:42:25.695201 MicroLIA-2.2.7/MicroLIA/data/
+-rwxr-xr-x   0 daniel     (501) staff       (20)  1384833 2022-07-17 06:13:15.000000 MicroLIA-2.2.7/MicroLIA/data/Miras_vo.xml
+drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-06-26 12:42:25.700594 MicroLIA-2.2.7/MicroLIA/data/Sesar2010/
+-rw-r--r--   0 daniel     (501) staff       (20)   172713 2023-05-22 18:52:51.000000 MicroLIA-2.2.7/MicroLIA/data/Sesar2010/RRLyr_ugriz_templates.tar.gz
+-rwxr-xr-x   0 daniel     (501) staff       (20)      365 2023-05-26 00:06:44.000000 MicroLIA-2.2.7/MicroLIA/data/Sesar2010/__init__.py
+-rwxr-xr-x   0 daniel     (501) staff       (20)      365 2023-05-26 00:06:30.000000 MicroLIA-2.2.7/MicroLIA/data/__init__.py
+-rw-r--r--   0 daniel     (501) staff       (20)    36399 2023-06-22 20:29:46.000000 MicroLIA-2.2.7/MicroLIA/data_augmentation.py
+-rw-r--r--   0 daniel     (501) staff       (20)    12654 2023-06-22 20:28:50.000000 MicroLIA-2.2.7/MicroLIA/data_processing.py
+-rw-r--r--   0 daniel     (501) staff       (20)    61567 2023-06-26 10:44:53.000000 MicroLIA-2.2.7/MicroLIA/ensemble_model.py
+-rwxr-xr-x   0 daniel     (501) staff       (20)     5295 2023-06-25 06:03:45.000000 MicroLIA-2.2.7/MicroLIA/extract_features.py
+-rwxr-xr-x   0 daniel     (501) staff       (20)   126392 2023-06-25 06:03:35.000000 MicroLIA-2.2.7/MicroLIA/features.py
+-rwxr-xr-x   0 daniel     (501) staff       (20)     2719 2023-03-19 23:16:44.000000 MicroLIA-2.2.7/MicroLIA/noise_models.py
+-rw-r--r--   0 daniel     (501) staff       (20)   141785 2023-06-26 12:17:13.000000 MicroLIA-2.2.7/MicroLIA/optimization.py
+-rwxr-xr-x   0 daniel     (501) staff       (20)     4533 2023-06-24 23:01:10.000000 MicroLIA-2.2.7/MicroLIA/quality_check.py
+-rwxr-xr-x   0 daniel     (501) staff       (20)    43276 2023-06-24 23:00:26.000000 MicroLIA-2.2.7/MicroLIA/simulate.py
+drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-06-26 12:42:25.709157 MicroLIA-2.2.7/MicroLIA/test/
+-rw-rw-r--   0 daniel     (501) staff       (20)       26 2019-01-16 07:54:34.000000 MicroLIA-2.2.7/MicroLIA/test/__init__.py
+-rw-rw-r--   0 daniel     (501) staff       (20)     5435 2023-06-26 12:32:39.000000 MicroLIA-2.2.7/MicroLIA/test/test_classifier.py
+-rw-rw-r--   0 daniel     (501) staff       (20)    45712 2023-06-26 12:35:39.000000 MicroLIA-2.2.7/MicroLIA/test/test_features.py
+-rw-r--r--   0 daniel     (501) staff       (20)     7076 2021-09-02 01:48:25.000000 MicroLIA-2.2.7/MicroLIA/test/test_ogle_lc.dat
+-rwxr-xr-x   0 daniel     (501) staff       (20)    27575 2023-06-24 23:10:27.000000 MicroLIA-2.2.7/MicroLIA/training_set.py
+drwxr-xr-x   0 daniel     (501) staff       (20)        0 2023-06-26 12:42:25.685328 MicroLIA-2.2.7/MicroLIA.egg-info/
+-rw-r--r--   0 daniel     (501) staff       (20)      572 2023-06-26 12:42:25.000000 MicroLIA-2.2.7/MicroLIA.egg-info/PKG-INFO
+-rw-r--r--   0 daniel     (501) staff       (20)      779 2023-06-26 12:42:25.000000 MicroLIA-2.2.7/MicroLIA.egg-info/SOURCES.txt
+-rw-r--r--   0 daniel     (501) staff       (20)        1 2023-06-26 12:42:25.000000 MicroLIA-2.2.7/MicroLIA.egg-info/dependency_links.txt
+-rw-r--r--   0 daniel     (501) staff       (20)      193 2023-06-26 12:42:25.000000 MicroLIA-2.2.7/MicroLIA.egg-info/requires.txt
+-rw-r--r--   0 daniel     (501) staff       (20)        9 2023-06-26 12:42:25.000000 MicroLIA-2.2.7/MicroLIA.egg-info/top_level.txt
+-rw-r--r--   0 daniel     (501) staff       (20)      572 2023-06-26 12:42:25.711968 MicroLIA-2.2.7/PKG-INFO
+-rwxr-xr-x   0 daniel     (501) staff       (20)     4175 2023-06-24 10:10:52.000000 MicroLIA-2.2.7/README.md
+-rw-r--r--   0 daniel     (501) staff       (20)      456 2023-05-22 20:31:54.000000 MicroLIA-2.2.7/pyproject.toml
+-rw-r--r--   0 daniel     (501) staff       (20)       38 2023-06-26 12:42:25.713747 MicroLIA-2.2.7/setup.cfg
+-rwxr-xr-x   0 daniel     (501) staff       (20)     1345 2023-06-23 08:33:52.000000 MicroLIA-2.2.7/setup.py
```

### Comparing `MicroLIA-2.2.6/LICENSE.txt` & `MicroLIA-2.2.7/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `MicroLIA-2.2.6/MicroLIA/cnn_model.py` & `MicroLIA-2.2.7/MicroLIA/cnn_model.py`

 * *Files 14% similar despite different names*

```diff
@@ -13,17 +13,18 @@
 import joblib
 import pickle 
 import numpy as np
 import pkg_resources
 from pathlib import Path
 import matplotlib.pyplot as plt
 import matplotlib.colors as mcolors
+from cycler import cycler
+
 from sklearn.manifold import TSNE
 from tensorflow.keras.utils import to_categorical
-
 import random as python_random
 ##https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development##
 np.random.seed(1909), python_random.seed(1909), tf.random.set_seed(1909)
 
 from tensorflow.keras import backend as K
 from tensorflow.keras.regularizers import l2
 from tensorflow.keras.callbacks import ModelCheckpoint
@@ -37,19 +38,19 @@
 from tensorflow.keras.layers import Input, Activation, Dense, Dropout, Conv2D, MaxPool2D, Add, ZeroPadding2D, \
     AveragePooling2D, GlobalAveragePooling2D, Flatten, BatchNormalization, Lambda, concatenate
 from optuna.importance import get_param_importances, FanovaImportanceEvaluator
 from MicroLIA.data_processing import process_class, create_training_set, concat_channels
 from MicroLIA.data_augmentation import augmentation, resize, smote_oversampling, plot
 from MicroLIA import optimization
 
-
 class Classifier:
     """
     Creates and trains the convolutional neural network. The built-in methods can be used predict new samples, and also optimize the engine and output visualizations.
-    
+    REMINDER: horizontal = vertical = rotation = True 
+
     Note:
         The smote_sampling parameter is used in the SMOTE algorithm to specify the desired 
         ratio of the minority class to the majority class after oversampling the majority.
 
         If smote_sampling=1.0, the minority class will be oversampled to have the same number 
         of instances as the majority class, resulting in a balanced dataset.
 
@@ -64,14 +65,19 @@
             be assigned the positive label '1'.
         negative_class (ndarray, str): The samples for the second class should be passed, which will automatically 
             be assigned the negative label '0'.
         val_positive (ndarray, optional): Positive class data to be used for validation. Defaults to None.
         val_negative (ndarray, optional): Negative class data to be used for validation. Defaults to None.
         test_positive (ndarray, optional): Positive class data to be used for post-trial testing. Defaults to None.
         test_negative (ndarray, optional): Negative class data to be used for post-trial testing. Defaults to None.
+        test_acc_threshold (float, optional): If input, models that yield test accuracies lower than the threshold will
+            be rejected by the optimizer. The accuracy of both the test_positive and test_negative is asessed, if input.
+            This is used to reject models that have over or under fit the training data. Defaults to None.
+        post_metric (bool): If True, the test_positive and/or test_negative inputs will be included in the final optimization score.
+            This will be the averaged out metric. Defaults to True. Can be set to False to only apply the test_acc_threshold.
         optimize (bool): If True the Boruta algorithm will be run to identify the features
             that contain useful information, after which the optimal Random Forest hyperparameters will be calculated 
             using Bayesian optimization. 
         n_iter (int): The maximum number of iterations to perform during the hyperparameter search. Defaults to 25. 
         train_epochs (int): Number of epochs to the train the CNN to during the optimization trials. Defaults to 25.
         img_num_channels (int): The number of filters. Defaults to 1.
         normalize (bool, optional): If True the data will be min-max normalized using the 
@@ -79,15 +85,21 @@
         min_pixel (int, optional): The minimum pixel count, pixels with counts 
             below this threshold will be set to this limit. Defaults to 0.
         max_pixel (int, list, optional): The maximum pixel count, pixels with counts 
             above this threshold will be set to this limit. Defaults to 100. If img_num_channels
             is not 1, the max_pixel should be a list containing two values, one for each band.
         metric (str): Assesment metric to use when both pruning and scoring the hyperparameter optimization trial.
             Defaults to 'loss'. Options include: 'loss' 'binary_accuracy', 'f1_score' 'all' or the validation equivalents (e.g. 'val_loss').
-        patience (int): Number of epochs without improvement before the optimization trial is terminated. Defaults to 0, which
+        metric2 (str, optional): Additional metric to be used solely for early-stopping purposes. If input, the trial will stop if either
+            metric or metric2 stop improving after the same patience number of epochs, but only the value of metric is used to assess
+            the performance of the model after each trial. Defaults to None.        patience (int): Number of epochs without improvement before the optimization trial is terminated. Defaults to 0, which
+            disables this feature.
+        metric3 (str, optional): Additional metric to be used solely for early-stopping purposes. If input, the trial will stop if either
+            metric or metric3 stop improving after the same patience number of epochs, but only the value of metric is used to assess
+            the performance of the model after each trial. Defaults to None.        patience (int): Number of epochs without improvement before the optimization trial is terminated. Defaults to 0, which
             disables this feature.
         average (bool): If False, the designated metric will be calculated according to its value at the end of the train_epochs. 
             If True, the metric will be averaged out across all train_epochs. Defaults to True.
         opt_model (bool): If True, the architecture parameters will be optimized. Defaults to True.
         opt_aug (bool): If True, the augmentation procedure will be optimized. Defaults to False.
         batch_min (int): The minimum number of augmentations to perform per image on the positive class, only applicable 
             if opt_aug=True. Defaults to 2.
@@ -101,17 +113,21 @@
             only applicable if opt_aug=True. Defaults to None.
         opt_max_max_pix (int, optional): The maximum max pixel value to use when tuning the normalization procedure, 
             only applicable if opt_aug=True. Defaults to None.
         shift (int): The max allowed vertical/horizontal shifts to use during the data augmentation routine, only applicable
             if opt_aug=True. Defaults to 10 pixels.
         mask_size (int, optional): If enabled, this will set the pixel length of a square cutout, to be randomly placed
             somewhere in the augmented image. This cutout will replace the image values with 0, therefore serving as a 
-            regularizear. Only applicable if opt_aug=True. Defaults to None.
-        num_masks (int, optional): The number of masks to create, to be used alongside the mask_size parameter. If 
-            this is set to a value greater than one, overlap may occur. 
+            regularizer. Only applicable if opt_aug=True. This value can either be an integer to hard-set the mask size everytime,
+            or can be a tuple representing the lower and upper bounds, respectively, in which case the mask size will be optimized. 
+            Defaults to None.
+        num_masks (int, optional): The number of masks to create, to be used alongside the mask_size parameter. Note that if 
+            this is set to a value greater than one, overlap may occur. This value can either be an integer to hard-set the number
+            of masks everytime, or it can be a tuple representing the lower and upper bounds, respectively, in which case the number
+            of masks will be optimized. Defaults to None.
         verbose (int): Controls the amount of output printed during the training process. A value of 0 is for silent mode, 
             a value of 1 is used for progress bar mode, and 2 for one line per epoch mode. Defaults to 1.
         opt_cv (int): Cross-validations to perform when assesing the performance at each
             hyperparameter optimization trial. For example, if cv=3, then each optimization trial
             will be assessed according to the 3-fold cross validation accuracy. Defaults to 10.
             NOTE: The higher this number, the longer the optimization will take.
         balance (bool, optional): This will determine whether the two classes
@@ -135,22 +151,23 @@
             blending augmentations, to be used if optimizing with opt_aug=True, then this parameter will be tuned and will be used as the 
             maximum increase to accept. For example, if opt_aug=True and blend_max=5, then the optimization will return
             an optimal value between 1 and 5. If 1, then the blending procedure is applied but the minority class size remains same the. If 5,
             then the minority class will be increased 500% via the blening routine. Defaults to 0 which disables this feature. To enable
             when opt_aug=True, set to to greater than or equal to 1.1 (a minimum of 10% increase), which would thus try different values for this
             during the optimization between 1 and 1.1.
         blend_other (float): Greater than or equal to 1. Can be zero to not apply augmentation to the majority class.
-    
+        path (str): Absolute path where the models and study object will be saved. Defaults to None, which saves the models and study
+            in the home directory.
     """
 
     def __init__(self, positive_class=None, negative_class=None, val_positive=None, val_negative=None, img_num_channels=1, clf='alexnet', 
-        normalize=False, min_pixel=0, max_pixel=100, optimize=False, n_iter=25, batch_size_min=16, batch_size_max=64, epochs=25, patience=5, metric='loss', 
-        average=True, test_positive=None, test_negative=None, opt_model=True, train_epochs=25, opt_cv=None,
-        opt_aug=False, batch_min=2, batch_max=25, batch_other=1, balance=True, image_size_min=50, image_size_max=100, shift=10, opt_max_min_pix=None, opt_max_max_pix=None, 
-        mask_size=None, num_masks=None, smote_sampling=0, blend_max=0, blending_func='mean', num_images_to_blend=2, blend_other=1, zoom_range=(0.9,1.1), skew_angle=0,
+        normalize=False, min_pixel=0, max_pixel=100, optimize=False, n_iter=25, batch_size_min=16, batch_size_max=64, epochs=25, patience=5, metric='loss', metric2=None, metric3=None,
+        average=True, test_positive=None, test_negative=None, test_acc_threshold=None, post_metric=True, opt_model=True, train_epochs=25, opt_cv=None,
+        opt_aug=False, batch_min=2, batch_max=25, batch_other=1, balance=True, image_size_min=50, image_size_max=100, opt_max_min_pix=None, opt_max_max_pix=None, 
+        shift=10, rotation=False, horizontal=False, vertical=False, mask_size=None, num_masks=None, smote_sampling=0, blend_max=0, blending_func='mean', num_images_to_blend=2, blend_other=1, zoom_range=None, skew_angle=0,
         limit_search=True, monitor1=None, monitor2=None, monitor1_thresh=None, monitor2_thresh=None, verbose=0, path=None, use_gpu=False):
 
         self.positive_class = positive_class
         self.negative_class = negative_class
         self.val_positive = val_positive
         self.val_negative = val_negative
         self.img_num_channels = img_num_channels
@@ -166,34 +183,41 @@
         self.n_iter = n_iter
         self.batch_size_min = batch_size_min
         self.batch_size_max = batch_size_max
         
         self.epochs = epochs
         self.patience = patience
         self.metric = metric
+        self.metric2 = metric2
+        self.metric3 = metric3
         self.average = average
         self.test_positive = test_positive
         self.test_negative = test_negative
+        self.test_acc_threshold = test_acc_threshold
+        self.post_metric = post_metric
         self.opt_model = opt_model
         self.train_epochs = train_epochs
         self.opt_cv = opt_cv
 
         #Augmentation params including min and max pixels normalization
         self.opt_aug = opt_aug
         self.batch_min = batch_min
         self.batch_max = batch_max
         self.batch_other = batch_other
         self.balance = balance
         self.image_size_min = image_size_min
         self.image_size_max = image_size_max
-        self.shift = shift
         self.opt_max_min_pix = opt_max_min_pix
         self.opt_max_max_pix = opt_max_max_pix
 
         #Image augmentation procedures
+        self.shift = shift
+        self.rotation = rotation
+        self.horizontal = horizontal
+        self.vertical = vertical
         self.mask_size = mask_size
         self.num_masks = num_masks
         self.smote_sampling = smote_sampling
         self.blend_max = blend_max
         self.blending_func = blending_func
         self.num_images_to_blend = num_images_to_blend
         self.blend_other = blend_other
@@ -215,18 +239,43 @@
 
         if self.use_gpu is False:
             os.environ['CUDA_VISIBLE_DEVICES'] = '-1' 
 
         if self.clf not in ['alexnet', 'vgg16', 'resnet18', 'custom_cnn']:
             raise ValueError('Invalid clf input, options are: "alexnet", "vgg16", "resnet18", or "custom_cnn".')
 
-        if self.val_positive is not None:
+        if self.positive_class is not None:
             if len(self.positive_class.shape) == 4 and self.img_num_channels != self.positive_class.shape[-1]:
                 print('NOTE: Detected {} filters but img_num_channels was set to {}, setting img_numg_channels={}'.format(self.positive_class.shape[-1], self.img_num_channels, self.positive_class.shape[-1]))
                 self.img_num_channels = self.positive_class.shape[-1]
+            if len(self.positive_class.shape) == 4 and self.img_num_channels == 1: #If it's just one filter convert to 3-D array
+                self.positive_class = np.squeeze(self.positive_class)
+            if len(self.negative_class.shape) == 4 and self.img_num_channels == 1: #If it's just one filter convert to 3-D array
+                self.negative_class = np.squeeze(self.negative_class)
+            if self.val_positive is not None:
+                if len(self.val_positive.shape) == 4 and self.img_num_channels == 1: #If it's just one filter convert to 3-D array
+                    self.val_positive = np.squeeze(self.val_positive)
+                if len(self.val_positive.shape) == 2:
+                    if self.img_num_channels != 1:
+                        raise ValueError('Single image detected as the positive validation data, img_num_channels must be 1!')
+                    else:
+                        self.val_positive = np.reshape(self.val_positive, (1, self.val_positive.shape[0], self.val_positive.shape[1]))
+            if self.val_negative is not None:
+                if len(self.val_negative.shape) == 4 and self.img_num_channels == 1: #If it's just one filter convert to 3-D array
+                    self.val_negative = np.squeeze(self.val_negative)
+                if len(self.val_negative.shape) == 2:
+                    if self.img_num_channels != 1:
+                        raise ValueError('Single image detected as the negative validation data, img_num_channels must be 1!')
+                    else:
+                        self.val_negative = np.reshape(self.val_negative, (1, self.val_negative.shape[0], self.val_negative.shape[1]))
+
+        if self.test_positive is not None or self.test_negative is not None:
+            if self.post_metric is False and self.test_acc_threshold is None:
+                raise ValueError('NOTE: Test data has been input but both post_metric=False and test_acc_threshold=None -- enable at least one option or set the test data to None!')
+
 
         #These will be the model attributes
         self.model = None
         self.history = None 
         self.best_params = None 
         self.optimization_results = None 
 
@@ -238,14 +287,17 @@
             overwrite_training (bool)
             save_training (bool):
         
         Returns:
             Trained classifier.
         """
 
+        if self.positive_class is None or self.negative_class is None:
+            raise ValueError('No training data found! Input both the positive_class and the negative_class.')
+            
         if self.optimize is False and self.best_params is None:
             if self.clf == 'alexnet':
                 print("Returning base AlexNet model...")
                 self.model, self.history = AlexNet(self.positive_class, self.negative_class, img_num_channels=self.img_num_channels, normalize=self.normalize,
                     min_pixel=self.min_pixel, max_pixel=self.max_pixel, val_positive=self.val_positive, val_negative=self.val_negative, epochs=self.epochs, 
                     smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, save_training_data=save_training, path=self.path)
             elif self.clf == 'vgg16':
@@ -259,29 +311,43 @@
                     min_pixel=self.min_pixel, max_pixel=self.max_pixel, val_positive=self.val_positive, val_negative=self.val_negative, epochs=self.epochs, 
                     smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, save_training_data=save_training, path=self.path)
             elif self.clf == 'custom_cnn':
                 print("Returning the base custom model (1 convolutional layer + 1 dense layer)...")
                 self.model, self.history = custom_model(self.positive_class, self.negative_class, img_num_channels=self.img_num_channels, normalize=self.normalize,
                     min_pixel=self.min_pixel, max_pixel=self.max_pixel, val_positive=self.val_positive, val_negative=self.val_negative, epochs=self.epochs, 
                     smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, save_training_data=save_training, path=self.path)          
+            
+            print(); print('Complete! To save the final model and optimization results, call the save() method.') 
+            if overwrite_training:
+                print(); print("Can only use overwrite_training=True if optimizing the model!")
+
             return      
 
         if self.best_params is None:
             self.best_params, self.optimization_results = optimization.hyper_opt(self.positive_class, self.negative_class, val_X=self.val_positive, val_Y=self.val_negative, img_num_channels=self.img_num_channels, clf=self.clf,
-                normalize=self.normalize, min_pixel=self.min_pixel, max_pixel=self.max_pixel, n_iter=self.n_iter, patience=self.patience, metric=self.metric, average=self.average,
-                test_positive=self.test_positive, test_negative=self.test_negative, opt_model=self.opt_model, batch_size_min=self.batch_size_min, batch_size_max=self.batch_size_max, train_epochs=self.train_epochs, opt_cv=self.opt_cv,
-                opt_aug=self.opt_aug, batch_min=self.batch_min, batch_max=self.batch_max, batch_other=self.batch_other, balance=self.balance, image_size_min=self.image_size_min, image_size_max=self.image_size_max, shift=self.shift, 
-                opt_max_min_pix=self.opt_max_min_pix, opt_max_max_pix=self.opt_max_max_pix, mask_size=self.mask_size, num_masks=self.num_masks, smote_sampling=self.smote_sampling, blend_max=self.blend_max, blend_other=self.blend_other, 
+                normalize=self.normalize, min_pixel=self.min_pixel, max_pixel=self.max_pixel, n_iter=self.n_iter, patience=self.patience, metric=self.metric, metric2=self.metric2, metric3=self.metric3, average=self.average,
+                test_positive=self.test_positive, test_negative=self.test_negative, test_acc_threshold=self.test_acc_threshold, post_metric=self.post_metric, opt_model=self.opt_model, batch_size_min=self.batch_size_min, batch_size_max=self.batch_size_max, 
+                train_epochs=self.train_epochs, opt_cv=self.opt_cv, opt_aug=self.opt_aug, batch_min=self.batch_min, batch_max=self.batch_max, batch_other=self.batch_other, balance=self.balance, image_size_min=self.image_size_min, image_size_max=self.image_size_max, 
+                shift=self.shift, rotation=self.rotation, horizontal=self.horizontal, vertical=self.vertical, opt_max_min_pix=self.opt_max_min_pix, opt_max_max_pix=self.opt_max_max_pix, mask_size=self.mask_size, num_masks=self.num_masks, smote_sampling=self.smote_sampling, blend_max=self.blend_max, blend_other=self.blend_other, 
                 num_images_to_blend=self.num_images_to_blend, blending_func=self.blending_func, zoom_range=self.zoom_range, skew_angle=self.skew_angle, limit_search=self.limit_search, monitor1=self.monitor1, monitor2=self.monitor2, monitor1_thresh=self.monitor1_thresh, 
                 monitor2_thresh=self.monitor2_thresh, verbose=self.verbose, return_study=True)
             print("Fitting and returning final model...")
         else:
-            print('Fitting model using the loaded best_params...')
-            
-        if self.epochs != 0:
+            if self.epochs != 0:
+                print(); print('Fitting model using the best_params, if the class attributes were not loaded ensure they have been enabled...')
+            else:
+                print(); print('The epochs parameter is zero, returning nothing...')
+                return 
+
+        if self.epochs == 0:
+
+            print(); print('The epochs parameter is zero, skipping final model training...')
+            return
+
+        else:
 
             clear_session()
 
             if self.opt_aug:
                 if self.img_num_channels == 1:
                     channel1, channel2, channel3 = copy.deepcopy(self.positive_class), None, None 
                 elif self.img_num_channels == 2:
@@ -297,21 +363,24 @@
                     max_pix.append(self.best_params['max_pixel_1']) if self.img_num_channels >= 1 else None
                     max_pix.append(self.best_params['max_pixel_2']) if self.img_num_channels >= 2 else None
                     max_pix.append(self.best_params['max_pixel_3']) if self.img_num_channels == 3 else None
                     self.max_pixel = max_pix; print('Setting max_pixel attribute to the tuned value(s)...')
                 else:
                     min_pix, max_pix = self.min_pixel, self.max_pixel
 
-                horizontal = vertical = rotation = True 
                 blend_multiplier = self.best_params['blend_multiplier'] if self.blend_max >= 1.1 else 0
                 skew_angle = self.best_params['skew_angle'] if self.skew_angle > 0 else 0
+                mask_size = self.best_params['mask_size'] if isinstance(self.mask_size, tuple) else self.mask_size
+                num_masks = self.best_params['num_masks'] if isinstance(self.num_masks, tuple) else self.num_masks
+
+                print(); print('======= Image Parameters ======'); print(); print('Num Augmentations :', self.best_params['num_aug']); print('Image Size : ', self.best_params['image_size']); print('Max Pixel(s) :', max_pix); print('Num Masks :', num_masks); print('Mask Size :', mask_size); print('Blend Multiplier :', blend_multiplier); print('Skew Angle :', skew_angle)
 
                 augmented_images = augmentation(channel1=channel1, channel2=channel2, channel3=channel3, batch=self.best_params['num_aug'], 
-                    width_shift=self.shift, height_shift=self.shift, horizontal=horizontal, vertical=vertical, rotation=rotation, 
-                    image_size=self.best_params['image_size'], mask_size=self.mask_size, num_masks=self.num_masks, blend_multiplier=blend_multiplier, 
+                    width_shift=self.shift, height_shift=self.shift, horizontal=self.horizontal, vertical=self.vertical, rotation=self.rotation, 
+                    image_size=self.best_params['image_size'], mask_size=mask_size, num_masks=num_masks, blend_multiplier=blend_multiplier, 
                     blending_func=self.blending_func, num_images_to_blend=self.num_images_to_blend, zoom_range=self.zoom_range, skew_angle=skew_angle)
 
                 #The augmentation routine returns an output for each filter, e.g. 3 outputs for RGB
                 if self.img_num_channels > 1:
                     class_1=[]
                     if self.img_num_channels == 2:
                         for i in range(len(augmented_images[0])):
@@ -328,16 +397,16 @@
                     channel1, channel2, channel3 = copy.deepcopy(self.negative_class), None, None 
                 elif self.img_num_channels == 2:
                     channel1, channel2, channel3 = copy.deepcopy(self.negative_class[:,:,:,0]), copy.deepcopy(self.negative_class[:,:,:,1]), None 
                 elif self.img_num_channels == 3:
                     channel1, channel2, channel3 = copy.deepcopy(self.negative_class[:,:,:,0]), copy.deepcopy(self.negative_class[:,:,:,1]), copy.deepcopy(self.negative_class[:,:,:,2])
                 
                 augmented_images_negative = augmentation(channel1=channel1, channel2=channel2, channel3=channel3, batch=self.batch_other, 
-                    width_shift=self.shift, height_shift=self.shift, horizontal=horizontal, vertical=vertical, rotation=rotation, 
-                    image_size=self.best_params['image_size'], mask_size=self.mask_size, num_masks=self.num_masks, blend_multiplier=self.blend_other, 
+                    width_shift=self.shift, height_shift=self.shift, horizontal=self.horizontal, vertical=self.vertical, rotation=self.rotation, 
+                    image_size=self.best_params['image_size'], mask_size=mask_size, num_masks=num_masks, blend_multiplier=self.blend_other, 
                     blending_func=self.blending_func, num_images_to_blend=self.num_images_to_blend, zoom_range=self.zoom_range, skew_angle=skew_angle)
                 
                 #The augmentation routine returns an output for each filter, e.g. 3 outputs for RGB
                 if self.img_num_channels > 1:
                     class_2=[]
                     if self.img_num_channels == 2:
                         for i in range(len(augmented_images_negative[0])):
@@ -412,24 +481,27 @@
             #Inverse time decay is set to 0, optimizzing beta and rho parameters instead.
             if optimizer == 'sgd':
                 momentum = self.best_params['momentum']
                 nesterov = self.best_params['nesterov']
                 beta_1 = beta_2 = 0; amsgrad = False
             elif optimizer == 'adam' or optimizer == 'adamax' or optimizer == 'nadam':
                 beta_1 = self.best_params['beta_1']
-                beta_2 = self.best_params['beta_1']
+                beta_2 = self.best_params['beta_2']
                 amsgrad = self.best_params['amsgrad'] if optimizer == 'adam' else False
                 momentum, nesterov = 0.0, False
             elif optimizer == 'adadelta' or optimizer == 'rmsprop':
                 rho = self.best_params['rho']
                 momentum = beta_1 = beta_2 = 0; nesterov = amsgrad = False
 
+            if self.opt_cv is not None and self.verbose == 1:
+                    print(); print('***********  CV - 1 ***********'); print()
+
             if self.opt_model:
                 #If opt_model=True, the optimization routine will tune the model regularizer and the pooling types
-                #If limit_search=False, the layer parameters (filters, pool sizes, etc) will be tuned as well (might crash machine!)
+                #If limit_search=False, the layer parameters (filters, pool sizes, etc) will be tuned as well (might crash machine due to memory allocation error!)
                 if self.clf == 'alexnet':
                     if self.limit_search:
                         self.model, self.history = AlexNet(class_1, class_2, img_num_channels=self.img_num_channels, 
                             normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
                             epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
                             beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, loss=self.best_params['loss'], activation_conv=self.best_params['activation_conv'], 
                             activation_dense=self.best_params['activation_dense'], conv_init=self.best_params['conv_init'], dense_init=self.best_params['dense_init'], 
@@ -550,19 +622,321 @@
                         smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
                 elif self.clf == 'resnet18':
                     self.model, self.history = Resnet18(class_1, class_2, img_num_channels=self.img_num_channels, normalize=self.normalize,
                         min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, epochs=self.epochs,
                         batch_size=batch_size, optimizer=optimizer, lr=lr, momentum=momentum, decay=decay, nesterov=nesterov, 
                         smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
         
-        print('Complete! To save the final model and optimization results, use save().') 
-        if overwrite_training:
-            self.positive_class, self.negative_class, self.val_positive, self.val_negative = class_1, class_2, val_class_1, val_class_2
+            #################################
 
-        return
+            ##### Cross-Validation Routine - implementation in which the validation data is inserted into the training data with the replacement serving as the new validation#####
+            if self.opt_cv is not None:
+
+                models, histories = [], [] #Will be used to append additional models, it opt_cv is enabled
+
+                models.append(self.model); histories.append(self.history) #Appending the already created first model & history
+
+                if self.val_positive is None and self.val_negative is None:
+                    raise ValueError('CNN cross-validation is only supported if validation data is input.')
+                if self.val_positive is not None:
+                    if len(self.positive_class) / len(self.val_positive) < self.opt_cv-1:
+                        raise ValueError('Cannot evenly partition the positive training/validation data, refer to the MicroLIA API documentation for instructions on how to use the opt_cv parameter.')
+                if self.val_negative is not None:
+                    if len(self.negative_class) / len(self.val_negative) < self.opt_cv-1:
+                        raise ValueError('Cannot evenly partition the negative training/validation data, refer to the MicroLIA API documentation for instructions on how to use the opt_cv parameter.')
+                
+                #The first model (therefore the first "fold") already ran, therefore sutbract 1      
+                for k in range(self.opt_cv-1):        
+
+                    #Make deep copies to avoid overwriting arrays
+                    class_1, class_2 = copy.deepcopy(self.positive_class), copy.deepcopy(self.negative_class)
+                    val_class_1, val_class_2 = copy.deepcopy(self.val_positive), copy.deepcopy(self.val_negative)
+
+                    #Sort the new data samples, no random shuffling, just a linear sequence
+                    if val_class_1 is not None:
+                        val_hold_1 = copy.deepcopy(class_1[k*len(val_class_1):len(val_class_1)*(k+1)]) #The new positive validation data
+                        class_1[k*len(val_class_1):len(val_class_1)*(k+1)] = copy.deepcopy(val_class_1) #The new class_1, copying to avoid linkage between arrays
+                        val_class_1 = val_hold_1 
+                    if val_class_2 is not None:
+                        val_hold_2 = copy.deepcopy(class_2[k*len(val_class_2):len(val_class_2)*(k+1)]) #The new validation data
+                        class_2[k*len(val_class_2):len(val_class_2)*(k+1)] = copy.deepcopy(val_class_2) #The new class_2, copying to avoid linkage between arrays
+                        val_class_2 = val_hold_2 
+
+                    if self.opt_aug:
+                        if self.img_num_channels == 1:
+                            channel1, channel2, channel3 = copy.deepcopy(class_1), None, None 
+                        elif self.img_num_channels == 2:
+                            channel1, channel2, channel3 = copy.deepcopy(class_1[:,:,:,0]), copy.deepcopy(class_1[:,:,:,1]), None 
+                        else:
+                            channel1, channel2, channel3 = copy.deepcopy(class_1[:,:,:,0]), copy.deepcopy(class_1[:,:,:,1]), copy.deepcopy(class_1[:,:,:,2])
+
+                        augmented_images = augmentation(channel1=channel1, channel2=channel2, channel3=channel3, batch=self.best_params['num_aug'], 
+                            width_shift=self.shift, height_shift=self.shift, horizontal=self.horizontal, vertical=self.vertical, rotation=self.rotation, 
+                            image_size=self.best_params['image_size'], mask_size=mask_size, num_masks=num_masks, blend_multiplier=blend_multiplier, 
+                            blending_func=self.blending_func, num_images_to_blend=self.num_images_to_blend, zoom_range=self.zoom_range, skew_angle=skew_angle)
+
+                        if self.img_num_channels > 1:
+                            class_1=[]
+                            if self.img_num_channels == 2:
+                                for i in range(len(augmented_images[0])):
+                                    class_1.append(concat_channels(augmented_images[0][i], augmented_images[1][i]))
+                            else:
+                                for i in range(len(augmented_images[0])):
+                                    class_1.append(concat_channels(augmented_images[0][i], augmented_images[1][i], augmented_images[2][i]))
+                            class_1 = np.array(class_1)
+                        else:
+                            class_1 = augmented_images
+
+                        #Perform same augmentation techniques on negative class data, batch_other=1 by default
+                        if self.img_num_channels == 1:
+                            channel1, channel2, channel3 = copy.deepcopy(class_2), None, None 
+                        elif self.img_num_channels == 2:
+                            channel1, channel2, channel3 = copy.deepcopy(class_2[:,:,:,0]), copy.deepcopy(class_2[:,:,:,1]), None 
+                        elif self.img_num_channels == 3:
+                            channel1, channel2, channel3 = copy.deepcopy(class_2[:,:,:,0]), copy.deepcopy(class_2[:,:,:,1]), copy.deepcopy(class_2[:,:,:,2])
+                        
+                        augmented_images_negative = augmentation(channel1=channel1, channel2=channel2, channel3=channel3, batch=self.batch_other, 
+                            width_shift=self.shift, height_shift=self.shift, horizontal=self.horizontal, vertical=self.vertical, rotation=self.rotation, 
+                            image_size=self.best_params['image_size'], mask_size=mask_size, num_masks=num_masks, blend_multiplier=self.blend_other, 
+                            blending_func=self.blending_func, num_images_to_blend=self.num_images_to_blend, zoom_range=self.zoom_range, skew_angle=skew_angle)
+
+                        #The augmentation routine returns an output for each filter, e.g. 3 outputs for RGB
+                        if self.img_num_channels > 1:
+                            class_2=[]
+                            if self.img_num_channels == 2:
+                                for i in range(len(augmented_images_negative[0])):
+                                    class_2.append(concat_channels(augmented_images_negative[0][i], augmented_images_negative[1][i]))
+                            else:
+                                for i in range(len(augmented_images_negative[0])):
+                                    class_2.append(concat_channels(augmented_images_negative[0][i], augmented_images_negative[1][i], augmented_images_negative[2][i]))
+                            class_2 = np.array(class_2)
+                        else:
+                            class_2 = augmented_images_negative
+
+                        #Balance the class sizes if necessary
+                        if self.balance:
+                            if self.batch_other > 1: #Must shuffle!!!
+                                ix = np.random.permutation(len(class_2))
+                                class_2 = class_2[ix]
+                            class_2 = class_2[:len(class_1)]   
+
+                        if self.img_num_channels == 1:
+                            class_2 = resize(class_2, size=self.best_params['image_size'])
+                        else:
+                            channel1 = resize(class_2[:,:,:,0], size=self.best_params['image_size'])
+                            channel2 = resize(class_2[:,:,:,1], size=self.best_params['image_size'])
+                            if self.img_num_channels == 2:
+                                class_2 = concat_channels(channel1, channel2)
+                            else:
+                                channel3 = resize(class_2[:,:,:,2], size=self.best_params['image_size'])
+                                class_2 = concat_channels(channel1, channel2, channel3)
+
+                        if val_class_1 is not None:
+                            if self.img_num_channels == 1:
+                                val_class_1 = resize(val_class_1, size=self.best_params['image_size'])
+                            else:
+                                val_channel1 = resize(val_class_1[:,:,:,0], size=self.best_params['image_size'])
+                                val_channel2 = resize(val_class_1[:,:,:,1], size=self.best_params['image_size'])
+                                if self.img_num_channels == 2:
+                                    val_class_1 = concat_channels(val_channel1, val_channel2)
+                                else:
+                                    val_channel3 = resize(val_class_1[:,:,:,2], size=self.best_params['image_size'])
+                                    val_class_1 = concat_channels(val_channel1, val_channel2, val_channel3)
+
+                        if val_class_2 is not None:
+                            if self.img_num_channels == 1:
+                                val_class_2 = resize(val_class_2, size=self.best_params['image_size'])
+                            elif self.img_num_channels > 1:
+                                val_channel1 = resize(val_class_2[:,:,:,0], size=self.best_params['image_size'])
+                                val_channel2 = resize(val_class_2[:,:,:,1], size=self.best_params['image_size'])
+                                if self.img_num_channels == 2:
+                                    val_class_2 = concat_channels(val_channel1, val_channel2)
+                                else:
+                                    val_channel3 = resize(val_class_2[:,:,:,2], size=self.best_params['image_size'])
+                                    val_class_2 = concat_channels(val_channel1, val_channel2, val_channel3)
+
+                    if self.verbose == 1:
+                        print(); print('***********  CV - {} ***********'.format(k+2)); print()
+
+                    clear_session()
+
+                    if self.opt_model is False:
+                        if self.clf == 'alexnet':
+                            model, history = AlexNet(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, 
+                                checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+                        elif self.clf == 'custom_cnn':
+                            model, history = custom_model(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, 
+                                checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+                        elif self.clf == 'vgg16':
+                            model, history = VGG16(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, 
+                                checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+                        elif self.clf == 'resnet18':
+                            model, history = Resnet18(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, 
+                                checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+                    else:
+                        if self.clf == 'alexnet':
+                            if self.limit_search:
+                                model, history = AlexNet(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                    normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                    epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                    beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, loss=self.best_params['loss'], activation_conv=self.best_params['activation_conv'], 
+                                    activation_dense=self.best_params['activation_dense'], conv_init=self.best_params['conv_init'], dense_init=self.best_params['dense_init'], 
+                                    model_reg=self.best_params['model_reg'], pooling_1=self.best_params['pooling_1'], pooling_2=self.best_params['pooling_2'], pooling_3=self.best_params['pooling_3'], 
+                                    smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+                            else:
+                                model, history = AlexNet(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                    normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                    epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                    beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, loss=self.best_params['loss'], activation_conv=self.best_params['activation_conv'], 
+                                    activation_dense=self.best_params['activation_dense'], conv_init=self.best_params['conv_init'], dense_init=self.best_params['dense_init'], model_reg=self.best_params['model_reg'], 
+                                    filter_1=self.best_params['filter_1'], filter_size_1=self.best_params['filter_size_1'], strides_1=self.best_params['strides_1'], pooling_1=self.best_params['pooling_1'], pool_size_1=self.best_params['pool_size_1'], pool_stride_1=self.best_params['pool_stride_1'],
+                                    filter_2=self.best_params['filter_2'], filter_size_2=self.best_params['filter_size_2'], strides_2=self.best_params['strides_2'], pooling_2=self.best_params['pooling_2'], pool_size_2=self.best_params['pool_size_2'], pool_stride_2=self.best_params['pool_stride_2'],
+                                    filter_3=self.best_params['filter_3'], filter_size_3=self.best_params['filter_size_3'], strides_3=self.best_params['strides_3'], pooling_3=self.best_params['pooling_3'], pool_size_3=self.best_params['pool_size_3'], pool_stride_3=self.best_params['pool_stride_3'], 
+                                    filter_4=self.best_params['filter_4'], filter_size_4=self.best_params['filter_size_4'], strides_4=self.best_params['strides_4'], 
+                                    filter_5=self.best_params['filter_5'], filter_size_5=self.best_params['filter_size_5'], strides_5=self.best_params['strides_5'], 
+                                    dense_neurons_1=self.best_params['dense_neurons_1'], dense_neurons_2=self.best_params['dense_neurons_2'], dropout_1=self.best_params['dropout_1'], dropout_2=self.best_params['dropout_2'],
+                                    smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+
+                        elif self.clf == 'resnet18':
+                            if self.limit_search:
+                                model, history = Resnet18(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                    normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                    epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                    beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, loss=self.best_params['loss'], activation_conv=self.best_params['activation_conv'], 
+                                    activation_dense=self.best_params['activation_dense'], conv_init=self.best_params['conv_init'], dense_init=self.best_params['dense_init'], 
+                                    model_reg=self.best_params['model_reg'], pooling=self.best_params['pooling'],
+                                    smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+                            else:
+                                model, history = Resnet18(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                    normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                    epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                    beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, loss=self.best_params['loss'], activation_conv=self.best_params['activation_conv'], 
+                                    activation_dense=self.best_params['activation_dense'], conv_init=self.best_params['conv_init'], dense_init=self.best_params['dense_init'], 
+                                    model_reg=self.best_params['model_reg'], filters=self.best_params['filters'], filter_size=self.best_params['filter_size'], strides=self.best_params['strides'],  
+                                    pooling=self.best_params['pooling'], pool_size=self.best_params['pool_size'], pool_stride=self.best_params['pool_stride'], block_filters_1=self.best_params['block_filters_1'], 
+                                    block_filters_2=self.best_params['block_filters_2'], block_filters_3=self.best_params['block_filters_3'], block_filters_4=self.best_params['block_filters_4'], 
+                                    block_filters_size=self.best_params['block_filters_size'], smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+                        
+                        elif self.clf == 'vgg16':
+                            if self.limit_search:
+                                model, history = VGG16(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                    normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                    epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                    beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, loss=self.best_params['loss'], activation_conv=self.best_params['activation_conv'], 
+                                    activation_dense=self.best_params['activation_dense'], conv_init=self.best_params['conv_init'], dense_init=self.best_params['dense_init'], 
+                                    model_reg=self.best_params['model_reg'], pooling_1=self.best_params['pooling_1'], pooling_2=self.best_params['pooling_2'], pooling_3=self.best_params['pooling_3'], 
+                                    pooling_4=self.best_params['pooling_4'], pooling_5=self.best_params['pooling_5'], smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+                            else:
+                                model, history = VGG16(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                    normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                    epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                    beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, loss=self.best_params['loss'], activation_conv=self.best_params['activation_conv'], 
+                                    activation_dense=self.best_params['activation_dense'], conv_init=self.best_params['conv_init'], dense_init=self.best_params['dense_init'], model_reg=self.best_params['model_reg'],                 
+                                    filter_1=self.best_params['filter_1'], filter_size_1=self.best_params['filter_size_1'], strides_1=self.best_params['strides_1'], pooling_1=self.best_params['pooling_1'], pool_size_1=self.best_params['pool_size_1'], pool_stride_1=self.best_params['pool_stride_1'],
+                                    filter_2=self.best_params['filter_2'], filter_size_2=self.best_params['filter_size_2'], strides_2=self.best_params['strides_2'], pooling_2=self.best_params['pooling_2'], pool_size_2=self.best_params['pool_size_2'], pool_stride_2=self.best_params['pool_stride_2'],
+                                    filter_3=self.best_params['filter_3'], filter_size_3=self.best_params['filter_size_3'], strides_3=self.best_params['strides_3'], pooling_3=self.best_params['pooling_3'], pool_size_3=self.best_params['pool_size_3'], pool_stride_3=self.best_params['pool_stride_3'],
+                                    filter_4=self.best_params['filter_4'], filter_size_4=self.best_params['filter_size_4'], strides_4=self.best_params['strides_4'], pooling_4=self.best_params['pooling_4'], pool_size_4=self.best_params['pool_size_4'], pool_stride_4=self.best_params['pool_stride_4'],
+                                    filter_5=self.best_params['filter_5'], filter_size_5=self.best_params['filter_size_5'], strides_5=self.best_params['strides_5'], pooling_5=self.best_params['pooling_5'], pool_size_5=self.best_params['pool_size_5'], pool_stride_5=self.best_params['pool_stride_5'],
+                                    dense_neurons_1=self.best_params['dense_neurons_1'], dense_neurons_2=self.best_params['dense_neurons_2'], dropout_1=self.best_params['dropout_1'], dropout_2=self.best_params['dropout_2'],
+                                    smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+                        
+                        elif self.clf == 'custom_cnn':
+                            #Need to extract the second and third layers manually 
+                            #Conv2D and Pooling Layers
+                            strides_1 = pool_stride_1 = 1 
+                            if self.best_params['num_conv_layers'] == 1:
+                                filter_2 = filter_size_2 = strides_2 = pool_size_2 = pool_stride_2 = filter_3 = filter_size_3 = strides_3 = pool_size_3 = pool_stride_3 = 0; pooling_2 = pooling_3 = None
+                            if self.best_params['num_conv_layers'] >= 2:
+                                filter_2 = self.best_params['filter_2']
+                                filter_size_2 = self.best_params['filter_size_2'] 
+                                pooling_2 = self.best_params['pooling_2']
+                                pool_size_2 = self.best_params['pool_size_2']
+                                strides_2 = pool_stride_2 = 1; filter_3 = filter_size_3 = strides_3 = pool_size_3 = pool_stride_3 = 0; pooling_3 = None
+                            if self.best_params['num_conv_layers'] == 3:
+                                filter_3 = self.best_params['filter_3']
+                                filter_size_3 = self.best_params['filter_size_3']
+                                pooling_3 = self.best_params['pooling_3']
+                                pool_size_3 = self.best_params['pool_size_3']
+                                strides_3 = pool_stride_3 = 1
+                            #Dense Layers
+                            if self.best_params['num_dense_layers'] == 1:
+                                dense_neurons_2 = dropout_2 = dense_neurons_3 = dropout_3 = 0
+                            if self.best_params['num_dense_layers'] >= 2:
+                                dense_neurons_2 = self.best_params['dense_neurons_2']
+                                dropout_2 = self.best_params['dropout_2'] 
+                                dense_neurons_3 = dropout_3 = 0
+                            if self.best_params['num_dense_layers'] == 3:
+                                dense_neurons_3 =  self.best_params['dense_neurons_3']                         
+                                dropout_3 = self.best_params['dropout_3'] 
+
+                            model, history = custom_model(class_1, class_2, img_num_channels=self.img_num_channels, 
+                                normalize=self.normalize, min_pixel=min_pix, max_pixel=max_pix, val_positive=val_class_1, val_negative=val_class_2, 
+                                epochs=self.epochs, batch_size=batch_size, optimizer=optimizer, lr=lr, decay=decay, momentum=momentum, nesterov=nesterov, 
+                                beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad, loss=self.best_params['loss'], activation_conv=self.best_params['activation_conv'], 
+                                activation_dense=self.best_params['activation_dense'], conv_init=self.best_params['conv_init'], dense_init=self.best_params['dense_init'], model_reg=self.best_params['model_reg'],
+                                filter_1=self.best_params['filter_1'], filter_size_1=self.best_params['filter_size_1'], strides_1=strides_1, pooling_1=self.best_params['pooling_1'], pool_size_1=self.best_params['pool_size_1'], pool_stride_1=pool_stride_1, 
+                                filter_2=filter_2, filter_size_2=filter_size_2, strides_2=strides_2, pooling_2=pooling_2, pool_size_2=pool_size_2, pool_stride_2=pool_stride_2, 
+                                filter_3=filter_3, filter_size_3=filter_size_3, strides_3=strides_3, pooling_3=pooling_3, pool_size_3=pool_size_3, pool_stride_3=pool_stride_3, 
+                                dense_neurons_1=self.best_params['dense_neurons_1'], dense_neurons_2=dense_neurons_2, dense_neurons_3=dense_neurons_3, 
+                                dropout_1=self.best_params['dropout_1'], dropout_2=dropout_2, dropout_3=dropout_3, 
+                                smote_sampling=self.smote_sampling, patience=self.patience, metric=self.metric, checkpoint=False, verbose=self.verbose, save_training_data=save_training, path=self.path)
+
+                    models.append(model), histories.append(history)
+
+                    try:
+                        if np.isfinite(history.history['loss'][-1]) is False:
+                            print(); print(f"NOTE: Training failed during fold {k} due to numerical instability!")
+                    except Exception as e:    
+                        print(); print(f"ERROR: Training failed during fold {k} due to error: {e}!")
+                        return
+
+            #################################
+
+            if self.opt_cv is None:
+                self.model_train_metrics = np.c_[self.history.history['binary_accuracy'], self.history.history['loss'], self.history.history['f1_score']]
+                if self.val_positive is not None:
+                    self.model_val_metrics = np.c_[self.history.history['val_binary_accuracy'], self.history.history['val_loss'], self.history.history['val_f1_score']]
+                print('Complete! To save the final model and optimization results, call the save() method.') 
+            else:
+                self.model, self.history = models, histories
+                self.model_train_metrics = [] 
+                for i in range(100): #If more than 100 CVs then this will break 
+                    try:
+                        model_train_metrics = np.c_[self.history[i].history['binary_accuracy'], self.history[i].history['loss'], self.history[i].history['f1_score']]
+                        self.model_train_metrics.append(model_train_metrics)
+                    except:
+                        break
+
+                if self.val_positive is not None:
+                    self.model_val_metrics = []
+                    for i in range(100): #If more than 100 CVs then this will break 
+                        try:
+                            model_val_metrics = np.c_[self.history[i].history['val_binary_accuracy'], self.history[i].history['val_loss'], self.history[i].history['val_f1_score']]
+                            self.model_val_metrics.append(model_val_metrics)
+                        except:
+                            break
+
+                print('Complete!'); print('NOTE: Cross-validation was enabled, therefore the model and history class attribute are lists containing all. To save, call the save() method.') 
+
+            if overwrite_training:
+                self.positive_class, self.negative_class, self.val_positive, self.val_negative = class_1, class_2, val_class_1, val_class_2
+
+            return
 
     def save(self, dirname=None, overwrite=False):
         """
         Saves the trained classifier in a new directory named 'MicroLIA_models', 
         as well as the imputer and the features to use, if applicable.
         
         Args:
@@ -601,19 +975,26 @@
                     os.rmdir(path+'MicroLIA_cnn_model')
                 os.mkdir(path+'MicroLIA_cnn_model')
             else:
                 raise ValueError('Tried to create "MicroLIA_cnn_model" directory in specified path but folder already exists! If you wish to overwrite set overwrite=True.')
         
         path += 'MicroLIA_cnn_model/'
         if self.model is not None:
-            save_model(self.model, path+'Keras_Model.h5')#,  custom_objects={'f1_score': f1_score})
-            np.savetxt(path+'model_train_metrics', np.c_[self.history.history['binary_accuracy'], self.history.history['loss'], self.history.history['f1_score']], header='binary_accuracy\tloss\tf1_score')
-            if self.val_positive is not None:
-                np.savetxt(path+'model_val_metrics', np.c_[self.history.history['val_binary_accuracy'], self.history.history['val_loss'], self.history.history['val_f1_score']], header='val_binary_accuracy\tval_loss\tval_f1_score')
-            
+            if isinstance(self.model, list) is False:
+                save_model(self.model, path+'Keras_Model.h5')#,  custom_objects={'f1_score': f1_score})
+                np.savetxt(path+'model_train_metrics', np.c_[self.history.history['binary_accuracy'], self.history.history['loss'], self.history.history['f1_score']], header='binary_accuracy\tloss\tf1_score')
+                if self.val_positive is not None:
+                    np.savetxt(path+'model_val_metrics', np.c_[self.history.history['val_binary_accuracy'], self.history.history['val_loss'], self.history.history['val_f1_score']], header='val_binary_accuracy\tval_loss\tval_f1_score')
+            else:
+                for counter in range(len(self.model)):
+                    save_model(self.model[counter], path+'Keras_Model_CV_'+str(counter+1)+'.h5')#,  custom_objects={'f1_score': f1_score})
+                    np.savetxt(path+'model_train_metrics_CV_'+str(counter+1), np.c_[self.history[counter].history['binary_accuracy'], self.history[counter].history['loss'], self.history[counter].history['f1_score']], header='binary_accuracy\tloss\tf1_score')
+                    if self.val_positive is not None:
+                        np.savetxt(path+'model_val_metrics_CV_'+str(counter+1), np.c_[self.history[counter].history['val_binary_accuracy'], self.history[counter].history['val_loss'], self.history[counter].history['val_f1_score']], header='val_binary_accuracy\tval_loss\tval_f1_score')
+
         if self.best_params is not None:
             joblib.dump(self.best_params, path+'Best_Params')
         if self.optimization_results is not None:
             joblib.dump(self.optimization_results, path+'HyperOpt_Results')
 
         try:
             #Save all class attributes except the ones that are generated during the routine, as these are saved above
@@ -646,55 +1027,105 @@
         """
 
         path = str(Path.home()) if path is None else path
         path += '/' if path[-1] != '/' else ''
         path += 'MicroLIA_cnn_model/'
 
         try:
+            attrs_dict = joblib.load(path + 'class_attributes.pkl')
+            for attr, value in attrs_dict.items():
+                setattr(self, attr, value)
+            class_attributes = ', class_attributes'
+        except:
+            class_attributes = ''
+
+        try:
             self.model = load_model(path+'Keras_Model.h5', compile=False) #custom_objects={'f1_score': f1_score, 'loss': loss})
             model = 'model'
         except:
-            print('Could not load model!')
-            model = ''
-                
+            try:
+                self.model = []
+                for i in range(1, 101): #If more than 100 CVs then this will break 
+                    try:
+                        model = load_model(path+'Keras_Model_CV_'+str(i)+'.h5', compile=False) #custom_objects={'f1_score': f1_score, 'loss': loss})
+                        self.model.append(model)
+                    except:
+                        break
+
+                if len(self.model) >= 1:
+                    model = 'models'
+                else:
+                    print('Could not load models!')
+                    model = ''
+            except:
+                print('Could not load model!')
+                model = ''
+
         try:
             self.model_train_metrics = np.loadtxt(path+'model_train_metrics')
             train_metrics = ', training_history'
         except:
-            print('Could not load training history!')
-            train_metrics = ''
+            try:
+                self.model_train_metrics = [] 
+                for i in range(1, 101): #If more than 100 CVs then this will break 
+                    try:
+                        model_train_metrics = np.loadtxt(path+'model_train_metrics_CV_'+str(i)) 
+                        self.model_train_metrics.append(model_train_metrics)
+                    except:
+                        continue
+
+                if len(self.model_train_metrics) >= 1:
+                    train_metrics = ', training_histories'
+                else:
+                    print('Could not load training histories!')
+                    train_metrics = ''
+            except:
+                print('Could not load training history!')
+                train_metrics = ''
 
         try:
             self.model_val_metrics = np.loadtxt(path+'model_val_metrics')
             val_metrics = ', val_training_history'
         except:
-            val_metrics = ''
+            try:
+                self.model_val_metrics = []
+                for i in range(1, 101): #If more than 100 CVs then this will break 
+                    try:
+                        model_val_metrics = np.loadtxt(path+'model_val_metrics_CV_'+str(i)) 
+                        self.model_val_metrics.append(model_val_metrics)
+                    except:
+                        continue
+
+                if len(self.model_val_metrics) >= 1:
+                    val_metrics = ', val_training_histories'
+                else:
+                    print('Could not load validation training histories!')
+                    val_metrics = ''
+            except:
+                print('Could not load training history!')
+                val_metrics = ''
 
         try:
             self.optimization_results = joblib.load(path+'HyperOpt_Results')
             optimization_results = ', optimization_results'
         except:
             optimization_results = '' 
 
         try:
             self.best_params = joblib.load(path+'Best_Params')
             best_params = ', best_params'
         except:
             best_params = '' 
 
-        try:
-            attrs_dict = joblib.load(path + 'class_attributes.pkl')
-            for attr, value in attrs_dict.items():
-                setattr(self, attr, value)
-            class_attributes = ', class_attributes'
-        except:
-            class_attributes = ''
-
         if load_training_data:
-            print('IMPORTANT: If re-creating a model, set opt_aug=False and normalize=False if applicable to avoid re-augmenting and re-normalizing the loaded data!')
+            if self.opt_cv is None:
+                print('IMPORTANT: If re-creating the model with loaded data, set opt_aug=False and normalize=False to avoid re-augmenting and re-normalizing the loaded data!')
+            else:
+                print('IMPORTANT: If re-creating the model with loaded data, set opt_aug=False and normalize=False to avoid re-augmenting and re-normalizing the loaded data! Also, set opt_cv=None if the training data has been augmented!')
+            
             try:
                 self.positive_class = np.load(path+'class_1.npy')
                 positive_class = ', positive_class'
             except:
                 positive_class = ''
 
             try:
@@ -716,61 +1147,98 @@
                 val_negative = ''
 
             print('Successfully loaded the following: {}{}{}{}{}{}{}{}{}{}'.format(model, train_metrics, val_metrics, optimization_results, best_params, class_attributes, positive_class, negative_class, val_positive, val_negative))
         else:
             print('Successfully loaded the following: {}{}{}{}{}{}'.format(model, train_metrics, val_metrics, optimization_results, best_params, class_attributes))
 
         self.path = path
-        
+
         return
 
-    def predict(self, data, target='LENS', return_proba=False):
+    def predict(self, data, target='ML', return_proba=False, cv_model=0):
         """
         Returns the class prediction. The input can either be a single 2D array 
         or a 3D array if there are multiple samples.
 
         Args:
             data: 2D array for single image, 3D array for multiple images.
             target (str): The name of the target class, assuming binary classification in 
                 which there is an 'OTHER' class. Defaults to 'ML'. 
             return_proba (bool): If True the output will return the probability prediction.
                 Defaults to False. 
+            cv_model (int): Index of the model to use. Only applicable if the model class
+                attribute is a list containing multiple models due to cross-validation.
+                Defaults to 0, the first model in the list. Can be set to 'all', in which case
+                all models will be used and an averaged prediction will be output.
 
         Returns:
             The class prediction(s).
         """
-        
+
         data = process_class(data, normalize=self.normalize, min_pixel=self.min_pixel, max_pixel=self.max_pixel, img_num_channels=self.img_num_channels)
         if self.normalize:
             data[data > 1] = 1; data[data < 0] = 0
 
-        image_size = self.model.layers[0].input_shape[1:][0]
+        model = self.model[0] if isinstance(self.model, list) else self.model 
+        image_size = model.layers[0].input_shape[1:][0]
+
         if data.shape[1] != image_size:
             if data.shape[1] < image_size:
                 raise ValueError('Model requires images of size {}, but the input images are size {}!'.format(image_size, data.shape[1]))
             print('Incorrect image size, the model requires size {}, resizing...'.format(image_size))
             data = resize(data, image_size)
     
-        predictions = self.model.predict(data)
 
-        output, probas = [], [] 
-        for i in range(len(predictions)):
-            if np.argmax(predictions[i]) == 1:
-                prediction = target
-                probas.append(predictions[i][1])
-            else:
-                prediction = 'OTHER'
-                probas.append(predictions[i][0])
+        if isinstance(self.model, list) is False or isinstance(cv_model, int):
+
+            model = self.model[cv_model] if isinstance(self.model, list) else self.model
+            predictions = model.predict(data)
+
+            output, probas = [], [] 
+            for i in range(len(predictions)):
+                if np.argmax(predictions[i]) == 1:
+                    prediction = target
+                    probas.append(predictions[i][1])
+                else:
+                    prediction = 'OTHER'
+                    probas.append(predictions[i][0])
+                output.append(prediction)
+
+            output = np.c_[output, probas] if return_proba else np.array(output)
+            
+        else: #cv_model='all' 
 
-            output.append(prediction)
+            model_outputs, model_probas = [], []
+            for __model__ in self.model:
+
+                predictions = __model__.predict(data)
+
+                output, probas = [], []                 
+                for i in range(len(predictions)):
+                    if np.argmax(predictions[i]) == 1:
+                        prediction = target
+                        probas.append(predictions[i][1])
+                    else:
+                        prediction = 'OTHER'
+                        probas.append(predictions[i][0])
+                    output.append(prediction)
 
-        if return_proba:
-            output = np.c_[output, probas]
+                model_outputs.append(output); model_probas.append(probas)
+
+            average_output, average_proba = [], [] 
+            for j in range(len(model_outputs[0])):
+                column = [model_outputs[i][j] for i in range(len(model_outputs))]
+                avg_output = target if column.count(target) >= column.count('OTHER') else 'OTHER'
+                avg_proba = np.mean([model_probas[i][j] for i in range(len(model_probas))])
+
+                average_output.append(avg_output); average_proba.append(avg_proba)
+
+            output = np.c_[average_output, average_proba] if return_proba else np.array(average_output)
             
-        return np.array(output)
+        return output
 
     def augment_positive(self, batch=1, width_shift=0, height_shift=0, horizontal=False, vertical=False, 
         rotation=False, fill='nearest', image_size=None, zoom_range=None, mask_size=None, num_masks=None, 
         blend_multiplier=0, blending_func='mean', num_images_to_blend=2, skew_angle=0):
         """
         Method to augment the positive class, requires all manual inputs!
 
@@ -899,44 +1367,47 @@
             savefig (bool): If True the figure will not disply but will be saved instead.
                 Defaults to False. 
 
         Returns:
             AxesImage. 
         """
 
+        if not (hasattr(self, 'positive_class') and hasattr(self, 'negative_class')):
+            raise ValueError('The training data is missing! Make sure the positive_class and negative_class are input.')
+
         #Reshape if 3D array (single-band) -- need 4D array first.
         if len(self.positive_class.shape) == 3:
             positive_class = np.reshape(self.positive_class, (self.positive_class.shape[0], self.positive_class.shape[1], self.positive_class.shape[2], 1))
             negative_class = np.reshape(self.negative_class, (self.negative_class.shape[0], self.negative_class.shape[1], self.negative_class.shape[2], 1))
             data = np.r_[positive_class, negative_class]
-            data_y = np.r_[['LENS Train']*len(positive_class),['OTHER Train']*len(negative_class)]
+            data_y = np.r_[['ML Train']*len(positive_class),['OTHER Train']*len(negative_class)]
             if self.val_positive is not None:
                 val_positive = np.reshape(self.val_positive, (self.val_positive.shape[0], self.val_positive.shape[1], self.val_positive.shape[2], 1))
             if self.val_negative is not None:
                 val_negative = np.reshape(self.val_negative, (self.val_negative.shape[0], self.val_negative.shape[1], self.val_negative.shape[2], 1))
             if self.val_positive is not None and self.val_negative is not None:
                 val_data = np.r_[val_positive, val_negative]
-                val_data_y = np.r_[['LENS Val']*len(val_positive),['OTHER Val']*len(val_negative)]
+                val_data_y = np.r_[['ML Val']*len(val_positive),['OTHER Val']*len(val_negative)]
             elif self.val_positive is not None and self.val_negative is None:
                 val_data = val_positive
-                val_data_y = np.r_[['LENS Val']*len(val_data)]
+                val_data_y = np.r_[['ML Val']*len(val_data)]
             elif self.val_positive is None and self.val_negative is not None:
                 val_data = val_negative
                 val_data_y = np.r_[['OTHER Val']*len(val_data)]
             else:
                 val_data = val_data_y = None 
         else:
             data = np.r_[self.positive_class, self.negative_class]
-            data_y = np.r_[['LENS Train']*len(self.positive_class),['OTHER Train']*len(self.negative_class)]
+            data_y = np.r_[['ML Train']*len(self.positive_class),['OTHER Train']*len(self.negative_class)]
             if self.val_positive is not None and self.val_negative is not None:
                 val_data = np.r_[self.val_positive, self.val_negative]
-                val_data_y = np.r_[['LENS Val']*len(self.val_positive),['OTHER Val']*len(self.val_negative)]
+                val_data_y = np.r_[['ML Val']*len(self.val_positive),['OTHER Val']*len(self.val_negative)]
             elif self.val_positive is not None and self.val_negative is None:
                 val_data = self.val_positive
-                val_data_y = np.r_[['LENS Val']*len(val_data)]
+                val_data_y = np.r_[['ML Val']*len(val_data)]
             elif self.val_positive is None and self.val_negative is not None:
                 val_data = self.val_negative
                 val_data_y = np.r_[['OTHER Val']*len(val_data)]
             else:
                 val_data = val_data_y = None 
 
         if val_data is not None:
@@ -955,37 +1426,49 @@
             method = 'barnes_hut' #Scales with O(N)
         else:
             method = 'exact' #Scales with O(N^2)
         print(data_x.shape)
         feats = TSNE(n_components=2, method=method, learning_rate=1000, 
             perplexity=35, init='random').fit_transform(data_x)
         x, y = feats[:,0], feats[:,1]
-     
+
+        markers = ['o', 's', '+', 'v', '.', 'x', 'h', 'p', '<', '>', '*']
+        color = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628', '#f781bf']
+
+        feats = np.unique(data_y)
+
+        for count, feat in enumerate(feats):
+            marker = markers[count % len(markers)]  # Wrap around the markers list
+            color_val = color[count % len(color)]  # Wrap around the color list
+            mask = np.where(data_y == feat)[0]
+            plt.scatter(x[mask], y[mask], marker=marker, c=color_val, label=str(feat), alpha=0.44)
+        """
         markers = ['o', 's', '+', 'v', '.', 'x', 'h', 'p', '<', '>', '*']
         #color = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'b', 'g', 'r', 'c']
         color = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628', '#f781bf']
 
         feats = np.unique(data_y) 
 
         for count, feat in enumerate(feats):
             if count+1 > len(markers):
                 count = -1
             mask = np.where(data_y == feat)[0]
             plt.scatter(x[mask], y[mask], marker=markers[count], c=color[count], label=str(feat), alpha=0.44)
-
+        """
         plt.legend(loc=legend_loc, ncol=len(np.unique(data_y)), frameon=False, handlelength=2)#prop={'size': 14}
         plt.title(title)#, size=18)
         plt.xticks()#fontsize=14)
         plt.yticks()#fontsize=14)
         plt.ylabel('t-SNE Dimension 1')
         plt.xlabel('t-SNE Dimension 2')
 
         if savefig:
+            _set_style_()
             plt.savefig('Images_tSNE_Projection.png', bbox_inches='tight', dpi=300)
-            plt.clf()
+            plt.clf(); plt.style.use('default')
         else:
             plt.show()
 
     def plot_hyper_opt(self, baseline=None, xlim=None, ylim=None, xlog=True, ylog=False, 
         savefig=False):
         """
         Plots the hyperparameter optimization history.
@@ -1034,17 +1517,17 @@
 
         if baseline is not None:
             plt.axhline(y=baseline, color='k', linestyle='--', label='Baseline Model')
             ncol=3
         else:
             ncol=2
 
-        if self.metric == 'val_accuracy':
+        if self.metric == 'val_accuracy' or self.metric == 'val_binary_accuracy':
             ylabel = 'Validation Accuracy'
-        elif self.metric == 'accuracy':
+        elif self.metric == 'accuracy' or self.metric == 'acc':
             ylabel = 'Training Accuracy'
         elif self.metric == 'val_loss':
             ylabel = '1 - Validation Loss'
         elif self.metric == 'loss':
             ylabel = '1 - Training Loss'
         else:
             ylabel = 'Optimization Metric'
@@ -1067,16 +1550,17 @@
             plt.yscale('log')
         #plt.tight_layout()
         #plt.legend(prop={'size': 12}, loc='upper left')
         plt.legend(loc='upper center', ncol=ncol, frameon=False)#, handlelength=4)#prop={'size': 14}
         plt.rcParams['axes.facecolor']='white'
         
         if savefig:
+            _set_style_()
             plt.savefig('CNN_Hyperparameter_Optimization.png', bbox_inches='tight', dpi=300)
-            plt.clf()
+            plt.clf(); plt.style.use('default')
         else:
             plt.show()
 
     def plot_hyper_param_importance(self, plot_time=True, savefig=False):
         """
         Plots the hyperparameter optimization history.
     
@@ -1126,32 +1610,31 @@
         ax.set_xscale('log')
         plt.gca().invert_yaxis()
         plt.xlim((0, 1.))#np.max(importance+duration_importance)))#np.max(importance+duration_importance)))
         #fig = plot_param_importances(self.optimization_results)
         #fig = plot_param_importances(self.optimization_results, target=lambda t: t.duration.total_seconds(), target_name="duration")
         #plt.tight_layout()
         if savefig:
+            _set_style_()
             if plot_time:
                 plt.savefig('CNN_Hyperparameter_Importance.png', bbox_inches='tight', dpi=300)
             else:
                 plt.savefig('CNN_Hyperparameter_Duration_Importance.png', bbox_inches='tight', dpi=300)
-            plt.clf()
+            plt.clf(); plt.style.use('default')
         else:
             plt.show()
 
     def save_hyper_importance(self):
         """
-        Calculates and saves binary files containing
-        dictionaries with importance information, one
+        Calculates and saves binary files containing dictionaries with importance information, one
         for the importance and one for the duration importance
 
         Note:
-            This procedure is time-consuming but must be run once before
-            plotting the importances. This function will save
-            two files in the model folder for future use. 
+            This procedure can be time-consuming but must be run once before the importances can be displayed. 
+            This function will save two files in the model folder for future use. 
 
         Returns:
             Saves two binary files, importance and duration importance.
         """
 
         print('Calculating and saving importances, this could take up to an hour...')
 
@@ -1172,85 +1655,132 @@
         
         print(f"Files saved in: {path}")
 
         self.path = path
 
         return  
 
-    def plot_performance(self, metric='acc', combine=False, ylabel=None, title=None,
-        xlim=None, ylim=None, xlog=False, ylog=False, savefig=False):
+    def plot_performance(self, metric='acc', combine=False, cv_model=0, ylabel=None, title=None,
+        xlim=None, ylim=None, xlog=False, ylog=False, legend_loc=9, savefig=False):
         """
         Plots the training/performance histories.
     
         Args:
             metric (str): Metric to plot, options are: 'acc', 'f1_score', 'loss'. Defaults to 'acc'
             combine (bool): If True the validation history will also be included, if applicable.
             ylabel (str, optional): The y-label of the plot.
             title (str, optional): The title of the plot.
             xlim (tuple, optional): The xlim range, matplotlib style.
             ylim (tuple, optional): The ylim range, matplotlib style.
             xlog (bool): Whether to log-scale the x-axis. Defaults to False.
             ylog (bool): Whether to log-scale the y-axis. Defaults to False.
             savefig (bool): If True the figure will not disply but will be saved instead. Defaults to False. 
+            cv_model (int): Index of the model to use. Only applicable if the model_train_metrics class
+                attribute is a list containing multiple models due to cross-validation.
+                Defaults to 0, the first history object in the list. Can be set to 'all', in which case
+                all histories will be used and plotted.
+            legend_loc (int, str, optional): The location of the legend, using the matplotlib.pyplot conventino.
+                Defaults to 0 aka 'upper center'.
 
         Returns:
             AxesImage
         """
 
+        if not hasattr(self, 'model_train_metrics'):
+            raise ValueError('Training history not found! Run the load() method first!')
+
+        if combine and not hasattr(self, 'model_val_metrics'):
+            raise ValueError('combine=True but no validation metrics found!')
+
         if metric == 'acc':
             index = 0 
         elif metric == 'loss':
             index = 1 
-        else:
+        elif metric == 'f1':
             index = 2
+        else:
+            raise ValueError('Invalid metric input! Valid options include: "acc", "loss" and "f1"')
 
-        try:
-            metric1 = self.model_train_metrics
+        if isinstance(self.model_train_metrics, list) is False or isinstance(cv_model, int):
+            metric1 = self.model_train_metrics[cv_model] if isinstance(self.model_train_metrics, list) else self.model_train_metrics
             metric1 = metric1[:,index]
-        except:
-            raise ValueError('Training history not found! Run the load() method first!')
-
-        if combine:
-            try:
-                metric2 = self.model_val_metrics
+        
+            if combine:
+                metric2 = self.model_val_metrics[cv_model] if isinstance(self.model_val_metrics, list) else self.model_val_metrics
                 metric2 = metric2[:,index]
                 label1, label2 = 'Training', 'Validation'
-            except:
-                raise ValueError('combine=True but no validation metrics found!')
+            else:
+                label1 = 'Training'
+        else: #cv_model='all'
+            metric1 = []
+            for _metric_ in self.model_train_metrics:
+                metric1.append(_metric_[:,index])
+
+            if combine:
+                metric2 = []
+                for _metric_ in self.model_val_metrics:
+                    metric2.append(_metric_[:,index])
+                label1, label2 = 'Training', 'Validation'
+            else:
+                label1 = 'Training'
+        
+        if cv_model == 'all':
+            markers = ['o', 's', '+', 'v', '.', 'x', 'h', 'p', '<', '>', '*']
+            color = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628', '#f781bf']
+
+            for i in range(len(metric1)):
+                marker = markers[i % len(markers)]  # Wrap around the markers list
+                plt.plot(range(1, len(metric1[i])+1), metric1[i], color=color[i % len(color)], alpha=0.83, linestyle='-', label=label1+' CV '+str(i+1))
+
+            if combine:
+                for i in range(len(metric2)):
+                    marker = markers[i % len(markers)]  # Wrap around the markers list
+                    plt.plot(range(1, len(metric2[i])+1), metric2[i], color=color[i % len(color)], alpha=0.83, linestyle='--', label=label2+' CV '+str(i+1))
+                plt.legend(loc=legend_loc, frameon=False, ncol=2)
+            else:
+                plt.legend(loc=legend_loc, frameon=False)
+
         else:
-            label1 = 'Training'
-            
-        plt.plot(range(1, len(metric1)+1), metric1, color='r', alpha=0.83, linestyle='-', label=label1)
-        if combine:
-            plt.plot(range(1, len(metric2)+1), metric2, color='b', alpha=0.83, linestyle='--', label=label2)
+            plt.plot(range(1, len(metric1)+1), metric1, color='r', alpha=0.83, linestyle='-', label=label1)
+            if combine:
+                plt.plot(range(1, len(metric2)+1), metric2, color='b', alpha=0.83, linestyle='--', label=label2)
+                plt.legend(loc=legend_loc, frameon=False, ncol=2)
+            else:
+                plt.legend(loc=legend_loc, frameon=False)
 
         if ylabel is None:
             ylabel = metric
         if title is None:
             title = metric
 
         plt.ylabel(ylabel, alpha=1, color='k')
         plt.title(title)
         plt.xlabel('Epoch', alpha=1, color='k'), plt.grid(False)
         if xlim is not None:
             plt.xlim(xlim)
         else:
-            plt.xlim((1, len(metric1)))
+            if cv_model == 'all':
+                len_ = []
+                for _metric_ in self.model_train_metrics:
+                    len_.append(len(_metric_))
+                plt.xlim(1, np.max(len_))
+            else:
+                plt.xlim((1, len(metric1)))
         if ylim is not None:
             plt.ylim(ylim)
         if xlog:
             plt.xscale('log')
         if ylog:
             plt.yscale('log')
-        plt.legend(loc='upper center', frameon=False) #ncol
+
         plt.rcParams['axes.facecolor']='white'
-        
         if savefig:
+            _set_style_()
             plt.savefig('CNN_Training_History_'+metric+'.png', bbox_inches='tight', dpi=300)
-            plt.clf()
+            plt.clf(); plt.style.use('default')
         else:
             plt.show()
 
     def _plot_positive(self, index=0, channel=0, default_scale=True, vmin=None, vmax=None, cmap='gray', title=''):
         """
         Plots the sample in the ``positive`` class, located an the specified index.
 
@@ -1346,15 +1876,14 @@
 
         if vmin is None and default_scale is False:
             plot(data[:,:,channel])
         else:   
             if default_scale is False:
                 plt.imshow(data[:,:,channel], vmin=vmin, vmax=vmax, cmap=cmap); plt.title(title); plt.show()
             else:
-                import pdb; pdb.set_trace()
                 plt.imshow(data[:,:,channel], vmin=vmin, vmax=vmax, cmap=cmap); plt.title(title); plt.show()
 
         return
 
 #Custom CNN model configured to genereate shallower CNNs than AlexNet
 
 def custom_model(positive_class, negative_class, img_num_channels=1, normalize=True, 
@@ -1370,16 +1899,16 @@
     weight=None, verbose=1, save_training_data=False, path=None):
     """
     CNN Model that allows between 1 and 3 convolutional layers (with pooling) followed by dense layers,
     also up to three layers. This is a simpler model than AlexNet that can be used to limit overfitting behavior.
     Batch normalization is hard-coded after every Conv2D layer.        
 
     Args:
-        positive_class (ndarray): 3D array containing more than one image of diffuse objects.
-        negative_class (ndarray): 3D array containing more than one image of non-diffuse objects.
+        positive_class (ndarray): 3D array containing more than one image of the positive objects.
+        negative_class (ndarray): 3D array containing more than one image of negative objects.
         img_num_channels (int): The number of filters used. Defaults to 1, as MicroLIA version 1
             has been trained with only blue broadband data.
         normalize (bool, optional): If True the data will be min-max normalized using the 
             input min and max pixels. Defaults to True.
         min_pixel (int, optional): The minimum pixel count, defaults to 638. 
             Pixels with counts below this threshold will be set to this limit.
         max_pixel (int, optional): The maximum pixel count, defaults to 3000. 
@@ -1419,14 +1948,18 @@
             ratio of the minority class to the majority class. Defaults to 0 which disables the procedure.
         patience (int): Number of epochs without improvement before the training is terminated. Defaults to 0, which
             disables this feature.
         metric (str): The metric to monitor according to the input patience. Defaults to 'binary_accuracy'.
         early_stop_callback (list, optional): Callbacks for early stopping and pruning with Optuna, defaults
             to None. Should only be used with the optimization routine, refer to MicroLIA.optimization.objective_cnn().
         weight (int): Weight to apply if using the weighted loss function. Defaults to None. 
+        save_training_data (bool): Whether to save the training data, useful for visualizing the images as they were
+            input for training. Defaults to False.
+        paht (str): Path where the training data should be saved, only used if save_training_data is True.
+            Defaults to None, which saves the data in the local home directory.
 
     Returns:
         The trained CNN model and accompanying history.
     """
     
     if batch_size < 16:
         print("Batch Normalization can be unstable with low batch sizes, if loss returns nan try a larger batch size and/or smaller learning rate.")
@@ -1486,15 +2019,15 @@
 
     if verbose == 1:
         filter_size_4 = filter_size_5 = filter_4 = filter_5 = 0; pooling_4 = pool_size_4 = pooling_5 = pool_size_5 ='None' 
         print_params(batch_size, lr, decay, momentum, nesterov, loss, optimizer, model_reg, conv_init, activation_conv, 
             dense_init, activation_dense, filter_1, filter_2, filter_3, filter_4, filter_5, filter_size_1, filter_size_2, 
             filter_size_3, filter_size_4, filter_size_5, pooling_1, pooling_2, pooling_3, pooling_4, pooling_5, pool_size_1, 
             pool_size_2, pool_size_3, pool_size_4, pool_size_5, conv_reg, dense_reg, dense_neurons_1, dense_neurons_2, 
-            dense_neurons_3, dropout_1, dropout_2, dropout_3)
+            dense_neurons_3, dropout_1, dropout_2, dropout_3, beta_1, beta_2, amsgrad, rho)
 
     #Uniform scaling initializer
     conv_init = VarianceScaling(scale=1.0, mode='fan_in', distribution='uniform', seed=None) if conv_init == 'uniform_scaling' else conv_init
     dense_init = VarianceScaling(scale=1.0, mode='fan_in', distribution='uniform', seed=None) if dense_init == 'uniform_scaling' else dense_init
 
     #Call the appropriate tf.keras.losses.Loss function
     loss = get_loss_function(loss, weight=weight)
@@ -1615,16 +2148,15 @@
     filter_3=384, filter_size_3=3, strides_3=1, pooling_3='max', pool_size_3=3, pool_stride_3=2, 
     filter_4=384, filter_size_4=3, strides_4=1, filter_5=256, filter_size_5=3, strides_5=1, 
     dense_neurons_1=4096, dense_neurons_2=4096, dropout_1=0.5, dropout_2=0.5,  
     smote_sampling=0, patience=0, metric='binary_accuracy', early_stop_callback=None, checkpoint=False, 
     weight=None, verbose=1, save_training_data=False, path=None):
     """
     The CNN model infrastructure presented by the 2012 ImageNet Large Scale 
-    Visual Recognition Challenge, AlexNet. Parameters were adapted for
-    our astronomy case of detecting diffuse emission.
+    Visual Recognition Challenge, AlexNet. 
 
     To avoid exploding gradients we need to normalize our pixels to be 
     between 0 and 1. By default normalize=True, which will perform
     min-max normalization using the min_pixel and max_pixel arguments, 
     which should be set carefully.
 
     The original AlexNet architecture employed the use of Local Response Normalization (LRN)
@@ -1652,16 +2184,16 @@
         of the minority class. The resulting synthetic samples can then be added to the training set to 
         balance the class distribution.
 
         Once SMOTE has generated the synthetic samples, the 2D array can be reshaped back into its 
         original image format to be used as input to a CNN model.
 
     Args:
-        positive_class (ndarray): 3D array containing more than one image of diffuse objects.
-        negative_class (ndarray): 3D array containing more than one image of non-diffuse objects.
+        positive_class (ndarray): 3D array containing more than one image of the positive objects.
+        negative_class (ndarray): 3D array containing more than one image of negative objects.
         img_num_channels (int): The number of filters used. Defaults to 1, as MicroLIA version 1
             has been trained with only blue broadband data.
         normalize (bool, optional): If True the data will be min-max normalized using the 
             input min and max pixels. Defaults to True.
         min_pixel (int, optional): The minimum pixel count, defaults to 638. 
             Pixels with counts below this threshold will be set to this limit.
         max_pixel (int, optional): The maximum pixel count, defaults to 3000. 
@@ -1702,14 +2234,18 @@
             ratio of the minority class to the majority class. Defaults to 0 which disables the procedure.
         patience (int): Number of epochs without improvement before the training is terminated. Defaults to 0, which
             disables this feature.
         metric (str): The metric to monitor according to the input patience. Defaults to 'binary_accuracy'.
         early_stop_callback (list, optional): Callbacks for early stopping and pruning with Optuna, defaults
             to None. Should only be used with the optimization routine, refer to MicroLIA.optimization.objective_cnn().
         weight (int): Weight to apply if using the weighted loss function. Defaults to None. 
+        save_training_data (bool): Whether to save the training data, useful for visualizing the images as they were
+            input for training. Defaults to False.
+        paht (str): Path where the training data should be saved, only used if save_training_data is True.
+            Defaults to None, which saves the data in the local home directory.
 
     Returns:
         The trained CNN model and accompanying history.
     """
     
     if batch_size < 16 and model_reg == 'batch_norm':
         print("Batch Normalization can be unstable with low batch sizes, if loss returns nan try a larger batch size and/or smaller learning rate.")
@@ -1764,15 +2300,15 @@
     
     if verbose == 1:
         dense_neurons_3 = dropout_3 = 0; pooling_4 = pool_size_4 = pooling_5 = pool_size_5 = 'None' 
         print_params(batch_size, lr, decay, momentum, nesterov, loss, optimizer, model_reg, conv_init, activation_conv, 
             dense_init, activation_dense, filter_1, filter_2, filter_3, filter_4, filter_5, filter_size_1, filter_size_2, 
             filter_size_3, filter_size_4, filter_size_5, pooling_1, pooling_2, pooling_3, pooling_4, pooling_5, pool_size_1, 
             pool_size_2, pool_size_3, pool_size_4, pool_size_5, conv_reg, dense_reg, dense_neurons_1, dense_neurons_2, 
-            dense_neurons_3, dropout_1, dropout_2, dropout_3)
+            dense_neurons_3, dropout_1, dropout_2, dropout_3, beta_1, beta_2, amsgrad, rho)
 
     #Uniform scaling initializer
     conv_init = VarianceScaling(scale=1.0, mode='fan_in', distribution='uniform', seed=None) if conv_init == 'uniform_scaling' else conv_init
     dense_init = VarianceScaling(scale=1.0, mode='fan_in', distribution='uniform', seed=None) if dense_init == 'uniform_scaling' else dense_init
 
     #Call the appropriate tf.keras.losses.Loss function
     loss = get_loss_function(loss, weight=weight)
@@ -1892,16 +2428,16 @@
     achieved state-of-the-art results on the classification task.
 
     The VGG16 network consists of 16 layers, including 13 convolutional layers and 3 fully connected layers. 
     The input to the network is a RGB image of size 224x224 pixels. The first layers of the network are convolutional 
     layers with small 3x3 filters, followed by a max pooling layer with a 2x2 filter (repeated 5 times).
 
     Args:
-        positive_class (ndarray): 3D array containing more than one image of diffuse objects.
-        negative_class (ndarray): 3D array containing more than one image of non-diffuse objects.
+        positive_class (ndarray): 3D array containing more than one image of the positive objects.
+        negative_class (ndarray): 3D array containing more than one image of the negative objects.
         img_num_channels (int): The number of filters used. Defaults to 1, as MicroLIA version 1
             has been trained with only blue broadband data.
         normalize (bool, optional): If True the data will be min-max normalized using the 
             input min and max pixels. Defaults to True.
         min_pixel (int, optional): The minimum pixel count, defaults to 638. 
             Pixels with counts below this threshold will be set to this limit.
         max_pixel (int, optional): The maximum pixel count, defaults to 3000. 
@@ -1942,14 +2478,18 @@
             ratio of the minority class to the majority class. Defaults to 0 which disables the procedure.
         patience (int): Number of epochs without improvement before the training is terminated. Defaults to 0, which
             disables this feature.
         metric (str): The metric to monitor according to the input patience. Defaults to 'binary_accuracy'.
         early_stop_callback (list, optional): Callbacks for early stopping and pruning with Optuna, defaults
             to None. Should only be used with the optimization routine, refer to MicroLIA.optimization.objective_cnn().
         weight (int): Weight to apply if using the weighted loss function. Defaults to None. 
+        save_training_data (bool): Whether to save the training data, useful for visualizing the images as they were
+            input for training. Defaults to False.
+        paht (str): Path where the training data should be saved, only used if save_training_data is True.
+            Defaults to None, which saves the data in the local home directory.
 
     Returns:
         The trained CNN model and accompanying history.
     """
 
     if batch_size < 16 and model_reg == 'batch_norm':
         print("Batch Normalization can be unstable with low batch sizes, if loss returns nan try a larger batch size and/or smaller learning rate.")
@@ -2004,15 +2544,15 @@
    
     if verbose == 1:
         dense_neurons_3 = dropout_3 = 'N/A'
         print_params(batch_size, lr, decay, momentum, nesterov, loss, optimizer, model_reg, conv_init, activation_conv, 
             dense_init, activation_dense, filter_1, filter_2, filter_3, filter_4, filter_5, filter_size_1, filter_size_2, 
             filter_size_3, filter_size_4, filter_size_5, pooling_1, pooling_2, pooling_3, pooling_4, pooling_5, pool_size_1, 
             pool_size_2, pool_size_3, pool_size_4, pool_size_5, conv_reg, dense_reg, dense_neurons_1, dense_neurons_2, 
-            dense_neurons_3, dropout_1, dropout_2, dropout_3)
+            dense_neurons_3, dropout_1, dropout_2, dropout_3, beta_1, beta_2, amsgrad, rho)
 
     #Uniform scaling initializer
     conv_init = VarianceScaling(scale=1.0, mode='fan_in', distribution='uniform', seed=None) if conv_init == 'uniform_scaling' else conv_init
     dense_init = VarianceScaling(scale=1.0, mode='fan_in', distribution='uniform', seed=None) if dense_init == 'uniform_scaling' else dense_init
 
     #Call the appropriate tf.keras.losses.Loss function
     loss = get_loss_function(loss, weight=weight)
@@ -2117,15 +2657,15 @@
     model.add(BatchNormalization()) if model_reg == 'batch_norm' else None  
 
     #Call the appropriate tf.keras.optimizers function
     optimizer = get_optimizer(optimizer, lr, momentum=momentum, decay=decay, rho=rho, nesterov=nesterov, beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad)
 
     #Compile the Model
     model.compile(loss=loss, optimizer=optimizer, metrics=[tf.keras.metrics.BinaryAccuracy(), f1_score])
-    
+
     #Wheter to maximize or minimize the metric
     mode = 'min' if 'loss' in metric else 'max'
 
     #Optional checkpoint callback, with the monitor being the input metric.
     callbacks_list = []
     callbacks_list.append(ModelCheckpoint(str(Path.home())+'/'+'checkpoint.hdf5', monitor=metric, verbose=2, save_best_only=True, mode=mode)) if checkpoint else None
 
@@ -2193,14 +2733,16 @@
         map in the last convolutional block to generate a single value for each feature map. This produces a fixed-length 
         feature vector that can be fed directly to the final fully connected layer for classification.
 
     Returns:
         The trained CNN model and accompanying history.
     """
 
+    raise ValueError('ResNet-18 Model is not currently stable, please select another model!')
+
     if batch_size < 16 and model_reg == 'batch_norm':
         print("Batch Normalization can be unstable with low batch sizes, if loss returns nan try a larger batch size and/or smaller learning rate.")
     
     if 'all' in metric: #This is an option for optimization purposes but not a valid argument
         if 'val' in metric:
             print("Cannot combine combined metrics for these callbacks, setting metric='val_loss'"); metric = 'val_loss'
         else:
@@ -2309,18 +2851,18 @@
 
     x = GlobalAveragePooling2D()(x) #Global pooling operation that reduces the spatial dimensions (height and width) of the input tensor to a single value per channel using the mean of all values in a given channel
     x = Dense(num_classes, kernel_initializer=dense_init)(x)
     x = Activation('sigmoid')(x)
 
     model = Model(inputs=input_tensor, outputs=x)
 
-    # Call the appropriate tf.keras.optimizers function
+    #Call the appropriate tf.keras.optimizers function
     optimizer = get_optimizer(optimizer, lr, momentum=momentum, decay=decay, rho=rho, nesterov=nesterov, beta_1=beta_1, beta_2=beta_2, amsgrad=amsgrad)
 
-    # Compile the Model
+    #Compile the Model
     model.compile(loss=loss, optimizer=optimizer, metrics=[tf.keras.metrics.BinaryAccuracy(), f1_score])
 
     #Wheter to maximize or minimize the metric
     mode = 'min' if 'loss' in metric else 'max'
 
     #Optional checkpoint callback, with the monitor being the input metric.
     callbacks_list = []
@@ -2410,23 +2952,54 @@
     Args:
         y_true (tensor): The true labels.
         y_pred (tensor): The predicted labels.
 
     Returns:
         The F1 score between true and predicted labels.
     """
-
+    
     tp = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))
     fp = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred - y_true, 0, 1)))
     fn = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true - y_pred, 0, 1)))
 
     precision = tp / (tp + fp + tf.keras.backend.epsilon())
     recall = tp / (tp + fn + tf.keras.backend.epsilon())
 
-    return 2.0 * precision * recall / (precision + recall + tf.keras.backend.epsilon())
+    f1 = 2.0 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())
+
+    return f1
+
+def calculate_tp_fp(model, sample, y_true):
+    """
+    Computes the true positives (tp) and false positives (fp) for a single sample using a given model.
+
+    Args:
+        model: The trained model.
+        sample: The input sample (image) for prediction.
+        y_true (array): The ground truth labels for the sample(s). Must be the same length as the input sample argument.
+
+    Returns:
+        tp: The number of true positives.
+        fp: The number of false positives.
+    """
+    # Make a prediction using the model
+    y_pred = model.predict(sample)
+
+    # Convert y_true and y_pred to binary values
+    y_true_binary = tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1))
+    y_pred_binary = tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1))
+
+    # Calculate true positives (tp)
+    tp = tf.keras.backend.sum(y_true_binary * y_pred_binary)
+
+    # Calculate false positives (fp)
+    fp = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred_binary - y_true_binary, 0, 1)))
+
+    return tp, fp
+
 
 def focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25):
     """
     This function computes focal loss, which is used to address class imbalance in classification tasks.
 
     Args:
         y_true (Tensor): The ground truth labels.
@@ -2610,15 +3183,15 @@
    
 def print_params(batch_size, lr, decay, momentum, nesterov, loss, optimizer, 
     model_reg, conv_init, activation_conv, dense_init, activation_dense,
     filter1, filter2, filter3, filter4, filter5, filter_size_1, filter_size_2, 
     filter_size_3, filter_size_4, filter_size_5, pooling_1, pooling_2, pooling_3,
     pooling_4, pooling_5, pool_size_1, pool_size_2, pool_size_3, pool_size_4, pool_size_5,
     conv_reg, dense_reg, dense_neurons_1, dense_neurons_2, dense_neurons_3, dropout_1, dropout_2, 
-    dropout_3):
+    dropout_3, beta_1, beta_2, amsgrad, rho):
     """
     Prints the model training parameters and architecture parameters.
 
     Args:
         batch_size (int): The number of samples per gradient update.
         lr (float): The learning rate for the model.
         decay (float): The learning rate decay over each update.
@@ -2629,91 +3202,76 @@
         model_reg (str): The regularization method used to prevent overfitting.
         conv_init (str): The initialization method used for the convolutional layers.
         activation_conv (str): The activation function used for the convolutional layers.
         dense_init (str): The initialization method used for the dense layers.
         activation_dense (str): The activation function used for the dense layers.
     """
 
-    print()
-    print('===== Training Parameters =====')
-    print()
+    print(); print('===== Training Parameters ====='); print()
     print('|| Batch Size : '+str(batch_size), '|| Loss Function : '+loss, '||')
+
     if optimizer == 'sgd':
         print('|| Optimizer : '+optimizer, '|| lr : '+str(np.round(lr, 7)), '|| Decay : '+str(np.round(decay, 5)), '|| Momentum : '+str(momentum), '|| Nesterov : '+str(nesterov)+' ||')
-    elif optimizer == 'rmsprop':
-        print('|| Optimizer : '+optimizer, '|| lr : '+str(np.round(lr, 7)), '|| Decay : '+str(np.round(decay, 5))+' ||')
-    else:
-        print('|| Optimizer : '+optimizer, '|| lr : '+str(np.round(lr, 7))+' ||')
-    print()
-    print('=== Architecture Parameters ===')
-    print()
+    elif optimizer == 'adadelta' or optimizer == 'rmsprop':
+        print('|| Optimizer : '+optimizer, '|| lr : '+str(np.round(lr, 7)), '|| rho : '+str(np.round(rho, 5)), '|| Decay : '+str(np.round(decay, 5))+' ||')
+    elif optimizer == 'adam' or optimizer == 'adamax' or optimizer == 'nadam':
+        print('|| Optimizer : '+optimizer, '|| lr : '+str(np.round(lr, 7)), '|| Beta 1 : '+str(np.round(beta_1, 5)), '|| Beta 2 : '+str(np.round(beta_2, 5)), '||  amsgrad : '+str(amsgrad)+' ||')
+    
+    print(); print('=== Architecture Parameters ==='); print()
     print('Model Regularizer : '+ str(model_reg))
     print('Convolutional L2 Regularizer : '+ str(conv_reg))
     print('Convolutional Initializer : '+ conv_init)
     print('Convolutional Activation Fn : '+ activation_conv)
     print('Dense L2 Regularizer : '+ str(dense_reg))
     print('Dense Initializer : '+ dense_init)
-    print('Dense Activation Fn : '+ activation_dense)
-    print()
+    print('Dense Activation Fn : '+ activation_dense); print()
 
     if dropout_3 != 'N/A': #This is AlexNet and custom_model since droput_3 = N/A is set for VGG16 and Resnet-18 only
-        print('======= Conv2D Layer Parameters ======')
-        print()
+        print('======= Conv2D Layer Parameters ======'); print()
         print('Filter 1 || Num: {}, Size : {}, Pooling : {}, Pooling Size : {}'.format(filter1, filter_size_1, pooling_1, pool_size_1))
         if filter_size_2 > 0:
             print('Filter 2 || Num: {}, Size : {}, Pooling : {}, Pooling Size : {}'.format(filter2, filter_size_2, pooling_2, pool_size_2))
         if filter_size_3 > 0:
             print('Filter 3 || Num: {}, Size : {}, Pooling : {}, Pooling Size : {}'.format(filter3, filter_size_3, pooling_3, pool_size_3))
         if filter_size_4 > 0:
             print('Filter 4 || Num: {}, Size : {}, Pooling : {}, Pooling Size : {}'.format(filter4, filter_size_4, pooling_4, pool_size_4))
         if filter_size_5 > 0:
             print('Filter 5 || Num: {}, Size : {}, Pooling : {}, Pooling Size : {}'.format(filter5, filter_size_5, pooling_5, pool_size_5))
-        print()
-        print('======= Dense Layer Parameters ======')
-        print()
+        
+        print(); print('======= Dense Layer Parameters ======'); print()
         print('Neurons 1 || Num : {}, Dropout : {}'.format(dense_neurons_1, dropout_1))
         if dense_neurons_2 > 0:
             print('Neurons 2 || Num : {}, Dropout : {}'.format(dense_neurons_2, dropout_2))
         if dense_neurons_3 > 0:
             print('Neurons 3 || Num : {}, Dropout : {}'.format(dense_neurons_3, dropout_3))
-        print()
-        print('===============================')
-        print()
+        print(); print('==============================='); print()
     else:
         if activation_dense == 'N/A': #For Resnet-18 
-            print('======= Conv2D Layer Parameters ======')
-            print()
+            print('======= Conv2D Layer Parameters ======'); print()
             print('Filter 1 || Num: {}, Size : {}, Pooling : {}'.format(filter1, filter_size_1, pooling_1, pool_size_1))
             if filter_size_2 > 0:
                 print('Residual Block 1 || Num: {}, Size : {}'.format(filter2, filter_size_2))
             if filter_size_3 > 0:
                 print('Residual Block 2 || Num: {}, Size : {}'.format(filter3, filter_size_3))
             if filter_size_4 > 0:
                 print('Residual Block 3 || Num: {}, Size : {}'.format(filter4, filter_size_4))
             if filter_size_5 > 0:
                 print('Residual Block 4 || Num: {}, Size : {},'.format(filter5, filter_size_5))
-            print()
-            print('===============================')
-            print()
+            print(); print('==============================='); print()
         else: #For VGG16
-            print('======= Conv2D Layer Parameters ======')
-            print()
+            print('======= Conv2D Layer Parameters ======'); print()
             print('Block 1 || Num: {}, Size : {}, Pooling : {}'.format(filter1, filter_size_1, pooling_1, pool_size_1))
             print('Block 2 || Num: {}, Size : {}'.format(filter2, filter_size_2))
             print('Block 3 || Num: {}, Size : {}'.format(filter3, filter_size_3))
             print('Block 4 || Num: {}, Size : {}'.format(filter4, filter_size_4))
             print('Block 5 || Num: {}, Size : {},'.format(filter5, filter_size_5))
-            print()
-            print('======= Dense Layer Parameters ======')
-            print()
+            print(); print('======= Dense Layer Parameters ======'); print()
             print('Neurons 1 || Num : {}, Dropout : {}'.format(dense_neurons_1, dropout_1))
             print('Neurons 2 || Num : {}, Dropout : {}'.format(dense_neurons_2, dropout_2))    
-            print()
-            print('===============================')
-            print()
+            print(); print('==============================='); print()
 
 def format_labels(labels: list) -> list:
     """
     Takes a list of labels and returns the list with all words capitalized and underscores removed.
     Also replaces 'eta' with 'Learning Rate' and 'n_estimators' with 'Number of Trees'.
     
     Args:
@@ -2729,7 +3287,59 @@
         if label == "lr":
             new_labels.append("Learning Rate")
             continue
         new_labels.append(label.title())
 
     return new_labels
 
+def _set_style_():
+    """
+    Function to configure the matplotlib.pyplot style. This function is called before any images are saved,
+    after which the style is reset to the default.
+    """
+
+    plt.rcParams["xtick.color"] = "323034"
+    plt.rcParams["ytick.color"] = "323034"
+    plt.rcParams["text.color"] = "323034"
+    plt.rcParams["lines.markeredgecolor"] = "black"
+    plt.rcParams["patch.facecolor"] = "#bc80bd"  # Replace with a valid color code
+    plt.rcParams["patch.force_edgecolor"] = True
+    plt.rcParams["patch.linewidth"] = 0.8
+    plt.rcParams["scatter.edgecolors"] = "black"
+    plt.rcParams["grid.color"] = "#b1afb5"  # Replace with a valid color code
+    plt.rcParams["axes.titlesize"] = 16
+    plt.rcParams["legend.title_fontsize"] = 12
+    plt.rcParams["xtick.labelsize"] = 16
+    plt.rcParams["ytick.labelsize"] = 16
+    plt.rcParams["font.size"] = 15
+    plt.rcParams["axes.prop_cycle"] = (cycler('color', ['#bc80bd', '#fb8072', '#b3de69', '#fdb462', '#fccde5', '#8dd3c7', '#ffed6f', '#bebada', '#80b1d3', '#ccebc5', '#d9d9d9']))  # Replace with valid color codes
+    plt.rcParams["mathtext.fontset"] = "stix"
+    plt.rcParams["font.family"] = "STIXGeneral"
+    plt.rcParams["lines.linewidth"] = 2
+    plt.rcParams["lines.markersize"] = 6
+    plt.rcParams["legend.frameon"] = True
+    plt.rcParams["legend.framealpha"] = 0.8
+    plt.rcParams["legend.fontsize"] = 13
+    plt.rcParams["legend.edgecolor"] = "black"
+    plt.rcParams["legend.borderpad"] = 0.2
+    plt.rcParams["legend.columnspacing"] = 1.5
+    plt.rcParams["legend.labelspacing"] = 0.4
+    plt.rcParams["text.usetex"] = False
+    plt.rcParams["axes.labelsize"] = 17
+    plt.rcParams["axes.titlelocation"] = "center"
+    plt.rcParams["axes.formatter.use_mathtext"] = True
+    plt.rcParams["axes.autolimit_mode"] = "round_numbers"
+    plt.rcParams["axes.labelpad"] = 3
+    plt.rcParams["axes.formatter.limits"] = (-4, 4)
+    plt.rcParams["axes.labelcolor"] = "black"
+    plt.rcParams["axes.edgecolor"] = "black"
+    plt.rcParams["axes.linewidth"] = 1
+    plt.rcParams["axes.grid"] = False
+    plt.rcParams["axes.spines.right"] = True
+    plt.rcParams["axes.spines.left"] = True
+    plt.rcParams["axes.spines.top"] = True
+    plt.rcParams["figure.titlesize"] = 18
+    plt.rcParams["figure.autolayout"] = True
+    plt.rcParams["figure.dpi"] = 300
+
+    return
+
```

### Comparing `MicroLIA-2.2.6/MicroLIA/data/Miras_vo.xml` & `MicroLIA-2.2.7/MicroLIA/data/Miras_vo.xml`

 * *Files identical despite different names*

### Comparing `MicroLIA-2.2.6/MicroLIA/data/Sesar2010/RRLyr_ugriz_templates.tar.gz` & `MicroLIA-2.2.7/MicroLIA/data/Sesar2010/RRLyr_ugriz_templates.tar.gz`

 * *Files identical despite different names*

### Comparing `MicroLIA-2.2.6/MicroLIA/data_augmentation.py` & `MicroLIA-2.2.7/MicroLIA/data_augmentation.py`

 * *Files 2% similar despite different names*

```diff
@@ -80,15 +80,15 @@
         rotation (int): If True full 360 rotation is allowed, if False no rotation is performed.
             Defaults to False.
         fill (str): This is the treatment for data outside the boundaries after roration
             and shifts. Default is set to 'nearest' which repeats the closest pixel values.
             Can be set to: {"constant", "nearest", "reflect", "wrap"}.
         image_size (int, bool): The length/width of the cropped image. This can be used to remove
             anomalies caused by the fill (defaults to 50). This can also be set to None in which case 
-            the image in its original size is returned.
+            the image in its original size is returned. Defaults to None.
         mask_size (int): The size of the cutout mask. Defaults to None to disable random cutouts.
         num_masks (int): Number of masks to apply to each image. Defaults to None, must be an integer
             if mask_size is used as this designates how many masks of that size to randomly place in the image.
         blend_multiplier (float): Sets the amount of synthetic images to make via image blending.
             Must be a ratio greater than or equal to 1. If set to 1, the data will be replaced with
             randomly blended images, if set to 1.5, it will increase the training set by 50% with blended images,
             and so forth. Deafults to 0 which disables this feature.
@@ -106,18 +106,18 @@
 
     Returns:
         Array containing the augmented images. When input, channel2 and channel3 yield 
         additionl outputs, respectively.
     """
 
     if batch == 0: #Setting this in case the negative class is not set to be augmented during the CNN optimization routine.
-        if channel_2 is None:
+        if channel2 is None:
             return channel1 
         else:
-            if channel_3 is None:
+            if channel3 is None:
                 return channel1, channel2
             else:
                 return channel1, channel2, channel3
 
     if isinstance(width_shift, int) == False or isinstance(height_shift, int) == False:
         raise ValueError("Shift parameters must be integers indicating +- pixel range")
     if mask_size is not None:
@@ -532,14 +532,18 @@
 
     return X_train_resampled, Y_resampled
 
 def resize(data, size=50):
     """
     Resizes the data by cropping out the outer boundaries outside the size x size limit.
     Can be either a 2D array containing one sample, or a 3D array for multiple samples.
+    
+    Note:
+        By design this function will not work if the data is a single sample, multiple channels (img_width, img_height, img_num_channels). 
+        In this case, reshape to be 4-D: data = data.reshape(1, img_width, img_height, img_num_channels)
 
     Args:
         data (array): 2D array to resize.
         size (int): The length/width of the output array. Defaults to 50 pixels. 
             Can be set to None to return the same image size.
 
     Returns:
@@ -689,10 +693,8 @@
     index = np.where(np.isfinite(data))
     std = np.median(np.abs(data[index]-np.median(data[index])))
     vmin = np.median(data[index]) - 3*std
     vmax = np.median(data[index]) + 10*std
     
     plt.imshow(data, vmin=vmin, vmax=vmax, cmap=cmap)
     plt.title(title)
-    plt.show()
-
-
+    plt.show()
```

### Comparing `MicroLIA-2.2.6/MicroLIA/data_processing.py` & `MicroLIA-2.2.7/MicroLIA/data_processing.py`

 * *Files 2% similar despite different names*

```diff
@@ -118,29 +118,18 @@
     if channel3 is None:
         colorized = (channel1[..., np.newaxis], channel2[..., np.newaxis])
     else:
         colorized = (channel1[..., np.newaxis], channel2[..., np.newaxis], channel3[..., np.newaxis])
 
     return np.concatenate(colorized, axis=-1)
 
-
 def normalize_pixels(channels, min_pixel, max_pixel, img_num_channels):
     """
     This function will apply min-max normalization. It returns a 4-d array.
     
-    Note:
-        min_pixel must be a single input, but the max_pixel can either be 
-        an int/float or a list. If it is an int/float then
-
-        Non-subtracted images in the NDWFS Bootes survey data (Bw):
-        NDWFS min 0.01% : 638.186
-        NDWFS max 99.99% : 7350.639
-        Max intensity of expected blobs : ~3000
-    
-
     Args:
         channel (array): 2D array for one image, 3D array for multiple images.
         min_pixel (int, optional): The minimum pixel count, defaults to 0. 
             Pixels with counts below this threshold will be set to this limit.
         max_pixel (int, optional): The maximum pixel count, defaults to 100. 
             Pixels with counts above this threshold will be set to this limit.
 
@@ -204,26 +193,28 @@
         Image anomalies can be removed by setting normalize=True, as the 
         values below/above the thresholds are set to the min/max limits. We
         strongly recommend normalizing your data.
 
     Args:
         channel (array): 2D array for one image, 3D array for multiple images.
         img_num_channels (int): The number of filters used. Defaults to 1.
-        label (int, optional): Class label, 0 for blob, 1 for other. Defaults to None.
+        label (int, optional): Class label. Defaults to None.
         normalize (bool, optional): True will apply min-max normalization.
         min_pixel (int, optional): The minimum pixel count, defaults to 638. 
             Pixels with counts below this threshold will be set to this limit.
         max_pixel (int, optional): The maximum pixel count, defaults to 3000. 
             Pixels with counts above this threshold will be set to this limit.
 
     Returns:      
         Reshaped data and label arrays.
     """
 
     if normalize:
+        if len(channel) >= 1000:
+            print('Normalizing images...') #For when predictions are being made
         data = normalize_pixels(channel, min_pixel=min_pixel, max_pixel=max_pixel, img_num_channels=img_num_channels)
     else:
         images = copy.deepcopy(channel)
         if len(images.shape) == 4:
             axis = images.shape[0]
             if images.shape[-1] != img_num_channels:
                 raise ValueError('img_num_channels parameter must match the number of filters! Number of filters detected: '+str(channel.shape[-1]))
@@ -251,15 +242,15 @@
 
     #reshape
     label = np.expand_dims(np.array([label]*len(data)), axis=1)
     label = to_categorical(label, 2)
     
     return data, label
 
-def create_training_set(blob_data, other_data, img_num_channels=1, normalize=True, min_pixel=638, max_pixel=3000):
+def create_training_set(positive_data, negative_data, img_num_channels=1, normalize=True, min_pixel=638, max_pixel=3000):
     """
     Combines image data of known class to create a training set.
     This is used for training the machine learning models. The 
     max_pixel parameter can be a single value corresponding to a single channel
     or to a list containing the value for each individual band.
 
     Note: 
@@ -273,27 +264,27 @@
         >>> class2_data, class2_label = process_class(data2, label=1)
         >>> class3_data, class3_label = process_class(data3, label=2)
 
         >>> training_data = np.r_[class1_data, class2_data, class3_data]
         >>> training_labels = np.r_[class1_label class2_label, class3_label]
 
     Args:
-        blob_data (array): 3D array containing more than one image of positive objects.
-        other_data (array): 3D array containing more than one image of non-positive objects.
+        positive_data (array): 3D array containing more than one image of positive objects.
+        negative_data (array): 3D array containing more than one image of negative objects.
         img_num_channels (int): The number of filters used. Defaults to 1.
         normalize (bool, optional): True will normalize the data using the input min and max pixels
         min_pixel (int, optional): The minimum pixel count, defaults to 638. 
             Pixels with counts below this threshold will be set to this limit.
         max_pixel (int, optional): The maximum pixel count, defaults to 3000. 
             Pixels with counts above this threshold will be set to this limit.
     
     Returns:      
         Reshaped data and label arrays.
     """
 
-    class1_data, class1_label = process_class(blob_data, label=1, normalize=normalize, min_pixel=min_pixel, max_pixel=max_pixel, img_num_channels=img_num_channels)
-    class2_data, class2_label = process_class(other_data, label=0, normalize=normalize, min_pixel=min_pixel, max_pixel=max_pixel, img_num_channels=img_num_channels)
+    class1_data, class1_label = process_class(positive_data, label=1, normalize=normalize, min_pixel=min_pixel, max_pixel=max_pixel, img_num_channels=img_num_channels)
+    class2_data, class2_label = process_class(negative_data, label=0, normalize=normalize, min_pixel=min_pixel, max_pixel=max_pixel, img_num_channels=img_num_channels)
     
     training_data = np.r_[class1_data, class2_data]
     training_labels = np.r_[class1_label, class2_label]
 
-    return training_data, training_labels
+    return training_data, training_labels
```

### Comparing `MicroLIA-2.2.6/MicroLIA/ensemble_model.py` & `MicroLIA-2.2.7/MicroLIA/ensemble_model.py`

 * *Files 22% similar despite different names*

```diff
@@ -10,75 +10,82 @@
 import random
 import itertools
 import numpy as np
 import pandas as pd
 import matplotlib.pyplot as plt
 import matplotlib.colors as mcolors 
 from matplotlib.ticker import ScalarFormatter,AutoMinorLocator
+from cycler import cycler
 from warnings import warn
 from pathlib import Path
 from collections import Counter  
 
 from sklearn import decomposition
+from xgboost import XGBClassifier
+from sklearn.svm import OneClassSVM
 from sklearn.preprocessing import MinMaxScaler
 from sklearn.ensemble import RandomForestClassifier
 from sklearn.neural_network import MLPClassifier
 from sklearn.metrics import confusion_matrix, auc, RocCurveDisplay
 from sklearn.model_selection import KFold, StratifiedKFold, train_test_split
+from scikitplot.metrics import plot_roc
 from sklearn.manifold import TSNE
 
 from optuna.importance import get_param_importances, FanovaImportanceEvaluator
-from MicroLIA.optimization import hyper_opt, borutashap_opt, KNN_imputation
+from MicroLIA.optimization import hyper_opt, borutashap_opt, impute_missing_values
 from MicroLIA import extract_features
-from xgboost import XGBClassifier
-import scikitplot as skplt
-
 
 class Classifier:
     """
     Creates a machine learning classifier object. The built-in methods can be used to optimize the engine and output visualizations.
 
     Args:
         data_x (ndarray): 2D array of size (n x m), where n is the
             number of samples, and m the number of features.
         data_y (ndarray, str): 1D array containing the corresponing labels.
         clf (str): The machine learning classifier to optimize. Can either be
             'rf' for Random Forest, 'nn' for Neural Network, or 'xgb' for Extreme Gradient Boosting. 
             Defaults to 'rf'.
         optimize (bool): If True the Boruta algorithm will be run to identify the features
-            that contain useful information, after which the optimal Random Forest hyperparameters
-            will be calculated using Bayesian optimization. 
-        opt_cv (int): Cross-validations to perform when assesing the performance at each
-            hyperparameter optimization trial. For example, if cv=3, then each optimization trial
+            that contain useful information (if boruta_trials > 0), after which the optimal engine 
+            hyperparameters will be determined using Bayesian optimization (if n_iter > 0).
+        opt_cv (int): Cross-validations to perform when assesing the performance during the
+            hyperparameter optimization. For example, if cv=3, then each optimization trial
             will be assessed according to the 3-fold cross validation accuracy. Defaults to 10.
             NOTE: The higher this number, the longer the optimization will take.
-        limit_search (bool): If True, the search space for the parameters will be expanded,
-            as there are some hyperparameters that can range from 0 to inf. Defaults to False.
-        impute (bool): If False no data imputation will be performed. Defaults to True,
-            which will result in two outputs, the classifier and the imputer to save
-            for future transformations. 
-        imp_method (str): The imputation techinque to apply, can either be 'KNN' for k-nearest
-            neighbors imputation, or...?. Defaults to 'KNN'.
-        n_iter (int): The maximum number of iterations to perform during 
-            the hyperparameter search. Defaults to 25. 
-        boruta_trials (int): The number of trials to run when running Boruta for
-            feature selection. Set to 0 for no feature selection. Defaults to 50.
-        boruta_model (str): The ensemble to use when calculating the feature importance
-            to be utilized by the Boruta algorithm. Can either be 'rf' or 'xgb'. Note
-            that this does not have to be the same as the machine learning classifier, clf.
-        balance (bool, optional): If True, a weights array will be calculated and used
-            when fitting the classifier. This can improve classification when classes
-            are imbalanced. This is only applied if the classification is a binary task. 
-            Defaults to True.        
+        limit_search (bool): If False, the search space for the parameters will be expanded,
+            as there are some hyperparameters that can range from 0 to inf. Defaults to True to
+            limit the search and speed up the optimization routine.
+        impute (bool): If True data imputation will be performed to replace NaN values. Defaults to False.
+            If set to True, the imputer attribute will be saved for future transformations. 
+        imp_method (str, optional): Imputation strategy to use if impute is set to True.
+            Defaults to 'knn'. The imputation methods supported include:
+            ('knn'): Fill missing values using k-Nearest Neighbor imputation.
+            ('mean'): Fill missing values with the mean of the non-missing values in the same column.
+            ('median'): Fill missing values with the median of the non-missing values in the same column.
+            ('mode'): Fill missing values with the mode (most frequent value) of the non-missing values in the same column.
+            ('constant'): Fill missing values with a constant value provided by the user.
+        n_iter (int): The maximum number of iterations to perform during the hyperparameter search. 
+            Defaults to 25. Can be set to 0 to avoid this optimization routine.
+        boruta_trials (int): The number of trials to run when running Boruta for feature selection. 
+            Can be set to 0 for no feature selection. Defaults to 50.
+        boruta_model (str): The ensemble algorithm to use when calculating the feature importance metrics
+            for the features, which is utilized by the Boruta algorithm to construct the distributions. 
+            Can either be 'rf' or 'xgb'. In practice setting this to 'xgb' will result in a more agressive 
+            feature selection. Defaults to 'rf'.
+        balance (bool, optional): If True, a weights array will be calculated and used when fitting the classifier. 
+            This can improve classification when classes are imbalanced and is ignored otherwise. This is only applied if 
+            the classification is a binary task. Defaults to True.        
         csv_file (DataFrame, optional): The csv file output after generating the training set. This can be
-            input in lieu of the data_x and data_y arguments.
+            input in lieu of the data_x and data_y arguments. Note that the csv_file must have a "label" column,
+            and is intended to be used after executing the MicroLIA.training_set routine.
     """
 
     def __init__(self, data_x=None, data_y=None, clf='rf', optimize=False, opt_cv=10, 
-        limit_search=True, impute=True, imp_method='KNN', n_iter=25, 
+        limit_search=True, impute=False, imp_method='knn', n_iter=25, 
         boruta_trials=50, boruta_model='rf', balance=True, csv_file=None):
 
         self.data_x = data_x
         self.data_y = data_y
         self.clf = clf
         self.optimize = optimize 
         self.opt_cv = opt_cv 
@@ -104,37 +111,41 @@
             self.data_y = csv_file.label
             print('Successfully loaded the data_x and data_y arrays from the input csv_file!')
         else:
             if self.data_x is None or self.data_y is None:
                 print('NOTE: data_x and data_y parameters are required to output visualizations.')
         
         if self.data_y is not None:
-            self.data_y_ = copy.deepcopy(self.data_y) #For plotting purposes, save the original label array as it will be overwrite with the numerical labels when plotting only
+            self.data_y_ = copy.deepcopy(self.data_y) #For plotting purposes, save the original label array as it will be overwritten with the numerical labels when plotting
             if self.clf == 'xgb':
                 if all(isinstance(val, (int, str)) for val in self.data_y):
                     print('XGBoost classifier requires numerical class labels! Converting class labels as follows:')
                     print('________________________________')
                     y = np.zeros(len(self.data_y))
                     for i in range(len(np.unique(self.data_y))):
                         print(str(np.unique(self.data_y)[i]).ljust(10)+'  ------------->     '+str(i))
                         index = np.where(self.data_y == np.unique(self.data_y)[i])[0]
                         y[index] = i
                     self.data_y = y 
                     print('________________________________')
         else:
             self.data_y_ = None 
 
-    def create(self):
+    def create(self, overwrite_training=False):
         """
         Creates the machine learning engine, current options are either a
         Random Forest, XGBoost, or a Neural Network classifier. 
+
+        overwrite_training (bool): Whether to replace the original input data_x with the pre-processed
+            data_x. Defaults to False. 
         
         Returns:
             Trained and optimized classifier.
         """
+
         if self.optimize is False:
             if len(np.unique(self.data_y)) == 2:
                 counter = Counter(self.data_y)
                 if counter[np.unique(self.data_y)[0]] != counter[np.unique(self.data_y)[1]]:
                     if self.balance: #If balance is True but optimize is False
                         print('Unbalanced dataset detected, to apply weights set optimize=True.')
 
@@ -150,67 +161,72 @@
                 y = np.zeros(len(self.data_y))
                 for i in range(len(np.unique(self.data_y))):
                     print(str(np.unique(self.data_y)[i]).ljust(10)+'  ------------->     '+str(i))
                     index = np.where(self.data_y == np.unique(self.data_y)[i])[0]
                     y[index] = i
                 self.data_y = y 
                 print('________________________________')
-
+        elif self.clf == 'ocsvm':
+            if self.data_y is not None:
+                if len(np.unique(self.data_y)) != 1:
+                    raise ValueError('The clf parameter has been set to "ocsvm" but OneClassSVM requires that only the positive class be input!')
+            model = OneClassSVM()
         else:
-            raise ValueError('clf argument must either be "rf", "nn", or "xgb".')
+            raise ValueError('clf argument must either be "rf", "nn", "ocsvm", or "xgb".')
         
+        self.data_x[np.isinf(self.data_x)] = np.nan
+
         if self.impute is False and self.optimize is False:
+            data = copy.deepcopy(self.data_x)
+            data[data>1e7], data[(data<1e-7)&(data>0)], data[data<-1e7] = 1e7, 1e-7, -1e7
             if np.any(np.isfinite(self.data_x)==False):
                 raise ValueError('data_x array contains nan values but impute is set to False! Set impute=True and run again.')
             print("Returning base {} model...".format(self.clf))
-            model.fit(self.data_x, self.data_y)
+            model.fit(data, self.data_y)
             self.model = model
+            self.data_x = data if overwrite_training else self.data_x
+
             return
 
         if self.impute:
-            if self.imp_method == 'KNN':
-                data, self.imputer = KNN_imputation(data=self.data_x, imputer=None)
-            else:
-                raise ValueError('Invalid imputation method, currently only k-NN is supported.')
-            
+            data, self.imputer = impute_missing_values(self.data_x, strategy=self.imp_method)
+            data[data>1e7], data[(data<1e-7)&(data>0)], data[data<-1e7] = 1e7, 1e-7, -1e7
             if self.optimize is False:
-                data[data>1e7], data[(data<1e-7)&(data>0)], data[data<-1e7] = 1e7, 1e-7, -1e7
                 print("Returning base {} model...".format(self.clf))
                 model.fit(data, self.data_y)
                 self.model = model 
+                self.data_x = data if overwrite_training else self.data_x
+
                 return
-                
         else:
-            data = self.data_x[:]
+            data = copy.deepcopy(self.data_x)
             data[data>1e7], data[(data<1e-7)&(data>0)], data[data<-1e7] = 1e7, 1e-7, -1e7
 
         if self.feats_to_use is None:
             self.feats_to_use, self.feature_history = borutashap_opt(data, self.data_y, boruta_trials=self.boruta_trials, model=self.boruta_model)
             if len(self.feats_to_use) == 0:
                 print('No features selected, increase the number of n_trials when running MicroLIA.optimization.borutashap_opt(). Using all features...')
                 self.feats_to_use = np.arange(data.shape[1])
         else:
-            print('feats_to_use attribute already exists, skipping feature selection...')
+            print('The feats_to_use attribute already exists, skipping feature selection...')
 
-        #Re-construct the imputer with the selected features as
-        #new predictions will only compute these metrics, need to fit again!
-        if self.imp_method == 'KNN':
-            data_x, self.imputer = KNN_imputation(data=self.data_x[:,self.feats_to_use], imputer=None)
-        else: 
-            data_x = self.data_x[:,self.feats_to_use]
+        #Re-construct the imputer with the selected features as new predictions will only compute these metrics, so need to fit again!
+        data_x, self.imputer = impute_missing_values(self.data_x[:,self.feats_to_use], strategy=self.imp_method) if self.impute else self.data_x[:,self.feats_to_use]
 
         if self.n_iter > 0:
-            self.model, self.best_params, self.optimization_results = hyper_opt(data_x, self.data_y, clf=self.clf, n_iter=self.n_iter, 
-                balance=self.balance, return_study=True, limit_search=self.limit_search, opt_cv=self.opt_cv)
+            self.model, self.best_params, self.optimization_results = hyper_opt(data_x, self.data_y, clf=self.clf, n_iter=self.n_iter, balance=self.balance, 
+                return_study=True, limit_search=self.limit_search, opt_cv=self.opt_cv)
         else:
             print("Fitting and returning final model...")
-            self.model = hyper_opt(data_x, self.data_y, clf=self.clf, n_iter=self.n_iter, 
-                balance=self.balance, return_study=True, limit_search=self.limit_search, opt_cv=self.opt_cv)
+            self.model = hyper_opt(data_x, self.data_y, clf=self.clf, n_iter=self.n_iter, balance=self.balance, return_study=True, limit_search=self.limit_search, opt_cv=self.opt_cv)
 
         self.model.fit(data_x, self.data_y)
+        self.data_x = data_x if overwrite_training else self.data_x
+
+        return
         
     def save(self, dirname=None, path=None, overwrite=False):
         """
         Saves the trained classifier in a new directory named 'MicroLIA_ensemble_model', 
         as well as the imputer and the features to use attributes, if not None.
         
         Args:
@@ -220,33 +236,31 @@
             path (str): Absolute path where the data folder will be saved
                 Defaults to None, in which case the directory is saved to the
                 local home directory.
             overwrite (bool, optional): If True the 'MicroLIA_ensemble_model' folder this
                 function creates in the specified path will be deleted if it exists
                 and created anew to avoid duplicate files. 
         """
+
         if self.model is None and self.imputer is None and self.feats_to_use is None:
             raise ValueError('The models have not been created! Run the create() method first.')
 
-        if path is None:
-            path = str(Path.home())
-        if path[-1] != '/':
-            path+='/'
-
+        path = str(Path.home()) if path is None else path 
+        path = path + '/' if path[-1] != '/' else path 
+        
         if dirname is not None:
-            if dirname[-1] != '/':
-                dirname+='/'
-            path = path+dirname
+            dirname = dirname + '/' if dirname[-1] != '/' else dirname
+            path = path + dirname
             try:
                 os.makedirs(path)
             except FileExistsError:
                 raise ValueError('The dirname folder already exists!')
 
         try:
-            os.mkdir(path+'MicroLIA_ensemble_model')
+            os.mkdir(path + 'MicroLIA_ensemble_model')
         except FileExistsError:
             if overwrite:
                 try:
                     os.rmdir(path+'MicroLIA_ensemble_model')
                 except OSError:
                     for file in os.listdir(path+'MicroLIA_ensemble_model'):
                         os.remove(path+'MicroLIA_ensemble_model/'+file)
@@ -264,14 +278,15 @@
             joblib.dump(self.feats_to_use, path+'Feats_Index')
         if self.optimization_results is not None:
             joblib.dump(self.optimization_results, path+'HyperOpt_Results')
         if self.best_params is not None:
             joblib.dump(self.best_params, path+'Best_Params')
         if self.feature_history is not None:
             joblib.dump(self.feature_history, path+'FeatureOpt_Results')
+
         print('Files saved in: {}'.format(path))
 
         self.path = path
 
         return 
 
     def load(self, path=None):
@@ -282,19 +297,16 @@
 
         Args:
             path (str): Path where the directory 'MicroLIA_models' is saved. 
                 Defaults to None, in which case the folder is assumed to be in the 
                 local home directory.
         """
 
-        if path is None:
-            path = str(Path.home())
-        if path[-1] != '/':
-            path+='/'
-
+        path = str(Path.home()) if path is None else path 
+        path = path+'/' if path[-1] != '/' else path 
         path += 'MicroLIA_ensemble_model/'
 
         try:
             self.model = joblib.load(path+'Model')
             model = 'model'
         except FileNotFoundError:
             model = ''
@@ -357,43 +369,42 @@
                 to flux. Defaults to 24.
 
         Returns:
             Array containing the classes and the corresponding probability predictions.
         """
 
         if len(mag) < 30:
-            warn('The number of data points is low -- results may be unstable')
+            warn('The number of data points is low -- results may be unstable!')
 
         #classes = ['CONSTANT', 'CV', 'LPV', 'ML', 'VARIABLE']
         classes = self.model.classes_
         stat_array=[]
         
         if self.imputer is None and self.feats_to_use is None:
             stat_array.append(extract_features.extract_all(time, mag, magerr, convert=convert, apply_weights=apply_weights, zp=zp))
             pred = self.model.predict_proba(stat_array)
             return np.c_[classes, pred[0]]
         
-        stat_array.append(extract_features.extract_all(time, mag, magerr, convert=convert, apply_weights=apply_weights, zp=zp, feats_to_use=self.feats_to_use))
-        
-        if self.imputer is not None:
-            stat_array = self.imputer.transform(stat_array)
+        stat_array.append(extract_features.extract_all(time, mag, magerr, convert=convert, apply_weights=apply_weights, zp=zp, feats_to_use=self.feats_to_use))        
+        stat_array = self.imputer.transform(stat_array) if self.imputer is not None else stat_array
+
         pred = self.model.predict_proba(stat_array)
 
         return np.c_[classes, pred[0]]
 
     def plot_tsne(self, data_y=None, special_class=None, norm=True, pca=False, 
         legend_loc='upper center', title='Feature Parameter Space', savefig=False):
         """
         Plots a t-SNE projection using the sklearn.manifold.TSNE() method.
 
         Note:
             To highlight individual samples, use the data_y optional input
             and set that sample's data_y value to a unique name, and set that 
-            same label in the special_class variable so that it can be visualized 
-            clearly.
+            same label in the special_class variable so that it can be highlighted 
+            clearly in the plot.
 
         Args:
             data_y (ndarray, optional): A custom labels array, that coincides with
                 the labels in model.data_y. Defaults to None, in which case the
                 model.data_y labels are used.
             special_class (optional): The class label that you wish to highlight,
                 setting this optional parameter will increase the size and alpha parameter
@@ -409,46 +420,35 @@
                 Defaults to False. 
 
         Returns:
             AxesImage. 
         """
 
         if self.feats_to_use is not None:
-            if len(self.data_x.shape) == 1:
-                data = self.data_x[self.feats_to_use].reshape(1,-1)
-            else:
-                data = self.data_x[:,self.feats_to_use]
+            data = self.data_x[self.feats_to_use].reshape(1,-1) if len(self.data_x.shape) == 1 else self.data_x[:,self.feats_to_use] 
         else:
-            data = self.data_x[:]
+            data = copy.deepcopy(self.data_x)
 
         if np.any(np.isnan(data)):
-            #print('Automatically imputing NaN values with KNN imputation...')
-            if self.imputer is not None and self.imp_method == 'KNN':
-                data = KNN_imputation(data=data, imputer=self.imputer)
-            else:
-                data = KNN_imputation(data=data)[0]
-
+            data = impute_missing_values(data, self.imputer) if self.imputer is not None else impute_missing_values(data, strategy=self.imp_method)[0]
+            
         data[data>1e7], data[(data<1e-7)&(data>0)], data[data<-1e7] = 1e7, 1e-7, -1e7
         
-        if len(data) > 5e3:
-            method = 'barnes_hut' #Scales with O(N)
-        else:
-            method = 'exact' #Scales with O(N^2)
-
+        method = 'barnes_hut' if len(data) > 5e3 else 'exact' #bh Scales with O(N), exact scales with O(N^2)
+        
         if norm:
             scaler = MinMaxScaler()
             data = scaler.fit_transform(data)
 
         if pca:
             pca_transformation = decomposition.PCA(n_components=data.shape[1], whiten=True, svd_solver='auto')
             pca_transformation.fit(data) 
             data = pca_transformation.transform(data)
 
-        feats = TSNE(n_components=2, method=method, learning_rate=1000, 
-            perplexity=35, init='random').fit_transform(data)
+        feats = TSNE(n_components=2, method=method, learning_rate=1000, perplexity=35, init='random').fit_transform(data)
         x, y = feats[:,0], feats[:,1]
      
         markers = ['o', 's', '+', 'v', '.', 'x', 'h', 'p', '<', '>', '*']
         #color = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'b', 'g', 'r', 'c']
         color = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628', '#f781bf', '#e41a1c', '#377eb8'] #Update the last two!
 
         if data_y is None:
@@ -461,19 +461,27 @@
                         if isinstance(data_y, np.ndarray) is False: 
                             if type(data_y) == list:
                                 data_y = np.array(data_y)
                             else:
                                 raise ValueError('data_y argument must either be a list or an array!')
                         feats = np.unique(data_y)
                 else:
-                    data_y = np.array(self.csv_file.label)
-                    feats = np.unique(data_y)
+                    if len(self.csv_file) == len(self.data_y):
+                        data_y = np.array(self.csv_file.label)
+                        feats = np.unique(data_y)
+                    else:
+                        data_y = self.data_y
+                        feats = np.unique(self.data_y)
             else:
-                data_y = self.data_y_ 
-                feats = np.unique(self.data_y_)
+                if len(self.data_y_) == len(self.data_y):
+                    data_y = self.data_y_ 
+                    feats = np.unique(self.data_y_)
+                else:
+                    data_y = self.data_y
+                    feats = np.unique(self.data_y)
         else:
             if isinstance(data_y, list):
                 data_y = np.array(data_y)
             feats = np.unique(data_y) 
 
         for count, feat in enumerate(feats):
             if count+1 > len(markers):
@@ -486,27 +494,27 @@
 
         if special_class is not None:
             mask = np.where(data_y == special_class)[0]
             if len(mask) == 0:
                 raise ValueError('The data_y array does not contain the value input in the special_class parameter.')
             plt.scatter(x[mask], y[mask], marker='*', c='red', label=special_class, s=200, alpha=1.0)
         
-        plt.legend(loc=legend_loc, ncol=len(np.unique(data_y)), frameon=False, handlelength=2)#prop={'size': 14}
-        plt.title(title)#, size=18)
-        plt.xticks()#fontsize=14)
-        plt.yticks()#fontsize=14)
-        plt.ylabel('t-SNE Dimension 1')
-        plt.xlabel('t-SNE Dimension 2')
+        plt.legend(loc=legend_loc, ncol=len(np.unique(data_y)), frameon=False, handlelength=2)
+        plt.title(title); plt.ylabel('t-SNE Dimension 1'); plt.xlabel('t-SNE Dimension 2')
+        plt.xticks(); plt.yticks()
 
         if savefig:
+            _set_style_()
             plt.savefig('tSNE_Projection.png', bbox_inches='tight', dpi=300)
-            plt.clf()
+            plt.clf(); plt.style.use('default')
         else:
             plt.show()
 
+        return
+
     def plot_conf_matrix(self, data_y=None, norm=False, pca=False, k_fold=10, normalize=True, 
         title='Confusion Matrix', savefig=False):
         """
         Returns a confusion matrix with k-fold validation.
 
         Args:
             data_y (ndarray, str, optional): 1D array containing the corresponing labels.
@@ -524,20 +532,22 @@
                 all k_fold iterations. Defaults to 10.
             normalize (bool, optional): If False the confusion matrix will display the
                 total number of objects in the sample. Defaults to True, in which case
                 the values are normalized between 0 and 1.
             title (str): Title of the figure.
             savefig (bool): If True the figure will not disply but will be saved instead.
                 Defaults to False. 
+
         Returns:
             AxesImage.
         """
 
         if self.data_x is None or self.data_y is None:
-            raise ValueError('Input data_x and data_y!')
+            raise ValueError('The data_x and data_y have not been input!')
+
         if self.model is None:
             raise ValueError('No model has been created! Run .create() first.')
 
         if data_y is not None:
             classes = [str(label) for label in np.unique(data_y)]
         else:
             if self.data_y_ is None:
@@ -550,23 +560,19 @@
 
         if self.feats_to_use is not None:
             if len(self.data_x.shape) == 1:
                 data = self.data_x[self.feats_to_use].reshape(1,-1)
             else:
                 data = self.data_x[:,self.feats_to_use]
         else:
-            data = self.data_x[:]
+            data = copy.deepcopy(self.data_x)
 
         if np.any(np.isnan(data)):
-            #print('Automatically imputing NaN values with KNN imputation...')
-            if self.imputer is not None and self.imp_method == 'KNN':
-                data = KNN_imputation(data=data, imputer=self.imputer)
-            else:
-                data = KNN_imputation(data=data)[0]
-
+            data = impute_missing_values(data, self.imputer) if self.imputer is not None else impute_missing_values(data, strategy=self.imp_method)[0]
+          
         data[data>1e7], data[(data<1e-7)&(data>0)], data[data<-1e7] = 1e7, 1e-7, -1e7
 
         if norm:
             scaler = MinMaxScaler()
             scaler.fit_transform(data)
 
         if pca:
@@ -581,161 +587,127 @@
     def plot_roc_curve(self, k_fold=10, pca=False, title="Receiver Operating Characteristic Curve", 
         savefig=False):
         """
         Plots ROC curve with k-fold cross-validation, as such the 
         standard deviation variations are also plotted.
         
         Args:
-            classifier: The machine learning classifier to optimize.
-            data_x (ndarray): 2D array of size (n x m), where n is the
-                number of samples, and m the number of features.
-            data_y (ndarray, str): 1D array containing the corresponing labels.
             k_fold (int, optional): The number of cross-validations to perform.
                 The output confusion matrix will display the mean accuracy across
                 all k_fold iterations. Defaults to 10.
+            pca (bool): If True the data will be fit to a Principal Component
+                Analysis and all of the corresponding principal components will 
+                be used to evaluate the classifier and construct the matrix. 
+                Defaults to False.
             title (str, optional): The title of the output plot.
-            savefig (bool): If True the figure will not disply but will be saved instead.
-                Defaults to False. 
-        
+            savefig (bool): If True the figure will not disply but will be saved instead. Defaults to False. 
+            
         Returns:
             AxesImage
         """
+
         if self.model is None:
             raise ValueError('No model has been created! Run model.create() first.')
 
         if self.feats_to_use is not None:
-            if len(self.data_x.shape) == 1:
-                data = self.data_x[self.feats_to_use].reshape(1,-1)
-            else:
-                data = self.data_x[:,self.feats_to_use]
+            data = self.data_x[self.feats_to_use].reshape(1,-1) if len(self.data_x.shape) == 1 else self.data_x[:,self.feats_to_use]
         else:
-            data = self.data_x[:]
+            data = copy.deepcopy(self.data_x)
 
         if np.any(np.isnan(data)):
-            print('Automatically imputing NaN values with KNN imputation...')
-            if self.imputer is not None and self.imp_method == 'KNN':
-                data = KNN_imputation(data=data, imputer=self.imputer)
-            else:
-                data = KNN_imputation(data=data)[0]
-
+            data = impute_missing_values(data, self.imputer) if self.imputer is not None else impute_missing_values(data, strategy=self.imp_method)[0]
+          
         data[data>1e7], data[(data<1e-7)&(data>0)], data[data<-1e7] = 1e7, 1e-7, -1e7
 
         if pca:
             pca_transformation = decomposition.PCA(n_components=data.shape[1], whiten=True, svd_solver='auto')
             pca_transformation.fit(data) 
             pca_data = pca_transformation.transform(data)
             data = np.asarray(pca_data).astype('float64')
         
-        model0 = self.model
+        model0 = copy.deepcopy(self.model)
+
         if len(np.unique(self.data_y)) != 2:
-            X_train, X_test, y_train, y_test = train_test_split(data, self.data_y, test_size=0.2, random_state=0)
+            test_size = 1. / k_fold
+            X_train, X_test, y_train, y_test = train_test_split(data, self.data_y, test_size=test_size, random_state=0)
             model0.fit(X_train, y_train)
             y_probas = model0.predict_proba(X_test)
-            skplt.metrics.plot_roc(y_test, y_probas, text_fontsize='large', title='ROC Curve', cmap='cividis', plot_macro=False, plot_micro=False)
-            plt.show()
-            return
+            plot_roc(y_test, y_probas, text_fontsize='large', title='ROC Curve', cmap='nipy_spectral', plot_macro=False, plot_micro=False)
+            
+            if savefig:
+                _set_style_()
+                plt.savefig('Ensemble_ROC_Curve.png', bbox_inches='tight', dpi=300)
+                plt.clf(); plt.style.use('default')
+            else:
+                plt.show()
 
+            return 
+            
         cv = StratifiedKFold(n_splits=k_fold)
         
-        tprs = []
-        aucs = []
+        tprs, aucs = [], []
         mean_fpr = np.linspace(0, 1, 100)
 
-        train = data
         fig, ax = plt.subplots()
 
-        for i, (data_x, test) in enumerate(cv.split(train, self.data_y)):
-            model0.fit(train[data_x], self.data_y[data_x])
-            viz = RocCurveDisplay.from_estimator(
-                model0,
-                train[test],
-                self.data_y[test],
-                alpha=0,#0.3,
-                lw=1,
-                ax=ax,
-                name="ROC fold {}".format(i+1),
-            )
+        for i, (data_x, test) in enumerate(cv.split(data, self.data_y)):
+            model0.fit(data[data_x], self.data_y[data_x])
+            viz = RocCurveDisplay.from_estimator(model0, data[test], self.data_y[test], alpha=0, lw=1, ax=ax, name="ROC fold {}".format(i+1))
             interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)
             interp_tpr[0] = 0.0
-            tprs.append(interp_tpr)
-            aucs.append(viz.roc_auc)
+            tprs.append(interp_tpr); aucs.append(viz.roc_auc)
 
         mean_tpr = np.mean(tprs, axis=0)
         mean_tpr[-1] = 1.0
-        mean_auc = auc(mean_fpr, mean_tpr)
-        std_auc = np.std(aucs)
-        lns1, = ax.plot(
-            mean_fpr,
-            mean_tpr,
-            color="b",
-            #label=r"Mean ROC (AUC = %0.2f $\pm$ %0.2f)" % (mean_auc, std_auc),
-            label=r"Mean (AUC = %0.2f)" % (mean_auc),
-            lw=2,
-            alpha=0.8,
-        )
+        mean_auc, std_auc = auc(mean_fpr, mean_tpr), np.std(aucs)
+        lns1, = ax.plot(mean_fpr, mean_tpr, color="b", label=r"Mean (AUC = %0.2f)" % (mean_auc), lw=2, alpha=0.8) #label=r"Mean ROC (AUC = %0.2f $\pm$ %0.2f)" % (mean_auc, std_auc),
 
         std_tpr = np.std(tprs, axis=0)
-        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
-        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
-        lns_sigma = ax.fill_between(
-            mean_fpr,
-            tprs_lower,
-            tprs_upper,
-            color="grey",
-            alpha=0.2,
-            label=r"$\pm$ 1$\sigma$",
-        )
-
-        ax.set(
-            xlim=[0, 1.0],
-            ylim=[0.0, 1.0],
-            title="Receiver Operating Characteristic Curve",
-        )
-        
+        tprs_upper, tprs_lower = np.minimum(mean_tpr + std_tpr, 1), np.maximum(mean_tpr - std_tpr, 0)
+        lns_sigma = ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color="grey", alpha=0.2, label=r"$\pm$ 1$\sigma$")
+
+        ax.set(xlim=[0, 1.0], ylim=[0.0, 1.0], title="Receiver Operating Characteristic Curve")
         lns2, = ax.plot([0, 1], [0, 1], linestyle="--", lw=2, color="r", label="Random (AUC=0.5)", alpha=0.8)
 
-        #handles, labels = ax.get_legend_handles_labels()
-        #ax.legend(handles[-3:], labels[-3:], loc="lower center", ncol=3, frameon=False, handlelength=2)
         ax.legend([lns2, (lns1, lns_sigma)], ['Random (AUC = 0.5)', r"Mean (AUC = %0.2f)" % (mean_auc)], loc='lower center', ncol=2, frameon=False, handlelength=2)
-
+        plt.title(label=title); plt.ylabel('True Positive Rate'); plt.xlabel('False Positive Rate')
         ax.set_facecolor("white")
-        plt.ylabel('True Positive Rate')#, size=14)
-        plt.xlabel('False Positive Rate')#, size=14)
-        plt.title(label=title)#,fontsize=18)
 
         if savefig:
+            _set_style_()
             plt.savefig('Ensemble_ROC_Curve.png', bbox_inches='tight', dpi=300)
-            plt.clf()
+            plt.clf(); plt.style.use('default')
         else:
             plt.show()
 
-    def plot_hyper_opt(self, baseline=None, xlim=None, ylim=None, xlog=True, ylog=False, 
-        savefig=False):
+        return
+
+    def plot_hyper_opt(self, baseline=None, xlim=None, ylim=None, xlog=True, ylog=False, savefig=False):
         """
         Plots the hyperparameter optimization history.
+
+        Note:
+            The Optuna API has its own plot function: plot_optimization_history(self.optimization_results)
     
         Args:
             baseline (float): Baseline accuracy achieved when using only
                 the default engine hyperparameters. If input a vertical
                 line will be plot to indicate this baseline accuracy.
                 Defaults to None.
-            xlim: Limits for the x-axis. Ex) xlim = (0, 1000)
-            ylim: Limits for the y-axis. Ex) ylim = (0.9, 0.94)
-            xlog (boolean): If True the x-axis will be log-scaled.
-                Defaults to True.
-            ylog (boolean): If True the y-axis will be log-scaled.
-                Defaults to False.
+            xlim (tuple): Limits for the x-axis, e.g. xlim = (0, 1000)
+            ylim (tuple): Limits for the y-axis. e.g. ylim = (0.9, 0.94)
+            xlog (bool): If True the x-axis will be log-scaled. Defaults to True.
+            ylog (bool): If True the y-axis will be log-scaled. Defaults to False.
             savefig (bool): If True the figure will not disply but will be saved instead.
                 Defaults to False. 
 
         Returns:
             AxesImage
         """
 
-        #fig = plot_optimization_history(self.optimization_results)
         trials = self.optimization_results.get_trials()
         trial_values, best_value = [], []
         for trial in range(len(trials)):
             value = trials[trial].values[0]
             trial_values.append(value)
             if trial == 0:
                 best_value.append(value)
@@ -755,45 +727,56 @@
 
         if baseline is not None:
             plt.axhline(y=baseline, color='k', linestyle='--', label='Baseline Model')
             ncol=3
         else:
             ncol=2
 
-        plt.plot(range(len(trials)), best_value, color='r', alpha=0.83, linestyle='-', label='Best Model')
+        plt.plot(range(len(trials)), best_value, color='r', alpha=0.83, linestyle='-', label='Optimized Model')
         plt.scatter(range(len(trials)), trial_values, c='b', marker='+', s=35, alpha=0.45, label='Trial')
         plt.xlabel('Trial #', alpha=1, color='k')
-        plt.ylabel('Accuracy', alpha=1, color='k')
-       # if self.clf == 'xgb':
-        plt.title('Hyperparameter Optimization')#, size=18) Make this a f" string option!!
-        #plt.xticks(fontsize=14)#, color='k')
-        #plt.yticks(fontsize=14)#, color='k')
-        #plt.grid(True, color='k', alpha=0.35, linewidth=1.5, linestyle='--')
+
+        if self.opt_cv > 0:
+            plt.ylabel(str(self.opt_cv)+'-Fold CV Accuracy', alpha=1, color='k')
+        else:
+            plt.ylabel('Accuracy', alpha=1, color='k')
+        
+        if self.clf == 'xgb':
+            plt.title('XGBoost Hyperparameter Optimization')
+        elif self.clf == 'rf':
+            plt.title('RF Hyperparameter Optimization')
+        elif self.clf == 'ocsvm':
+            plt.title('OneClass SVM Hyperparameter Optimization')
+        elif self.clf == 'nn':
+            plt.title('Neural Network Hyperparameter Optimization')
+
+        plt.legend(loc='upper center', ncol=ncol, frameon=False)
+        plt.rcParams['axes.facecolor']='white'
         plt.grid(False)
+
         if xlim is not None:
             plt.xlim(xlim)
         else:
             plt.xlim((1, len(trials)))
         if ylim is not None:
             plt.ylim(ylim)
         if xlog:
             plt.xscale('log')
         if ylog:
             plt.yscale('log')
-        #plt.tight_layout()
-        #plt.legend(prop={'size': 12}, loc='upper left')
-        plt.legend(loc='upper center', ncol=ncol, frameon=False)#, handlelength=4)#prop={'size': 14}
-        plt.rcParams['axes.facecolor']='white'
         
         if savefig:
+            _set_style_()
             plt.savefig('Ensemble_Hyperparameter_Optimization.png', bbox_inches='tight', dpi=300)
-            plt.clf()
+            plt.clf(); plt.style.use('default')
         else:
             plt.show()
 
+        return
+
     def plot_feature_opt(self, feat_names=None, top='all', include_other=True, include_shadow=True, 
         include_rejected=False, flip_axes=True, save_data=False, savefig=False):
         """
         Returns whisker plot displaying the z-score distribution of each feature
         across all trials.
     
         Note:
@@ -802,183 +785,199 @@
             model.feature_history.plot(which_features='accepted', X_size=14)
 
             Can designate to display either 'all', 'accepted', or 'tentative'
 
         Args: 
             feat_names (ndarry, optional): A list or array containing the names
                 of the features in the data_x matrix, in order. Defaults to None,
-                in which case the respective indices will appear instead.
+                in which case the respective indices will appear instead. Can be set to
+                'default' which will the features in MicroLIA.features module, so only to be used
+                if all the features were extracted using MicroLIA.extract_features.
             top (float, optional): Designates how many features to plot. If set to 3, it 
                 will plot the top 3 performing features. Can be 'all' in which casee all features
                 that were accepted are plotted. Defaults to 'all'.
             include_other (bool): Whether to include the features that are not in the top designation,
                 if True these features will be averaged out and displayed. Defaults to True.
-            include_shadow (bool): Whether to include the max shadow feature that was used as a 
+            include_shadow (bool): Whether to include the mean shadow feature that was used as a 
                 baseline for 'random' behavior. Defaults to True.
-            include_rejected (bool): Whether to include the rejected features, if True these features 
-                will be averaged out and displayed.
+            include_rejected (bool): Whether to include the rejected features, if False these features 
+                will not be shown. If set to True or 'all', all the rejected features will show. If set to
+                a number, only the designated top rejected features will show. Defaults to False.
             flip_axes (bool): Whether transpose the figure. Defaults to True.
             save_data (bool): Whether to save the feature importances as a csv file, defaults to False.
             savefig (bool): If True the figure will not disply but will be saved instead.
                 Defaults to False. 
 
         Returns:
             AxesImage
         """
 
-        fname = str(Path.home())+'/__borutaimportances__' #Temporary file
+        if feat_names is None and self.csv_file is not None:
+            feat_names = self.csv_file.columns[:-1]
+
+        if feat_names == 'default':
+            feat_names = ['Anderson-Darling', 'FluxPctRatioMid20', 'FluxPctRatioMid35', 'FluxPctRatioMid50', 'FluxPctRatioMid65', 'FluxPctRatioMid80', 
+                'Median-Based Skew', 'Linear Trend', 'Max Slope', 'Pair Slope Trend', 'Percent Amp.', 'Percent DiffFluxPct', 'Above 1', 'Above 3', 
+                'Above 5', 'Abs. Energy', 'Abs. Sum Changes', 'Amplitude', 'Autocorrelation', 'Below 1', 'Below 3', 'Below 5', 'Benford Correlation', 
+                'C3 Non-Linearity', 'Dup. Val. Check', 'Max Val. Dup. Check', 'Min. Val. Dup. Check', 'Max. Last Loc. Check', 'Min. Last Loc. Check', 
+                'Complexity', 'Consec. Cluster Count', 'Num. Points Above', 'Num. Points Below', 'Cumulative Sum', 'First Loc. Max', 'First Loc. Min', 
+                'Half Mag. Amp. Ratio', 'Mass Quant. Index', 'Integration', 'Kurtosis', 'Large Std. Dev.', 'Longest Strike Above', 'Longest Strike Below', 
+                'Mean Magnitude', 'Mean Abs. Change', 'Mean Change', 'Mean of Abs. Maxima', 'Mean Second Deriv.', 'Median Abs. Dev.', 'Median Buffer Range', 
+                'Median Distance', 'Num. CWT Peaks', 'Num. Crossings', 'Num. Peaks', 'Peaks Detection', 'Permutation Entropy', 'Quantile', 'Recurring Pts. Ratio', 
+                'Root Mean Squared', 'Sample Entropy', 'Shannon Entropy', 'Shapiro-Wilk', 'Skewness', 'Std. Dev. over Mean', 'Stetson J', 'Stetson K', 'Stetson L', 
+                'Sum of Vals.', 'Symmetry Looking', 'Time Reversal Asym.', 'Variance', 'Var. Exceeds Std. Dev.', 'Variation Coeff.', 'vonNeumannRatio', 
+                'Deriv-Anderson-Darling', 'Deriv-FluxPctRatioMid20', 'Deriv-FluxPctRatioMid35', 'Deriv-FluxPctRatioMid50', 'Deriv-FluxPctRatioMid65', 'Deriv-FluxPctRatioMid80', 
+                'Deriv-Median-Based Skew', 'Deriv-Linear Trend', 'Deriv-Max Slope', 'Deriv-Pair Slope Trend', 'Deriv-Percent Amp.', 'Deriv-Percent DiffFluxPct', 'Deriv-Above 1', 'Deriv-Above 3', 
+                'Deriv-Above 5', 'Deriv-Abs. Energy', 'Deriv-Abs. Sum Changes', 'Deriv-Amplitude', 'Deriv-Autocorrelation', 'Deriv-Below 1', 'Deriv-Below 3', 'Deriv-Below 5', 'Deriv-Benford Correlation', 
+                'Deriv-C3 Non-Linearity', 'Deriv-Dup. Val. Check', 'Deriv-Max Val. Dup. Check', 'Deriv-Min. Val. Dup. Check', 'Deriv-Max. Last Loc. Check', 'Deriv-Min. Last Loc. Check', 
+                'Deriv-Complexity', 'Deriv-Consec. Cluster Count', 'Deriv-Num. Points Above', 'Deriv-Num. Points Below', 'Deriv-Cumulative Sum', 'Deriv-First Loc. Max', 'Deriv-First Loc. Min', 
+                'Deriv-Half Mag. Amp. Ratio', 'Deriv-Mass Quant. Index', 'Deriv-Integration', 'Deriv-Kurtosis', 'Deriv-Large Std. Dev.', 'Deriv-Longest Strike Above', 'Deriv-Longest Strike Below', 
+                'Deriv-Mean Magnitude', 'Deriv-Mean Abs. Change', 'Deriv-Mean Change', 'Deriv-Mean of Abs. Maxima', 'Deriv-Mean Second Deriv.', 'Deriv-Median Abs. Dev.', 'Deriv-Median Buffer Range', 
+                'Deriv-Median Distance', 'Deriv-Num. CWT Peaks', 'Deriv-Num. Crossings', 'Deriv-Num. Peaks', 'Deriv-Peaks Detection', 'Deriv-Permutation Entropy', 'Deriv-Quantile', 'Deriv-Recurring Pts. Ratio', 
+                'Deriv-Root Mean Squared', 'Deriv-Sample Entropy', 'Deriv-Shannon Entropy', 'Deriv-Shapiro-Wilk', 'Deriv-Skewness', 'Deriv-Std. Dev. over Mean', 'Deriv-Stetson J', 'Deriv-Stetson K', 'Deriv-Stetson L', 
+                'Deriv-Sum of Vals.', 'Deriv-Symmetry Looking', 'Deriv-Time Reversal Asym.', 'Deriv-Variance', 'Deriv-Var. Exceeds Std. Dev.', 'Deriv-Variation Coeff.', 'Deriv-vonNeumannRatio']
+
+        fname = str(Path.home()) + '/__borutaimportances__' #Temporary file
+
         try:
             self.feature_history.results_to_csv(filename=fname)
         except AttributeError:
             raise ValueError('No optimization history found for feature selection, run .create() with optimize=True!')
 
         csv_data = pd.read_csv(fname+'.csv')
-        #os.remove(fname+'.csv')
+        if save_data is False:
+            os.remove(fname+'.csv')
+
         accepted_indices = np.where(csv_data.Decision == 'Accepted')[0]
         if top == 'all':
             top = len(accepted_indices)
         else:
             if top > len(accepted_indices):
                 top = len(accepted_indices)
                 print('The top parameter exceeds the number of accepted variables, setting to the maximum value of {}'.format(str(top)))
 
         x, y, y_err = [], [], []
 
         for i in accepted_indices[:top]:
-            if feat_names is None:
-                if self.csv_file is None:
-                    x.append(int(i))
-                else:
-                    x.append(int(csv_data.iloc[i].Features))
-            else:
-                x.append(int(csv_data.iloc[i].Features))
+            x.append(int(csv_data.iloc[i].Features))
             y.append(float(csv_data.iloc[i]['Average Feature Importance']))
             y_err.append(float(csv_data.iloc[i]['Standard Deviation Importance']))
-            
-        if len(accepted_indices) == top:
-            include_other = False
+
+        include_other = False if len(accepted_indices) == top else include_other
 
         if include_other:
             mean, std = [], []
-            for j in accepted_indices[top:]:
-                mean.append(float(csv_data.iloc[j]['Average Feature Importance']))
-                std.append(float(csv_data.iloc[j]['Standard Deviation Importance']))
+            for i in accepted_indices[top:]:
+                mean.append(float(csv_data.iloc[i]['Average Feature Importance']))
+                std.append(float(csv_data.iloc[i]['Standard Deviation Importance']))
             x.append(0), y.append(np.mean(mean)), y_err.append(np.mean(std))
 
         if include_shadow:
-            ix = np.where(csv_data.Features == 'Max_Shadow')[0]
+            ix = np.where(csv_data.Features == 'Mean_Shadow')[0]
             y.append(float(csv_data.iloc[ix]['Average Feature Importance']))
             y_err.append(float(csv_data.iloc[ix]['Standard Deviation Importance']))
-            x.append(int(ix))
+            x.append(0) #Just a placeholder
 
         if feat_names is not None:  
-            if isinstance(feat_names, np.ndarray) is False: 
-                feat_names = np.array(feat_names)
+            feat_names = np.array(feat_names) if isinstance(feat_names, np.ndarray) is False else feat_names
             if include_shadow is False:
-                if include_other is False:
-                    x_names = feat_names[x] #By default x is the index of the feature
-                else:
-                    x_names = np.r_[feat_names[x[:-1]], ['Other Accepted']]
+                x_names = feat_names[x] if include_other is False else np.r_[feat_names[x[:-1]], ['Other Accepted']] #By default x is the index of the feature
             else:
-                if include_other is False:
-                    x_names = np.r_[feat_names[x[:-1]], ['Max Shadow']]
-                else:
-                    x_names = np.r_[feat_names[x[:-2]], ['Other Accepted'], ['Max Shadow']]
+                x_names = np.r_[feat_names[x[:-1]], ['Mean Shadow']] if include_other is False else np.r_[feat_names[x[:-2]], ['Other Accepted'], ['Mean Shadow']]
         else:
-            if self.csv_file is None:
-                if include_other is False:
-                    if include_shadow is False:
-                        x_names = csv_data.iloc[x].Features
-                    else:
-                        x_names = np.r_[csv_data.iloc[x[:-1]].Features, ['Max Shadow']]
-                else:
-                    if include_shadow is False:
-                        x_names = np.r_[csv_data.iloc[x[:-1]].Features, ['Max Shadow']]
-                    else:
-                        x_names = np.r_[csv_data.iloc[x[:-2]].Features, ['Other Accepted'], ['Max Shadow']]
+            if include_other is False:
+                x_names = csv_data.iloc[x].Features if include_shadow is False else np.r_[csv_data.iloc[x[:-1]].Features, ['Mean Shadow']]
             else:
-                if include_other is False:
-                    if include_shadow is False:
-                        x_names = self.csv_file.columns[x[:-1]]
-                    else:
-                        x_names = np.r_[self.csv_file.columns[x[:-1]], ['Max Shadow']]
-                else:
-                    if include_shadow is False:
-                        x_names = np.r_[self.csv_file.columns[x[:-1]], ['Max Shadow']]
-                    else:
-                        x_names = np.r_[self.csv_file.columns[x[:-2]], ['Other Accepted'], ['Max Shadow']]
+                x_names = np.r_[csv_data.iloc[x[:-1]].Features, ['Other Accepted']] if include_shadow is False else np.r_[csv_data.iloc[x[:-2]].Features, ['Other Accepted'], ['Mean Shadow']]
+        
 
-        if include_rejected:
+        if include_rejected is not False:
             x = []
             rejected_indices = np.where(csv_data.Decision == 'Rejected')[0]
-            for i in rejected_indices:
-                if feat_names is None:
-                    if self.csv_file is None:
-                        x.append(int(i))
-                    else:
-                        x.append(int(csv_data.iloc[i].Features))
-                else:
+            if include_rejected == 'all' or include_rejected == True:
+                for i in rejected_indices:
                     x.append(int(csv_data.iloc[i].Features))
-                y.append(float(csv_data.iloc[i]['Average Feature Importance']))
-                y_err.append(float(csv_data.iloc[i]['Standard Deviation Importance']))
-
-            if feat_names is None:
-                if self.csv_file is None:
-                    x_names = np.r_[x_names, csv_data.iloc[x].Features]
-                else:
-                    x_names = np.r_[x_names, self.csv_file.columns[x]]
+                    y.append(float(csv_data.iloc[i]['Average Feature Importance']))
+                    y_err.append(float(csv_data.iloc[i]['Standard Deviation Importance']))
+            
             else:
-                x_names = np.r_[x_names, feat_names[x]]
+                if include_rejected > len(rejected_indices):
+                    include_rejected = len(rejected_indices)
+                    print('The include_rejected parameter exceeds the number of rejected features, setting to the maximum value of {}'.format(str(include_rejected)))
+
+                for i in rejected_indices[:include_rejected]:
+                    x.append(int(csv_data.iloc[i].Features))
+                    y.append(float(csv_data.iloc[i]['Average Feature Importance']))
+                    y_err.append(float(csv_data.iloc[i]['Standard Deviation Importance']))
+            
+            rejected_names = csv_data.iloc[x].Features if feat_names is None else feat_names[x]
+            x_names = np.r_[x_names, rejected_names] if feat_names is None else np.r_[x_names, rejected_names]
+
         
         y, y_err = np.array(y), np.array(y_err)
+
         fig, ax = plt.subplots()
         if flip_axes:
             lns, = ax.plot(y, np.arange(len(x_names)), 'k*--', lw=0.77)
             lns_sigma = ax.fill_betweenx(np.arange(len(x_names)), y-y_err, y+y_err, color="grey", alpha=0.2)
-            ax.set_xlabel('Z Score', alpha=1, color='k')
-            ax.set_yticks(np.arange(len(x_names)), x_names)#, rotation=90)
+            ax.set_xlabel('Z Score', alpha=1, color='k'); ax.set_yticks(np.arange(len(x_names)), x_names)#, rotation=90)
+            
             for t in ax.get_yticklabels():
                 txt = t.get_text()
-                if 'Max Shadow' in txt:
+                if 'Mean Shadow' in txt:
                     t.set_color('red')
                     if include_rejected is False:
-                        ax.plot(y[-1], np.arange(len(x_names))[-1], marker='*', color='red')
-                    else:
+                        idx = 1
+                    elif include_rejected == 'all' or include_rejected == True:
                         idx = 1 + len(rejected_indices)
-                        ax.plot(y[-idx], np.arange(len(x_names))[-idx], marker='*', color='red')
+                    else:
+                        idx = 1 + len(rejected_indices[:include_rejected])
+                    ax.plot(y[-idx], np.arange(len(x_names))[-idx], marker='*', color='red')
 
             ax.set_ylim((np.arange(len(x_names))[0]-0.5, np.arange(len(x_names))[-1]+0.5))
             ax.set_xlim((np.min(y)-1, np.max(y)+1))
-            ax.invert_yaxis(), ax.invert_xaxis()
+            ax.invert_yaxis(); ax.invert_xaxis()
         else:
             lns, = ax.plot(np.arange(len(x_names)), y, 'k*--', lw=0.77)#, label='XGBoost', lw=0.77)
             lns_sigma = ax.fill_between(np.arange(len(x_names)), y-y_err, y+y_err, color="grey", alpha=0.2)
-            ax.set_ylabel('Z Score', alpha=1, color='k')
-            ax.set_xticks(np.arange(len(x_names)), x_names, rotation=90)
+            ax.set_ylabel('Z Score', alpha=1, color='k'); ax.set_xticks(np.arange(len(x_names)), x_names, rotation=90)
             for t in ax.get_xticklabels():
                 txt = t.get_text()
-                if 'Max Shadow' in txt:
+                if 'Mean Shadow' in txt:
                     t.set_color('red')
-                    ax.plot(np.arange(len(x_names))[-1], y[-1], marker='*', color='red')
+                    if include_rejected is False:
+                        idx = 1
+                    elif include_rejected == 'all' or include_rejected == True:
+                        idx = 1 + len(rejected_indices)
+                    else:
+                        idx = 1 + len(rejected_indices[:include_rejected])
+                    ax.plot(np.arange(len(x_names))[-idx], y[-idx], marker='*', color='red')
+
             ax.set_xlim((np.arange(len(x_names))[0]-0.5, np.arange(len(x_names))[-1]+0.5))
             ax.set_ylim((np.min(y)-1, np.max(y)+1))
 
-        ax.set_title('Feature Importance')#, size=18)
         ax.legend([(lns, lns_sigma)], [r'$\pm$ 1$\sigma$'], loc='upper right', ncol=1, frameon=False, handlelength=2)
+        ax.set_title('Feature Importance')
 
         if savefig:
+            _set_style_()
             plt.savefig('Feature_Importance.png', bbox_inches='tight', dpi=300)
-            plt.clf()
+            plt.clf(); plt.style.use('default')
         else:
             plt.show()
 
+        return
+
     def plot_hyper_param_importance(self, plot_time=True, savefig=False):
         """
         Plots the hyperparameter optimization history.
     
+        Note:
+            The Optuna API provides its own plotting function: plot_param_importances(self.optimization_results)
+
         Args:
             plot_tile (bool): If True, the importance on the duration will also be included. Defaults to True.
             savefig (bool): If True the figure will not disply but will be saved instead. Defaults to False. 
 
         Returns:
             AxesImage
         """
@@ -1006,37 +1005,35 @@
         for name in params:
             importance.append(hyper_importances[name])
             duration_importance.append(duration_importances[name])
 
         xtick_labels = format_labels(params)
 
         fig, ax = plt.subplots()
-        #fig.subplots_adjust(top=0.8)
         ax.barh(xtick_labels, importance, label='Importance for Classification', color=mcolors.TABLEAU_COLORS["tab:blue"], alpha=0.87)
         if plot_time:
             ax.barh(xtick_labels, duration_importance, label='Impact on Engine Speed', color=mcolors.TABLEAU_COLORS["tab:orange"], alpha=0.7, hatch='/')
 
-        ax.set_ylabel("Hyperparameter")
-        ax.set_xlabel("Importance Evaluation")
+        ax.set_ylabel("Hyperparameter"); ax.set_xlabel("Importance Evaluation")
         ax.legend(ncol=2, frameon=False, handlelength=2, bbox_to_anchor=(0.5, 1.1), loc='upper center')
-        ax.set_xscale('log')
+        ax.set_xscale('log'); plt.xlim((0, 1.))
         plt.gca().invert_yaxis()
-        plt.xlim((0, 1.))#np.max(importance+duration_importance)))#np.max(importance+duration_importance)))
-        #fig = plot_param_importances(self.optimization_results)
-        #fig = plot_param_importances(self.optimization_results, target=lambda t: t.duration.total_seconds(), target_name="duration")
-        #plt.tight_layout()
+
         if savefig:
+            _set_style_()
             if plot_time:
                 plt.savefig('Ensemble_Hyperparameter_Importance.png', bbox_inches='tight', dpi=300)
             else:
                 plt.savefig('Ensemble_Hyperparameter_Duration_Importance.png', bbox_inches='tight', dpi=300)
-            plt.clf()
+            plt.clf(); plt.style.use('default')
         else:
             plt.show()
 
+        return
+
     def save_hyper_importance(self):
         """
         Calculates and saves binary files containing
         dictionaries with importance information, one
         for the importance and one for the duration importance
 
         Note:
@@ -1044,21 +1041,19 @@
             plotting the importances. This function will save
             two files in the model folder for future use. 
 
         Returns:
             Saves two binary files, importance and duration importance.
         """
         
-        print('Calculating and saving importances, this could take up to an hour...')
+        if self.n_iter >= 500:
+            print('Calculating and saving importances, this could take up to an hour...')
 
         try:
-            if isinstance(self.path, str):
-                path = self.path  
-            else:
-                path = str(Path.home())
+            path = self.path if isinstance(self.path, str) else str(Path.home())
         except:
             path = str(Path.home())
 
         hyper_importance = get_param_importances(self.optimization_results)
         joblib.dump(hyper_importance, path+'Hyperparameter_Importance')
 
         importance = FanovaImportanceEvaluator()
@@ -1067,15 +1062,14 @@
         
         print(f"Files saved in: {path}")
 
         self.path = path
 
         return  
 
-
 #Helper functions below to generate confusion matrix
 def format_labels(labels: list) -> list:
     """
     Takes a list of labels and returns the list with all words capitalized and underscores removed.
     Also replaces 'eta' with 'Learning Rate' and 'n_estimators' with 'Number of Trees'.
     
     Args:
@@ -1085,75 +1079,70 @@
         Reformatted list, of same lenght.
     """
 
     new_labels = []
     for label in labels:
         label = label.replace("_", " ")
         if label == "eta":
-            new_labels.append("Learning Rate")
-            continue
+            new_labels.append("Learning Rate"); continue
         if label == "n estimators":
-            new_labels.append("Num of Trees")
-            continue
+            new_labels.append("Num of Trees"); continue
         if label == "colsample bytree":
-            new_labels.append("ColSample ByTree")
-            continue
+            new_labels.append("ColSample ByTree"); continue
         new_labels.append(label.title())
 
     return new_labels
 
 def evaluate_model(classifier, data_x, data_y, normalize=True, k_fold=10):
     """
     Cross-checks model accuracy and outputs both the predicted
     and the true class labels. 
 
     Args:
         classifier: The machine learning classifier to optimize.
         data_x (ndarray): 2D array of size (n x m), where n is the
-            number of samples, and m the number of features.
-        data_y (ndarray, str): 1D array containing the corresponing labels.
-        normalize (bool, optional): If False the confusion matrix will display the
+            number of samples, and m is the number of features.
+        data_y (ndarray, str): 1D array containing the corresponding labels.
+        normalize (bool, optional): If False, the confusion matrix will display the
             total number of objects in the sample. Defaults to True, in which case
             the values are normalized between 0 and 1. 
         k_fold (int, optional): The number of cross-validations to perform.
             The output confusion matrix will display the mean accuracy across
             all k_fold iterations. Defaults to 10.
 
     Returns:
         The first output is the 1D array of the true class labels.
         The second output is the 1D array of the predicted class labels.
     """
 
-    k_fold = KFold(k_fold, shuffle=True)#, random_state=1)
-    #k_fold = StratifiedKFold(k_fold, shuffle=False)#, random_state=8)
+    kf = KFold(n_splits=k_fold, shuffle=True, random_state=42)
+    predicted_targets = []
+    actual_targets = []
+
+    for train_index, test_index in kf.split(data_x):
+        classifier.fit(data_x[train_index], data_y[train_index])
+        predicted_targets.extend(classifier.predict(data_x[test_index]))
+        actual_targets.extend(data_y[test_index])
 
-    predicted_targets = np.array([])
-    actual_targets = np.array([])
-
-    for train_ix, test_ix in k_fold.split(data_x, data_y):
-        train_x, train_y, test_x, test_y = data_x[train_ix], data_y[train_ix], data_x[test_ix], data_y[test_ix]
-        # Fit the classifier
-        classifier.fit(train_x, train_y)
-        # Predict the labels of the test set samples
-        predicted_labels = classifier.predict(test_x)
-        predicted_targets = np.append(predicted_targets, predicted_labels)
-        actual_targets = np.append(actual_targets, test_y)
+    predicted_targets = np.array(predicted_targets)
+    actual_targets = np.array(actual_targets)
 
     return predicted_targets, actual_targets
 
+
 def generate_matrix(predicted_labels_list, actual_targets, classes, normalize=True, 
     title='Confusion Matrix', savefig=False):
     """
     Generates the confusion matrix using the output from the evaluate_model() function.
 
     Args:
         predicted_labels_list: 1D array containing the predicted class labels.
         actual_targets: 1D array containing the actual class labels.
         classes (list): A list containing the label of the two training bags. This
-            will be used to set the axis. Ex) classes = ['DIFFUSE', 'OTHER']
+            will be used to set the axis. Ex) classes = ['ML', 'OTHER']
         normalize (bool, optional): If True the matrix accuracy will be normalized
             and displayed as a percentage accuracy. Defaults to True.
         title (str, optional): The title of the output plot. 
         savefig (bool): If True the figure will not disply but will be saved instead. Defaults to False. 
 
     Returns:
         AxesImage.
@@ -1161,63 +1150,57 @@
 
     conf_matrix = confusion_matrix(actual_targets, predicted_labels_list)
     np.set_printoptions(precision=2)
 
     plt.figure()
     if normalize:
         generate_plot(conf_matrix, classes=classes, normalize=normalize, title=title)
-    elif normalize == False:
+    else:
         generate_plot(conf_matrix, classes=classes, normalize=normalize, title=title)
     
     if savefig:
+        _set_style_()
         plt.savefig('Ensemble_Confusion_Matrix.png', bbox_inches='tight', dpi=300)
-        plt.clf()
+        plt.clf(); plt.style.use('default')
     else:
         plt.show()
     
 def generate_plot(conf_matrix, classes, normalize=False, title='Confusion Matrix'):
     """
     Generates the confusion matrix figure object, but does not plot.
     
     Args:
         conf_matrix: The confusion matrix generated using the generate_matrix() function.
         classes (list): A list containing the label of the two training bags. This
-            will be used to set the axis. Defaults to a list containing 'DIFFUSE' & 'OTHER'. 
+            will be used to set the axis. Defaults to a list containing 'ML' & 'OTHER'. 
         normalize (bool, optional): If True the matrix accuracy will be normalized
             and displayed as a percentage accuracy. Defaults to True.
         title (str, optional): The title of the output plot. 
 
     Returns:
         AxesImage object. 
     """
 
     if normalize:
         conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]
 
     plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.get_cmap('Blues'))
-    plt.title(title)#, fontsize=20)
-    plt.colorbar()
+    plt.title(title); plt.colorbar()
 
     tick_marks = np.arange(len(classes))
-    plt.xticks(tick_marks, classes, alpha=1, color='k')#rotation=45, fontsize=14,
-    plt.yticks(tick_marks, classes, alpha=1, color='k', rotation=90)#fontsize=14,
-    #plt.xticks(tick_marks, ['DIFFUSE','OTHER'], rotation=45, fontsize=14)
-    #plt.yticks(tick_marks, ['DIFFUSE','OTHER'], fontsize=14)
+    plt.xticks(tick_marks, classes, alpha=1, color='k'); plt.yticks(tick_marks, classes, alpha=1, color='k', rotation=90)
 
     fmt = '.4f' if normalize is True else 'd'
     thresh = conf_matrix.max() / 2.
 
     for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):
-        plt.text(j, i, format(conf_matrix[i, j], fmt), horizontalalignment="center",
-                 color="white" if conf_matrix[i, j] > thresh else "black")#fontsize=14,
+        plt.text(j, i, format(conf_matrix[i, j], fmt), horizontalalignment="center", color="white" if conf_matrix[i, j] > thresh else "black")
 
-    plt.grid(False)
-    plt.ylabel('True label', alpha=1, color='k')#fontsize=18
-    plt.xlabel('Predicted label',alpha=1, color='k')#fontsize=18
-    plt.tight_layout()
+    plt.ylabel('True label', alpha=1, color='k'); plt.xlabel('Predicted label',alpha=1, color='k')
+    plt.grid(False); plt.tight_layout()
 
     return conf_matrix
 
 def min_max_norm(data_x):
     """
     Normalizes the data to be between 0 and 1. NaN values are ignored.
     The transformation matrix will be returned as it will be needed
@@ -1230,13 +1213,62 @@
         Normalized data array.
     """
 
     Ny, Nx = data_x.shape
     new_array = np.zeros((Ny, Nx))
     
     for i in range(Nx):
-        print((np.max(data_x[:,i]) - np.min(data_x[:,i])))
         new_array[:,i] = (data_x[:,i] - np.min(data_x[:,i])) / (np.max(data_x[:,i]) - np.min(data_x[:,i]))
 
     return new_array
     
+def _set_style_():
+    """
+    Function to configure the matplotlib.pyplot style. This function is called before any images are saved,
+    after which the style is reset to the default.
+    """
+
+    plt.rcParams["xtick.color"] = "323034"
+    plt.rcParams["ytick.color"] = "323034"
+    plt.rcParams["text.color"] = "323034"
+    plt.rcParams["lines.markeredgecolor"] = "black"
+    plt.rcParams["patch.facecolor"] = "#bc80bd"  # Replace with a valid color code
+    plt.rcParams["patch.force_edgecolor"] = True
+    plt.rcParams["patch.linewidth"] = 0.8
+    plt.rcParams["scatter.edgecolors"] = "black"
+    plt.rcParams["grid.color"] = "#b1afb5"  # Replace with a valid color code
+    plt.rcParams["axes.titlesize"] = 16
+    plt.rcParams["legend.title_fontsize"] = 12
+    plt.rcParams["xtick.labelsize"] = 16
+    plt.rcParams["ytick.labelsize"] = 16
+    plt.rcParams["font.size"] = 15
+    plt.rcParams["axes.prop_cycle"] = (cycler('color', ['#bc80bd', '#fb8072', '#b3de69', '#fdb462', '#fccde5', '#8dd3c7', '#ffed6f', '#bebada', '#80b1d3', '#ccebc5', '#d9d9d9']))  # Replace with valid color codes
+    plt.rcParams["mathtext.fontset"] = "stix"
+    plt.rcParams["font.family"] = "STIXGeneral"
+    plt.rcParams["lines.linewidth"] = 2
+    plt.rcParams["lines.markersize"] = 6
+    plt.rcParams["legend.frameon"] = True
+    plt.rcParams["legend.framealpha"] = 0.8
+    plt.rcParams["legend.fontsize"] = 13
+    plt.rcParams["legend.edgecolor"] = "black"
+    plt.rcParams["legend.borderpad"] = 0.2
+    plt.rcParams["legend.columnspacing"] = 1.5
+    plt.rcParams["legend.labelspacing"] = 0.4
+    plt.rcParams["text.usetex"] = False
+    plt.rcParams["axes.labelsize"] = 17
+    plt.rcParams["axes.titlelocation"] = "center"
+    plt.rcParams["axes.formatter.use_mathtext"] = True
+    plt.rcParams["axes.autolimit_mode"] = "round_numbers"
+    plt.rcParams["axes.labelpad"] = 3
+    plt.rcParams["axes.formatter.limits"] = (-4, 4)
+    plt.rcParams["axes.labelcolor"] = "black"
+    plt.rcParams["axes.edgecolor"] = "black"
+    plt.rcParams["axes.linewidth"] = 1
+    plt.rcParams["axes.grid"] = False
+    plt.rcParams["axes.spines.right"] = True
+    plt.rcParams["axes.spines.left"] = True
+    plt.rcParams["axes.spines.top"] = True
+    plt.rcParams["figure.titlesize"] = 18
+    plt.rcParams["figure.autolayout"] = True
+    plt.rcParams["figure.dpi"] = 300
 
+    return
```

### Comparing `MicroLIA-2.2.6/MicroLIA/extract_features.py` & `MicroLIA-2.2.7/MicroLIA/extract_features.py`

 * *Files 4% similar despite different names*

```diff
@@ -12,139 +12,128 @@
     """
     This function will compute the statistics used to train the RF.
     Amplitude dependent features are computed first, after which the
     mag/flux is normalized by the maximum value to compute the remanining
     features. By default a conversion from mag to flux is performed. If input
     is in flux or you wish to work in mag, set convert to False.  
     
-    Parameters
+    Parameters:
     ----------
-    time : array
-        Time of observations
-    mag : array
-        Magnitude array.
-    magerr : array
-        Corresponing photometric errors.  
-    feats_to_use : array
-        Array containing indices of features to use. This will be used to index the columns 
-        in the data array. Defaults to None, in which case all columns in the data array are used.
-    convert : boolean, optional 
-        If False the features are computed with the input magnitudes,
-        defaults to True to convert and compute in flux. 
-    zp : float
-        Zeropoint of the instrument, only used if convert=True. Defaults to 24.
-    return_names : bool
-        If True the first output will be the stats array, and the second
-        will be the list of corresponding feature names. Defaults to False,
-        in which case only the stats array is returned.
+        time : array
+            Time of observations
+        mag : array
+            Magnitude array.
+        magerr : array
+            Corresponing photometric errors.  
+        apply_weights : bool, optional
+                Whether to apply weights based on the magnitude errors. Defaults to True.
+        feats_to_use : array
+            Array containing indices of features to use. This will be used to index the columns 
+            in the data array. Defaults to None, in which case all columns in the data array are used.
+        convert : boolean, optional 
+            If False the features are computed with the input magnitudes,
+            defaults to True to convert and compute in flux. 
+        zp : float
+            Zeropoint of the instrument, only used if convert=True. Defaults to 24.
+        return_names : bool
+            If True the first output will be the stats array, and the second
+            will be the list of corresponding feature names. Defaults to False,
+            in which case only the stats array is returned.
 
-    Returns
+    Returns:
     -------
-    stats : array
-        All features to use for classification
+    array
+        All features to use for classification.
     """
 
     if isinstance(time, np.ndarray) is False:
         if type(time) == list:
             time = np.array(time)
         else:
-            raise ValueError('time argument must be a list or array.')
+            raise ValueError('The time argument must be a list or array.')
+
     if isinstance(mag, np.ndarray) is False:
         if type(mag) == list:
             mag = np.array(mag)
         else:
-            raise ValueError('mag argument must be a list or array.')
+            raise ValueError('The mag argument must be a list or array.')
+
     if isinstance(magerr, np.ndarray) is False:
         if type(magerr) == list:
             magerr = np.array(magerr)
         else:
-            raise ValueError('magerr argument must be a list or array.')
+            raise ValueError('The magerr argument must be a list or array.')
 
     #Remove the nan and inf values, if present in the lightcurve
     mask = np.where(np.isfinite(time) & np.isfinite(mag) & np.isfinite(magerr))[0]
     time, mag, magerr = time[mask], mag[mask], magerr[mask]
 
     if convert is True:
-        flux = 10**(-(mag-zp)/2.5)
-        flux_err = (magerr*flux)/(2.5)*np.log(10)
+        flux = 10**(-(mag-zp) / 2.5)
+        flux_err = (magerr * flux) / (2.5) * np.log(10)
     elif convert is False:
-        flux = mag
-        flux_err = magerr
+        flux, flux_err = mag, magerr
 
     # Normalize by max flux
-    norm_flux = flux/np.max(flux)
-    norm_fluxerr = flux_err*(norm_flux/flux)
+    norm_flux = flux / np.max(flux)
+    norm_fluxerr = flux_err * (norm_flux / flux)
     
+    # Retrive all the statistical metrics from the features module
     all_features_functions = getmembers(features, isfunction)
 
-    stats = []
-    feature_names = [] 
+    stats, feature_names = [], []
 
-    #normal space
+    #Normal space
     counter = 0
     for func in all_features_functions:
         if feats_to_use is not None:
             if counter not in feats_to_use:
-                counter += 1
-                continue
-        #try:
+                counter += 1; continue
+
         if func[0] == 'amplitude' or func[0] == 'median_buffer_range':
             try:
                 feature = func[1](time, flux, flux_err, apply_weights=apply_weights)  #amplitude dependent features use non-normalized flux
             except:# (ZeroDivisionError, ValueError, IndexError):
                 feature = np.nan
         else:
             try:
                 feature = func[1](time, norm_flux, norm_fluxerr, apply_weights=apply_weights)
             except:# (ZeroDivisionError, ValueError, IndexError):
                 feature = np.nan
 
-        feature_names.append(func[0])
-
-        if np.isfinite(feature):
-            stats.append(feature)
-        else:
-            stats.append(feature)
-
+        feature_names.append(func[0]); stats.append(feature)
         counter += 1
             
-    #derivative space
+    #Derivative space
     flux_deriv = np.gradient(flux, time)
     flux_deriv_err = np.gradient(flux_err, time) 
     
-    norm_flux_deriv = flux_deriv/np.max(flux_deriv)
-    norm_flux_deriv_err = flux_deriv_err*(norm_flux_deriv/flux_deriv)
+    norm_flux_deriv = flux_deriv / np.max(flux_deriv)
+    norm_flux_deriv_err = flux_deriv_err * (norm_flux_deriv / flux_deriv)
 
     for func in all_features_functions:
         if feats_to_use is not None:
             if counter not in feats_to_use:
-                counter += 1
-                continue
+                counter += 1; continue
+
         if func[0] == 'amplitude' or func[0] == 'median_buffer_range':
             try:
                 feature = func[1](time, flux, flux_err, apply_weights=apply_weights)  #amplitude dependent features use non-normalized flux
             except:# (ZeroDivisionError, ValueError, IndexError):
                 feature = np.nan
         else:
             try:
                 feature = func[1](time, norm_flux, norm_fluxerr, apply_weights=apply_weights)
             except:# (ZeroDivisionError, ValueError, IndexError):
                 feature = np.nan
 
-        feature_names.append(func[0]+'_deriv')
-
-        if np.isfinite(feature):
-            stats.append(feature)
-        else:
-            stats.append(feature)
-        
+        feature_names.append(func[0]+'_deriv'); stats.append(feature)
         counter += 1
 
     stats = np.array(stats)
     stats[np.isfinite(stats)==False] = np.nan
     stats[stats>1e7], stats[(stats<1e-7)&(stats>0)], stats[stats<-1e7] = 1e7, 1e-7, -1e7
 
     if return_names is False:
         return stats
     else:
         return stats, feature_names
-
```

### Comparing `MicroLIA-2.2.6/MicroLIA/features.py` & `MicroLIA-2.2.7/MicroLIA/features.py`

 * *Files 14% similar despite different names*

```diff
@@ -8,39 +8,47 @@
 import numpy as np
 import itertools
 import math
 import peakutils
 import scipy.integrate as sintegrate
 import scipy.signal as ssignal
 import scipy.stats as sstats
+
 import warnings; warnings.filterwarnings("ignore")
 
 def shannon_entropy(time, mag, magerr, apply_weights=True):
     """
     Shannon entropy (Shannon et al. 1949) is used as a metric to quantify the amount of
     information carried by a signal. The procedure employed here follows that outlined by
     (D. Mislis et al. 2015). The probability of each point is given by a Cumulative Distribution
     Function (CDF). Following the same procedure as (D. Mislis et al. 2015), this function employs
     both the normal and inversed gaussian CDF, with the total shannon entropy given by a combination of
     the two. See: (SIDRA: a blind algorithm for signal detection in photometric surveys, D. Mislis et al., 2015)
-     
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Not used in this function.
     
-    Returns
+    Does not incorporate errors.
+
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
+
+    Returns:
     -------  
-    rtype: float
+    float
+        The Shannon Entropy of the lightcurve.
     """
     
     mean = np.median(mag)
-    RMS = root_mean_squared(time, mag, magerr)
+    RMS = root_mean_squared(time, mag, magerr, apply_weights=False)
     
     p_list1 = []
     p_list2 = []
     inv_list1 = []
     inv_list2 = []
     
     t = range(0, len(mag))
@@ -92,29 +100,37 @@
     of the measurements in the largest bin.
 
     In this updated version of the con function, the upper and lower bounds for each 
     measurement are defined as mag[i] + 3*magerr[i] and mag[i] - 3*magerr[i], respectively. 
     These bounds are then used to check if a measurement is within a cluster. 
     If a measurement is outside the bounds and we're in a cluster, the cluster is ended.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------  
-    rtype: float       
+    Returns:
+    -------
+    float
+        The ratio of clusters satisfying the conditions to the total number of measurements.     
     """
 
+    if len(mag) < 3:
+        return 0
+
     # Find the median of the magnitudes
     mean = np.median(mag)
-    
+
     # Initialize variables
     con = 0
     deviating = False
 
     if apply_weights:
         # Loop over the magnitudes
         for i in range(len(mag)-2):
@@ -140,52 +156,54 @@
                     pass
             
             # If the current measurement is outside the bounds and we're in a
             # cluster, end the cluster
             elif deviating:
                 deviating = False
     else:
-        if len(a) < 3:
-            return 0
-        else:
-            for i in range(len(mag)-2):
-                first = mag[i]
-                second = mag[i+1]
-                third = mag[i+2]
-                if (first <= mean+3*magerr[i] and
-                    second <= mean+3*magerr[i+1] and
-                    third <= mean+3*magerr[i+2]):
-                    if (not deviating):
-                        con += 1
-                        deviating = True
-                    elif deviating:
-                        deviating = False
+        for i in range(len(mag)-2):
+            first = mag[i]
+            second = mag[i+1]
+            third = mag[i+2]
+            if (first <= mean+3*magerr[i] and
+                second <= mean+3*magerr[i+1] and
+                third <= mean+3*magerr[i+2]):
+                if (not deviating):
+                    con += 1
+                    deviating = True
+                elif deviating:
+                    deviating = False
 
     return con/len(mag)
 
 def kurtosis(time, mag, magerr, apply_weights=True):
     """"
     This function returns the calculated kurtosis of the lightcurve.
     It's a measure of the peakedness (or flatness) of the lightcurve relative
     to a normal distribution. See: www.xycoon.com/peakedness_small_sample_test_1.htm
     
     This updated implementation calculates the weighted mean x_mean and the weighted 
     standard deviation sigma using numpy.average() with the weights parameter set to 1/magerr**2. 
     Then it calculates the weighted kurtosis using the above formula and returns the result.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The calculated kurtosis of the lightcurve.
     """
 
     if apply_weights:
         x_mean = np.average(mag, weights=1/magerr**2)
         sigma = np.sqrt(np.average((mag-x_mean)**2, weights=1/magerr**2))
         kurtosis = np.sum((mag-x_mean)**4 * 1/magerr**2) / (np.sum(1/magerr**2) * sigma**4) - 3
     else:
@@ -197,24 +215,29 @@
     """
     Skewness measures the asymmetry of a lightcurve, with a positive skewness
     indicating a skew to the right, and a negative skewness indicating a skew to the left.
     
     This function calculates the weighted mean and standard deviation using the photometric 
     errors as weights, and then uses these values to compute the weighted skewness.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
-
-    Returns
-    -------        
-    rtype: float
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
+
+    Returns:
+    -------
+    float
+        The calculated skewness of the lightcurve.
     """
     
     if apply_weights:
         # Calculate the weighted mean and standard deviation
         wmean = np.average(mag, weights=1/magerr**2)
         wstd = np.sqrt(np.sum((mag - wmean)**2 / magerr**2) / np.sum(1/magerr**2))
         skewness = np.sum(((mag - wmean) / wstd)**3 * 1/magerr**2) / np.sum(1/magerr**2)
@@ -232,24 +255,29 @@
     
     In this updated version, np.average() is used to calculate the weighted average of the measurement 
     errors squared as the sample variance. The weights argument in np.average() is used to specify 
     the weights for each element in the input array, with larger weights given to elements with smaller errors. 
     We also modify the calculation of delta to take into account the measurement errors by dividing the 
     differences between successive magnitudes by the corresponding errors.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------  
-    rtype: float
+    Returns:
+    -------
+    float
+        The calculated von Neumann Ratio of the lightcurve.
     """
     
     if apply_weights:
         n = float(len(mag))
         delta = sum(((mag[1:] - mag[:-1]) / magerr[:-1])**2 / (n-1.))
         sample_variance = np.average(magerr**2, weights=1/magerr**2)
         vNR = delta / sample_variance
@@ -264,27 +292,32 @@
 def stetsonJ(time, mag, magerr, apply_weights=True):
     """
     The variability index J was first suggested by Peter B. Stetson and serves as a
     measure of the correlation between the data points, tending to 0 for variable stars
     and getting large as the difference between the successive data points increases.
     See: (P. B. Stetson, Publications of the Astronomical Society of the Pacific 108, 851 (1996)).
     
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Not used in this function.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    ------- 
-    rtype: float
+    Returns:
+    -------
+    float
+        The calculated stetsonJ variability index of the lightcurve.
     """
     
-    n = np.float(len(mag))
+    n = float(len(mag))
     mean = np.median(mag)
     delta_list=[]
     
     for i in range(0, len(mag)-1):
         delta = np.sqrt(n/(n-1.))*((mag[i] - mean)/magerr[i])
         delta2 = np.sqrt(n/(n-1.))*((mag[i+1] - mean)/magerr[i+1])
         delta_list.append(np.nan_to_num(delta*delta2))
@@ -295,89 +328,104 @@
 
 def stetsonK(time, mag, magerr, apply_weights=True):
     """
     The variability index K was first suggested by Peter B. Stetson and serves as a
     measure of the kurtosis of the magnitude distribution.
     See: (P. B. Stetson, Publications of the Astronomical Society of the Pacific 108, 851 (1996)).
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Not used in this function.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------    
-    rtype: float
+    Returns:
+    -------
+    float
+        The calculated stetsonK variability index of the lightcurve.
     """  
     
     n = float(len(mag))
     mean = np.median(mag)
     delta = np.sqrt((n/(n-1.)))*((mag - mean)/magerr)
     
     stetsonK = ((1./n)*sum(abs(delta)))/(np.sqrt((1./n)*sum(delta**2)))
 
     return np.nan_to_num(stetsonK)
 
-def stetsonL(time, mag, magerr):
+def stetsonL(time, mag, magerr, apply_weights=True):
     """
     The variability index L was first suggested by Peter B. Stetson and serves as a
     means of distinguishing between different types of variation. When individual random
     errors dominate over the actual variation of the signal, K approaches 0.798 (Gaussian limit).
     Thus, when the nature of the errors is Gaussian, stetsonL = stetsonJ, except it will be amplified
     by a small factor for smoothly varying signals, or suppressed by a large factor when data
     is infrequent or corrupt. 
     See: (P. B. Stetson, Publications of the Astronomical Society of the Pacific 108, 851 (1996)).
         
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Not used in this function.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------    
-    rtype: float    
+    Returns:
+    -------
+    float
+        The calculated stetsonL variability index of the lightcurve.   
     """  
     
-    stetL = (stetsonJ(time, mag, magerr)*stetsonK(time, mag, magerr)) / 0.798
+    stetL = (stetsonJ(time, mag, magerr, apply_weights=apply_weights)*stetsonK(time, mag, magerr, apply_weights=apply_weights)) / 0.798
 
     return stetL
 
 def median_buffer_range(time, mag, magerr, apply_weights=True):
     """
     This function returns the ratio of points that are between plus or minus 10% of the
     amplitude value over the mean.
 
     In this updated version, we compute the weighted mean of the mag array using the 
     corresponding magerr values as weights. Then we use the weighted mean to compute a and b values 
     for the range around the mean that we want to consider. Finally, we compute the ratio of points 
     within this range to the total number of points.
 
-    Parameters
+    Parameters:
     ----------
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------
-    rtype: float
+    float
+        The ratio of points that are between plus or minus 10% of the lightcurve's amplitude value over the mean.
     """
     
+    amp = amplitude(time, mag, magerr, apply_weights=apply_weights)
+
     if apply_weights:
-        amp = amplitude(time, mag, magerr)
         w_mean = np.average(mag, weights=1/magerr**2)
         a = w_mean - amp*0.1
         b = w_mean + amp*0.1
     else:
-        amp = amplitude(time, mag, magerr)
         #mean = meanMag(mag, magerr)
         mean = np.median(mag)
         a = mean - amp*0.1
         b = mean + amp*0.1
         
     return len(np.argwhere((mag > a) & (mag < b))) / float(len(mag))
 
@@ -387,24 +435,29 @@
     
     In this version, weights is calculated as the inverse square 
     of magerr. The weighted_mean is calculated as the weighted average 
     of mag, where the weights are given by weights. weighted_var is the 
     weighted variance, and weighted_std is the square root of weighted_var. 
     The final line returns the ratio of weighted_std and weighted_mean.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The ratio of standard deviation to the lightcurve's mean.
     """
 
     if apply_weights:
         weights = 1.0 / (magerr ** 2)
         mean = np.sum(mag * weights) / np.sum(weights)
         weighted_var = np.sum(weights * (mag - mean) ** 2) / np.sum(weights)
         std = np.sqrt(weighted_var)
@@ -420,24 +473,29 @@
     removing the upper and lower 2% of magnitudes.
     
     In this updated implementation we first sort the magnitude and error arrays based on the magnitude values. 
     We then compute the median magnitude value after excluding the upper and lower 2% of magnitudes to account 
     for outliers. We compute both the standard amplitude and the weighted amplitude, where each magnitude measurement 
     is weighed by its corresponding error. The weighted amplitude is then returned by the function.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
     
-    Returns
-    ------- 
-    rtype: float
+    Returns:
+    -------
+    float
+        The calculated amplitude of the lightcurve.
     """
     
     if apply_weights:
         sorted_indices = np.argsort(mag)
         sorted_mag = mag[sorted_indices]
         sorted_magerr = magerr[sorted_indices]
         n = len(mag)
@@ -452,24 +510,29 @@
     return amp
 
 def median_distance(time, mag, magerr, apply_weights=True):
     """
     This function calculates the median Euclidean distance between each photometric
     measurement, a helpful metric for detecting overlapped lightcurves.
 
-    Parameters
+    Parameters:
     ----------
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------
-    rtype: float
+    float
+        The calculated median Euclidean distance between each lightcurve measurement.
     """
 
     if apply_weights:
         delta_mag = (mag[1:] - mag[:-1])**2
         delta_t = (time[1:] - time[:-1])**2
         delta_magerr = (magerr[1:]**2 + magerr[:-1]**2)
         return np.median(np.sqrt(delta_mag/delta_magerr + delta_t/delta_magerr))
@@ -484,205 +547,240 @@
     from the median magnitude, weighted by their errors.
     
     In this updated function, each data point is weighed according to its error. The weighted 
     ratio of points that are above 1 standard deviation from the median magnitude is returned.
     By weighting each data point according to its error, we are taking into account the fact 
     that more weight should be given to data points that have lower measurement uncertainties. 
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the light curve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The number of points above 1 standard deviation from the light curve's median measurement.
     """
+    median_mag = np.median(mag)
+    std = np.std(mag)
     
     if apply_weights:
-        median_mag = np.median(mag)
-        std = np.std(mag)
-        weighted_above1 = np.sum((mag - median_mag > std) * (mag - median_mag - std) / magerr**2)
-        total_weight = np.sum((mag - median_mag > std) / magerr**2)
-        return weighted_above1 / total_weight
+        weighted_above1 = np.mean((mag - median_mag) > std)
+        weighted_above1 /= np.mean((mag - median_mag + std) / magerr**2)
+        return weighted_above1
     else:
-        above1 = len(np.where(mag-np.median(mag)>magerr)[0])/len(mag)
+        above1 = np.mean((mag - median_mag) > std)
         return above1
 
 def above3(time, mag, magerr, apply_weights=True):
     """
     This function measures the ratio of data points that are above 3 standard deviations
     from the median magnitude, weighted by their errors.
     
     In this updated function, each data point is weighed according to its error. The weighted 
     ratio of points that are above 3 standard deviations from the median magnitude is returned.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the light curve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The number of points above 3 standard deviations from the light curve's median measurement.
     """
+    median_mag = np.median(mag)
+    std = np.std(mag)
     
     if apply_weights:
-        median_mag = np.median(mag)
-        std = np.std(mag)
-        weighted_above3 = np.sum((mag - median_mag > 3 * magerr) * (mag - median_mag - 3 * std) / magerr**2)
-        total_weight = np.sum(1 / magerr**2) 
-        return weighted_above3 / total_weight
+        weighted_above3 = np.mean((mag - median_mag) > 3 * std)
+        weighted_above3 /= np.mean((mag - median_mag + 3 * std) / magerr**2)
+        return weighted_above3
     else:
-        above3 = len(np.where(mag-np.median(mag)>3*magerr)[0])/len(mag)
+        above3 = np.mean((mag - median_mag) > 3 * std)
         return above3
 
 def above5(time, mag, magerr, apply_weights=True):
     """
     This function measures the ratio of data points that are above 5 standard deviations
     from the median magnitude, weighted by their errors.
     
     In this updated function, each data point is weighed according to its error. The weighted 
     ratio of points that are above 5 standard deviations from the median magnitude is returned.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the light curve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------    
-    rtype: float   
+    Returns:
+    -------
+    float
+        The number of points above 5 standard deviations from the light curve's median measurement.
     """
+    median_mag = np.median(mag)
+    std = np.std(mag)
     
     if apply_weights:
-        median_mag = np.median(mag)
-        std = np.std(mag)
-        weighted_above5 = np.sum((mag - median_mag > 5 * magerr) * (mag - median_mag - 5 * std) / magerr**2)
-        total_weight = np.sum(1 / magerr**2)   
-        return weighted_above5 / total_weight
+        weighted_above5 = np.mean((mag - median_mag) > 5 * std)
+        weighted_above5 /= np.mean((mag - median_mag + 5 * std) / magerr**2)
+        return weighted_above5
     else:
-        above5 = len(np.where(mag-np.median(mag)>5*magerr)[0])/len(mag)
+        above5 = np.mean((mag - median_mag) > 5 * std)
         return above5
 
 def below1(time, mag, magerr, apply_weights=True):
     """
     This function measures the ratio of data points that are below 1 standard deviation
     from the median magnitude, weighted by their errors.
     
     In this updated function, each data point is weighed according to its error. The weighted 
     ratio of points that are below 1 standard deviation from the median magnitude is returned.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the light curve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The number of points below 1 standard deviation from the light curve's median measurement.
     """
+    median_mag = np.median(mag)
+    std = np.std(mag)
     
     if apply_weights:
-        median_mag = np.median(mag)
-        std = np.std(mag)
-        weighted_below1 = np.sum((-mag + median_mag > magerr) * (-mag + median_mag - std) / magerr**2)
-        total_weight = np.sum(1 / magerr**2)
-        return weighted_below1 / total_weight
+        weighted_below1 = np.mean((-mag + median_mag) > std)
+        weighted_below1 /= np.mean((-mag + median_mag + std) / magerr**2)
+        return weighted_below1
     else:
-        below1 = len(np.where(-mag+np.median(mag)>magerr)[0])/len(mag)
-        return below1 
+        below1 = np.mean((-mag + median_mag) > std)
+        return below1
 
 def below3(time, mag, magerr, apply_weights=True):
     """
     This function measures the ratio of data points that are below 3 standard deviations
     from the median magnitude, weighted by their errors.
     
     In this updated function, each data point is weighed according to its error. The weighted 
     ratio of points that are below 3 standard deviations from the median magnitude is returned.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the light curve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The number of points below 3 standard deviations from the light curve's median measurement.
     """
+    median_mag = np.median(mag)
+    std = np.std(mag)
     
     if apply_weights:
-        median_mag = np.median(mag)
-        std = np.std(mag)
-        weighted_below3 = np.sum((-mag + median_mag > 3*magerr) * (-mag + median_mag - 3*std) / magerr**2)
-        total_weight = np.sum(1 / magerr**2)
-        return weighted_below3 / total_weight
+        weighted_below3 = np.mean((-mag + median_mag) > 3 * std)
+        weighted_below3 /= np.mean((-mag + median_mag + 3 * std) / magerr**2)
+        return weighted_below3
     else:
-        below3 = len(np.where(-mag+np.median(mag)>3*magerr)[0])/len(mag)
+        below3 = np.mean((-mag + median_mag) > 3 * std)
         return below3
 
 def below5(time, mag, magerr, apply_weights=True):
     """
     This function measures the ratio of data points that are below 5 standard deviations
     from the median magnitude, weighted by their errors.
     
     In this updated function, each data point is weighed according to its error. The weighted 
     ratio of points that are below 5 standard deviations from the median magnitude is returned.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the light curve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The number of points below 5 standard deviations from the light curve's median measurement.
     """
+    median_mag = np.median(mag)
+    std = np.std(mag)
     
     if apply_weights:
-        median_mag = np.median(mag)
-        std = np.std(mag)
-        weighted_below5 = np.sum((-mag + median_mag > 5*magerr) * (-mag + median_mag - 5*std) / magerr**2)
-        total_weight = np.sum(1 / magerr**2)
-        return weighted_below5 / total_weight
+        weighted_below5 = np.mean((-mag + median_mag) > 5 * std)
+        weighted_below5 /= np.mean((-mag + median_mag + 5 * std) / magerr**2)
+        return weighted_below5
     else:
-        below5 = len(np.where(-mag+np.median(mag)>5*magerr)[0])/len(mag)
+        below5 = np.mean((-mag + median_mag) > 5 * std)
         return below5
 
 def medianAbsDev(time, mag, magerr, apply_weights=True):
     """
     A measure of the mean average distance between each magnitude value
     and the mean magnitude. https://en.wikipedia.org/wiki/Median_absolute_deviation 
     
     This updated function first calculates the median of the magnitude array, 
     then calculates the absolute deviation from the median, divided by the corresponding error value. 
     The median of these absolute deviations is returned as the MAD value.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The median absolute deviation of the lightcurve.
     """
 
     if apply_weights:
         med = np.median(mag)
         absdev = np.abs(mag - med) / magerr
         mad = np.median(absdev)
         return mad
@@ -697,24 +795,29 @@
     
     In this new version, the magnitudes are weighted by their corresponding errors, which takes
     into account the uncertainty in the measurements. The weighted mean of the magnitudes is 
     subtracted from each magnitude to calculate the weighted deviations, which are then squared 
     and averaged to get the weighted mean of the squared deviations. Finally, the square root of 
     this quantity gives the root mean square deviation that takes into account the photometric errors.
 
-    Parameters
-    ----------   
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rms: The root mean square deviation. Must be a float.
+    Returns:
+    -------
+    float
+        The root-mean-square of the lightcurve.
     """
 
     if apply_weights:
         weighted_mean = np.sum(mag / magerr**2) / np.sum(1 / magerr**2)
         weights = 1 / magerr**2
         deviations = (mag - weighted_mean)
         weighted_deviations = deviations * weights
@@ -725,24 +828,29 @@
 
     return rms
 
 def meanMag(time,mag, magerr, apply_weights=True):
     """
     Calculates mean magnitude, weighted by the errors.
         
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Not used in this function.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The weighted mean measurement of the lightcurve.
     """
             
     return sum(mag/magerr**2)/sum(1./magerr**2)
 
 def integrate(time, mag, magerr, apply_weights=True):
     """
     Integrate magnitude using the trapezoidal rule.
@@ -750,24 +858,29 @@
     
     In the case of integrating the magnitude using the trapezoidal rule, 
     it is not necessary to incorporate the error since the error in magnitude 
     will affect each individual data point, but not the overall integration. 
     The trapezoidal rule uses the values of the magnitudes and their timestamps 
     to compute the area under the curve, without considering the individual errors at each point.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Not used in this function.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: tuple
+    Returns:
+    -------
+    float
+        The integral value of the lightcurve.
     """
     
     integrated_mag = np.trapz(mag, time)
     
     return integrated_mag
 
 def auto_corr(time, mag, magerr, apply_weights=True):
@@ -777,62 +890,80 @@
     This version of the function first calculates the mean and standard deviation 
     of the magnitudes, and then uses these values to normalize the data before 
     computing the autocovariance function. The weights for each data point are 
     also calculated based on their measurement uncertainties, and are used to compute 
     the weighted autocovariance. Finally, the autocovariance function is normalized by 
     its value at zero lag to obtain the autocorrelation function.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The auto-correlation measurement of the lightcurve.
     """
 
     if apply_weights:
-        #Calculate the mean and standard deviation of the magnitudes
+        # Calculate the mean and standard deviation of the magnitudes
         mag_mean = np.mean(mag)
         mag_std = np.std(mag)
-        #Calculate the autocovariance function using the weighted data points
-        autocov = np.correlate((mag - mag_mean) / mag_std, (mag - mag_mean) / mag_std, mode='full')
+        
+        # Calculate the normalized magnitudes
+        normalized_mag = (mag - mag_mean) / mag_std
+        
+        # Calculate the autocovariance function
+        autocov = np.correlate(normalized_mag, normalized_mag, mode='full')
         autocov = autocov[autocov.size // 2:]
-        #Calculate the weights for each data point based on their measurement uncertainties
+        
+        # Calculate the weights for each data point based on their measurement uncertainties
         weights = 1. / magerr**2
-        #Calculate the weighted autocovariance function
-        weighted_autocov = np.sum(weights[:-1] * weights[1:] * autocov[1:]) / np.sum(weights)**2
-        #Normalize by the autocovariance at zero lag to obtain the autocorrelation function
-        auto_corr = weighted_autocov / autocov[0]
+        
+        # Compute the weighted autocovariance function
+        weighted_autocov = np.sum(weights * autocov)
+        
+        # Normalize by the autocovariance at zero lag to obtain the autocorrelation function
+        auto_corr = weighted_autocov / (np.sum(weights) * autocov[0])
     else:
-        auto_corr = np.corrcoef(mag[:-1],mag[1:])[1,0]
+        # If weights are not applied, use the regular correlation function
+        auto_corr = np.corrcoef(mag[:-1], mag[1:])[1, 0]
 
     return auto_corr
 
 def peak_detection(time, mag, magerr, apply_weights=True):
     """
     Function to detect number of peaks.
     
     Does not need to incorporate error since it is simply detecting 
     the number of peaks in the lightcurve, which is based on the 
     magnitude values alone.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Not used in this function.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: int
+    Returns:
+    -------
+    float
+        The number of peaks detected in the lightcurve.
     """
     
     mag = abs(mag - np.median(mag))
 
     try:
         indices = peakutils.indexes(mag, thres=.5, min_dist=10)
     except ValueError:
@@ -849,50 +980,64 @@
     Examining successive (time-sorted) magnitudes, the maximal first difference
     (value of delta magnitude over delta time)
     
     In this updated version of the function, the slope between successive magnitudes 
     is calculated using the errors as weights, and the weighted slope is returned as 
     a single value, not the max slopes as is the case when apply_weights=False.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The maximum-slope detected within the lightcurve.
     """
 
     if apply_weights:
         #Calculate the slope using the errors as weights
         weights = 1 / magerr[:-1]**2 + 1 / magerr[1:]**2
-        slope = np.abs((mag[1:] - mag[:-1]) / (time[1:] - time[:-1]))
-        weighted_slope = np.sum(weights * slope) / np.sum(weights)
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            slope = np.abs((mag[1:] - mag[:-1]) / (time[1:] - time[:-1]))
+        weighted_slope = np.sum(weights[np.isfinite(slope)] * slope[np.isfinite(slope)]) / np.sum(weights[np.isfinite(slope)])
         return weighted_slope
     else:
-        slope = np.abs(mag[1:] - mag[:-1]) / (time[1:] - time[:-1])
-        return np.max(slope)
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            slope = np.abs(mag[1:] - mag[:-1]) / (time[1:] - time[:-1])
+        return np.max(slope[np.isfinite(slope)])
 
 def LinearTrend(time, mag, magerr, apply_weights=True):
     """
     Slope of a weighted linear fit to the light-curve.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The slope of a weighted linear fit to the lightcurve.
     """
 
     if apply_weights:
         # Perform weighted linear regression
         weights = 1.0 / magerr**2
         regression_slope = np.polyfit(time, mag, deg=1, w=weights)[0]
     else:
@@ -904,320 +1049,289 @@
     """
     This is the percentage of all pairs of consecutive flux measurements that have positive slope,
     considering only the last 30 (time-sorted) magnitude measurements.
 
     This updated function incorporates error by calculating the weighted first differences 
     and then taking the weighted mean of the positive differences and negative differences separately.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The percentage of all pairs of consecutive lightcurve measurements that have positive a slope.
     """
 
     if apply_weights:
         data_last = mag[-30:]
         err_last = magerr[-30:]
-        #Calculate the weighted first differences
-        weights = 1 / err_last[:-1]**2 + 1 / err_last[1:]**2
+        # Calculate the weighted first differences
+        weights = 1.0 / (err_last[:-1]**2 + err_last[1:]**2)
         diff = data_last[1:] - data_last[:-1]
         diff_weighted = diff * weights
-        pos_diff_weighted = diff_weighted[diff_weighted > 0]
-        neg_diff_weighted = diff_weighted[diff_weighted < 0]
-        #Calculate the weighted mean of positive and negative differences
-        if len(pos_diff_weighted) > 0:
-            pos_mean = np.sum(pos_diff_weighted) / np.sum(weights[diff_weighted > 0])
-        else:
-            pos_mean = 0
-        if len(neg_diff_weighted) > 0:
-            neg_mean = np.sum(neg_diff_weighted) / np.sum(weights[diff_weighted < 0])
-        else:
-            neg_mean = 0
-        PST = (np.sum(pos_diff_weighted) - np.sum(neg_diff_weighted)) / np.sum(weights)
+        pos_diff_weighted = diff_weighted[diff > 0]
+        neg_diff_weighted = diff_weighted[diff < 0]
+        # Calculate the weighted mean of positive and negative differences
+        pos_mean = np.mean(pos_diff_weighted) if len(pos_diff_weighted) > 0 else 0
+        neg_mean = np.mean(neg_diff_weighted) if len(neg_diff_weighted) > 0 else 0
+        # Calculate the percentage of pairs with a positive slope
+        PST = len(pos_diff_weighted) / (len(pos_diff_weighted) + len(neg_diff_weighted))
     else:
         data_last = mag[-30:]
-        PST = (len(np.where(np.diff(data_last) > 0)[0]) - len(np.where(np.diff(data_last) <= 0)[0])) / 30.0
+        #PST = (len(np.where(np.diff(data_last) > 0)[0]) - len(np.where(np.diff(data_last) <= 0)[0])) / 30.0
+        PST = len(np.where(np.diff(data_last) > 0)[0]) / 30.0
 
     return PST
 
 def FluxPercentileRatioMid20(time, mag, magerr, apply_weights=True):
     """
     In order to characterize the sorted magnitudes distribution we use percentiles. 
     If F5,95 is the difference between 95% and 5% magnitude values, we calculate the following:
     Ratio of flux percentiles (60th - 40th) over (95th - 5th)
     
     In this updated version of the function, we first sort the magnitude data and associated uncertainties. 
-    We then calculate the weighted percentiles of the magnitude data using the percentileofscore function from scipy.stats. 
+    We then calculate the weighted percentiles of the magnitude data using the cumulative sum of the weights. 
     We calculate the percentiles using np.interp with the cumulative sum of the weights, and then calculate the 
     flux percentile ratios using the weighted percentiles.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The ratio of the (60th - 40th) flux percentile over the (95th - 5th) percentile.
     """
 
+    sorted_data = np.sort(mag)
+    lc_length = len(sorted_data)
+    
     if apply_weights:
-        sorted_indices = np.argsort(mag)
-        sorted_mag = mag[sorted_indices]
-        sorted_magerr = magerr[sorted_indices]
-        #Calculate the weighted percentiles
-        weights = 1 / sorted_magerr ** 2
-        cum_weights = np.cumsum(weights)
-        percentile_5 = np.interp(5, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_95 = np.interp(95, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_40 = np.interp(40, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_60 = np.interp(60, cum_weights / cum_weights[-1], sorted_mag)
-        #Calculate the flux percentile ratios
-        F_40_60 = percentile_60 - percentile_40
-        F_5_95 = percentile_95 - percentile_5
-        F_mid20 = F_40_60 / F_5_95
+        weights = 1.0 / (magerr ** 2)
+        cumulative_weights = np.cumsum(weights)
+        percentiles = np.interp([0.05, 0.40, 0.60, 0.95], cumulative_weights / cumulative_weights[-1], sorted_data)
     else:
-        sorted_data = np.sort(mag)
-        lc_length = len(sorted_data)
-        F_60_index = int(math.ceil(0.60 * lc_length))
-        F_40_index = int(math.ceil(0.40 * lc_length))
-        F_5_index = int(math.ceil(0.05 * lc_length))
-        F_95_index = int(math.ceil(0.95 * lc_length))
-        F_40_60 = sorted_data[F_60_index] - sorted_data[F_40_index]
-        F_5_95 = sorted_data[F_95_index] - sorted_data[F_5_index]
-        F_mid20 = F_40_60 / F_5_95
+        percentiles = np.percentile(sorted_data, [5, 40, 60, 95])
+    
+    F_40_60 = percentiles[2] - percentiles[1]
+    F_5_95 = percentiles[3] - percentiles[0]
+    F_mid20 = F_40_60 / F_5_95
 
     return F_mid20
 
 def FluxPercentileRatioMid35(time, mag, magerr, apply_weights=True):
     """
     In order to characterize the sorted magnitudes distribution we use percentiles. 
     If F5,95 is the difference between 95% and 5% magnitude values, we calculate the following:
     Ratio of flux percentiles (67.5th - 32.5th) over (95th - 5th)
     
     In this updated version of the function, we first sort the magnitude data and associated uncertainties. 
     We then calculate the weighted percentiles of the magnitude data using np.interp with the cumulative sum of 
     the weights, and then calculate the flux percentile ratios using the weighted percentiles.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The ratio of the (67.5th - 32.5th) flux percentile over the (95th - 5th) percentile.
     """
 
+    sorted_data = np.sort(mag)
+    lc_length = len(sorted_data)
+
     if apply_weights:
-        sorted_indices = np.argsort(mag)
-        sorted_mag = mag[sorted_indices]
-        sorted_magerr = magerr[sorted_indices]
-        #Calculate the weighted percentiles
-        weights = 1 / sorted_magerr ** 2
-        cum_weights = np.cumsum(weights)
-        percentile_5 = np.interp(5, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_95 = np.interp(95, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_325 = np.interp(32.5, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_675 = np.interp(67.5, cum_weights / cum_weights[-1], sorted_mag)
-        #Calculate the flux percentile ratios
-        F_325_675 = percentile_675 - percentile_325
-        F_5_95 = percentile_95 - percentile_5
-        F_mid35 = F_325_675 / F_5_95
+        weights = 1.0 / (magerr ** 2)
+        cumulative_weights = np.cumsum(weights)
+        percentiles = np.interp([0.05, 0.325, 0.675, 0.95], cumulative_weights / cumulative_weights[-1], sorted_data)
     else:
-        sorted_data = np.sort(mag)
-        lc_length = len(sorted_data)
-        F_325_index = int(math.ceil(0.325 * lc_length))
-        F_675_index = int(math.ceil(0.675 * lc_length))
-        F_5_index = int(math.ceil(0.05 * lc_length))
-        F_95_index = int(math.ceil(0.95 * lc_length))
-        F_325_675 = sorted_data[F_675_index] - sorted_data[F_325_index]
-        F_5_95 = sorted_data[F_95_index] - sorted_data[F_5_index]
-        F_mid35 = F_325_675 / F_5_95
+        percentiles = np.percentile(sorted_data, [5, 32.5, 67.5, 95])
+
+    F_325_675 = percentiles[2] - percentiles[1]
+    F_5_95 = percentiles[3] - percentiles[0]
+    F_mid35 = F_325_675 / F_5_95
 
     return F_mid35
 
 def FluxPercentileRatioMid50(time, mag, magerr, apply_weights=True):
     """
     In order to characterize the sorted magnitudes distribution we use percentiles. 
     If F5,95 is the difference between 95% and 5% magnitude values, we calculate the following:
     Ratio of flux percentiles (75th - 25th) over (95th - 5th)
     
     In this updated version of the function, we first sort the magnitude data and associated uncertainties. 
-    We then calculate the weighted percentiles of the magnitude data using the percentileofscore function from scipy.stats. 
-    We calculate the percentiles using np.interp with the cumulative sum of the weights, and then calculate the 
-    flux percentile ratios using the weighted percentiles.
+    We then calculate the weighted percentiles of the magnitude data using np.interp with the cumulative sum of 
+    the weights, and then calculate the flux percentile ratios using the weighted percentiles.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The ratio of the (75th - 25th) flux percentile over the (95th - 5th) percentile.
     """
 
+    sorted_data = np.sort(mag)
+    lc_length = len(sorted_data)
+
     if apply_weights:
-        sorted_indices = np.argsort(mag)
-        sorted_mag = mag[sorted_indices]
-        sorted_magerr = magerr[sorted_indices]
-        # Calculate the weighted percentiles
-        weights = 1 / sorted_magerr ** 2
-        cum_weights = np.cumsum(weights)
-        percentile_25 = np.interp(25, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_75 = np.interp(75, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_5 = np.interp(5, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_95 = np.interp(95, cum_weights / cum_weights[-1], sorted_mag)
-        # Calculate the flux percentile ratios
-        F_25_75 = percentile_75 - percentile_25
-        F_5_95 = percentile_95 - percentile_5
-        F_mid50 = F_25_75 / F_5_95
+        weights = 1.0 / (magerr ** 2)
+        cumulative_weights = np.cumsum(weights)
+        percentiles = np.interp([0.05, 0.25, 0.75, 0.95], cumulative_weights / cumulative_weights[-1], sorted_data)
     else:
-        sorted_data = np.sort(mag)
-        lc_length = len(sorted_data)
-        F_25_index = int(math.ceil(0.25 * lc_length))
-        F_75_index = int(math.ceil(0.75 * lc_length))
-        F_5_index = int(math.ceil(0.05 * lc_length))
-        F_95_index = int(math.ceil(0.95 * lc_length))
-        F_25_75 = sorted_data[F_75_index] - sorted_data[F_25_index]
-        F_5_95 = sorted_data[F_95_index] - sorted_data[F_5_index]
-        F_mid50 = F_25_75 / F_5_95
+        percentiles = np.percentile(sorted_data, [5, 25, 75, 95])
+
+    F_25_75 = percentiles[2] - percentiles[1]
+    F_5_95 = percentiles[3] - percentiles[0]
+    F_mid50 = F_25_75 / F_5_95
 
     return F_mid50
 
 def FluxPercentileRatioMid65(time, mag, magerr, apply_weights=True):
     """
     In order to characterize the sorted magnitudes distribution we use percentiles. 
     If F5,95 is the difference between 95% and 5% magnitude values, we calculate the following:
     Ratio of flux percentiles (82.5th - 17.5th) over (95th - 5th)
 
     In this updated version of the function, we first sort the magnitude data and associated uncertainties. 
-    We then calculate the weighted percentiles of the magnitude data using the percentileofscore function from scipy.stats. 
-    We calculate the percentiles using np.interp with the cumulative sum of the weights, and then calculate the 
-    flux percentile ratios using the weighted percentiles.
+    We then calculate the weighted percentiles of the magnitude data using np.interp with the cumulative sum of 
+    the weights, and then calculate the flux percentile ratios using the weighted percentiles.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The ratio of the (82.5th - 17.5th) flux percentile over the (95th - 5th) percentile.
     """
-    
+
+    sorted_data = np.sort(mag)
+    lc_length = len(sorted_data)
+
     if apply_weights:
-        sorted_indices = np.argsort(mag)
-        sorted_mag = mag[sorted_indices]
-        sorted_magerr = magerr[sorted_indices]
-        # Calculate the weighted percentiles
-        weights = 1 / sorted_magerr ** 2
-        cum_weights = np.cumsum(weights)
-        percentile_175 = np.interp(17.5, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_825 = np.interp(82.5, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_5 = np.interp(5, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_95 = np.interp(95, cum_weights / cum_weights[-1], sorted_mag)
-        # Calculate the flux percentile ratios
-        F_175_825 = percentile_825 - percentile_175
-        F_5_95 = percentile_95 - percentile_5
-        F_mid65 = F_175_825 / F_5_95
+        weights = 1.0 / (magerr ** 2)
+        cumulative_weights = np.cumsum(weights)
+        percentiles = np.interp([0.05, 0.175, 0.825, 0.95], cumulative_weights / cumulative_weights[-1], sorted_data)
     else:
-        sorted_data = np.sort(mag)
-        lc_length = len(sorted_data)
-        F_175_index = int(math.ceil(0.175 * lc_length))
-        F_825_index = int(math.ceil(0.825 * lc_length))
-        F_5_index = int(math.ceil(0.05 * lc_length))
-        F_95_index = int(math.ceil(0.95 * lc_length))
-        F_175_825 = sorted_data[F_825_index] - sorted_data[F_175_index]
-        F_5_95 = sorted_data[F_95_index] - sorted_data[F_5_index]
-        F_mid65 = F_175_825 / F_5_95
+        percentiles = np.percentile(sorted_data, [5, 17.5, 82.5, 95])
+
+    F_175_825 = percentiles[2] - percentiles[1]
+    F_5_95 = percentiles[3] - percentiles[0]
+    F_mid65 = F_175_825 / F_5_95
 
     return F_mid65
 
 def FluxPercentileRatioMid80(time, mag, magerr, apply_weights=True):
     """
     In order to characterize the sorted magnitudes distribution we use percentiles. 
     If F5,95 is the difference between 95% and 5% magnitude values, we calculate the following:
     Ratio of flux percentiles (90th - 10th) over (95th - 5th)
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The ratio of the (90th - 10th) flux percentile over the (95th - 5th) percentile.
     """
-    
+ 
+    sorted_data = np.sort(mag)
+    lc_length = len(sorted_data)
+
     if apply_weights:
-        sorted_indices = np.argsort(mag)
-        sorted_mag = mag[sorted_indices]
-        sorted_magerr = magerr[sorted_indices]
-        # Calculate the weighted percentiles
-        weights = 1 / sorted_magerr ** 2
-        cum_weights = np.cumsum(weights)
-        percentile_10 = np.interp(10, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_90 = np.interp(90, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_5 = np.interp(5, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_95 = np.interp(95, cum_weights / cum_weights[-1], sorted_mag)
-        # Calculate the flux percentile ratios
-        F_10_90 = percentile_90 - percentile_10
-        F_5_95 = percentile_95 - percentile_5
-        F_mid80 = F_10_90 / F_5_95
+        weights = 1.0 / (magerr ** 2)
+        cumulative_weights = np.cumsum(weights)
+        percentiles = np.interp([0.05, 0.10, 0.90, 0.95], cumulative_weights / cumulative_weights[-1], sorted_data)
     else:
-        sorted_data = np.sort(mag)
-        lc_length = len(sorted_data)
-        F_10_index = int(math.ceil(0.10 * lc_length))
-        F_90_index = int(math.ceil(0.90 * lc_length))
-        F_5_index = int(math.ceil(0.05 * lc_length))
-        F_95_index = int(math.ceil(0.95 * lc_length))
-        F_10_90 = sorted_data[F_90_index] - sorted_data[F_10_index]
-        F_5_95 = sorted_data[F_95_index] - sorted_data[F_5_index]
-        F_mid80 = F_10_90 / F_5_95
+        percentiles = np.percentile(sorted_data, [5, 10, 90, 95])
+
+    F_10_90 = percentiles[2] - percentiles[1]
+    F_5_95 = percentiles[3] - percentiles[0]
+    F_mid80 = F_10_90 / F_5_95
 
     return F_mid80
 
 def PercentAmplitude(time, mag, magerr, apply_weights=True):
     """
     The largest absolute departure from the median flux, divided by the median flux
     Largest percentage difference between either the max or min magnitude and the median.
     
     This function calculates both the regular median and a weighted median that takes into 
     account the photometric errors. It then calculates the largest absolute departure from 
     each of these medians and returns the largest percentage difference between either the 
     max or min magnitude and the weighted median.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The largest percentage difference present in the lightcurve with respect to the median.
     """
 
     if apply_weights:
         weights = 1.0 / magerr**2
         median = np.median(mag)
         w_median = np.ma.average(mag, weights=weights)
         distance_median = np.abs(mag - median)
@@ -1231,75 +1345,89 @@
         median = np.median(mag)
         distance_median = np.abs(mag - median)
         max_distance = np.max(distance_median)
         return max_distance / median
 
 def PercentDifferenceFluxPercentile(time, mag, magerr, apply_weights=True):
     """
-    Ratio of F5,95 over the median flux.
+    Calculates the ratio of the flux difference between the 5th and 95th percentiles of 
+    the data (F5,95) to the median flux.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    If apply_weights is set to True, the function first sorts the mag array and the corresponding magerr
+    based on the magnitude values. It then calculates the weighted percentiles by interpolating the values 
+    at the desired percentiles (2%, 5%, 95%, and 98%) using cumulative weights. The difference between 
+    the 95th and 5th percentiles (F5,95) is calculated based on the interpolated values.
+
+    If apply_weights is set to False, the function directly operates on the mag array. It sorts the array and 
+    calculates the indices corresponding to the 5th and 95th percentiles. The flux difference between these 
+    percentiles (F5,95) is then calculated.
 
-    Returns
-    -------     
-    rtype: float
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
+
+    Returns:
+    -------
+    float
+        The ratio of the flux difference between the 5th and 95th percentiles to the median lightcurve measurement.
     """
 
     if apply_weights:
         sorted_indices = np.argsort(mag)
         sorted_mag = mag[sorted_indices]
         sorted_magerr = magerr[sorted_indices]
-        median = np.median(sorted_mag)
-        # Calculate the weighted percentiles
         weights = 1 / sorted_magerr ** 2
-        cum_weights = np.cumsum(weights)
-        percentile_2 = np.interp(2, cum_weights / cum_weights[-1], sorted_mag) #can be used to find the percentile of the value 2 in the distribution defined by sorted_mag and cum_weights.
-        percentile_98 = np.interp(98, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_5 = np.interp(5, cum_weights / cum_weights[-1], sorted_mag)
-        percentile_95 = np.interp(95, cum_weights / cum_weights[-1], sorted_mag)
-        # Calculate the flux percentile ratios
+        total_weights = np.sum(weights)
+        cum_weights = np.cumsum(weights) / total_weights
+        percentile_95 = np.interp(0.95, cum_weights, sorted_mag)
+        percentile_5 = np.interp(0.05, cum_weights, sorted_mag)
         F_5_95 = percentile_95 - percentile_5
     else:
-        median = np.median(mag)
         sorted_data = np.sort(mag)
         lc_length = len(sorted_data)
         F_5_index = int(math.ceil(0.05 * lc_length))
         F_95_index = int(math.ceil(0.95 * lc_length))
         F_5_95 = sorted_data[F_95_index] - sorted_data[F_5_index]
 
-    return F_5_95 / median
+    return F_5_95 / np.median(mag)
 
 #Below stats from Kim (2015), used in Upsilon
 #https://arxiv.org/pdf/1512.01611.pdf
 
 def half_mag_amplitude_ratio(time, mag, magerr, apply_weights=True):
     """
-    The ratio of the squared sum of residuals of magnitudes
-    that are either brighter than or fainter than the mean
-    magnitude. For EB-like variability, having sharp flux gradients around its eclipses, A is larger
-    than 1.
-
-    In this modified version, the weighted standard deviation of each set of magnitudes (i.e., those above 
-    and those below the median) is used.
-
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    The ratio of the squared sum of residuals of magnitudes that are either brighter 
+    than or fainter than the mean magnitude. For EB-like variability, having sharp 
+    flux gradients around its eclipses, this value is larger than 1.
 
-    Returns
-    -------     
-    rtype: float
+    In this modified version, the weighted standard deviation of each set of 
+    magnitudes (i.e., those above and those below the median) is used if apply_weights is set to True.
+
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
+
+    Returns:
+    -------
+    float
+        The ratio of squared residuals for measurements above and below the median.    
     """
 
     if apply_weights:
         #For fainter magnitude than average.
         avg = np.median(mag)
         index = np.argwhere(mag > avg)
         lower_mag = mag[index]
@@ -1329,24 +1457,29 @@
     Range of cumulative sum.
 
     In this updated version, we first calculate the weighted standard deviation of 
     the magnitude using the formula wstd = np.sqrt(np.sum((mag - np.median(mag))**2 / magerr**2) / np.sum(1. / magerr**2)). 
     Then we use this value instead of np.std(mag) to normalize the cumulative sum. This takes into account the error in 
     the measurements of the magnitude.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The range of the cumulative sums of the lightcurve measurements.
     """
 
     if apply_weights:
         #Calculate the weighted standard deviation
         wstd = np.sqrt(np.sum((mag - np.median(mag))**2 / magerr**2) / np.sum(1. / magerr**2))
         c = np.cumsum(mag - np.median(mag)) * 1./(len(mag)*wstd)
     else:
@@ -1358,28 +1491,31 @@
     """
     The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution.
     
     If this statistic is close to 1, then it suggests that the null hypothesis cannot be rejected, 
     which means the data is likely to follow a normal distribution. Note that there is no error incorporation, 
     as the Shapiro-Wilk test implemented in scipy.stats does not provide an option to incorporate measurement error.
     
-    Note
-    ----------
-    The Shapiro-Wilk test implemented in scipy.stats does not provide an option to incorporate measurement errors.
+    Note that the Shapiro-Wilk test implemented in scipy.stats does not provide the option to incorporate measurement errors.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Not used in this function.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------
+    float
+        The Shapiro-Wilk statistic.
     """
 
     shapiro_w = sstats.shapiro(mag)[0]
 
     return shapiro_w
 
 #Following stats pulled from FEETS
@@ -1401,25 +1537,29 @@
     When applied to testing if a normal distribution adequately describes a set of data, 
     it is one of the most powerful statistical tools for detecting most departures from normality.
     
     From Kim et al. 2009: "To test normality, we use the Anderson–Darling test (Anderson & Darling 1952; Stephens 1974) 
     which tests the null hypothesis that a data set comes from the normal distribution."
     (Doi:10.1111/j.1365-2966.2009.14967.x.)
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------     
     float
-        The Anderson-Darling test statistic for the normality test.
+        The Anderson-Darling test statistic.
     """
     
     if apply_weights:
         weights = 1.0 / np.square(magerr)
         wmag = np.average(mag, weights=weights)
         wmagsq = np.average(np.square(mag), weights=weights)
         wvar = wmagsq - wmag**2
@@ -1440,155 +1580,189 @@
     Gskew is a measure of the skewness of a distribution of magnitudes. It is defined as the 
     sum of the medians of the magnitudes below and above the 3rd and 97th percentiles, respectively, 
     minus twice the median magnitude. In other words, Gskew is a measure of the asymmetry of the 
     distribution of magnitudes. A positive Gskew value indicates a distribution that is skewed to the 
     right (has a long tail on the right side), while a negative Gskew value indicates a distribution 
     that is skewed to the left (has a long tail on the left side).
 
-    It is a median-based measure of the skewness. See: Lopez et al. 2016: "A machine learned classifier for RR Lyrae in the VVV survey" 
+    It is essentially a median-based measure of the skewness. See: Lopez et al. 2016: "A machine learned classifier for RR Lyrae in the VVV survey" 
 
     Gskew = mq3 + mq97 − 2m
     mq3 is the median of magnitudes lesser or equal than the quantile 3.
     mq97 is the median of magnitudes greater or equal than the quantile 97.
     2m is 2 times the median magnitude.
 
     If apply_weights=True a modified version will be used that incorporates the photometric 
     errors of the data points. It calculates a weighted median for the magnitudes that 
     fall below the 3rd percentile and above the 97th percentile, using the inverse 
     square of the photometric errors as weights. The resulting weighted medians and 
-    the median magnitude are then used to calculate the Gskew value, which is a measure 
-    of the skewness of the lightcurve.
+    the median magnitude are then used to calculate the Gskew value.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------  
+    float   
+        The median-based skewness of the lightcurve.
     """
 
     if apply_weights:
         #Sort the magnitude and error arrays by magnitude
         sorted_indices = np.argsort(mag)
         sorted_mag = mag[sorted_indices]
         sorted_magerr = magerr[sorted_indices]
-        #Calculate the cumulative weights
+
+        # Calculate the cumulative weights
         weights = 1.0 / np.square(sorted_magerr)
         cum_weights = np.cumsum(weights)
-        #Calculate the indices of the median and quantiles
-        median_index = np.searchsorted(cum_weights, 0.5*cum_weights[-1])
-        q3_index = np.searchsorted(cum_weights, 0.03*cum_weights[-1])
-        q97_index = np.searchsorted(cum_weights, 0.97*cum_weights[-1])
-        #Calculate the median and quantiles
+
+        # Calculate the indices of the median and quantiles
+        median_index = np.searchsorted(cum_weights, 0.5 * cum_weights[-1])
+        q3_index = np.searchsorted(cum_weights, 0.03 * cum_weights[-1])
+        q97_index = np.searchsorted(cum_weights, 0.97 * cum_weights[-1])
+
+        # Calculate the median and quantiles
         median_mag = sorted_mag[median_index]
         F_3_value = sorted_mag[q3_index]
         F_97_value = sorted_mag[q97_index]
-        #Calculate the weighted median of magnitudes <= F_3_value
-        cum_weights_3 = cum_weights[q3_index-1]
+
+        # Calculate the weighted median of magnitudes <= F_3_value
+        cum_weights_3 = cum_weights[:q3_index]
         weights_3 = weights[:q3_index]
         cum_weights_3 -= cum_weights_3[0]
         cum_weights_3 /= cum_weights_3[-1]
-        mq3 = np.interp(0.5, cum_weights_3, sorted_mag[:q3_index])
-        #Calculate the weighted median of magnitudes >= F_97_value
-        cum_weights_97 = cum_weights[q97_index-1]
+        mq3 = np.interp(0.5, cum_weights_3[::-1], sorted_mag[:q3_index][::-1])
+
+        # Calculate the weighted median of magnitudes >= F_97_value
+        cum_weights_97 = cum_weights[q97_index-1:]
         weights_97 = weights[q97_index-1:]
         cum_weights_97 -= cum_weights_97[0]
         cum_weights_97 /= cum_weights_97[-1]
         mq97 = np.interp(0.5, cum_weights_97, sorted_mag[q97_index-1:])
-        gs = mq3 + mq97 - 2*median_mag
+
+        gs = mq3 + mq97 - 2 * median_mag
+
     else:
         median_mag = np.median(mag)
         F_3_value = np.percentile(mag, 3)
         F_97_value = np.percentile(mag, 97)
         gs = (np.median(mag[mag <= F_3_value]) + np.median(mag[mag >= F_97_value]) - 2*median_mag)
 
     return gs
 
 def abs_energy(time, mag, magerr, apply_weights=True):
     """
-    Returns the absolute energy of the time series, defined to be the sum over the squared
-    values of the time-series, weighted by the inverse square of the photometric errors.
-    
-    In this modified function, we calculate the inverse square of the photometric errors 
+    Calculates the absolute energy of the time series, defined to be the sum over the squared
+    values of the time-series.
+
+    If apply_weights is set to True, we calculate the inverse square of the photometric errors 
     and use them as weights to calculate the weighted sum of squares of the magnitudes.
+    In the case where weights are applied, the magnitudes are multiplied by their corresponding 
+    weights (inverse square of photometric errors) before squaring and summing them. This results in 
+    a larger contribution from data points with smaller errors, as they receive higher weights. As a result, 
+    the absolute energy value increases. On the other hand, when weights are not applied (apply_weights=False), 
+    all magnitudes are squared and summed without considering their errors. This leads to a smaller 
+    absolute energy value as the contributions from individual data points are not scaled by their respective errors.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
+
+    Returns:
+    -------   
+    float  
+        The sum over the squared values of the lightcurve measurements.
     """
 
     if apply_weights:
         weights = 1.0 / np.square(magerr)
         abs_energy = np.sum(weights * np.square(mag))
     else:
         abs_energy = np.dot(mag, mag)
 
     return abs_energy
 
 def abs_sum_changes(time, mag, magerr, apply_weights=True):
     """
-    Returns sum over the abs value of consecutive changes in mag, weighted by the errors.
+    Calculates the sum over the abs value of consecutive changes in mag, weighted by the errors.
     
     In this updated version we incorporate photometric errors by dividing the absolute value 
     of the difference between consecutive magnitudes by the square root of the sum of their squared errors. 
     Therefore larger errors will result in smaller weight for the corresponding changes in magnitude.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------    
+    float 
+        The sum over the absolute value of consecutive changes in the lightcurve measurements.
     """
 
     if apply_weights:
         delta_mag = np.abs(np.diff(mag))
         delta_err = np.sqrt(np.square(magerr[:-1]) + np.square(magerr[1:]))
         weighted_delta = delta_mag / delta_err
         return np.sum(weighted_delta)
     else:
         return np.sum(np.abs(np.diff(mag)))
 
 def benford_correlation(time, mag, magerr, apply_weights=True):
     """
-    Useful for anomaly detection applications. Returns the 
+    Useful for anomaly detection applications. Calculates the 
     correlation from first digit distribution when compared to 
     the Newcomb-Benford’s Law distribution, weighted by the inverse variance of the magnitudes.
     
     In this updated version, we calculate the weights as the inverse 
     variance of the magnitudes (i.e., the inverse of the squared photometric errors), and use 
     these weights to calculate the weighted distribution of the data. We then normalize this 
     weighted distribution and compute the weighted correlation between the Benford distribution 
     and the weighted data distribution.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------     
-    rtype: float
+    float
+        The Benford Correlation statistic.
     """
 
     if apply_weights:
         #Retrieve first digit from data
         x = np.array([int(str(np.format_float_scientific(i))[:1]) for i in np.abs(np.nan_to_num(mag))])
         # benford distribution
         benford_distribution = np.array([np.log10(1 + 1 / n) for n in range(1, 10)])
@@ -1629,25 +1803,31 @@
     with these terms. Finally, we calculate the third-order correlation as the weighted average of the terms, where the 
     weights are given by the inverse squared errors. Note that this version of the function assumes Gaussian errors in the magerr array.
 
     See: Measure of non-linearity in time series: [1] Schreiber, T. and Schmitz, A. (1997).
     Discrimination power of measures for nonlinearity in a time series
     PHYSICAL REVIEW E, VOLUME 55, NUMBER 5
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    lag: The lag to use. Must be an integer.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        lag: int
+            The lag to use. Defaults to 1.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------  
+    float   
+        The C3 non-linearity statistic.
     """
 
     n = len(mag)
     if 2 * lag >= n:
         return 0
     else:
         if apply_weights:
@@ -1668,24 +1848,29 @@
     See: Batista, Gustavo EAPA, et al (2014). CID: an efficient complexity-invariant 
     distance for time series. Data Mining and Knowledge Difscovery 28.3 (2014): 634-669.
     
     To incorporate errors into the complexity function, we apply the weighted standard deviation formula. 
     We exclude the last element of magerr since np.diff reduces the size of the mag array 
     by one. Also, if the sum of the weights is zero, we return 0 to avoid division by zero errors.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------     
-    rtype: float
+    float
+        The complexity measurement of the lightcurve.
     """
 
     if apply_weights:
         dmag = np.diff(mag)
         w = 1 / magerr[:-1]**2  #weights based on magerr
         w_sum = np.sum(w)
         if w_sum == 0:
@@ -1703,24 +1888,29 @@
     Number of values higher than the weighted median.
 
     This function calculates the weighted median of the mag array using the photometric errors in magerr, 
     and then counts the number of values in mag that are above the weighted median. The fraction of values 
     above the weighted median is then calculated using the weights from magerr. If magerr is zero for all values, 
     the function returns zero.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------     
-    rtype: float
+    float
+        The number of lightcurve measurements above the median value.
     """ 
 
     if apply_weights:
         #Calculate the weighted median
         weights = 1.0 / (magerr ** 2)
         w_median = np.median(np.insert(mag, 0, -np.inf))
         
@@ -1736,63 +1926,73 @@
         else:
             return w_above / w_total
     else:
         return (np.where(mag > np.median(mag))[0].size)/len(mag)
 
 def count_below(time, mag, magerr, apply_weights=True):
     """
-    Number of values below the weighted median.
+    Number of values below the median.
 
     To incorporate errors, we use the weighted median instead of the regular median. 
     The weighted median takes into account the uncertainties associated with each data point.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------     
-    rtype: float
+    float
+        The number of lightcurve measurements below the median value.
     """
 
     if apply_weights:
         #Compute the weighted median
         weights = 1/magerr**2
         median = np.average(mag, weights=weights)
         #Count the number of values below the weighted median
         below_median = mag < median
         return np.sum(below_median * weights) / np.sum(weights)
     else:
         return (np.where(mag < np.median(mag))[0].size)/len(mag)
 
 def first_loc_max(time, mag, magerr, apply_weights=True):
     """
-    Returns location of maximum mag relative to the 
-    length of mag array, weighted by inverse square of magerr.
+    Calculates the location of maximum mag relative to the length of mag array, 
+    weighted by inverse square of magerr if apply_weights is True.
     
     In this modified version, we first calculate the inverse square 
     of magerr and set it to 0 where magerr2 is 0 to avoid division by zero. 
     Then we multiply each value of mag by the corresponding inverse square of magerr, 
     giving more weight to values with smaller magerr. Finally, we find the index of the 
     maximum value in the weighted mag array using np.argmax, and return the location of 
     the maximum relative to the length of mag.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------     
-    rtype: float
+    float
+        The relative position of the maximum detected lightcurve measurement.
     """
 
     if len(mag) == 0:
         return np.NaN
 
     if apply_weights:
         #Calculate inverse square of magerr
@@ -1803,32 +2003,37 @@
         #Return location of maximum mag relative to the length of mag array
         return weighted_max / len(mag)
     else:
         return np.argmax(mag) / len(mag)
 
 def first_loc_min(time, mag, magerr, apply_weights=True):
     """
-    Returns location of minimum mag relative to the 
+    Calculates the location of minimum mag relative to the 
     length of mag array.
     
     This updated implementation first computes the weights for each measurement 
     using the provided photometric errors in magerr. It then replaces all zero 
     weights with 1 to avoid division by zero. Finally, it computes the location 
     of the minimum mag by taking the weighted minimum of mag using the computed weights.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: int
+    Returns:
+    -------    
+    float 
+        The relative position of the minimum detected lightcurve measurement.
     """
 
     if len(mag) == 0:
         return np.NaN
 
     if apply_weights:
         # Compute weights
@@ -1840,33 +2045,38 @@
         loc_min = w_argmin / len(mag) 
         return loc_min
     else:
         return np.argmin(mag) / len(mag)
 
 def check_for_duplicate(time, mag, magerr, apply_weights=True):
     """
-    Checks if any value in mag repeats, taking into account photometric errors.
-    Returns 1 if True, 0 if False.
+    Checks if any value in mag repeats, taking into account photometric errors if apply_weights
+    is enabled so as to identify measurements that are within the error bars.
     
     To incorporate error, we use np.isclose to check if two values of mag are close to each other, 
     taking into account their respective errors. The tolerance is set using the atol argument, which is 
     set to the sum of the errors in quadrature, to account for the fact that two measurements with similar 
     values but different errors may still be considered duplicates. If a duplicate is found, the function 
     returns 1, otherwise it returns 0.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------     
-    rtype: int
+    int
+        Whether or not a duplicate lightcurve measurement is found, 1 for True, 0 for False.
     """
 
     if apply_weights:
         # Check for duplicates with photometric error tolerance
         for i in range(len(mag)):
             for j in range(i+1, len(mag)):
                 if np.isclose(mag[i], mag[j], rtol=0, atol=2*np.sqrt(magerr[i]**2 + magerr[j]**2)):
@@ -1876,33 +2086,38 @@
         if mag.size != np.unique(mag).size:
             return 1
         else:     
             return 0
 
 def check_for_max_duplicate(time, mag, magerr, apply_weights=True):
     """
-    Checks if the maximum value in mag repeats, taking into account photometric errors.
-    Returns 1 if a duplicate is found, 0 otherwise.
+    Checks if the maximum value in mag repeats, taking into account photometric errors if apply_weights
+    is enabled so as to identify measurements that are within the error bars.
 
     To incorporate error, we use np.isclose to check if the maximum value in mag is close to any other
     value in mag, taking into account their respective errors. The tolerance is set using the atol argument, 
     which is calculated as the maximum of the maximum error and the error of the closest value to the maximum, 
     to account for the fact that two measurements with similar values but different errors may still be 
     considered duplicates. If a duplicate is found, the function returns 1, otherwise it returns 0.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: int
+    Returns:
+    -------    
+    int 
+        Whether or not the maximum lightcurve measurement is found more than once, 1 for True, 0 for False.
     """
 
     if apply_weights:
         max_mag = np.max(mag)
         #Calculate the atol value based on the maximum error and the error of the closest value to the maximum
         closest_mag_err = np.min(np.abs(mag - max_mag))  #error of the closest value to the maximum
         atol = np.maximum(magerr, closest_mag_err)  # max of the maximum error and the error of the closest value to the maximum
@@ -1915,27 +2130,32 @@
         if np.sum(mag == np.max(mag)) >= 2:
              return 1
         else:     
              return 0
 
 def check_for_min_duplicate(time, mag, magerr, apply_weights=True):
     """
-    Checks if the minimum value in mag repeats, taking into account photometric errors.
-    Returns 1 if True, 0 if False.
+    Checks if the minimum value in mag repeats, taking into account photometric errors if apply_weights
+    is enabled so as to identify measurements that are within the error bars.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------     
-    rtype: int
+    int
+        Whether or not the minimum lightcurve measurement is found more than once, 1 for True, 0 for False.
     """
 
     if apply_weights:
         min_mag = np.min(mag)
         #Find the indices of the minimum values in mag
         min_idx = np.where(np.isclose(mag, min_mag, rtol=0, atol=magerr))[0]
         #Check for duplicates with photometric error tolerance
@@ -1947,33 +2167,38 @@
         if np.sum(mag == np.min(mag)) >= 2:
             return 1
         else:     
             return 0
 
 def check_max_last_loc(time, mag, magerr, apply_weights=True):
     """
-    Returns position of last maximum mag relative to
+    Calculates the position of last maximum mag relative to
     the length of mag array, taking into account photometric errors.
     
     In this implementation, we first find the maximum value in mag and calculate the tolerance 
     value atol as the maximum photometric error in magerr. We then use np.isclose() with atol 
     as the atol argument to find the indices of all values in mag that are within tolerance of max_mag. 
     We select the last index in the resulting array (which corresponds to the last maximum value in mag) and 
     calculate its position relative to the length of mag. If there are no values within tolerance (3sigma), we return np.NaN.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------     
-    rtype: int
+    float
+        The relative position where the maximum lightcurve measurement was last found.
     """
 
     if apply_weights:
         #Find the maximum value in mag
         max_mag = np.max(mag)
         #Calculate the tolerance value based on the photometric errors
         atol = np.max(magerr) * 3
@@ -1984,35 +2209,40 @@
         else:
             return np.NaN
     else:
         return 1.0 - np.argmax(mag[::-1]) / len(mag) if len(mag) > 0 else np.NaN
 
 def check_min_last_loc(time, mag, magerr, apply_weights=True):
     """
-    Returns position of last minimum mag relative to
+    Calculates the position of last minimum mag relative to
     the length of mag array, taking into account photometric errors.
     
     To incorporate errors, this implementation finds the minimum value in mag, 
     then calculates the atol value based on the error of the minimum value and 
     the error of the closest value to the minimum. It then uses np.isclose() with 
     atol as the atol argument to find the indices of all values in mag that are within 
     tolerance of min_mag. It selects the last index in the resulting array (which corresponds 
     to the last minimum value in mag) and calculates its position relative to the length of mag. 
     If there are no values within tolerance, it returns np.NaN.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The relative position where the minimum lightcurve measurement was last found.
     """
 
     if apply_weights:
         #Find the minimum value in mag
         min_mag = np.min(mag)
         #Find the error of the closest value to the minimum in magerr
         closest_mag_err = magerr[np.argmin(mag)]
@@ -2025,199 +2255,234 @@
         else:
             return np.NaN
     else:
         return 1.0 - np.argmin(mag[::-1]) / len(mag) if len(mag) > 0 else np.NaN
 
 def longest_strike_above(time, mag, magerr, apply_weights=True):
     """
-    Returns the length of the longest consecutive subsequence in 
+    Calculates the length of the longest consecutive subsequence in 
     mag that is bigger than the median. 
     
     This updated implementation first calculates the median of the mag 
     array and creates a boolean mask of True for elements greater than the 
     median plus their errors and False for elements less than or equal to the 
     median plus their errors. It then splits the mask into groups of consecutive 
     True values, and returns the length of the longest group as a fraction of 
     the length of the mag array. If there are no values greater than the median plus 
     their errors, the function returns 0.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The length of the longest consecutive subsequence in the lightcurve measurements which are larger than the median.
     """
 
     if apply_weights:
         median = np.median(mag)
         mask = mag > median + magerr
         if np.sum(mask) == 0:
             return 0
         else:
             groups = np.split(mask, np.where(np.diff(mask.astype(int)) != 0)[0]+1)
             return np.max([len(group) for group in groups if np.all(group)]) / len(mag)
     else:
         val = np.max([len(list(group)) for value, group in itertools.groupby(mag) if value == 1]) if mag.size > 0 else 0
-        return val/len(mag)
+        return val / len(mag)
 
 def longest_strike_below(time, mag, magerr, apply_weights=True):
     """
-    Returns the length of the longest consecutive subsequence in mag 
+    Calculates the length of the longest consecutive subsequence in mag 
     that is smaller than the median.
     
     To incorporate errors, first we calculate the median of mag and create 
     a boolean mask of True for elements smaller than the median minus their errors 
     and False for elements greater than or equal to the median minus their errors. 
     Then we split the mask into groups of consecutive True values, and return the 
     length of the longest group as a fraction of the length of the mag array. If 
     there are no values smaller than the median minus their errors, the function returns 0.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The length of the longest consecutive subsequence in the lightcurve measurements which are smaller than the median.
     """
 
     if apply_weights:
         median = np.median(mag)
         mask = mag < median - magerr
         if np.sum(mask) == 0:
             return 0
         else:
             groups = np.split(mask, np.where(np.diff(mask.astype(int)) != 0)[0]+1)
             return np.max([len(group) for group in groups if np.all(group)]) / len(mag)
     else:
         val = np.max([len(list(group)) for value, group in itertools.groupby(mag) if value == 1]) if mag.size > 0 else 0
-        return val/len(mag)
+        return val / len(mag)
 
 def mean_change(time, mag, magerr, apply_weights=True):
     """
-    Returns mean over the differences between subsequent observations,
-    weighted by the inverse square of their errors.
+    Calculates mean over the differences between subsequent observations,
+    weighted by the inverse square of their errors if apply_weights is True.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------  
+    float   
+        The mean over the differences between all subsequent lightcurve measurements.
     """
 
     if apply_weights:
         if len(mag) < 2:
             return np.NaN
         else:
             diffs = np.diff(mag)
             weights = 1.0 / (magerr[1:]**2 + magerr[:-1]**2)
             return np.average(diffs, weights=weights)
     else:
         return (mag[-1] - mag[0]) / (len(mag) - 1) if len(mag) > 1 else np.NaN
 
 def mean_abs_change(time, mag, magerr, apply_weights=True):
     """
-    Returns the mean absolute change in the magnitude per unit of error.
+    Calculates the mean absolute change in the magnitude per unit of error.
     
     To incorporate error we weight each absolute difference by the corresponding error, 
     and then take the mean of the weighted differences. This would give a measure of the 
     average absolute change in units of the error.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    -------  
+    float   
+        The mean absolute change in the lightcurve measurements.
     """
 
     if apply_weights:
         diffs = np.abs(np.diff(mag))
         weights = magerr[:-1] + magerr[1:]
         return np.average(diffs, weights=weights)
     else:
         return np.mean(np.abs(np.diff(mag)))
 
-def mean_n_abs_max(time, mag, magerr, number_of_maxima=1, apply_weights=True):
+def mean_n_abs_max(time, mag, magerr, number_of_maxima=10, apply_weights=True):
     """
-    Calculates the weighted arithmetic mean of the n absolute maximum values of the time series, n = 1.
+    Calculates the weighted arithmetic mean of the n absolute maximum values of the time series, n=10 by design.
     
     We incorporate errors in the calculation by sorting the absolute values of the magnitude and corresponding 
     errors, and then taking the arithmetic mean of the top n maximum values weighted by their errors.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    number_of_maxima: the number of maxima to be considered
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        number_of_maxima : int
+            The number of maxima to consider. Defaults to 10.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
+    Returns:
     -------     
-    rtype: float
+    float
+        The mean of the 10 absolute maximum values of the lightcurve. 
     """
     
     if number_of_maxima >= len(mag):
         return np.NaN
 
     if apply_weights:
         sort_idx = np.argpartition(np.abs(mag), -number_of_maxima)[-number_of_maxima:]
         mag_sorted = mag[sort_idx]
         magerr_sorted = magerr[sort_idx]
-        weights = 1 / magerr_sorted ** 2
-        weighted_mean = np.sum(mag_sorted * weights) / np.sum(weights)
+        weights = 1 / np.square(magerr_sorted)
+        weighted_mean = np.sum(np.abs(mag_sorted) * weights) / np.sum(weights)
         return weighted_mean
     else:
         n_absolute_maximum_values = np.sort(np.abs(mag))[-number_of_maxima:]
         return np.mean(n_absolute_maximum_values)
 
 def mean_second_derivative(time, mag, magerr, apply_weights=True):
     """
-    Returns the weighted mean value of a central approximation of the second derivative,
+    Calculates the weighted mean value of a central approximation of the second derivative,
     where weights are the inverse square of the errors. Note that the first and last values 
     of the second derivative are not included in the calculation, as they cannot be approximated 
     using a central difference.
     
-    Parameters
+    Parameters:
     ----------
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------
-    rtype: float
+    Returns:
+    -------  
+    float   
+        The mean value of a central approximation of the second derivative.
     """
 
     if len(mag) < 3:
         return np.NaN
     
     if apply_weights:
         diffs = np.diff(mag)
         times = np.diff(time)
-        errors = np.abs(diffs / times ** 2) * np.sqrt((magerr[:-1] / diffs) ** 2 + (magerr[1:] / diffs) ** 2)
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            errors = np.abs(diffs / times ** 2) * np.sqrt((magerr[:-1] / diffs) ** 2 + (magerr[1:] / diffs) ** 2)
+        mask = np.isfinite(errors)
+        diffs, times, errors = diffs[mask], times[mask], errors[mask]
         weights = 1 / errors ** 2
         weighted_diffs = diffs[1:-1] * weights[1:-1]
         return np.sum(weighted_diffs) / np.sum(weights[1:-1])
     else:   
         return (mag[-1] - mag[-2] - mag[1] + mag[0]) / (2 * (len(mag) - 2)) if len(mag) > 2 else np.NaN
 
 def number_of_crossings(time, mag, magerr, apply_weights=True):
@@ -2228,35 +2493,40 @@
     
     We incorporate errors by calculating the differences between consecutive values of the positive array and store it in 
     the crossings variable. Finally, we multiply the crossings array with a Boolean array that checks if the difference 
     between consecutive values of mag is greater than the corresponding error in magerr. The resulting array will have a 
     value of 1 for each crossing that is greater than the corresponding error, and 0 for each crossing that is smaller 
     than or equal to the error. We then sum this array to get the total number of crossings.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: int
+    Returns:
+    ------- 
+    float    
+        The number of crossings about the lightcurve's median.
     """
 
     positive = mag > np.median(mag)
 
     if apply_weights:
         crossings = np.abs(np.diff(positive))
         # check if the difference is greater than the corresponding error
         crossings = crossings * (np.abs(np.diff(mag)) > magerr[:-1])
-        return np.sum(crossings)
+        return np.sum(crossings) / len(mag)
     else:
-        return (np.where(np.diff(positive))[0].size)/len(mag)
+        return (np.where(np.diff(positive))[0].size) / len(mag)
 
 def number_of_peaks(time, mag, magerr, n=7, apply_weights=True):
     """
     Calculates the number of peaks of at least support n in the time series x. 
     A peak of support n is defined as a subsequence of x where a value occurs, 
     which is bigger than its n neighbors to the left and to the right.
     n = 7
@@ -2276,25 +2546,31 @@
     To incorporate the error bars we first reduce the mag and magerr arrays by n elements from both ends to ensure that 
     we can check for peaks of support n. We then iterate over the mag array and calculate the differences between 
     the values of the mag array and its i-th neighbor to the left and to the right. We also calculate the corresponding 
     errors for the differences using the error arrays magerr and xerr_reduced. We then check if the absolute value of 
     the difference is greater than the corresponding error to determine if we have a peak of support n. Finally, we combine 
     the results using logical AND to get the total number of peaks.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    n: The support of the peak. Must be an int.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        n : int
+            The support of the peak. Defaults to 7.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: int
+    Returns:
+    ------- 
+    float    
+        The number of peaks of at least support 7 within the lightcurve, normalized according to the size of the lightcurve.
     """
 
     if apply_weights:
         x_reduced = mag[n:-n]
         xerr_reduced = magerr[n:-n]
         res = None
         for i in range(1, n + 1):
@@ -2310,47 +2586,52 @@
             result_first = np.abs(diff_left) > err_left
             result_second = np.abs(diff_right) > err_right
             # combine the results with logical AND
             if res is None:
                 res = result_first & result_second
             else:
                 res &= result_first & result_second
-        return np.sum(res)
+        return float(np.sum(res)/len(mag))
     else:
         x_reduced = mag[n:-n]
         res = None
         for i in range(1, n + 1):
             result_first = x_reduced > np.roll(mag, i)[n:-n]
             if res is None:
                 res = result_first
             else:
                 res &= result_first
             res &= x_reduced > np.roll(mag, -i)[n:-n]
         return float(np.sum(res)/len(mag))
 
 def ratio_recurring_points(time, mag, magerr, apply_weights=True):
     """
-    Returns the ratio of unique values, that are present in the time 
+    Calculates the ratio of unique values, that are present in the time 
     series more than once, normalized to the number of data points. 
     
     If apply weights is set to True, the photometric errors will be 
     used by looping over the unique values and checking if the number of values 
     that are close to it (using the np.isclose function) is greater than 1. If so, 
     the value is counted as a recurring point.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The number of unique measurements normalized according to the size of the lightcurve.
     """
 
     unique, counts = np.unique(mag, return_counts=True)
 
     if counts.shape[0] == 0:
         return 0
     
@@ -2361,32 +2642,37 @@
                 recurring_count += 1
         return recurring_count / float(counts.shape[0])
     else:
         return np.sum(counts > 1) / float(counts.shape[0])
 
 def sample_entropy(time, mag, magerr, apply_weights=True):
     """
-    Returns sample entropy: http://en.wikipedia.org/wiki/Sample_Entropy
+    Calculates sample entropy: http://en.wikipedia.org/wiki/Sample_Entropy
     
     One approach to incorporate error is to modify the distance metric used in the algorithm 
     to account for measurement error. "Modified Sample Entropy Method in the Presence of Noise" by Zhang et al. 
     proposes a modified version of sample entropy that uses a weighted distance metric based on both the difference 
     in magnitudes and the difference in measurement errors between pairs of data points, but
     MicroLIA does not support this as the noise level may alter the value range significantly. 
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Not used in this function.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The sample entropy of the lightcurve.
     """
 
     m = 2  # common value for m, according to wikipedia...
     tolerance = 0.2 * np.std(mag)  # 0.2 is a common value for r, according to wikipedia...
     every_n = 1
 
     num_shifts = (len(mag) - m) // every_n + 1
@@ -2413,83 +2699,100 @@
 def sum_values(time, mag, magerr, apply_weights=True):
     """
     Sums over all mag values.
     
     If apply_weights=True, the formula for weighted mean is used to calculate the sum of the magnitudes. 
     The weights are given by the inverse square of the magnitudes' errors.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The sum of all the measurements, normalized to the size of the lightcurve.
     """
 
     if apply_weights:
         return np.sum(mag/magerr**2)/np.sum(1/magerr**2)
     else:
         return np.sum(mag)/len(mag)
 
 def time_reversal_asymmetry(time, mag, magerr, lag=1, apply_weights=True):
     """
-    Derives a feature introduced by Fulcher.
-    See: (Fulcher, B.D., Jones, N.S. (2014). Highly comparative 
-    feature-based time-series classification. Knowledge and Data Engineering, 
-    IEEE Transactions on 26, 3026–3037.)
+    Derives the time reversal asymmetric statistic introduced by Fulcher.
+
+    See: (Fulcher, B.D., Jones, N.S. (2014). Highly comparative feature-based time-series classification. Knowledge and Data Engineering, IEEE Transactions on 26, 3026–3037.)
     
     We incorporate errors by dividing each term by the square of its corresponding magerr, 
     which effectively gives more weight to terms with smaller errors. Note that this modification 
     assumes that the errors are Gaussian and uncorrelated, which may not always be true in practice.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    lag: The lag to use. Must be an integer.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        lag : int
+            The lag to apply. Defaults to 1.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The time reversal symmetry statistic.
     """
 
     n = len(mag)
 
     if 2 * lag >= n:
         return 0
     else:
         one_lag = np.roll(mag, -lag)
         two_lag = np.roll(mag, 2 * -lag)
         if apply_weights:
             weights = 1.0 / (magerr ** 2)
             weighted_mean = np.sum(mag * weights) / np.sum(weights ** 2)
-            return np.mean((two_lag * two_lag * one_lag - one_lag * mag * mag) / (magerr * magerr) / weights)[0 : (n - 2 * lag)]
+            result = ((two_lag * two_lag * one_lag - one_lag * mag * mag) / (magerr * magerr)) / weights
+            return np.mean(result[:n - 2 * lag])
         else:
-            return np.mean((two_lag * two_lag * one_lag - one_lag * mag * mag)[0 : (n - 2 * lag)])
+            result = (two_lag * two_lag * one_lag - one_lag * mag * mag)
+            return np.mean(result[:n - 2 * lag])
 
 def variance(time, mag, magerr, apply_weights=True):
     """
-    Returns the variance, or the weighted variance of the light curve if apply_weights=True.
+    Calculates the variance, or the weighted variance of the light curve if apply_weights=True.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The variance of the lightcurve measurements.
     """
 
     if apply_weights:
         return np.sum((mag - np.mean(mag))**2 / magerr**2) / np.sum(1/magerr**2)
     else:
         return np.var(mag)
 
@@ -2497,24 +2800,29 @@
     """
     This feature denotes if the variance of x is greater than its standard deviation. 
     Is equal to variance of x being larger than 1. 1 is True, 0 is False. 
 
     If apply_weights=True a weighting factor to the magnitude values when computing the variance and standard deviation will be used. 
     This factor gives more weight to the more precise measurements and less weight to the less precise measurements.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: int
+    Returns:
+    ------- 
+    int    
+        Whether or not the lightcurve's variance is greater than the standard deviation, 1 for True, 0 for False.
     """
 
     if apply_weights:
         weight = 1.0 / (magerr * magerr)
         weighted_mean = np.sum(mag * weight) / np.sum(weight)
         weighted_var = np.sum(weight * (mag - weighted_mean) ** 2) / np.sum(weight)
         weighted_std = np.sqrt(weighted_var)
@@ -2527,28 +2835,33 @@
         if var > np.sqrt(var):
             return 1
         else:
             return 0
 
 def variation_coefficient(time, mag, magerr, apply_weights=True):
     """
-    Returns the variation coefficient (standard error / mean, give relative value of variation around mean) of x.
+    Calculates the variation coefficient (standard error / mean, gives the relative value of variation around mean) of x.
     
     We incorporate errors by using the weighted standard deviation and weighted mean.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The lightcurve standard deviation over the mean.
     """
 
     if apply_weights:
         weighted_mean = np.sum(mag / magerr**2) / np.sum(1 / magerr**2)
         weighted_std = np.sqrt(np.sum((mag - weighted_mean)**2 / magerr**2) / np.sum(1 / magerr**2))
         if weighted_mean != 0:
             return weighted_std / weighted_mean
@@ -2564,25 +2877,31 @@
 def large_standard_deviation(time, mag, magerr, r=.3, apply_weights=True):
     """
     Does time series have "large" standard deviation?
 
     Boolean variable denoting if the standard dev of x is higher than 'r' times the range = difference between max and
     min of x. To incorporate errors we use the weighted standard deviation instead of the regular standard deviation.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    r: The percentage of the range to compare with. Must be a float between 0 and 1.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        r : float
+            The percentage of the range to compare with. Must be between 0 and 1. Defaults to 0.3.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    int    
+        Whether or not the lightcurve has a large standard deviation, 1 for True, 0 for False.
     """
 
     if apply_weights:   
         weights = 1/magerr**2  # calculate weights from magerr
         weighted_std = np.sqrt(np.sum(weights * (mag - np.average(mag, weights=weights))**2) / np.sum(weights))
         if weighted_std > (r * (np.max(mag) - np.min(mag))):
             return 1
@@ -2600,25 +2919,31 @@
 
     | mean(X)-median(X)| < r * (max(X)-min(X))
 
     where r is the percentage of the range to compare with.
     
     If apply_weights=True, the weighted mean and the weighted median are used instead of the regular mean and median.
     
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    r: The percentage of the range to compare with. Must be a float between 0 and 1.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        r : float
+            The percentage of the range to compare with. Must be between 0 and 1. Deaults to 0.5.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: int
+    Returns:
+    ------- 
+    int    
+        Whether or not the lightcurve appears symmetric, 1 for True, 0 for False.
     """
 
     if apply_weights:
         weights = 1 / magerr ** 2
         w_mean = np.sum(mag * weights) / np.sum(weights)
         sorted_indices = np.argsort(mag)
         cum_weights = np.cumsum(weights[sorted_indices])
@@ -2638,27 +2963,33 @@
             return 0
   
 def index_mass_quantile(time, mag, magerr, r=0.5, apply_weights=True):
     """
     Calculates the relative index i of time series x where r% of the mass of x lies left of i.
     For example for r = 50% this feature will return the mass center of the time series.
     
-    Errors can be incorporated into this function by weighing the contributions of each data point with its inverse variance.
+    Errors are incorporated into this function by weighing the contributions of each data point with its inverse variance.
     
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    r: The percentage of the range to compare with. Must be a float between 0 and 1.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        r : float 
+            The percentage of the range to compare with. Must be between 0 and 1. Defaults to 0.5.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The relative index of the lightcurve measurement that is to the right of the 50% of the cumulative sum.
     """
 
     if apply_weights:
         abs_mag = np.abs(mag)
         inv_var = 1.0 / (magerr ** 2)
         weighted_abs_mag = np.sum(abs_mag * inv_var)
         #Calculate the cumulative sum of the weighted absolute values of mag
@@ -2669,116 +3000,117 @@
         return i / len(mag)
     else:
         abs_x = np.abs(mag)
         s = np.sum(abs_x)
         mass_centralized = np.cumsum(abs_x) / s
         return (np.argmax(mass_centralized >= r) + 1) / len(mag)
 
-def number_cwt_peaks(time, mag, magerr, n=30, apply_weights=True, snr_threshold=3):
+def number_cwt_peaks(time, mag, magerr, n=30, apply_weights=True):
     """
     Number of different peaks in the magnitude array.
 
     To estimate the numbers of peaks, x is smoothed by a ricker wavelet for widths ranging from 1 to n. This feature
     calculator returns the number of peaks that occur at enough width scales and with sufficiently high
-    Signal-to-Noise-Ratio (SNR). If apply_weights=True, we first calculate the SNR of each peak by dividing the peak 
-    amplitude by the average noise level (which we assume is given by the mean magnitude error). We then count only the peaks 
-    whose SNR is above the snr_threshold parameter.
-
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    n : The maximum time width to consider. Must be an integer.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
-    snr_threshold : Integer that determines the minimum Signal-to-Noise Ratio (SNR) required for 
-        a peak to be counted in the final result when apply_weights is set to True. Defaults to 3.
-    
-    Returns
-    -------   
-    rtype: int
+    Signal-to-Noise-Ratio (SNR). Weights are not meant to be applied in this case.
+
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        n : int 
+            The maximum time width to consider. Defaults to 30.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
+
+    Returns:
+    ------- 
+    float    
+        The number of peaks in the lightcurve after smoothing with a wavelet transformation.
     """
 
-    if apply_weights:
-        #Calculate the SNR of each peak
-        widths = np.array(list(range(1, n + 1)))
-        peaks = ssignal.find_peaks_cwt(vector=mag, widths=widths, wavelet=ssignal.ricker)
-        snrs = []
-        for peak in peaks:
-            noise = np.mean(magerr)
-            signal = mag[peak]
-            snr = signal / noise
-            snrs.append(snr)
-        #Count the number of peaks above the SNR threshold
-        snrs = np.array(snrs)
-        peak_count = np.sum(snrs > snr_threshold)
-        return peak_count / len(mag)
-    else:
-        val = len(ssignal.find_peaks_cwt(vector=mag, widths=np.array(list(range(1, n + 1))), wavelet=ssignal.ricker))
-        return val/len(mag)
+    val = len(ssignal.find_peaks_cwt(vector=mag, widths=np.array(list(range(1, n + 1))), wavelet=ssignal.ricker))
+    return val / len(mag)
 
 def permutation_entropy(time, mag, magerr, tau=1, dimension=3, apply_weights=True):
     """
     Calculate the permutation entropy.
 
     Ref: https://www.aptech.com/blog/permutation-entropy/
          Bandt, Christoph and Bernd Pompe.
          “Permutation entropy: a natural complexity measure for time series.”
          Physical review letters 88 17 (2002): 174102 
     
     In this modified version, if apply_weights=True, we compute the weights as the reciprocal of the magnitude errors 
     and divide each count by the corresponding weight. Then we compute the weighted average probabilities and return
     the negative sum of the probabilities times their logarithms.
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array. 
-    tau: The embedded time delay that determines the time separation between the mag values. Must be an integer.
-    dimension: The embedding dimension. Must be an integer.
-    apply_weights: Whether to apply weights based on the magnitude errors. Defaults to True.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        tau : int
+            The embedded time delay that determines the time separation between the measurements.
+            Defaults to 1.
+        dimension : int
+            The embedding dimension to use. Defaults to 3.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------   
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The permutation entropy of the lightcurve.
     """
 
     num_shifts = (len(mag) - dimension) // tau + 1
     shift_starts = tau * np.arange(num_shifts)
     indices = np.arange(dimension)
     indexer = np.expand_dims(indices, axis=0) + np.expand_dims(shift_starts, axis=1)
 
     X = np.asarray(mag)[indexer]
     permutations = np.argsort(np.argsort(X))
     counts = np.unique(permutations, axis=0, return_counts=True)[1]
 
     if apply_weights:
         weights = 1 / np.asarray(magerr)[indexer]
-        weighted_counts = counts / weights
+        weighted_counts = counts / np.expand_dims(weights.reshape(-1), axis=1)
         probs = np.sum(weighted_counts, axis=1) / np.sum(weighted_counts)
     else:
         probs = counts / len(permutations)
 
     return -np.sum(probs * np.log(probs))
 
 def quantile(time, mag, magerr, r=0.75, apply_weights=True):
     """
     Calculates the r quantile of the mag. This is the value of mag greater than r% of the ordered values.
 
     Errors are not incorporated in this function. 
 
-    Parameters
-    ----------   
-    mag: The time-varying intensity of the lightcurve. Must be an array.
-    magerr: Photometric error for the intensity. Must be an array.
-    time: The timestamps of the corresponding mag and magerr measurements. Must be an array.
-    r: The percentage of the range to compare with. Must be a float between 0 and 1.
-    apply_weights: Whether to apply weights based on the magnitude errors. Not used in this function.
+    Parameters:
+    ----------
+        time : array
+            The timestamps of the corresponding mag and magerr measurements. Must be an array.
+        mag : array
+            The time-varying intensity of the lightcurve. Must be an array.
+        magerr : array
+            Photometric error for the intensity. Must be an array.
+        r : float
+            The percentage of the range to compare with. Must be between 0 and 1. Defaults to 0.75.
+        apply_weights : bool, optional
+            Whether to apply weights based on the magnitude errors. Defaults to True.
 
-    Returns
-    -------     
-    rtype: float
+    Returns:
+    ------- 
+    float    
+        The 75th quantile of the ordered lightcurve measurements.
     """
 
     return np.quantile(mag, r)
```

### Comparing `MicroLIA-2.2.6/MicroLIA/noise_models.py` & `MicroLIA-2.2.7/MicroLIA/noise_models.py`

 * *Files identical despite different names*

### Comparing `MicroLIA-2.2.6/MicroLIA/optimization.py` & `MicroLIA-2.2.7/MicroLIA/optimization.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,8125 +2,8861 @@
 00000010: 7974 686f 6e33 0a23 202d 2a2d 2063 6f64  ython3.# -*- cod
 00000020: 696e 673a 2075 7466 2d38 202d 2a2d 0a22  ing: utf-8 -*-."
 00000030: 2222 0a43 7265 6174 6564 206f 6e20 5361  "".Created on Sa
 00000040: 7420 4665 6220 2032 3520 3130 3a33 393a  t Feb  25 10:39:
 00000050: 3233 2032 3032 330a 0a40 6175 7468 6f72  23 2023..@author
 00000060: 3a20 6461 6e69 656c 0a22 2222 0a69 6d70  : daniel.""".imp
 00000070: 6f72 7420 6f73 2c20 7379 732c 2063 6f70  ort os, sys, cop
-00000080: 792c 2067 632c 2073 656c 6563 746f 7273  y, gc, selectors
-00000090: 2c20 7465 726d 696f 730a 6f73 2e65 6e76  , termios.os.env
-000000a0: 6972 6f6e 5b27 5059 5448 4f4e 4841 5348  iron['PYTHONHASH
-000000b0: 5345 4544 275d 3d20 2730 2720 232c 206f  SEED']= '0' #, o
-000000c0: 732e 656e 7669 726f 6e5b 2254 465f 4445  s.environ["TF_DE
-000000d0: 5445 524d 494e 4953 5449 435f 4f50 5322  TERMINISTIC_OPS"
-000000e0: 5d20 3d31 0a69 6d70 6f72 7420 7465 6e73  ] =1.import tens
-000000f0: 6f72 666c 6f77 2061 7320 7466 0a0a 696d  orflow as tf..im
-00000100: 706f 7274 206e 756d 7079 2061 7320 6e70  port numpy as np
-00000110: 0a69 6d70 6f72 7420 7261 6e64 6f6d 2061  .import random a
-00000120: 7320 7079 7468 6f6e 5f72 616e 646f 6d0a  s python_random.
-00000130: 6e70 2e72 616e 646f 6d2e 7365 6564 2831  np.random.seed(1
-00000140: 3930 3929 2c20 7079 7468 6f6e 5f72 616e  909), python_ran
-00000150: 646f 6d2e 7365 6564 2831 3930 3929 2c20  dom.seed(1909), 
-00000160: 7466 2e72 616e 646f 6d2e 7365 745f 7365  tf.random.set_se
-00000170: 6564 2831 3930 3929 2023 2368 7474 7073  ed(1909) ##https
-00000180: 3a2f 2f6b 6572 6173 2e69 6f2f 6765 7474  ://keras.io/gett
-00000190: 696e 675f 7374 6172 7465 642f 6661 712f  ing_started/faq/
-000001a0: 2368 6f77 2d63 616e 2d69 2d6f 6274 6169  #how-can-i-obtai
-000001b0: 6e2d 7265 7072 6f64 7563 6962 6c65 2d72  n-reproducible-r
-000001c0: 6573 756c 7473 2d75 7369 6e67 2d6b 6572  esults-using-ker
-000001d0: 6173 2d64 7572 696e 672d 6465 7665 6c6f  as-during-develo
-000001e0: 706d 656e 7423 230a 6672 6f6d 2070 616e  pment##.from pan
-000001f0: 6461 7320 696d 706f 7274 2044 6174 6146  das import DataF
-00000200: 7261 6d65 0a66 726f 6d20 7761 726e 696e  rame.from warnin
-00000210: 6773 2069 6d70 6f72 7420 6669 6c74 6572  gs import filter
-00000220: 7761 726e 696e 6773 0a66 696c 7465 7277  warnings.filterw
-00000230: 6172 6e69 6e67 7328 2269 676e 6f72 6522  arnings("ignore"
-00000240: 2c20 6361 7465 676f 7279 3d46 7574 7572  , category=Futur
-00000250: 6557 6172 6e69 6e67 290a 6672 6f6d 2063  eWarning).from c
-00000260: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
-00000270: 7420 436f 756e 7465 7220 0a0a 696d 706f  t Counter ..impo
-00000280: 7274 2073 6b6c 6561 726e 2e6e 6569 6768  rt sklearn.neigh
-00000290: 626f 7273 2e5f 6261 7365 0a73 7973 2e6d  bors._base.sys.m
-000002a0: 6f64 756c 6573 5b27 736b 6c65 6172 6e2e  odules['sklearn.
-000002b0: 6e65 6967 6862 6f72 732e 6261 7365 275d  neighbors.base']
-000002c0: 203d 2073 6b6c 6561 726e 2e6e 6569 6768   = sklearn.neigh
-000002d0: 626f 7273 2e5f 6261 7365 0a66 726f 6d20  bors._base.from 
-000002e0: 736b 6c65 6172 6e2e 696d 7075 7465 2069  sklearn.impute i
-000002f0: 6d70 6f72 7420 4b4e 4e49 6d70 7574 6572  mport KNNImputer
-00000300: 0a66 726f 6d20 736b 6c65 6172 6e2e 656e  .from sklearn.en
-00000310: 7365 6d62 6c65 2069 6d70 6f72 7420 5261  semble import Ra
-00000320: 6e64 6f6d 466f 7265 7374 436c 6173 7369  ndomForestClassi
-00000330: 6669 6572 0a66 726f 6d20 736b 6c65 6172  fier.from sklear
-00000340: 6e2e 6e65 7572 616c 5f6e 6574 776f 726b  n.neural_network
-00000350: 2069 6d70 6f72 7420 4d4c 5043 6c61 7373   import MLPClass
-00000360: 6966 6965 720a 6672 6f6d 2073 6b6c 6561  ifier.from sklea
-00000370: 726e 2e6d 6574 7269 6373 2069 6d70 6f72  rn.metrics impor
-00000380: 7420 6163 6375 7261 6379 5f73 636f 7265  t accuracy_score
-00000390: 0a66 726f 6d20 736b 6c65 6172 6e2e 6d6f  .from sklearn.mo
-000003a0: 6465 6c5f 7365 6c65 6374 696f 6e20 696d  del_selection im
-000003b0: 706f 7274 2074 7261 696e 5f74 6573 745f  port train_test_
-000003c0: 7370 6c69 742c 2063 726f 7373 5f76 616c  split, cross_val
-000003d0: 6964 6174 652c 2063 726f 7373 5f76 616c  idate, cross_val
-000003e0: 5f73 636f 7265 0a0a 6672 6f6d 2073 6b6f  _score..from sko
-000003f0: 7074 2069 6d70 6f72 7420 4261 7965 7353  pt import BayesS
-00000400: 6561 7263 6843 562c 2070 6c6f 7473 2c20  earchCV, plots, 
-00000410: 6770 5f6d 696e 696d 697a 650a 6672 6f6d  gp_minimize.from
-00000420: 2073 6b6f 7074 2e70 6c6f 7473 2069 6d70   skopt.plots imp
-00000430: 6f72 7420 706c 6f74 5f63 6f6e 7665 7267  ort plot_converg
-00000440: 656e 6365 2c20 706c 6f74 5f6f 626a 6563  ence, plot_objec
-00000450: 7469 7665 0a66 726f 6d20 736b 6f70 742e  tive.from skopt.
-00000460: 7370 6163 6520 696d 706f 7274 2052 6561  space import Rea
-00000470: 6c2c 2049 6e74 6567 6572 2c20 4361 7465  l, Integer, Cate
-00000480: 676f 7269 6361 6c20 0a66 726f 6d20 7465  gorical .from te
-00000490: 6e73 6f72 666c 6f77 2e6b 6572 6173 2e62  nsorflow.keras.b
-000004a0: 6163 6b65 6e64 2069 6d70 6f72 7420 636c  ackend import cl
-000004b0: 6561 725f 7365 7373 696f 6e20 0a66 726f  ear_session .fro
-000004c0: 6d20 7465 6e73 6f72 666c 6f77 2e6b 6572  m tensorflow.ker
-000004d0: 6173 2e63 616c 6c62 6163 6b73 2069 6d70  as.callbacks imp
-000004e0: 6f72 7420 4561 726c 7953 746f 7070 696e  ort EarlyStoppin
-000004f0: 672c 2043 616c 6c62 6163 6b0a 0a69 6d70  g, Callback..imp
-00000500: 6f72 7420 6f70 7475 6e61 0a66 726f 6d20  ort optuna.from 
-00000510: 426f 7275 7461 5368 6170 2069 6d70 6f72  BorutaShap impor
-00000520: 7420 426f 7275 7461 5368 6170 0a66 726f  t BorutaShap.fro
-00000530: 6d20 626f 7275 7461 2069 6d70 6f72 7420  m boruta import 
-00000540: 426f 7275 7461 5079 0a66 726f 6d20 7867  BorutaPy.from xg
-00000550: 626f 6f73 7420 696d 706f 7274 2058 4742  boost import XGB
-00000560: 436c 6173 7369 6669 6572 2c20 444d 6174  Classifier, DMat
-00000570: 7269 782c 2074 7261 696e 0a66 726f 6d20  rix, train.from 
-00000580: 6f70 7475 6e61 2e69 6e74 6567 7261 7469  optuna.integrati
-00000590: 6f6e 2069 6d70 6f72 7420 5446 4b65 7261  on import TFKera
-000005a0: 7350 7275 6e69 6e67 4361 6c6c 6261 636b  sPruningCallback
-000005b0: 0a6f 7074 756e 612e 6c6f 6767 696e 672e  .optuna.logging.
-000005c0: 7365 745f 7665 7262 6f73 6974 7928 6f70  set_verbosity(op
-000005d0: 7475 6e61 2e6c 6f67 6769 6e67 2e57 4152  tuna.logging.WAR
-000005e0: 4e49 4e47 290a 6672 6f6d 204d 6963 726f  NING).from Micro
-000005f0: 4c49 412e 6461 7461 5f61 7567 6d65 6e74  LIA.data_augment
-00000600: 6174 696f 6e20 696d 706f 7274 2061 7567  ation import aug
-00000610: 6d65 6e74 6174 696f 6e2c 2072 6573 697a  mentation, resiz
-00000620: 650a 6672 6f6d 204d 6963 726f 4c49 4120  e.from MicroLIA 
-00000630: 696d 706f 7274 2064 6174 615f 7072 6f63  import data_proc
-00000640: 6573 7369 6e67 2c20 636e 6e5f 6d6f 6465  essing, cnn_mode
-00000650: 6c0a 0a0a 636c 6173 7320 6f62 6a65 6374  l...class object
-00000660: 6976 655f 636e 6e28 6f62 6a65 6374 293a  ive_cnn(object):
-00000670: 0a20 2020 2022 2222 0a20 2020 204f 7074  .    """.    Opt
-00000680: 696d 697a 6174 696f 6e20 6f62 6a65 6374  imization object
-00000690: 6976 6520 6675 6e63 7469 6f6e 2066 6f72  ive function for
-000006a0: 204d 6963 726f 4c49 4127 7320 636f 6e76   MicroLIA's conv
-000006b0: 6f6c 7574 696f 6e61 6c20 6e65 7572 616c  olutional neural
-000006c0: 206e 6574 776f 726b 732e 0a0a 2020 2020   networks...    
-000006d0: 5468 6973 2069 7320 7061 7373 6564 2074  This is passed t
-000006e0: 6872 6f75 6768 2074 6865 2068 7970 6572  hrough the hyper
-000006f0: 5f6f 7074 2829 2066 756e 6374 696f 6e20  _opt() function 
-00000700: 7768 656e 206f 7074 696d 697a 696e 6720  when optimizing 
-00000710: 7769 7468 0a20 2020 204f 7074 756e 612e  with.    Optuna.
-00000720: 2054 6865 204f 7074 756e 6120 736f 6674   The Optuna soft
-00000730: 7761 7265 2066 6f72 2068 7970 6572 7061  ware for hyperpa
-00000740: 7261 6d65 7465 7220 6f70 7469 6d69 7a61  rameter optimiza
-00000750: 7469 6f6e 2077 6173 2070 7562 6c69 7368  tion was publish
-00000760: 6564 2069 6e20 0a20 2020 2032 3031 3920  ed in .    2019 
-00000770: 6279 2041 6b69 6261 2065 7420 616c 2e20  by Akiba et al. 
-00000780: 5061 7065 723a 2068 7474 7073 3a2f 2f61  Paper: https://a
-00000790: 7278 6976 2e6f 7267 2f61 6273 2f31 3930  rxiv.org/abs/190
-000007a0: 372e 3130 3930 320a 0a20 2020 2055 6e6c  7.10902..    Unl
-000007b0: 696b 6520 7468 6520 6f62 6a65 6374 6976  ike the objectiv
-000007c0: 6520 6675 6e63 7469 6f6e 7320 666f 7220  e functions for 
-000007d0: 7468 6520 656e 7365 6d62 6c65 2061 6c67  the ensemble alg
-000007e0: 6f72 6974 686d 732c 2074 6869 7320 7461  orithms, this ta
-000007f0: 6b65 7320 6173 2069 6e70 7574 0a20 2020  kes as input.   
-00000800: 2074 6865 2074 776f 2063 6c61 7373 6573   the two classes
-00000810: 2064 6972 6563 746c 792c 2070 6f73 6974   directly, posit
-00000820: 6976 655f 636c 6173 7320 2620 6e65 6761  ive_class & nega
-00000830: 7469 7665 5f63 6c61 7373 2c20 696e 7374  tive_class, inst
-00000840: 6561 6420 6f66 2074 6865 2074 7261 6469  ead of the tradi
-00000850: 7469 6f6e 616c 200a 2020 2020 6461 7461  tional .    data
-00000860: 2028 6461 7461 5f78 2920 616e 6420 6163   (data_x) and ac
-00000870: 636f 6d70 616e 7969 6e67 206c 6162 656c  companying label
-00000880: 2061 7272 6179 2028 6461 7461 5f79 292e   array (data_y).
-00000890: 2054 6869 7320 6973 2062 6563 6175 7365   This is because
-000008a0: 2074 6865 2063 6f6e 6669 6775 7265 6420   the configured 
-000008b0: 434e 4e20 6d6f 6465 6c73 200a 2020 2020  CNN models .    
-000008c0: 7461 6b65 2061 7320 696e 7075 7420 7468  take as input th
-000008d0: 6520 7477 6f20 636c 6173 7365 7320 7365  e two classes se
-000008e0: 7061 7261 7465 6c79 2c20 6166 7465 7220  parately, after 
-000008f0: 7768 6963 6820 6974 2061 7574 6f6d 6174  which it automat
-00000900: 6963 616c 6c79 2061 7373 6967 6e73 2074  ically assigns t
-00000910: 6865 2031 2061 6e64 2030 206c 6162 656c  he 1 and 0 label
-00000920: 732c 2072 6573 7065 6374 6976 656c 792e  s, respectively.
-00000930: 0a0a 2020 2020 4279 2064 6566 6175 6c74  ..    By default
-00000940: 2c20 6f70 745f 6d6f 6465 6c3d 5472 7565  , opt_model=True
-00000950: 2061 6e64 206f 7074 5f61 7567 3d46 616c   and opt_aug=Fal
-00000960: 7365 2e20 4966 206f 7074 5f61 7567 3d54  se. If opt_aug=T
-00000970: 7275 652c 2074 6865 2069 6d61 6765 2073  rue, the image s
-00000980: 697a 6520 616e 640a 2020 2020 6e75 6d62  ize and.    numb
-00000990: 6572 206f 6620 6175 676d 656e 7461 7469  er of augmentati
-000009a0: 6f6e 7320 746f 2070 6572 666f 726d 206f  ons to perform o
-000009b0: 6e20 6561 6368 2069 6d61 6765 2077 696c  n each image wil
-000009c0: 6c20 6265 2069 6e63 6c75 6465 6420 6173  l be included as
-000009d0: 206f 7074 696d 697a 6162 6c65 2076 6172   optimizable var
-000009e0: 6961 626c 6573 2e0a 2020 2020 4966 2074  iables..    If t
-000009f0: 6865 206f 7074 5f6d 6178 5f6d 696e 5f70  he opt_max_min_p
-00000a00: 6978 2061 6e64 206f 7074 5f6d 6178 5f6d  ix and opt_max_m
-00000a10: 6178 5f70 6978 2061 7265 2073 6574 2c20  ax_pix are set, 
-00000a20: 7468 6520 6f70 7469 6d61 6c20 6d61 7869  the optimal maxi
-00000a30: 6d75 6d20 7069 7865 6c20 7661 6c75 6520  mum pixel value 
-00000a40: 746f 2075 7365 0a20 2020 2077 6865 6e20  to use.    when 
-00000a50: 6d69 6e2d 6d61 7820 6e6f 726d 616c 697a  min-max normaliz
-00000a60: 696e 6720 6561 6368 2062 616e 6420 7769  ing each band wi
-00000a70: 6c6c 2061 6c73 6f20 6265 206f 7074 696d  ll also be optim
-00000a80: 697a 6162 6c65 2076 6172 6961 626c 6573  izable variables
-00000a90: 2074 6861 7420 7769 6c6c 2062 6520 7475   that will be tu
-00000aa0: 6e65 6420 616e 6420 7265 7475 726e 6564  ned and returned
-00000ab0: 2e0a 2020 2020 4966 206f 7074 5f6d 6f64  ..    If opt_mod
-00000ac0: 656c 3d54 7275 652c 2061 6464 6974 696f  el=True, additio
-00000ad0: 6e61 6c20 6172 6368 6974 6563 7475 7265  nal architecture
-00000ae0: 2070 6172 616d 6574 6572 7320 7769 6c6c   parameters will
-00000af0: 2061 6c73 6f20 6265 2074 756e 6564 2e20   also be tuned. 
-00000b00: 496e 2062 6f74 6820 696e 7374 616e 6365  In both instance
-00000b10: 7320 7468 6520 7472 6169 6e69 6e67 2070  s the training p
-00000b20: 6172 616d 6574 6572 7320 0a20 2020 2077  arameters .    w
-00000b30: 696c 6c20 6265 206f 7074 696d 697a 6564  ill be optimized
-00000b40: 2c20 7768 6963 6820 696e 636c 7564 6520  , which include 
-00000b50: 7468 6520 6f70 7469 6d69 7a65 722c 206c  the optimizer, l
-00000b60: 6561 726e 696e 6720 7261 7465 2c20 6465  earning rate, de
-00000b70: 6361 792c 2061 6e64 206d 6f6d 656e 7475  cay, and momentu
-00000b80: 6d2c 2069 6620 6170 706c 6963 6162 6c65  m, if applicable
-00000b90: 2e0a 0a20 2020 204e 6f74 653a 0a20 2020  ...    Note:.   
-00000ba0: 2020 2020 2049 6620 6f70 745f 6175 6720       If opt_aug 
-00000bb0: 6973 2065 6e61 626c 6564 2c20 7468 656e  is enabled, then
-00000bc0: 2074 6865 2070 6f73 6974 6976 655f 636c   the positive_cl
-00000bd0: 6173 7320 7361 6d70 6c65 2077 696c 6c20  ass sample will 
-00000be0: 6265 2074 6865 2064 6174 6120 7468 6174  be the data that
-00000bf0: 2077 696c 6c20 6175 676d 656e 7465 642e   will augmented.
-00000c00: 0a20 2020 2020 2020 2049 7420 6973 2062  .        It is b
-00000c10: 6573 7420 746f 206b 6565 7020 626f 7468  est to keep both
-00000c20: 2063 6c61 7373 2073 697a 6573 2074 6865   class sizes the
-00000c30: 2073 616d 6520 6166 7465 7220 6175 676d   same after augm
-00000c40: 656e 7461 7469 6f6e 2c20 7468 6572 6566  entation, theref
-00000c50: 6f72 6520 6261 6c61 6e63 653d 5472 7565  ore balance=True
-00000c60: 0a20 2020 2020 2020 2062 7920 6465 6661  .        by defa
-00000c70: 756c 742c 2077 6869 6368 2077 696c 6c20  ult, which will 
-00000c80: 7472 756e 6361 7465 2074 6865 206e 6567  truncate the neg
-00000c90: 6174 6976 655f 636c 6173 7320 7361 6d70  ative_class samp
-00000ca0: 6c65 2074 6f20 6d61 7463 6820 7468 6520  le to match the 
-00000cb0: 6175 676d 656e 7465 6420 706f 7369 7469  augmented positi
-00000cc0: 7665 5f63 6c61 7373 2073 697a 652e 0a20  ve_class size.. 
-00000cd0: 2020 2020 2020 2054 6865 206f 7468 6572         The other
-00000ce0: 2063 6c61 7373 2077 696c 6c20 616c 736f   class will also
-00000cf0: 2075 6e64 6572 676f 2074 6865 2073 616d   undergo the sam
-00000d00: 6520 6461 7461 2061 7567 6d65 6e74 6174  e data augmentat
-00000d10: 696f 6e20 7465 6368 6e69 7175 6520 6275  ion technique bu
-00000d20: 7420 6f6e 6c79 206f 6e65 2069 6d61 6765  t only one image
-00000d30: 2077 696c 6c20 6265 2072 6574 7572 6e65   will be returne
-00000d40: 640a 2020 2020 2020 2020 7065 7220 7361  d.        per sa
-00000d50: 6d70 6c65 2c20 7468 6973 2069 7320 746f  mple, this is to
-00000d60: 2065 6e73 7572 6520 626f 7468 2063 6c61   ensure both cla
-00000d70: 7373 6573 2063 6f6e 7461 696e 2074 6865  sses contain the
-00000d80: 2073 616d 6520 6c65 7665 6c20 6f66 2076   same level of v
-00000d90: 6172 6961 7469 6f6e 2c20 6573 7065 6369  ariation, especi
-00000da0: 616c 6c79 2069 6d70 6f72 7461 6e74 0a20  ally important. 
-00000db0: 2020 2020 2020 2077 6865 6e20 6170 706c         when appl
-00000dc0: 7969 6e67 2074 6865 206d 6173 6b2d 6375  ying the mask-cu
-00000dd0: 746f 7574 2074 6563 686e 6971 7565 2074  tout technique t
-00000de0: 6f20 7468 6520 6175 676d 656e 7461 7469  o the augmentati
-00000df0: 6f6e 2070 726f 6365 6475 7265 2e0a 0a20  on procedure... 
-00000e00: 2020 2020 2020 2053 696e 6365 2074 6865         Since the
-00000e10: 206d 6178 696d 756d 206e 756d 6265 7220   maximum number 
-00000e20: 6f66 2061 7567 6d65 6e74 6174 696f 6e73  of augmentations
-00000e30: 2061 6c6c 6f77 6564 2069 7320 6261 7463   allowed is batc
-00000e40: 685f 6d61 7820 7065 7220 6561 6368 2073  h_max per each s
-00000e50: 616d 706c 652c 2069 6e20 7072 6163 7469  ample, in practi
-00000e60: 6365 206e 6567 6174 6976 655f 636c 6173  ce negative_clas
-00000e70: 7320 0a20 2020 2020 2020 2073 686f 756c  s .        shoul
-00000e80: 6420 636f 6e74 6169 6e20 6261 7463 685f  d contain batch_
-00000e90: 6d61 7820 7469 6d65 7320 7468 6520 7369  max times the si
-00000ea0: 7a65 206f 6620 706f 7369 7469 7665 5f63  ze of positive_c
-00000eb0: 6c61 7373 2e20 4475 7269 6e67 2074 6865  lass. During the
-00000ec0: 206f 7074 696d 697a 6174 696f 6e20 7072   optimization pr
-00000ed0: 6f63 6564 7572 652c 2069 6620 616e 200a  ocedure, if an .
-00000ee0: 2020 2020 2020 2020 6175 676d 656e 7461          augmenta
-00000ef0: 7469 6f6e 2062 6174 6368 2073 697a 6520  tion batch size 
-00000f00: 6f66 2031 3030 2069 7320 6173 7365 7365  of 100 is assese
-00000f10: 6420 616e 6420 706f 7369 7469 7665 2063  d and positive c
-00000f20: 6c61 7373 2063 6f6e 7461 696e 7320 6e20  lass contains n 
-00000f30: 7361 6d70 6c65 732c 2074 6865 6e20 3130  samples, then 10
-00000f40: 302a 6e20 6175 676d 656e 7465 6420 696d  0*n augmented im
-00000f50: 6167 6573 2077 696c 6c20 6265 2063 7265  ages will be cre
-00000f60: 6174 6564 2c20 0a20 2020 2020 2020 2061  ated, .        a
-00000f70: 6e64 2074 6865 7265 666f 7265 2064 7572  nd therefore dur
-00000f80: 696e 6720 7468 6174 2070 6172 7469 6375  ing that particu
-00000f90: 6c61 7220 7472 6961 6c20 7468 6520 6669  lar trial the fi
-00000fa0: 7273 7420 3130 302a 6e20 7361 6d70 6c65  rst 100*n sample
-00000fb0: 7320 6672 6f6d 206e 6567 6174 6976 655f  s from negative_
-00000fc0: 636c 6173 7320 7769 6c6c 2062 6520 7573  class will be us
-00000fd0: 6564 2c20 6966 2061 7661 696c 6162 6c65  ed, if available
-00000fe0: 2e20 0a20 2020 2020 2020 2054 6f20 7573  . .        To us
-00000ff0: 6520 7468 6520 656e 7469 7265 206e 6567  e the entire neg
-00001000: 6174 6976 655f 636c 6173 7320 7361 6d70  ative_class samp
-00001010: 6c65 2072 6567 6172 646c 6573 7320 6f66  le regardless of
-00001020: 2074 6865 206e 756d 6265 7220 6175 676d   the number augm
-00001030: 656e 7461 7469 6f6e 7320 7065 7266 6f72  entations perfor
-00001040: 6d65 642c 2073 6574 2062 616c 616e 6365  med, set balance
-00001050: 3d46 616c 7365 2e0a 2020 2020 0a20 2020  =False..    .   
-00001060: 2020 2020 2054 6865 206d 696e 5f70 6978       The min_pix
-00001070: 656c 2061 6e64 206d 6178 5f70 6978 656c  el and max_pixel
-00001080: 2076 616c 7565 2077 696c 6c20 6265 2075   value will be u
-00001090: 7365 6420 746f 206d 696e 2d6d 6178 206e  sed to min-max n
-000010a0: 6f72 6d61 6c69 7a65 2074 6865 2069 6d61  ormalize the ima
-000010b0: 6765 732c 2069 6620 6e6f 726d 616c 697a  ges, if normaliz
-000010c0: 653d 5472 7565 2e20 5468 6520 6f70 745f  e=True. The opt_
-000010d0: 6d61 785f 6d69 6e5f 7069 780a 2020 2020  max_min_pix.    
-000010e0: 2020 2020 616e 6420 6f70 745f 6d61 785f      and opt_max_
-000010f0: 6d61 785f 7069 782c 2077 6865 6e20 7365  max_pix, when se
-00001100: 742c 2077 696c 6c20 6265 2075 7365 6420  t, will be used 
-00001110: 696e 7374 6561 6420 6475 7269 6e67 2074  instead during t
-00001120: 6865 206f 7074 696d 697a 6174 696f 6e20  he optimization 
-00001130: 7072 6f63 6564 7572 652c 2073 6f20 6173  procedure, so as
-00001140: 2074 6f20 6465 7465 726d 696e 650a 2020   to determine.  
-00001150: 2020 2020 2020 7768 6174 206f 7074 696d        what optim
-00001160: 616c 206d 6178 696d 756d 2076 616c 7565  al maximum value
-00001170: 2074 6f20 7573 6520 7768 656e 206e 6f72   to use when nor
-00001180: 6d61 6c69 7a69 6e67 2074 6865 2069 6d61  malizing the ima
-00001190: 6765 732e 2054 6869 7320 6973 2069 6d70  ges. This is imp
-000011a0: 6f72 7461 6e74 2077 6865 6e20 6465 616c  ortant when deal
-000011b0: 696e 6720 7769 7468 2064 6565 702d 7375  ing with deep-su
-000011c0: 7276 6579 2064 6174 612e 200a 2020 2020  rvey data. .    
-000011d0: 2020 2020 4966 206f 7074 696d 697a 696e      If optimizin
-000011e0: 6720 7468 6520 6e6f 726d 616c 697a 6174  g the normalizat
-000011f0: 696f 6e20 7363 6865 6d65 2c20 7468 6520  ion scheme, the 
-00001200: 6465 6661 756c 7420 6d69 6e5f 7069 7865  default min_pixe
-00001210: 6c20 7769 6c6c 2062 6520 7365 7420 746f  l will be set to
-00001220: 207a 6572 6f2c 2061 7320 7375 6368 206f   zero, as such o
-00001230: 6e6c 7920 7468 6520 6f70 7469 6d61 6c20  nly the optimal 
-00001240: 6d61 785f 7069 7865 6c20 0a20 2020 2020  max_pixel .     
-00001250: 2020 2066 6f72 2065 7665 7279 2062 616e     for every ban
-00001260: 6420 7769 6c6c 2062 6520 6f75 7470 7574  d will be output
-00001270: 2e0a 0a20 2020 2041 7267 733a 0a20 2020  ...    Args:.   
-00001280: 2020 2020 2070 6f73 6974 6976 655f 636c       positive_cl
-00001290: 6173 7320 286e 6461 7272 6179 293a 2054  ass (ndarray): T
-000012a0: 6865 2073 616d 706c 6573 2066 6f72 2074  he samples for t
-000012b0: 6865 2066 6972 7374 2063 6c61 7373 2073  he first class s
-000012c0: 686f 756c 6420 6265 2070 6173 7365 642c  hould be passed,
-000012d0: 2077 6869 6368 2077 696c 6c20 6175 746f   which will auto
-000012e0: 6d61 7469 6361 6c6c 7920 0a20 2020 2020  matically .     
-000012f0: 2020 2020 2020 2062 6520 6173 7369 676e         be assign
-00001300: 6564 2074 6865 2070 6f73 6974 6976 6520  ed the positive 
-00001310: 6c61 6265 6c20 2731 272e 0a20 2020 2020  label '1'..     
-00001320: 2020 206e 6567 6174 6976 655f 636c 6173     negative_clas
-00001330: 7320 286e 6461 7272 6179 293a 2054 6865  s (ndarray): The
-00001340: 2073 616d 706c 6573 2066 6f72 2074 6865   samples for the
-00001350: 2073 6563 6f6e 6420 636c 6173 7320 7368   second class sh
-00001360: 6f75 6c64 2062 6520 7061 7373 6564 2c20  ould be passed, 
-00001370: 7768 6963 6820 7769 6c6c 2061 7574 6f6d  which will autom
-00001380: 6174 6963 616c 6c79 200a 2020 2020 2020  atically .      
-00001390: 2020 2020 2020 6265 2061 7373 6967 6e65        be assigne
-000013a0: 6420 7468 6520 6e65 6761 7469 7665 206c  d the negative l
-000013b0: 6162 656c 2027 3027 2e0a 2020 2020 2020  abel '0'..      
-000013c0: 2020 696d 675f 6e75 6d5f 6368 616e 6e65    img_num_channe
-000013d0: 6c73 2028 696e 7429 3a20 5468 6520 6e75  ls (int): The nu
-000013e0: 6d62 6572 206f 6620 6669 6c74 6572 732e  mber of filters.
-000013f0: 2044 6566 6175 6c74 7320 746f 2031 2e0a   Defaults to 1..
-00001400: 2020 2020 2020 2020 6e6f 726d 616c 697a          normaliz
-00001410: 6520 2862 6f6f 6c2c 206f 7074 696f 6e61  e (bool, optiona
-00001420: 6c29 3a20 4966 2054 7275 6520 7468 6520  l): If True the 
-00001430: 6461 7461 2077 696c 6c20 6265 206d 696e  data will be min
-00001440: 2d6d 6178 206e 6f72 6d61 6c69 7a65 6420  -max normalized 
-00001450: 7573 696e 6720 7468 6520 0a20 2020 2020  using the .     
-00001460: 2020 2020 2020 2069 6e70 7574 206d 696e         input min
-00001470: 2061 6e64 206d 6178 2070 6978 656c 732e   and max pixels.
-00001480: 2044 6566 6175 6c74 7320 746f 2054 7275   Defaults to Tru
-00001490: 652e 0a20 2020 2020 2020 206d 696e 5f70  e..        min_p
-000014a0: 6978 656c 2028 696e 742c 206f 7074 696f  ixel (int, optio
-000014b0: 6e61 6c29 3a20 5468 6520 6d69 6e69 6d75  nal): The minimu
-000014c0: 6d20 7069 7865 6c20 636f 756e 742c 2070  m pixel count, p
-000014d0: 6978 656c 7320 7769 7468 2063 6f75 6e74  ixels with count
-000014e0: 7320 0a20 2020 2020 2020 2020 2020 2062  s .            b
-000014f0: 656c 6f77 2074 6869 7320 7468 7265 7368  elow this thresh
-00001500: 6f6c 6420 7769 6c6c 2062 6520 7365 7420  old will be set 
-00001510: 746f 2074 6869 7320 6c69 6d69 742e 2044  to this limit. D
-00001520: 6566 6175 6c74 7320 746f 2030 2e0a 2020  efaults to 0..  
-00001530: 2020 2020 2020 6d61 785f 7069 7865 6c20        max_pixel 
-00001540: 2869 6e74 2c20 6c69 7374 2c20 6f70 7469  (int, list, opti
-00001550: 6f6e 616c 293a 2054 6865 206d 6178 696d  onal): The maxim
-00001560: 756d 2070 6978 656c 2063 6f75 6e74 2c20  um pixel count, 
-00001570: 7069 7865 6c73 2077 6974 6820 636f 756e  pixels with coun
-00001580: 7473 200a 2020 2020 2020 2020 2020 2020  ts .            
-00001590: 6162 6f76 6520 7468 6973 2074 6872 6573  above this thres
-000015a0: 686f 6c64 2077 696c 6c20 6265 2073 6574  hold will be set
-000015b0: 2074 6f20 7468 6973 206c 696d 6974 2e20   to this limit. 
-000015c0: 4465 6661 756c 7473 2074 6f20 3130 302e  Defaults to 100.
-000015d0: 2049 6620 696d 675f 6e75 6d5f 6368 616e   If img_num_chan
-000015e0: 6e65 6c73 0a20 2020 2020 2020 2020 2020  nels.           
-000015f0: 2069 7320 6e6f 7420 312c 2074 6865 206d   is not 1, the m
-00001600: 6178 5f70 6978 656c 2073 686f 756c 6420  ax_pixel should 
-00001610: 6265 2061 206c 6973 7420 636f 6e74 6169  be a list contai
-00001620: 6e69 6e67 2074 776f 2076 616c 7565 732c  ning two values,
-00001630: 206f 6e65 2066 6f72 2065 6163 6820 6261   one for each ba
-00001640: 6e64 2e0a 2020 2020 2020 2020 7661 6c5f  nd..        val_
-00001650: 706f 7369 7469 7665 2028 6e64 6172 7261  positive (ndarra
-00001660: 792c 206f 7074 696f 6e61 6c29 3a20 506f  y, optional): Po
-00001670: 7369 7469 7665 2063 6c61 7373 2064 6174  sitive class dat
-00001680: 6120 746f 2062 6520 7573 6564 2066 6f72  a to be used for
-00001690: 2076 616c 6964 6174 696f 6e2e 2044 6566   validation. Def
-000016a0: 6175 6c74 7320 746f 204e 6f6e 652e 0a20  aults to None.. 
-000016b0: 2020 2020 2020 2076 616c 5f6e 6567 6174         val_negat
-000016c0: 6976 6520 286e 6461 7272 6179 2c20 6f70  ive (ndarray, op
-000016d0: 7469 6f6e 616c 293a 204e 6567 6174 6976  tional): Negativ
-000016e0: 6520 636c 6173 7320 6461 7461 2074 6f20  e class data to 
-000016f0: 6265 2075 7365 6420 666f 7220 7661 6c69  be used for vali
-00001700: 6461 7469 6f6e 2e20 4465 6661 756c 7473  dation. Defaults
-00001710: 2074 6f20 4e6f 6e65 2e0a 2020 2020 2020   to None..      
-00001720: 2020 7465 7374 5f70 6f73 6974 6976 6520    test_positive 
-00001730: 286e 6461 7272 6179 2c20 6f70 7469 6f6e  (ndarray, option
-00001740: 616c 293a 2050 6f73 6974 6976 6520 636c  al): Positive cl
-00001750: 6173 7320 6461 7461 2074 6f20 6265 2075  ass data to be u
-00001760: 7365 6420 666f 7220 706f 7374 2d74 7269  sed for post-tri
-00001770: 616c 2074 6573 7469 6e67 2e20 4465 6661  al testing. Defa
-00001780: 756c 7473 2074 6f20 4e6f 6e65 2e0a 2020  ults to None..  
-00001790: 2020 2020 2020 7465 7374 5f6e 6567 6174        test_negat
-000017a0: 6976 6520 286e 6461 7272 6179 2c20 6f70  ive (ndarray, op
-000017b0: 7469 6f6e 616c 293a 204e 6567 6174 6976  tional): Negativ
-000017c0: 6520 636c 6173 7320 6461 7461 2074 6f20  e class data to 
-000017d0: 6265 2075 7365 6420 666f 7220 706f 7374  be used for post
-000017e0: 2d74 7269 616c 2074 6573 7469 6e67 2e20  -trial testing. 
-000017f0: 4465 6661 756c 7473 2074 6f20 4e6f 6e65  Defaults to None
-00001800: 2e0a 2020 2020 2020 2020 7472 6169 6e5f  ..        train_
-00001810: 6570 6f63 6873 2028 696e 7429 3a20 4e75  epochs (int): Nu
-00001820: 6d62 6572 206f 6620 6570 6f63 6873 2074  mber of epochs t
-00001830: 6f20 7468 6520 7472 6169 6e20 7468 6520  o the train the 
-00001840: 434e 4e20 746f 2064 7572 696e 6720 7468  CNN to during th
-00001850: 6520 6f70 7469 6d69 7a61 7469 6f6e 2074  e optimization t
-00001860: 7269 616c 732e 2044 6566 6175 6c74 7320  rials. Defaults 
-00001870: 746f 2032 352e 0a20 2020 2020 2020 206d  to 25..        m
-00001880: 6574 7269 6320 2873 7472 293a 2041 7373  etric (str): Ass
-00001890: 6573 6d65 6e74 206d 6574 7269 6320 746f  esment metric to
-000018a0: 2075 7365 2077 6865 6e20 626f 7468 2070   use when both p
-000018b0: 7275 6e69 6e67 2061 6e64 2073 636f 7269  runing and scori
-000018c0: 6e67 2074 6865 2068 7970 6572 7061 7261  ng the hyperpara
-000018d0: 6d65 7465 7220 6f70 7469 6d69 7a61 7469  meter optimizati
-000018e0: 6f6e 2074 7269 616c 2e0a 2020 2020 2020  on trial..      
-000018f0: 2020 2020 2020 4465 6661 756c 7473 2074        Defaults t
-00001900: 6f20 276c 6f73 7327 2e20 4f70 7469 6f6e  o 'loss'. Option
-00001910: 7320 696e 636c 7564 653a 2027 6c6f 7373  s include: 'loss
-00001920: 2720 2762 696e 6172 795f 6163 6375 7261  ' 'binary_accura
-00001930: 6379 272c 2027 6631 5f73 636f 7265 2720  cy', 'f1_score' 
-00001940: 2761 6c6c 2720 6f72 2074 6865 2076 616c  'all' or the val
-00001950: 6964 6174 696f 6e20 6571 7569 7661 6c65  idation equivale
-00001960: 6e74 7320 2865 2e67 2e20 2776 616c 5f6c  nts (e.g. 'val_l
-00001970: 6f73 7327 292e 0a20 2020 2020 2020 2070  oss')..        p
-00001980: 6174 6965 6e63 6520 2869 6e74 293a 204e  atience (int): N
-00001990: 756d 6265 7220 6f66 2065 706f 6368 7320  umber of epochs 
-000019a0: 7769 7468 6f75 7420 696d 7072 6f76 656d  without improvem
-000019b0: 656e 7420 6265 666f 7265 2074 6865 206f  ent before the o
-000019c0: 7074 696d 697a 6174 696f 6e20 7472 6961  ptimization tria
-000019d0: 6c20 6973 2074 6572 6d69 6e61 7465 642e  l is terminated.
-000019e0: 2044 6566 6175 6c74 7320 746f 2030 2c20   Defaults to 0, 
-000019f0: 7768 6963 680a 2020 2020 2020 2020 2020  which.          
-00001a00: 2020 6469 7361 626c 6573 2074 6869 7320    disables this 
-00001a10: 6665 6174 7572 652e 0a20 2020 2020 2020  feature..       
-00001a20: 2061 7665 7261 6765 2028 626f 6f6c 293a   average (bool):
-00001a30: 2049 6620 4661 6c73 652c 2074 6865 2064   If False, the d
-00001a40: 6573 6967 6e61 7465 6420 6d65 7472 6963  esignated metric
-00001a50: 2077 696c 6c20 6265 2063 616c 6375 6c61   will be calcula
-00001a60: 7465 6420 6163 636f 7264 696e 6720 746f  ted according to
-00001a70: 2069 7473 2076 616c 7565 2061 7420 7468   its value at th
-00001a80: 6520 656e 6420 6f66 2074 6865 2074 7261  e end of the tra
-00001a90: 696e 5f65 706f 6368 732e 200a 2020 2020  in_epochs. .    
-00001aa0: 2020 2020 2020 2020 4966 2054 7275 652c          If True,
-00001ab0: 2074 6865 206d 6574 7269 6320 7769 6c6c   the metric will
-00001ac0: 2062 6520 6176 6572 6167 6564 206f 7574   be averaged out
-00001ad0: 2061 6372 6f73 7320 616c 6c20 7472 6169   across all trai
-00001ae0: 6e5f 6570 6f63 6873 2e20 4465 6661 756c  n_epochs. Defaul
-00001af0: 7473 2074 6f20 5472 7565 2e0a 2020 2020  ts to True..    
-00001b00: 2020 2020 6f70 745f 6d6f 6465 6c20 2862      opt_model (b
-00001b10: 6f6f 6c29 3a20 4966 2054 7275 652c 2074  ool): If True, t
-00001b20: 6865 2061 7263 6869 7465 6374 7572 6520  he architecture 
-00001b30: 7061 7261 6d65 7465 7273 2077 696c 6c20  parameters will 
-00001b40: 6265 206f 7074 696d 697a 6564 2e20 4465  be optimized. De
-00001b50: 6661 756c 7473 2074 6f20 5472 7565 2e0a  faults to True..
-00001b60: 2020 2020 2020 2020 6f70 745f 6175 6720          opt_aug 
-00001b70: 2862 6f6f 6c29 3a20 4966 2054 7275 652c  (bool): If True,
-00001b80: 2074 6865 2061 7567 6d65 6e74 6174 696f   the augmentatio
-00001b90: 6e20 7072 6f63 6564 7572 6520 7769 6c6c  n procedure will
-00001ba0: 2062 6520 6f70 7469 6d69 7a65 642e 2044   be optimized. D
-00001bb0: 6566 6175 6c74 7320 746f 2046 616c 7365  efaults to False
-00001bc0: 2e0a 2020 2020 2020 2020 6261 7463 685f  ..        batch_
-00001bd0: 6d69 6e20 2869 6e74 293a 2054 6865 206d  min (int): The m
-00001be0: 696e 696d 756d 206e 756d 6265 7220 6f66  inimum number of
-00001bf0: 2061 7567 6d65 6e74 6174 696f 6e73 2074   augmentations t
-00001c00: 6f20 7065 7266 6f72 6d20 7065 7220 696d  o perform per im
-00001c10: 6167 6520 6f6e 2074 6865 2070 6f73 6974  age on the posit
-00001c20: 6976 6520 636c 6173 732c 206f 6e6c 7920  ive class, only 
-00001c30: 6170 706c 6963 6162 6c65 200a 2020 2020  applicable .    
-00001c40: 2020 2020 2020 2020 6966 206f 7074 5f61          if opt_a
-00001c50: 7567 3d54 7275 652e 2044 6566 6175 6c74  ug=True. Default
-00001c60: 7320 746f 2032 2e0a 2020 2020 2020 2020  s to 2..        
-00001c70: 6261 7463 685f 6d61 7820 2869 6e74 293a  batch_max (int):
-00001c80: 2054 6865 206d 6178 696d 756d 206e 756d   The maximum num
-00001c90: 6265 7220 6f66 2061 7567 6d65 6e74 6174  ber of augmentat
-00001ca0: 696f 6e73 2074 6f20 7065 7266 6f72 6d20  ions to perform 
-00001cb0: 7065 7220 696d 6167 6520 6f6e 2074 6865  per image on the
-00001cc0: 2070 6f73 6974 6976 6520 636c 6173 732c   positive class,
-00001cd0: 206f 6e6c 7920 6170 706c 6963 6162 6c65   only applicable
-00001ce0: 200a 2020 2020 2020 2020 2020 2020 6966   .            if
-00001cf0: 206f 7074 5f61 7567 3d54 7275 652e 2044   opt_aug=True. D
-00001d00: 6566 6175 6c74 7320 746f 2032 352e 0a20  efaults to 25.. 
-00001d10: 2020 2020 2020 2062 6174 6368 5f6f 7468         batch_oth
-00001d20: 6572 2028 696e 7429 3a20 5468 6520 6e75  er (int): The nu
-00001d30: 6d62 6572 206f 6620 6175 676d 656e 7461  mber of augmenta
-00001d40: 7469 6f6e 7320 746f 2070 6572 666f 726d  tions to perform
-00001d50: 2074 6f20 7468 6520 6f74 6865 7220 636c   to the other cl
-00001d60: 6173 732c 2070 7265 7375 6d65 6420 746f  ass, presumed to
-00001d70: 2062 6520 7468 6520 6d61 6a6f 7269 7479   be the majority
-00001d80: 2063 6c61 7373 2e0a 2020 2020 2020 2020   class..        
-00001d90: 2020 2020 4465 6661 756c 7473 2074 6f20      Defaults to 
-00001da0: 312e 2054 6869 7320 6973 2064 6f6e 6520  1. This is done 
-00001db0: 746f 2065 6e73 7572 6520 6175 676d 656e  to ensure augmen
-00001dc0: 7461 7469 6f6e 2074 6563 686e 6971 7565  tation technique
-00001dd0: 7320 6172 6520 6170 706c 6965 6420 636f  s are applied co
-00001de0: 6e73 6973 7465 6e74 6c79 2061 6372 6f73  nsistently acros
-00001df0: 7320 626f 7468 2063 6c61 7373 6573 2e0a  s both classes..
-00001e00: 2020 2020 2020 2020 696d 6167 655f 7369          image_si
-00001e10: 7a65 5f6d 696e 2028 696e 7429 3a20 5468  ze_min (int): Th
-00001e20: 6520 6d69 6e69 6d75 6d20 696d 6167 6520  e minimum image 
-00001e30: 7369 7a65 2074 6f20 6173 7365 7373 2c20  size to assess, 
-00001e40: 6f6e 6c79 2061 7070 6c69 6361 626c 6520  only applicable 
-00001e50: 6966 206f 7074 5f61 7567 3d54 7275 652e  if opt_aug=True.
-00001e60: 2044 6566 6175 6c74 7320 746f 2035 302e   Defaults to 50.
-00001e70: 0a20 2020 2020 2020 2069 6d61 6765 5f73  .        image_s
-00001e80: 697a 655f 6d61 7820 2869 6e74 293a 2054  ize_max (int): T
-00001e90: 6865 206d 6178 696d 756d 2069 6d61 6765  he maximum image
-00001ea0: 2073 697a 6520 746f 2061 7373 6573 732c   size to assess,
-00001eb0: 206f 6e6c 7920 6170 706c 6963 6162 6c65   only applicable
-00001ec0: 2069 6620 6f70 745f 6175 673d 5472 7565   if opt_aug=True
-00001ed0: 2e20 4465 6661 756c 7473 2074 6f20 3130  . Defaults to 10
-00001ee0: 302e 0a20 2020 2020 2020 206f 7074 5f6d  0..        opt_m
-00001ef0: 6178 5f6d 696e 5f70 6978 2028 696e 742c  ax_min_pix (int,
-00001f00: 206f 7074 696f 6e61 6c29 3a20 5468 6520   optional): The 
-00001f10: 6d69 6e69 6d75 6d20 6d61 7820 7069 7865  minimum max pixe
-00001f20: 6c20 7661 6c75 6520 746f 2075 7365 2077  l value to use w
-00001f30: 6865 6e20 7475 6e69 6e67 2074 6865 206e  hen tuning the n
-00001f40: 6f72 6d61 6c69 7a61 7469 6f6e 2070 726f  ormalization pro
-00001f50: 6365 6475 7265 2c20 0a20 2020 2020 2020  cedure, .       
-00001f60: 2020 2020 206f 6e6c 7920 6170 706c 6963       only applic
-00001f70: 6162 6c65 2069 6620 6f70 745f 6175 673d  able if opt_aug=
-00001f80: 5472 7565 2e20 4465 6661 756c 7473 2074  True. Defaults t
-00001f90: 6f20 4e6f 6e65 2e0a 2020 2020 2020 2020  o None..        
-00001fa0: 6f70 745f 6d61 785f 6d61 785f 7069 7820  opt_max_max_pix 
-00001fb0: 2869 6e74 2c20 6f70 7469 6f6e 616c 293a  (int, optional):
-00001fc0: 2054 6865 206d 6178 696d 756d 206d 6178   The maximum max
-00001fd0: 2070 6978 656c 2076 616c 7565 2074 6f20   pixel value to 
-00001fe0: 7573 6520 7768 656e 2074 756e 696e 6720  use when tuning 
-00001ff0: 7468 6520 6e6f 726d 616c 697a 6174 696f  the normalizatio
-00002000: 6e20 7072 6f63 6564 7572 652c 200a 2020  n procedure, .  
-00002010: 2020 2020 2020 2020 2020 6f6e 6c79 2061            only a
-00002020: 7070 6c69 6361 626c 6520 6966 206f 7074  pplicable if opt
-00002030: 5f61 7567 3d54 7275 652e 2044 6566 6175  _aug=True. Defau
-00002040: 6c74 7320 746f 204e 6f6e 652e 0a20 2020  lts to None..   
-00002050: 2020 2020 2073 6869 6674 2028 696e 7429       shift (int)
-00002060: 3a20 5468 6520 6d61 7820 616c 6c6f 7765  : The max allowe
-00002070: 6420 7665 7274 6963 616c 2f68 6f72 697a  d vertical/horiz
-00002080: 6f6e 7461 6c20 7368 6966 7473 2074 6f20  ontal shifts to 
-00002090: 7573 6520 6475 7269 6e67 2074 6865 2064  use during the d
-000020a0: 6174 6120 6175 676d 656e 7461 7469 6f6e  ata augmentation
-000020b0: 2072 6f75 7469 6e65 2c20 6f6e 6c79 2061   routine, only a
-000020c0: 7070 6c69 6361 626c 650a 2020 2020 2020  pplicable.      
-000020d0: 2020 2020 2020 6966 206f 7074 5f61 7567        if opt_aug
-000020e0: 3d54 7275 652e 2044 6566 6175 6c74 7320  =True. Defaults 
-000020f0: 746f 2031 3020 7069 7865 6c73 2e0a 2020  to 10 pixels..  
-00002100: 2020 2020 2020 6d61 736b 5f73 697a 6520        mask_size 
-00002110: 2869 6e74 2c20 6f70 7469 6f6e 616c 293a  (int, optional):
-00002120: 2049 6620 656e 6162 6c65 642c 2074 6869   If enabled, thi
-00002130: 7320 7769 6c6c 2073 6574 2074 6865 2070  s will set the p
-00002140: 6978 656c 206c 656e 6774 6820 6f66 2061  ixel length of a
-00002150: 2073 7175 6172 6520 6375 746f 7574 2c20   square cutout, 
-00002160: 746f 2062 6520 7261 6e64 6f6d 6c79 2070  to be randomly p
-00002170: 6c61 6365 640a 2020 2020 2020 2020 2020  laced.          
-00002180: 2020 736f 6d65 7768 6572 6520 696e 2074    somewhere in t
-00002190: 6865 2061 7567 6d65 6e74 6564 2069 6d61  he augmented ima
-000021a0: 6765 2e20 5468 6973 2063 7574 6f75 7420  ge. This cutout 
-000021b0: 7769 6c6c 2072 6570 6c61 6365 2074 6865  will replace the
-000021c0: 2069 6d61 6765 2076 616c 7565 7320 7769   image values wi
-000021d0: 7468 2030 2c20 7468 6572 6566 6f72 6520  th 0, therefore 
-000021e0: 7365 7276 696e 6720 6173 2061 200a 2020  serving as a .  
-000021f0: 2020 2020 2020 2020 2020 7265 6775 6c61            regula
-00002200: 7269 7a65 722e 204f 6e6c 7920 6170 706c  rizer. Only appl
-00002210: 6963 6162 6c65 2069 6620 6f70 745f 6175  icable if opt_au
-00002220: 673d 5472 7565 2e20 4465 6661 756c 7473  g=True. Defaults
-00002230: 2074 6f20 4e6f 6e65 2e0a 2020 2020 2020   to None..      
-00002240: 2020 6e75 6d5f 6d61 736b 7320 2869 6e74    num_masks (int
-00002250: 2c20 6f70 7469 6f6e 616c 293a 2054 6865  , optional): The
-00002260: 206e 756d 6265 7220 6f66 206d 6173 6b73   number of masks
-00002270: 2074 6f20 6372 6561 7465 2c20 746f 2062   to create, to b
-00002280: 6520 7573 6564 2061 6c6f 6e67 7369 6465  e used alongside
-00002290: 2074 6865 206d 6173 6b5f 7369 7a65 2070   the mask_size p
-000022a0: 6172 616d 6574 6572 2e20 4966 200a 2020  arameter. If .  
-000022b0: 2020 2020 2020 2020 2020 7468 6973 2069            this i
-000022c0: 7320 7365 7420 746f 2061 2076 616c 7565  s set to a value
-000022d0: 2067 7265 6174 6572 2074 6861 6e20 6f6e   greater than on
-000022e0: 652c 206f 7665 726c 6170 206d 6179 206f  e, overlap may o
-000022f0: 6363 7572 2e20 0a20 2020 2020 2020 2076  ccur. .        v
-00002300: 6572 626f 7365 2028 696e 7429 3a20 436f  erbose (int): Co
-00002310: 6e74 726f 6c73 2074 6865 2061 6d6f 756e  ntrols the amoun
-00002320: 7420 6f66 206f 7574 7075 7420 7072 696e  t of output prin
-00002330: 7465 6420 6475 7269 6e67 2074 6865 2074  ted during the t
-00002340: 7261 696e 696e 6720 7072 6f63 6573 732e  raining process.
-00002350: 2041 2076 616c 7565 206f 6620 3020 6973   A value of 0 is
-00002360: 2066 6f72 2073 696c 656e 7420 6d6f 6465   for silent mode
-00002370: 2c20 0a20 2020 2020 2020 2020 2020 2061  , .            a
-00002380: 2076 616c 7565 206f 6620 3120 6973 2075   value of 1 is u
-00002390: 7365 6420 666f 7220 7072 6f67 7265 7373  sed for progress
-000023a0: 2062 6172 206d 6f64 652c 2061 6e64 2032   bar mode, and 2
-000023b0: 2066 6f72 206f 6e65 206c 696e 6520 7065   for one line pe
-000023c0: 7220 6570 6f63 6820 6d6f 6465 2e20 4465  r epoch mode. De
-000023d0: 6661 756c 7473 2074 6f20 312e 0a20 2020  faults to 1..   
-000023e0: 2020 2020 206f 7074 5f63 7620 2869 6e74       opt_cv (int
-000023f0: 293a 2043 726f 7373 2d76 616c 6964 6174  ): Cross-validat
-00002400: 696f 6e73 2074 6f20 7065 7266 6f72 6d20  ions to perform 
-00002410: 7768 656e 2061 7373 6573 7369 6e67 2074  when assessing t
-00002420: 6865 2070 6572 666f 726d 616e 6365 2061  he performance a
-00002430: 7420 6561 6368 0a20 2020 2020 2020 2020  t each.         
-00002440: 2020 2068 7970 6572 7061 7261 6d65 7465     hyperparamete
-00002450: 7220 6f70 7469 6d69 7a61 7469 6f6e 2074  r optimization t
-00002460: 7269 616c 2e20 466f 7220 6578 616d 706c  rial. For exampl
-00002470: 652c 2069 6620 6376 3d33 2c20 7468 656e  e, if cv=3, then
-00002480: 2065 6163 6820 6f70 7469 6d69 7a61 7469   each optimizati
-00002490: 6f6e 2074 7269 616c 0a20 2020 2020 2020  on trial.       
-000024a0: 2020 2020 2077 696c 6c20 6265 2061 7373       will be ass
-000024b0: 6573 7365 6420 6163 636f 7264 696e 6720  essed according 
-000024c0: 746f 2074 6865 2033 2d66 6f6c 6420 6372  to the 3-fold cr
-000024d0: 6f73 7320 7661 6c69 6461 7469 6f6e 2061  oss validation a
-000024e0: 6363 7572 6163 792e 2044 6566 6175 6c74  ccuracy. Default
-000024f0: 7320 746f 2031 302e 0a20 2020 2020 2020  s to 10..       
-00002500: 2020 2020 204e 4f54 453a 2054 6865 2068       NOTE: The h
-00002510: 6967 6865 7220 7468 6973 206e 756d 6265  igher this numbe
-00002520: 722c 2074 6865 206c 6f6e 6765 7220 7468  r, the longer th
-00002530: 6520 6f70 7469 6d69 7a61 7469 6f6e 2077  e optimization w
-00002540: 696c 6c20 7461 6b65 2e0a 2020 2020 2020  ill take..      
-00002550: 2020 6261 6c61 6e63 6520 2862 6f6f 6c2c    balance (bool,
-00002560: 206f 7074 696f 6e61 6c29 3a20 5468 6973   optional): This
-00002570: 2077 696c 6c20 6465 7465 726d 696e 6520   will determine 
-00002580: 7768 6574 6865 7220 7468 6520 7477 6f20  whether the two 
-00002590: 636c 6173 7365 730a 2020 2020 2020 2020  classes.        
-000025a0: 2020 2020 6172 6520 6b65 7074 2074 6865      are kept the
-000025b0: 2073 616d 6520 7369 7a65 2064 7572 696e   same size durin
-000025c0: 6720 6f70 7469 6d69 7a61 7469 6f6e 2c20  g optimization, 
-000025d0: 6170 706c 6963 6162 6c65 2069 6620 7475  applicable if tu
-000025e0: 6e69 6e67 2074 6865 2061 7567 6d65 6e74  ning the augment
-000025f0: 6174 696f 6e0a 2020 2020 2020 2020 2020  ation.          
-00002600: 2020 7061 7261 6d65 7465 7273 2e20 4465    parameters. De
-00002610: 6661 756c 7473 2074 6f20 5472 7565 2e0a  faults to True..
-00002620: 2020 2020 2020 2020 636c 6620 2873 7472          clf (str
-00002630: 293a 2043 616e 2062 6520 2761 6c65 786e  ): Can be 'alexn
-00002640: 6574 2720 6f72 2027 6375 7374 6f6d 5f63  et' or 'custom_c
-00002650: 6e6e 2720 666f 7220 7468 6520 6375 7374  nn' for the cust
-00002660: 6f6d 6c79 2063 6f6e 6669 6775 7265 642c  omly configured,
-00002670: 2073 6861 6c6c 6f77 6572 206d 6f64 656c   shallower model
-00002680: 2e20 4361 6e20 616c 736f 2062 6520 0a20  . Can also be . 
-00002690: 2020 2020 2020 2020 2020 2027 7667 6731             'vgg1
-000026a0: 3627 206f 7220 2772 6573 6e65 7431 3827  6' or 'resnet18'
-000026b0: 2e0a 2020 2020 2020 2020 6c69 6d69 745f  ..        limit_
-000026c0: 7365 6172 6368 2028 626f 6f6c 293a 2057  search (bool): W
-000026d0: 6865 7468 6572 2074 6f20 6578 7061 6e64  hether to expand
-000026e0: 2074 6865 2068 7970 6572 7061 7261 6d65   the hyperparame
-000026f0: 7465 7220 7365 6172 6368 2073 7061 6365  ter search space
-00002700: 2c20 6f6e 6c79 2069 6620 6170 706c 6963  , only if applic
-00002710: 6162 6c65 2069 6620 636c 663d 2761 6c65  able if clf='ale
-00002720: 786e 6574 272c 2066 6f72 2065 7861 6d70  xnet', for examp
-00002730: 6c65 2c0a 2020 2020 2020 2020 2020 2020  le,.            
-00002740: 7468 6973 2077 696c 6c20 696e 636c 7564  this will includ
-00002750: 6520 7468 6520 7475 6e69 6e67 206f 6620  e the tuning of 
-00002760: 7468 6520 696e 6469 7669 6475 616c 206c  the individual l
-00002770: 6179 6572 2070 6172 616d 6574 6572 7320  ayer parameters 
-00002780: 7375 6368 2061 7320 7468 6520 6e75 6d62  such as the numb
-00002790: 6572 206f 6620 6669 6c74 6572 2c20 7369  er of filter, si
-000027a0: 7a65 2026 2073 7472 6964 652e 0a20 2020  ze & stride..   
-000027b0: 2020 2020 2020 2020 2044 6566 6175 6c74           Default
-000027c0: 7320 746f 2054 7275 6520 6475 6520 746f  s to True due to
-000027d0: 206d 656d 6f72 7920 616c 6c6f 6361 7469   memory allocati
-000027e0: 6f6e 2069 7373 7565 7320 7768 656e 2068  on issues when h
-000027f0: 616e 646c 696e 6720 6c6f 7473 206f 6620  andling lots of 
-00002800: 7475 6e61 626c 6520 7061 7261 6d65 7465  tunable paramete
-00002810: 7273 2e0a 2020 2020 2020 2020 6261 7463  rs..        batc
-00002820: 685f 7369 7a65 5f6d 696e 2028 696e 7429  h_size_min (int)
-00002830: 3a20 5468 6520 6d69 6e69 6d75 6d20 6261  : The minimum ba
-00002840: 7463 6820 7369 7a65 2074 6f20 7573 6520  tch size to use 
-00002850: 6475 7269 6e67 2074 7261 696e 696e 672e  during training.
-00002860: 2053 686f 756c 6420 6265 206d 756c 7469   Should be multi
-00002870: 706c 6573 206f 6620 3136 2066 6f72 206f  ples of 16 for o
-00002880: 7074 696d 616c 2068 6172 6477 6172 6520  ptimal hardware 
-00002890: 7573 653f 3f20 4465 6661 756c 7473 2074  use?? Defaults t
-000028a0: 6f20 3136 2e0a 2020 2020 2020 2020 6261  o 16..        ba
-000028b0: 7463 685f 7369 7a65 5f6d 6178 2028 696e  tch_size_max (in
-000028c0: 7429 3a20 5468 6520 4d61 7869 6d75 6d20  t): The Maximum 
-000028d0: 6261 7463 6820 7369 7a65 2074 6f20 7573  batch size to us
-000028e0: 6520 6475 7269 6e67 2074 7261 696e 696e  e during trainin
-000028f0: 672e 2053 686f 756c 6420 6265 206d 756c  g. Should be mul
-00002900: 7469 706c 6573 206f 6620 3136 2066 6f72  tiples of 16 for
-00002910: 206f 7074 696d 616c 2068 6172 6477 6172   optimal hardwar
-00002920: 6520 7573 653f 3f20 4465 6661 756c 7473  e use?? Defaults
-00002930: 2074 6f20 3634 2e0a 2020 2020 2020 2020   to 64..        
-00002940: 6d6f 6e69 746f 7231 2028 7374 722c 206f  monitor1 (str, o
-00002950: 7074 696f 6e61 6c29 3a20 5468 6520 6669  ptional): The fi
-00002960: 7273 7420 6d65 7472 6963 2074 6f20 6d6f  rst metric to mo
-00002970: 6e69 746f 722c 2063 616e 2074 616b 6520  nitor, can take 
-00002980: 7468 6520 7361 6d65 2076 616c 7565 7320  the same values 
-00002990: 6173 2074 6865 206d 6574 7269 6320 6172  as the metric ar
-000029a0: 6775 6d65 6e74 2e20 4465 6661 756c 7473  gument. Defaults
-000029b0: 2074 6f20 4e6f 6e65 2e0a 2020 2020 2020   to None..      
-000029c0: 2020 6d6f 6e69 746f 7232 2028 7374 722c    monitor2 (str,
-000029d0: 206f 7074 696f 6e61 6c29 3a20 5468 6520   optional): The 
-000029e0: 7365 636f 6e64 206d 6574 7269 6320 746f  second metric to
-000029f0: 206d 6f6e 6974 6f72 2c20 6361 6e20 7461   monitor, can ta
-00002a00: 6b65 2074 6865 2073 616d 6520 7661 6c75  ke the same valu
-00002a10: 6573 2061 7320 7468 6520 6d65 7472 6963  es as the metric
-00002a20: 2061 7267 756d 656e 742e 2044 6566 6175   argument. Defau
-00002a30: 6c74 7320 746f 204e 6f6e 652e 0a20 2020  lts to None..   
-00002a40: 2020 2020 206d 6f6e 6974 6f72 315f 7468       monitor1_th
-00002a50: 7265 7368 2028 666c 6f61 742c 206f 7074  resh (float, opt
-00002a60: 696f 6e61 6c29 3a20 5468 6520 7468 7265  ional): The thre
-00002a70: 7368 6f6c 6420 7661 6c75 6520 6f66 2074  shold value of t
-00002a80: 6865 2066 6972 7374 206d 6f6e 6974 6f72  he first monitor
-00002a90: 206d 6574 7269 632e 2049 6620 7468 6520   metric. If the 
-00002aa0: 6d65 7472 6963 2069 7320 6c6f 7373 2d72  metric is loss-r
-00002ab0: 656c 6174 6564 0a20 2020 2020 2020 2020  elated.         
-00002ac0: 2020 2074 6865 2074 7261 696e 696e 6720     the training 
-00002ad0: 7769 6c6c 2073 746f 7020 6561 726c 7920  will stop early 
-00002ae0: 6966 2074 6865 2076 616c 7565 2066 616c  if the value fal
-00002af0: 6c73 2062 656c 6f77 2074 6869 7320 7468  ls below this th
-00002b00: 7265 7368 6f6c 642e 2053 696d 696c 6172  reshold. Similar
-00002b10: 6c79 2c20 6966 2074 6865 206d 6574 7269  ly, if the metri
-00002b20: 6320 6973 2061 6363 7572 6163 792d 7265  c is accuracy-re
-00002b30: 6c61 7465 642c 0a20 2020 2020 2020 2020  lated,.         
-00002b40: 2020 2074 6865 6e20 7468 6520 7472 6169     then the trai
-00002b50: 6e69 6e67 2077 696c 6c20 7374 6f70 2065  ning will stop e
-00002b60: 6172 6c79 2069 6620 7468 6520 7661 6c75  arly if the valu
-00002b70: 6520 6661 6c6c 7320 6162 6f76 6520 7468  e falls above th
-00002b80: 6973 2074 6872 6573 686f 6c64 2e20 4465  is threshold. De
-00002b90: 6661 756c 7473 2074 6f20 4e6f 6e65 2e0a  faults to None..
-00002ba0: 2020 2020 2020 2020 6d6f 6e69 746f 7232          monitor2
-00002bb0: 5f74 6872 6573 6820 2866 6c6f 6174 2c20  _thresh (float, 
-00002bc0: 6f70 7469 6f6e 616c 293a 2054 6865 2074  optional): The t
-00002bd0: 6872 6573 686f 6c64 2076 616c 7565 206f  hreshold value o
-00002be0: 6620 7468 6520 7365 636f 6e64 206d 6f6e  f the second mon
-00002bf0: 6974 6f72 206d 6574 7269 632e 2049 6620  itor metric. If 
-00002c00: 7468 6520 6d65 7472 6963 2069 7320 6c6f  the metric is lo
-00002c10: 7373 2d72 656c 6174 6564 0a20 2020 2020  ss-related.     
-00002c20: 2020 2020 2020 2074 6865 2074 7261 696e         the train
-00002c30: 696e 6720 7769 6c6c 2073 746f 7020 6561  ing will stop ea
-00002c40: 726c 7920 6966 2074 6865 2076 616c 7565  rly if the value
-00002c50: 2066 616c 6c73 2062 656c 6f77 2074 6869   falls below thi
-00002c60: 7320 7468 7265 7368 6f6c 642e 2053 696d  s threshold. Sim
-00002c70: 696c 6172 6c79 2c20 6966 2074 6865 206d  ilarly, if the m
-00002c80: 6574 7269 6320 6973 2061 6363 7572 6163  etric is accurac
-00002c90: 792d 7265 6c61 7465 642c 0a20 2020 2020  y-related,.     
-00002ca0: 2020 2020 2020 2074 6865 6e20 7468 6520         then the 
-00002cb0: 7472 6169 6e69 6e67 2077 696c 6c20 7374  training will st
-00002cc0: 6f70 2065 6172 6c79 2069 6620 7468 6520  op early if the 
-00002cd0: 7661 6c75 6520 6661 6c6c 7320 6162 6f76  value falls abov
-00002ce0: 6520 7468 6973 2074 6872 6573 686f 6c64  e this threshold
-00002cf0: 2e20 4465 6661 756c 7473 2074 6f20 4e6f  . Defaults to No
-00002d00: 6e65 2e0a 2020 2020 2020 2020 736d 6f74  ne..        smot
-00002d10: 655f 7361 6d70 6c69 6e67 2028 666c 6f61  e_sampling (floa
-00002d20: 7429 3a20 5468 6520 736d 6f74 655f 7361  t): The smote_sa
-00002d30: 6d70 6c69 6e67 2070 6172 616d 6574 6572  mpling parameter
-00002d40: 2069 7320 7573 6564 2069 6e20 7468 6520   is used in the 
-00002d50: 534d 4f54 4520 616c 676f 7269 7468 6d20  SMOTE algorithm 
-00002d60: 746f 2073 7065 6369 6679 2074 6865 2064  to specify the d
-00002d70: 6573 6972 6564 200a 2020 2020 2020 2020  esired .        
-00002d80: 2020 2020 7261 7469 6f20 6f66 2074 6865      ratio of the
-00002d90: 206d 696e 6f72 6974 7920 636c 6173 7320   minority class 
-00002da0: 746f 2074 6865 206d 616a 6f72 6974 7920  to the majority 
-00002db0: 636c 6173 732e 2044 6566 6175 6c74 7320  class. Defaults 
-00002dc0: 746f 2030 2077 6869 6368 2064 6973 6162  to 0 which disab
-00002dd0: 6c65 7320 7468 6520 7072 6f63 6564 7572  les the procedur
-00002de0: 652e 2046 6f72 206d 6f72 650a 2020 2020  e. For more.    
-00002df0: 2020 2020 2020 2020 696e 666f 726d 6174          informat
-00002e00: 696f 6e20 7265 6665 7220 746f 2074 6865  ion refer to the
-00002e10: 2065 6e73 656d 626c 655f 6d6f 6465 6c20   ensemble_model 
-00002e20: 6d6f 6475 6c65 2e0a 2020 2020 2020 2020  module..        
-00002e30: 626c 656e 645f 6d61 7820 2866 6c6f 6174  blend_max (float
-00002e40: 293a 2049 6620 7573 6564 2074 6869 7320  ): If used this 
-00002e50: 7769 6c6c 2061 7070 6c79 2062 6c65 6e64  will apply blend
-00002e60: 696e 6720 6175 676d 656e 7461 7469 6f6e  ing augmentation
-00002e70: 200a 2020 2020 2020 2020 6e75 6d5f 696d   .        num_im
-00002e80: 6167 6573 5f74 6f5f 626c 656e 6420 2869  ages_to_blend (i
-00002e90: 6e74 293a 0a20 2020 2020 2020 207a 6f6f  nt):.        zoo
-00002ea0: 6d5f 7261 6e67 6520 2874 7570 6c65 293a  m_range (tuple):
-00002eb0: 0a20 2020 2020 2020 2062 6174 6368 5f6f  .        batch_o
-00002ec0: 7468 6572 2028 696e 7429 3a20 4361 6e20  ther (int): Can 
-00002ed0: 6265 2073 6574 2074 6f20 7a65 726f 2e0a  be set to zero..
-00002ee0: 2020 2020 2020 2020 626c 656e 6469 6e67          blending
-00002ef0: 5f66 756e 6320 2873 7472 293a 0a20 2020  _func (str):.   
-00002f00: 2020 2020 2073 6b65 775f 616e 676c 650a       skew_angle.
-00002f10: 0a20 2020 2052 6574 7572 6e73 3a0a 2020  .    Returns:.  
-00002f20: 2020 2020 2020 5468 6520 7065 7266 6f72        The perfor
-00002f30: 6d61 6e63 6520 6d65 7472 6963 2e0a 2020  mance metric..  
-00002f40: 2020 2222 220a 0a20 2020 2064 6566 205f    """..    def _
-00002f50: 5f69 6e69 745f 5f28 7365 6c66 2c20 706f  _init__(self, po
-00002f60: 7369 7469 7665 5f63 6c61 7373 2c20 6e65  sitive_class, ne
-00002f70: 6761 7469 7665 5f63 6c61 7373 2c20 7661  gative_class, va
-00002f80: 6c5f 706f 7369 7469 7665 3d4e 6f6e 652c  l_positive=None,
-00002f90: 2076 616c 5f6e 6567 6174 6976 653d 4e6f   val_negative=No
-00002fa0: 6e65 2c20 696d 675f 6e75 6d5f 6368 616e  ne, img_num_chan
-00002fb0: 6e65 6c73 3d31 2c20 636c 663d 2761 6c65  nels=1, clf='ale
-00002fc0: 786e 6574 272c 200a 2020 2020 2020 2020  xnet', .        
-00002fd0: 6e6f 726d 616c 697a 653d 5472 7565 2c20  normalize=True, 
-00002fe0: 6d69 6e5f 7069 7865 6c3d 302c 206d 6178  min_pixel=0, max
-00002ff0: 5f70 6978 656c 3d31 3030 302c 2070 6174  _pixel=1000, pat
-00003000: 6965 6e63 653d 352c 206d 6574 7269 633d  ience=5, metric=
-00003010: 276c 6f73 7327 2c20 6176 6572 6167 653d  'loss', average=
-00003020: 5472 7565 2c20 0a20 2020 2020 2020 2074  True, .        t
-00003030: 6573 745f 706f 7369 7469 7665 3d4e 6f6e  est_positive=Non
-00003040: 652c 2074 6573 745f 6e65 6761 7469 7665  e, test_negative
-00003050: 3d4e 6f6e 652c 2062 6174 6368 5f73 697a  =None, batch_siz
-00003060: 655f 6d69 6e3d 3136 2c20 6261 7463 685f  e_min=16, batch_
-00003070: 7369 7a65 5f6d 6178 3d36 342c 206f 7074  size_max=64, opt
-00003080: 5f6d 6f64 656c 3d54 7275 652c 2074 7261  _model=True, tra
-00003090: 696e 5f65 706f 6368 733d 3235 2c20 6f70  in_epochs=25, op
-000030a0: 745f 6376 3d4e 6f6e 652c 0a20 2020 2020  t_cv=None,.     
-000030b0: 2020 206f 7074 5f61 7567 3d46 616c 7365     opt_aug=False
-000030c0: 2c20 6261 7463 685f 6d69 6e3d 322c 2062  , batch_min=2, b
-000030d0: 6174 6368 5f6d 6178 3d32 352c 2062 6174  atch_max=25, bat
-000030e0: 6368 5f6f 7468 6572 3d31 2c20 6261 6c61  ch_other=1, bala
-000030f0: 6e63 653d 5472 7565 2c20 696d 6167 655f  nce=True, image_
-00003100: 7369 7a65 5f6d 696e 3d35 302c 2069 6d61  size_min=50, ima
-00003110: 6765 5f73 697a 655f 6d61 783d 3130 302c  ge_size_max=100,
-00003120: 2073 6869 6674 3d31 302c 206f 7074 5f6d   shift=10, opt_m
-00003130: 6178 5f6d 696e 5f70 6978 3d4e 6f6e 652c  ax_min_pix=None,
-00003140: 206f 7074 5f6d 6178 5f6d 6178 5f70 6978   opt_max_max_pix
-00003150: 3d4e 6f6e 652c 200a 2020 2020 2020 2020  =None, .        
-00003160: 6d61 736b 5f73 697a 653d 4e6f 6e65 2c20  mask_size=None, 
-00003170: 6e75 6d5f 6d61 736b 733d 4e6f 6e65 2c20  num_masks=None, 
-00003180: 736d 6f74 655f 7361 6d70 6c69 6e67 3d30  smote_sampling=0
-00003190: 2c20 626c 656e 645f 6d61 783d 302c 206e  , blend_max=0, n
-000031a0: 756d 5f69 6d61 6765 735f 746f 5f62 6c65  um_images_to_ble
-000031b0: 6e64 3d32 2c20 626c 656e 6469 6e67 5f66  nd=2, blending_f
-000031c0: 756e 633d 276d 6561 6e27 2c20 626c 656e  unc='mean', blen
-000031d0: 645f 6f74 6865 723d 312c 200a 2020 2020  d_other=1, .    
-000031e0: 2020 2020 736b 6577 5f61 6e67 6c65 3d30      skew_angle=0
-000031f0: 2c20 7a6f 6f6d 5f72 616e 6765 3d28 302e  , zoom_range=(0.
-00003200: 392c 312e 3129 2c20 6c69 6d69 745f 7365  9,1.1), limit_se
-00003210: 6172 6368 3d54 7275 652c 206d 6f6e 6974  arch=True, monit
-00003220: 6f72 313d 4e6f 6e65 2c20 6d6f 6e69 746f  or1=None, monito
-00003230: 7232 3d4e 6f6e 652c 206d 6f6e 6974 6f72  r2=None, monitor
-00003240: 315f 7468 7265 7368 3d4e 6f6e 652c 206d  1_thresh=None, m
-00003250: 6f6e 6974 6f72 325f 7468 7265 7368 3d4e  onitor2_thresh=N
-00003260: 6f6e 652c 2076 6572 626f 7365 3d30 293a  one, verbose=0):
-00003270: 0a0a 2020 2020 2020 2020 7365 6c66 2e70  ..        self.p
-00003280: 6f73 6974 6976 655f 636c 6173 7320 3d20  ositive_class = 
-00003290: 706f 7369 7469 7665 5f63 6c61 7373 0a20  positive_class. 
-000032a0: 2020 2020 2020 2073 656c 662e 6e65 6761         self.nega
-000032b0: 7469 7665 5f63 6c61 7373 203d 206e 6567  tive_class = neg
-000032c0: 6174 6976 655f 636c 6173 730a 2020 2020  ative_class.    
-000032d0: 2020 2020 7365 6c66 2e69 6d67 5f6e 756d      self.img_num
-000032e0: 5f63 6861 6e6e 656c 7320 3d20 696d 675f  _channels = img_
-000032f0: 6e75 6d5f 6368 616e 6e65 6c73 0a20 2020  num_channels.   
-00003300: 2020 2020 2073 656c 662e 6e6f 726d 616c       self.normal
-00003310: 697a 6520 3d20 6e6f 726d 616c 697a 6520  ize = normalize 
-00003320: 0a20 2020 2020 2020 2073 656c 662e 6d69  .        self.mi
-00003330: 6e5f 7069 7865 6c20 3d20 6d69 6e5f 7069  n_pixel = min_pi
-00003340: 7865 6c0a 2020 2020 2020 2020 7365 6c66  xel.        self
-00003350: 2e6d 6178 5f70 6978 656c 203d 206d 6178  .max_pixel = max
-00003360: 5f70 6978 656c 0a20 2020 2020 2020 2073  _pixel.        s
-00003370: 656c 662e 7661 6c5f 706f 7369 7469 7665  elf.val_positive
-00003380: 203d 2076 616c 5f70 6f73 6974 6976 650a   = val_positive.
-00003390: 2020 2020 2020 2020 7365 6c66 2e76 616c          self.val
-000033a0: 5f6e 6567 6174 6976 6520 3d20 7661 6c5f  _negative = val_
-000033b0: 6e65 6761 7469 7665 0a20 2020 2020 2020  negative.       
-000033c0: 2073 656c 662e 7465 7374 5f70 6f73 6974   self.test_posit
-000033d0: 6976 6520 3d20 7465 7374 5f70 6f73 6974  ive = test_posit
-000033e0: 6976 650a 2020 2020 2020 2020 7365 6c66  ive.        self
-000033f0: 2e74 6573 745f 6e65 6761 7469 7665 203d  .test_negative =
-00003400: 2074 6573 745f 6e65 6761 7469 7665 0a20   test_negative. 
-00003410: 2020 2020 2020 2073 656c 662e 6261 7463         self.batc
-00003420: 685f 7369 7a65 5f6d 696e 203d 2062 6174  h_size_min = bat
-00003430: 6368 5f73 697a 655f 6d69 6e0a 2020 2020  ch_size_min.    
-00003440: 2020 2020 7365 6c66 2e62 6174 6368 5f73      self.batch_s
-00003450: 697a 655f 6d61 7820 3d20 6261 7463 685f  ize_max = batch_
-00003460: 7369 7a65 5f6d 6178 0a20 2020 2020 2020  size_max.       
-00003470: 200a 2020 2020 2020 2020 7365 6c66 2e74   .        self.t
-00003480: 7261 696e 5f65 706f 6368 7320 3d20 7472  rain_epochs = tr
-00003490: 6169 6e5f 6570 6f63 6873 0a20 2020 2020  ain_epochs.     
-000034a0: 2020 2073 656c 662e 7061 7469 656e 6365     self.patience
-000034b0: 203d 2070 6174 6965 6e63 6520 0a20 2020   = patience .   
-000034c0: 2020 2020 2073 656c 662e 6f70 745f 6d6f       self.opt_mo
-000034d0: 6465 6c20 3d20 6f70 745f 6d6f 6465 6c20  del = opt_model 
-000034e0: 200a 2020 2020 2020 2020 7365 6c66 2e6f   .        self.o
-000034f0: 7074 5f61 7567 203d 206f 7074 5f61 7567  pt_aug = opt_aug
-00003500: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
-00003510: 7463 685f 6d69 6e20 3d20 6261 7463 685f  tch_min = batch_
-00003520: 6d69 6e20 0a20 2020 2020 2020 2073 656c  min .        sel
-00003530: 662e 6261 7463 685f 6d61 7820 3d20 6261  f.batch_max = ba
-00003540: 7463 685f 6d61 7820 0a20 2020 2020 2020  tch_max .       
-00003550: 2073 656c 662e 6261 7463 685f 6f74 6865   self.batch_othe
-00003560: 7220 3d20 6261 7463 685f 6f74 6865 720a  r = batch_other.
-00003570: 2020 2020 2020 2020 7365 6c66 2e69 6d61          self.ima
-00003580: 6765 5f73 697a 655f 6d69 6e20 3d20 696d  ge_size_min = im
-00003590: 6167 655f 7369 7a65 5f6d 696e 0a20 2020  age_size_min.   
-000035a0: 2020 2020 2073 656c 662e 696d 6167 655f       self.image_
-000035b0: 7369 7a65 5f6d 6178 203d 2069 6d61 6765  size_max = image
-000035c0: 5f73 697a 655f 6d61 780a 2020 2020 2020  _size_max.      
-000035d0: 2020 7365 6c66 2e62 616c 616e 6365 203d    self.balance =
-000035e0: 2062 616c 616e 6365 0a20 2020 2020 2020   balance.       
-000035f0: 2073 656c 662e 6f70 745f 6d61 785f 6d69   self.opt_max_mi
-00003600: 6e5f 7069 7820 3d20 6f70 745f 6d61 785f  n_pix = opt_max_
-00003610: 6d69 6e5f 7069 780a 2020 2020 2020 2020  min_pix.        
-00003620: 7365 6c66 2e6f 7074 5f6d 6178 5f6d 6178  self.opt_max_max
-00003630: 5f70 6978 203d 206f 7074 5f6d 6178 5f6d  _pix = opt_max_m
-00003640: 6178 5f70 6978 0a20 2020 2020 2020 2073  ax_pix.        s
-00003650: 656c 662e 6d65 7472 6963 203d 206d 6574  elf.metric = met
-00003660: 7269 6320 0a20 2020 2020 2020 2073 656c  ric .        sel
-00003670: 662e 6176 6572 6167 6520 3d20 6176 6572  f.average = aver
-00003680: 6167 650a 2020 2020 2020 2020 7365 6c66  age.        self
-00003690: 2e73 6869 6674 203d 2073 6869 6674 200a  .shift = shift .
-000036a0: 2020 2020 2020 2020 7365 6c66 2e6f 7074          self.opt
-000036b0: 5f63 7620 3d20 6f70 745f 6376 0a20 2020  _cv = opt_cv.   
-000036c0: 2020 2020 2073 656c 662e 7665 7262 6f73       self.verbos
-000036d0: 6520 3d20 7665 7262 6f73 650a 2020 2020  e = verbose.    
-000036e0: 2020 2020 7365 6c66 2e6d 6173 6b5f 7369      self.mask_si
-000036f0: 7a65 203d 206d 6173 6b5f 7369 7a65 0a20  ze = mask_size. 
-00003700: 2020 2020 2020 2073 656c 662e 6e75 6d5f         self.num_
-00003710: 6d61 736b 7320 3d20 6e75 6d5f 6d61 736b  masks = num_mask
-00003720: 730a 2020 2020 2020 2020 7365 6c66 2e6c  s.        self.l
-00003730: 696d 6974 5f73 6561 7263 6820 3d20 6c69  imit_search = li
-00003740: 6d69 745f 7365 6172 6368 0a20 2020 2020  mit_search.     
-00003750: 2020 2073 656c 662e 636c 6620 3d20 636c     self.clf = cl
-00003760: 660a 0a20 2020 2020 2020 2073 656c 662e  f..        self.
-00003770: 6d6f 6e69 746f 7231 203d 206d 6f6e 6974  monitor1 = monit
-00003780: 6f72 310a 2020 2020 2020 2020 7365 6c66  or1.        self
-00003790: 2e6d 6f6e 6974 6f72 3220 3d20 6d6f 6e69  .monitor2 = moni
-000037a0: 746f 7232 0a20 2020 2020 2020 2073 656c  tor2.        sel
-000037b0: 662e 6d6f 6e69 746f 7231 5f74 6872 6573  f.monitor1_thres
-000037c0: 6820 3d20 6d6f 6e69 746f 7231 5f74 6872  h = monitor1_thr
-000037d0: 6573 680a 2020 2020 2020 2020 7365 6c66  esh.        self
-000037e0: 2e6d 6f6e 6974 6f72 325f 7468 7265 7368  .monitor2_thresh
-000037f0: 203d 206d 6f6e 6974 6f72 325f 7468 7265   = monitor2_thre
-00003800: 7368 0a20 2020 2020 2020 2073 656c 662e  sh.        self.
-00003810: 736d 6f74 655f 7361 6d70 6c69 6e67 203d  smote_sampling =
-00003820: 2073 6d6f 7465 5f73 616d 706c 696e 670a   smote_sampling.
-00003830: 2020 2020 2020 2020 7365 6c66 2e62 6c65          self.ble
-00003840: 6e64 5f6d 6178 203d 2062 6c65 6e64 5f6d  nd_max = blend_m
-00003850: 6178 0a20 2020 2020 2020 2073 656c 662e  ax.        self.
-00003860: 6e75 6d5f 696d 6167 6573 5f74 6f5f 626c  num_images_to_bl
-00003870: 656e 6420 3d20 6e75 6d5f 696d 6167 6573  end = num_images
-00003880: 5f74 6f5f 626c 656e 640a 2020 2020 2020  _to_blend.      
-00003890: 2020 7365 6c66 2e62 6c65 6e64 696e 675f    self.blending_
-000038a0: 6675 6e63 203d 2062 6c65 6e64 696e 675f  func = blending_
-000038b0: 6675 6e63 0a20 2020 2020 2020 2073 656c  func.        sel
-000038c0: 662e 626c 656e 645f 6f74 6865 7220 3d20  f.blend_other = 
-000038d0: 626c 656e 645f 6f74 6865 720a 2020 2020  blend_other.    
-000038e0: 2020 2020 7365 6c66 2e7a 6f6f 6d5f 7261      self.zoom_ra
-000038f0: 6e67 6520 3d20 7a6f 6f6d 5f72 616e 6765  nge = zoom_range
-00003900: 0a20 2020 2020 2020 2073 656c 662e 736b  .        self.sk
-00003910: 6577 5f61 6e67 6c65 203d 2073 6b65 775f  ew_angle = skew_
-00003920: 616e 676c 650a 0a20 2020 2020 2020 2069  angle..        i
-00003930: 6620 2761 6c6c 2720 6e6f 7420 696e 2073  f 'all' not in s
-00003940: 656c 662e 6d65 7472 6963 2061 6e64 2027  elf.metric and '
-00003950: 6c6f 7373 2720 6e6f 7420 696e 2073 656c  loss' not in sel
-00003960: 662e 6d65 7472 6963 2061 6e64 2027 6631  f.metric and 'f1
-00003970: 5f73 636f 7265 2720 6e6f 7420 696e 2073  _score' not in s
-00003980: 656c 662e 6d65 7472 6963 2061 6e64 2027  elf.metric and '
-00003990: 6269 6e61 7279 5f61 6363 7572 6163 7927  binary_accuracy'
-000039a0: 206e 6f74 2069 6e20 7365 6c66 2e6d 6574   not in self.met
-000039b0: 7269 633a 0a20 2020 2020 2020 2020 2020  ric:.           
-000039c0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-000039d0: 7228 2249 6e76 616c 6964 206d 6574 7269  r("Invalid metri
-000039e0: 6320 696e 7075 742c 206f 7074 696f 6e73  c input, options
-000039f0: 2061 7265 3a20 276c 6f73 7327 2c20 2762   are: 'loss', 'b
-00003a00: 696e 6172 795f 6163 6375 7261 6379 272c  inary_accuracy',
-00003a10: 2027 6631 5f73 636f 7265 272c 206f 7220   'f1_score', or 
-00003a20: 2761 6c6c 272c 2061 6e64 2074 6865 2076  'all', and the v
-00003a30: 616c 6964 6174 696f 6e20 6571 7569 7661  alidation equiva
-00003a40: 6c65 6e74 7320 2861 6464 2076 616c 5f20  lents (add val_ 
-00003a50: 6174 2074 6865 2062 6567 696e 6e69 6e67  at the beginning
-00003a60: 292e 2229 0a20 2020 2020 2020 200a 2020  ).").        .  
-00003a70: 2020 2020 2020 6966 2073 656c 662e 6d65        if self.me
-00003a80: 7472 6963 203d 3d20 2776 616c 5f6c 6f73  tric == 'val_los
-00003a90: 7327 206f 7220 7365 6c66 2e6d 6574 7269  s' or self.metri
-00003aa0: 6320 3d3d 2027 7661 6c5f 6269 6e61 7279  c == 'val_binary
-00003ab0: 5f61 6363 7572 6163 7927 3a0a 2020 2020  _accuracy':.    
-00003ac0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00003ad0: 7661 6c5f 706f 7369 7469 7665 2069 7320  val_positive is 
-00003ae0: 4e6f 6e65 2061 6e64 2073 656c 662e 7661  None and self.va
-00003af0: 6c5f 6e65 6761 7469 7665 2069 7320 4e6f  l_negative is No
-00003b00: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00003b10: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
-00003b20: 7272 6f72 2827 4e6f 2076 616c 6964 6174  rror('No validat
-00003b30: 696f 6e20 6461 7461 2069 6e70 7574 2c20  ion data input, 
-00003b40: 6368 616e 6765 2074 6865 206d 6574 7269  change the metri
-00003b50: 6320 746f 2065 6974 6865 7220 226c 6f73  c to either "los
-00003b60: 7322 2c20 2262 696e 6172 795f 6163 6375  s", "binary_accu
-00003b70: 7261 6379 222c 2022 6631 5f73 636f 7265  racy", "f1_score
-00003b80: 222c 206f 7220 2261 6c6c 222e 2729 0a0a  ", or "all".')..
-00003b90: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00003ba0: 6f70 745f 6d61 785f 6d69 6e5f 7069 7820  opt_max_min_pix 
-00003bb0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-00003bc0: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-00003bd0: 2e6f 7074 5f6d 6178 5f6d 6178 5f70 6978  .opt_max_max_pix
-00003be0: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
-00003bf0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00003c00: 5661 6c75 6545 7272 6f72 2827 546f 206f  ValueError('To o
-00003c10: 7074 696d 697a 6520 6d69 6e2f 6d61 7820  ptimize min/max 
-00003c20: 6e6f 726d 616c 697a 6174 696f 6e20 7069  normalization pi
-00003c30: 7865 6c20 7661 6c75 652c 2062 6f74 6820  xel value, both 
-00003c40: 6f70 745f 6d69 6e5f 7069 7820 616e 6420  opt_min_pix and 
-00003c50: 6f70 745f 6d61 785f 7069 7820 6d75 7374  opt_max_pix must
-00003c60: 2062 6520 696e 7075 7427 290a 0a20 2020   be input')..   
-00003c70: 2020 2020 2069 6620 7365 6c66 2e6f 7074       if self.opt
-00003c80: 5f6d 6178 5f6d 6178 5f70 6978 2069 7320  _max_max_pix is 
-00003c90: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-00003ca0: 2020 2020 2020 6966 2073 656c 662e 6f70        if self.op
-00003cb0: 745f 6d61 785f 6d69 6e5f 7069 7820 6973  t_max_min_pix is
-00003cc0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-00003cd0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-00003ce0: 7565 4572 726f 7228 2754 6f20 6f70 7469  ueError('To opti
-00003cf0: 6d69 7a65 206d 696e 2f6d 6178 206e 6f72  mize min/max nor
-00003d00: 6d61 6c69 7a61 7469 6f6e 2070 6978 656c  malization pixel
-00003d10: 2076 616c 7565 2c20 626f 7468 206f 7074   value, both opt
-00003d20: 5f6d 696e 5f70 6978 2061 6e64 206f 7074  _min_pix and opt
-00003d30: 5f6d 6178 5f70 6978 206d 7573 7420 6265  _max_pix must be
-00003d40: 2069 6e70 7574 2729 0a0a 2020 2020 2020   input')..      
-00003d50: 2020 6966 2073 656c 662e 6261 6c61 6e63    if self.balanc
-00003d60: 6520 616e 6420 7365 6c66 2e73 6d6f 7465  e and self.smote
-00003d70: 5f73 616d 706c 696e 6720 3e20 303a 0a20  _sampling > 0:. 
-00003d80: 2020 2020 2020 2020 2020 2070 7269 6e74             print
-00003d90: 2827 5741 524e 494e 473a 2062 616c 616e  ('WARNING: balan
-00003da0: 6365 3d54 7275 6520 6275 7420 534d 4f54  ce=True but SMOT
-00003db0: 4520 7361 6d70 6c69 6e67 2077 696c 6c20  E sampling will 
-00003dc0: 6e6f 7420 6265 2061 7070 6c69 6564 2069  not be applied i
-00003dd0: 6620 7468 6520 636c 6173 7365 7320 6172  f the classes ar
-00003de0: 6520 6261 6c61 6e63 6564 2e27 290a 0a20  e balanced.').. 
-00003df0: 2020 2064 6566 205f 5f63 616c 6c5f 5f28     def __call__(
-00003e00: 7365 6c66 2c20 7472 6961 6c29 3a0a 0a20  self, trial):.. 
-00003e10: 2020 2020 2020 2069 6620 7365 6c66 2e6f         if self.o
-00003e20: 7074 5f61 7567 3a0a 2020 2020 2020 2020  pt_aug:.        
-00003e30: 2020 2020 6966 2073 656c 662e 696d 675f      if self.img_
-00003e40: 6e75 6d5f 6368 616e 6e65 6c73 203d 3d20  num_channels == 
-00003e50: 313a 0a20 2020 2020 2020 2020 2020 2020  1:.             
-00003e60: 2020 2063 6861 6e6e 656c 312c 2063 6861     channel1, cha
-00003e70: 6e6e 656c 322c 2063 6861 6e6e 656c 3320  nnel2, channel3 
-00003e80: 3d20 636f 7079 2e64 6565 7063 6f70 7928  = copy.deepcopy(
-00003e90: 7365 6c66 2e70 6f73 6974 6976 655f 636c  self.positive_cl
-00003ea0: 6173 7329 2c20 4e6f 6e65 2c20 4e6f 6e65  ass), None, None
-00003eb0: 200a 2020 2020 2020 2020 2020 2020 656c   .            el
-00003ec0: 6966 2073 656c 662e 696d 675f 6e75 6d5f  if self.img_num_
-00003ed0: 6368 616e 6e65 6c73 203d 3d20 323a 0a20  channels == 2:. 
-00003ee0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00003ef0: 6861 6e6e 656c 312c 2063 6861 6e6e 656c  hannel1, channel
-00003f00: 322c 2063 6861 6e6e 656c 3320 3d20 636f  2, channel3 = co
-00003f10: 7079 2e64 6565 7063 6f70 7928 7365 6c66  py.deepcopy(self
-00003f20: 2e70 6f73 6974 6976 655f 636c 6173 735b  .positive_class[
-00003f30: 3a2c 3a2c 3a2c 305d 292c 2063 6f70 792e  :,:,:,0]), copy.
-00003f40: 6465 6570 636f 7079 2873 656c 662e 706f  deepcopy(self.po
-00003f50: 7369 7469 7665 5f63 6c61 7373 5b3a 2c3a  sitive_class[:,:
-00003f60: 2c3a 2c31 5d29 2c20 4e6f 6e65 200a 2020  ,:,1]), None .  
-00003f70: 2020 2020 2020 2020 2020 656c 6966 2073            elif s
-00003f80: 656c 662e 696d 675f 6e75 6d5f 6368 616e  elf.img_num_chan
-00003f90: 6e65 6c73 203d 3d20 333a 0a20 2020 2020  nels == 3:.     
-00003fa0: 2020 2020 2020 2020 2020 2063 6861 6e6e             chann
-00003fb0: 656c 312c 2063 6861 6e6e 656c 322c 2063  el1, channel2, c
-00003fc0: 6861 6e6e 656c 3320 3d20 636f 7079 2e64  hannel3 = copy.d
-00003fd0: 6565 7063 6f70 7928 7365 6c66 2e70 6f73  eepcopy(self.pos
-00003fe0: 6974 6976 655f 636c 6173 735b 3a2c 3a2c  itive_class[:,:,
-00003ff0: 3a2c 305d 292c 2063 6f70 792e 6465 6570  :,0]), copy.deep
-00004000: 636f 7079 2873 656c 662e 706f 7369 7469  copy(self.positi
-00004010: 7665 5f63 6c61 7373 5b3a 2c3a 2c3a 2c31  ve_class[:,:,:,1
-00004020: 5d29 2c20 636f 7079 2e64 6565 7063 6f70  ]), copy.deepcop
-00004030: 7928 7365 6c66 2e70 6f73 6974 6976 655f  y(self.positive_
-00004040: 636c 6173 735b 3a2c 3a2c 3a2c 325d 290a  class[:,:,:,2]).
-00004050: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00004060: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00004070: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-00004080: 6f72 2827 4f6e 6c79 2074 6872 6565 2066  or('Only three f
-00004090: 696c 7465 7273 2061 7265 2073 7570 706f  ilters are suppo
-000040a0: 7274 6564 2127 290a 0a20 2020 2020 2020  rted!')..       
-000040b0: 2069 6620 7365 6c66 2e6f 7074 5f61 7567   if self.opt_aug
-000040c0: 3a0a 2020 2020 2020 2020 2020 2020 726f  :.            ro
-000040d0: 7461 7469 6f6e 203d 2068 6f72 697a 6f6e  tation = horizon
-000040e0: 7461 6c20 3d20 7665 7274 6963 616c 203d  tal = vertical =
-000040f0: 2054 7275 6520 0a20 2020 2020 2020 2020   True .         
-00004100: 2020 206e 756d 5f61 7567 203d 2074 7269     num_aug = tri
-00004110: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-00004120: 6e75 6d5f 6175 6727 2c20 7365 6c66 2e62  num_aug', self.b
-00004130: 6174 6368 5f6d 696e 2c20 7365 6c66 2e62  atch_min, self.b
-00004140: 6174 6368 5f6d 6178 2c20 7374 6570 3d31  atch_max, step=1
-00004150: 290a 2020 2020 2020 2020 2020 2020 626c  ).            bl
-00004160: 656e 645f 6d75 6c74 6970 6c69 6572 203d  end_multiplier =
-00004170: 2074 7269 616c 2e73 7567 6765 7374 5f66   trial.suggest_f
-00004180: 6c6f 6174 2827 626c 656e 645f 6d75 6c74  loat('blend_mult
-00004190: 6970 6c69 6572 272c 2031 2e30 2c20 7365  iplier', 1.0, se
-000041a0: 6c66 2e62 6c65 6e64 5f6d 6178 2c20 7374  lf.blend_max, st
-000041b0: 6570 3d30 2e30 3529 2069 6620 7365 6c66  ep=0.05) if self
-000041c0: 2e62 6c65 6e64 5f6d 6178 203e 3d20 312e  .blend_max >= 1.
-000041d0: 3120 656c 7365 2030 0a20 2020 2020 2020  1 else 0.       
-000041e0: 2020 2020 2073 6b65 775f 616e 676c 6520       skew_angle 
-000041f0: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
-00004200: 696e 7428 2773 6b65 775f 616e 676c 6527  int('skew_angle'
-00004210: 2c20 302c 2073 656c 662e 736b 6577 5f61  , 0, self.skew_a
-00004220: 6e67 6c65 2c20 7374 6570 3d31 2920 6966  ngle, step=1) if
-00004230: 2073 656c 662e 736b 6577 5f61 6e67 6c65   self.skew_angle
-00004240: 203e 2030 2065 6c73 6520 300a 2020 2020   > 0 else 0.    
-00004250: 2020 2020 2020 2020 696d 6167 655f 7369          image_si
-00004260: 7a65 203d 2074 7269 616c 2e73 7567 6765  ze = trial.sugge
-00004270: 7374 5f69 6e74 2827 696d 6167 655f 7369  st_int('image_si
-00004280: 7a65 272c 2073 656c 662e 696d 6167 655f  ze', self.image_
-00004290: 7369 7a65 5f6d 696e 2c20 7365 6c66 2e69  size_min, self.i
-000042a0: 6d61 6765 5f73 697a 655f 6d61 782c 2073  mage_size_max, s
-000042b0: 7465 703d 3129 0a0a 2020 2020 2020 2020  tep=1)..        
-000042c0: 2020 2020 6175 676d 656e 7465 645f 696d      augmented_im
-000042d0: 6167 6573 203d 2061 7567 6d65 6e74 6174  ages = augmentat
-000042e0: 696f 6e28 6368 616e 6e65 6c31 3d63 6861  ion(channel1=cha
-000042f0: 6e6e 656c 312c 2063 6861 6e6e 656c 323d  nnel1, channel2=
-00004300: 6368 616e 6e65 6c32 2c20 6368 616e 6e65  channel2, channe
-00004310: 6c33 3d63 6861 6e6e 656c 332c 2062 6174  l3=channel3, bat
-00004320: 6368 3d6e 756d 5f61 7567 2c20 0a20 2020  ch=num_aug, .   
-00004330: 2020 2020 2020 2020 2020 2020 2077 6964               wid
-00004340: 7468 5f73 6869 6674 3d73 656c 662e 7368  th_shift=self.sh
-00004350: 6966 742c 2068 6569 6768 745f 7368 6966  ift, height_shif
-00004360: 743d 7365 6c66 2e73 6869 6674 2c20 686f  t=self.shift, ho
-00004370: 7269 7a6f 6e74 616c 3d68 6f72 697a 6f6e  rizontal=horizon
-00004380: 7461 6c2c 2076 6572 7469 6361 6c3d 7665  tal, vertical=ve
-00004390: 7274 6963 616c 2c20 726f 7461 7469 6f6e  rtical, rotation
-000043a0: 3d72 6f74 6174 696f 6e2c 200a 2020 2020  =rotation, .    
-000043b0: 2020 2020 2020 2020 2020 2020 696d 6167              imag
-000043c0: 655f 7369 7a65 3d69 6d61 6765 5f73 697a  e_size=image_siz
-000043d0: 652c 206d 6173 6b5f 7369 7a65 3d73 656c  e, mask_size=sel
-000043e0: 662e 6d61 736b 5f73 697a 652c 206e 756d  f.mask_size, num
-000043f0: 5f6d 6173 6b73 3d73 656c 662e 6e75 6d5f  _masks=self.num_
-00004400: 6d61 736b 732c 2062 6c65 6e64 5f6d 756c  masks, blend_mul
-00004410: 7469 706c 6965 723d 626c 656e 645f 6d75  tiplier=blend_mu
-00004420: 6c74 6970 6c69 6572 2c20 0a20 2020 2020  ltiplier, .     
-00004430: 2020 2020 2020 2020 2020 2062 6c65 6e64             blend
-00004440: 696e 675f 6675 6e63 3d73 656c 662e 626c  ing_func=self.bl
-00004450: 656e 6469 6e67 5f66 756e 632c 206e 756d  ending_func, num
-00004460: 5f69 6d61 6765 735f 746f 5f62 6c65 6e64  _images_to_blend
-00004470: 3d73 656c 662e 6e75 6d5f 696d 6167 6573  =self.num_images
-00004480: 5f74 6f5f 626c 656e 642c 207a 6f6f 6d5f  _to_blend, zoom_
-00004490: 7261 6e67 653d 7365 6c66 2e7a 6f6f 6d5f  range=self.zoom_
-000044a0: 7261 6e67 652c 2073 6b65 775f 616e 676c  range, skew_angl
-000044b0: 653d 736b 6577 5f61 6e67 6c65 290a 0a20  e=skew_angle).. 
-000044c0: 2020 2020 2020 2020 2020 2023 436f 6e63             #Conc
-000044d0: 6174 2063 6861 6e6e 656c 7320 7369 6e63  at channels sinc
-000044e0: 6520 6175 676d 656e 7461 7469 6f6e 2066  e augmentation f
-000044f0: 756e 6374 696f 6e20 7265 7475 726e 7320  unction returns 
-00004500: 616e 206f 7574 7075 7420 666f 7220 6561  an output for ea
-00004510: 6368 2066 696c 7465 722c 2065 2e67 2e20  ch filter, e.g. 
-00004520: 3320 6f75 7470 7574 7320 666f 7220 5247  3 outputs for RG
-00004530: 420a 2020 2020 2020 2020 2020 2020 6966  B.            if
-00004540: 2073 656c 662e 696d 675f 6e75 6d5f 6368   self.img_num_ch
-00004550: 616e 6e65 6c73 203e 2031 3a0a 2020 2020  annels > 1:.    
-00004560: 2020 2020 2020 2020 2020 2020 636c 6173              clas
-00004570: 735f 313d 5b5d 0a20 2020 2020 2020 2020  s_1=[].         
-00004580: 2020 2020 2020 2069 6620 7365 6c66 2e69         if self.i
-00004590: 6d67 5f6e 756d 5f63 6861 6e6e 656c 7320  mg_num_channels 
-000045a0: 3d3d 2032 3a0a 2020 2020 2020 2020 2020  == 2:.          
-000045b0: 2020 2020 2020 2020 2020 666f 7220 6920            for i 
-000045c0: 696e 2072 616e 6765 286c 656e 2861 7567  in range(len(aug
-000045d0: 6d65 6e74 6564 5f69 6d61 6765 735b 305d  mented_images[0]
-000045e0: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
-000045f0: 2020 2020 2020 2020 2020 2020 636c 6173              clas
-00004600: 735f 312e 6170 7065 6e64 2864 6174 615f  s_1.append(data_
-00004610: 7072 6f63 6573 7369 6e67 2e63 6f6e 6361  processing.conca
-00004620: 745f 6368 616e 6e65 6c73 2861 7567 6d65  t_channels(augme
-00004630: 6e74 6564 5f69 6d61 6765 735b 305d 5b69  nted_images[0][i
-00004640: 5d2c 2061 7567 6d65 6e74 6564 5f69 6d61  ], augmented_ima
-00004650: 6765 735b 315d 5b69 5d29 290a 2020 2020  ges[1][i])).    
-00004660: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00004670: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00004680: 2020 2020 2020 666f 7220 6920 696e 2072        for i in r
-00004690: 616e 6765 286c 656e 2861 7567 6d65 6e74  ange(len(augment
-000046a0: 6564 5f69 6d61 6765 735b 305d 2929 3a0a  ed_images[0])):.
-000046b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000046c0: 2020 2020 2020 2020 636c 6173 735f 312e          class_1.
-000046d0: 6170 7065 6e64 2864 6174 615f 7072 6f63  append(data_proc
-000046e0: 6573 7369 6e67 2e63 6f6e 6361 745f 6368  essing.concat_ch
-000046f0: 616e 6e65 6c73 2861 7567 6d65 6e74 6564  annels(augmented
-00004700: 5f69 6d61 6765 735b 305d 5b69 5d2c 2061  _images[0][i], a
-00004710: 7567 6d65 6e74 6564 5f69 6d61 6765 735b  ugmented_images[
-00004720: 315d 5b69 5d2c 2061 7567 6d65 6e74 6564  1][i], augmented
-00004730: 5f69 6d61 6765 735b 325d 5b69 5d29 290a  _images[2][i])).
-00004740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004750: 636c 6173 735f 3120 3d20 6e70 2e61 7272  class_1 = np.arr
-00004760: 6179 2863 6c61 7373 5f31 290a 2020 2020  ay(class_1).    
-00004770: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00004780: 2020 2020 2020 2020 2020 2020 2020 636c                cl
-00004790: 6173 735f 3120 3d20 6175 676d 656e 7465  ass_1 = augmente
-000047a0: 645f 696d 6167 6573 0a0a 2020 2020 2020  d_images..      
-000047b0: 2020 2020 2020 2350 6572 666f 726d 2073        #Perform s
-000047c0: 616d 6520 6175 676d 656e 7461 7469 6f6e  ame augmentation
-000047d0: 2074 6563 686e 6971 7565 7320 6f6e 206e   techniques on n
-000047e0: 6567 6174 6976 6520 636c 6173 7320 6461  egative class da
-000047f0: 7461 2066 6f72 2062 616c 616e 6365 2062  ta for balance b
-00004800: 7574 2075 7365 2062 6174 6368 3d62 6174  ut use batch=bat
-00004810: 6368 5f6f 7468 6572 2c20 6e75 6d5f 696d  ch_other, num_im
-00004820: 6167 6573 5f74 6f5f 626c 656e 643d 7365  ages_to_blend=se
-00004830: 6c66 2e6e 756d 5f69 6d61 6765 735f 746f  lf.num_images_to
-00004840: 5f62 6c65 6e64 200a 2020 2020 2020 2020  _blend .        
-00004850: 2020 2020 2354 6869 7320 6973 2064 6f6e      #This is don
-00004860: 6520 736f 2074 6861 7420 7468 6520 7472  e so that the tr
-00004870: 6169 6e69 6e67 2064 6174 6120 616c 736f  aining data also
-00004880: 2069 6e63 6c75 6465 7320 7468 6520 7361   includes the sa
-00004890: 6d65 2061 7567 6d65 6e74 6174 696f 6e20  me augmentation 
-000048a0: 7465 6368 6e69 7175 6573 2c20 6966 2063  techniques, if c
-000048b0: 6f6e 6669 6775 7265 642e 0a20 2020 2020  onfigured..     
-000048c0: 2020 2020 2020 2069 6620 7365 6c66 2e69         if self.i
-000048d0: 6d67 5f6e 756d 5f63 6861 6e6e 656c 7320  mg_num_channels 
-000048e0: 3d3d 2031 3a0a 2020 2020 2020 2020 2020  == 1:.          
-000048f0: 2020 2020 2020 6368 616e 6e65 6c31 2c20        channel1, 
-00004900: 6368 616e 6e65 6c32 2c20 6368 616e 6e65  channel2, channe
-00004910: 6c33 203d 2063 6f70 792e 6465 6570 636f  l3 = copy.deepco
-00004920: 7079 2873 656c 662e 6e65 6761 7469 7665  py(self.negative
-00004930: 5f63 6c61 7373 292c 204e 6f6e 652c 204e  _class), None, N
-00004940: 6f6e 6520 0a20 2020 2020 2020 2020 2020  one .           
-00004950: 2065 6c69 6620 7365 6c66 2e69 6d67 5f6e   elif self.img_n
-00004960: 756d 5f63 6861 6e6e 656c 7320 3d3d 2032  um_channels == 2
-00004970: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00004980: 2020 6368 616e 6e65 6c31 2c20 6368 616e    channel1, chan
-00004990: 6e65 6c32 2c20 6368 616e 6e65 6c33 203d  nel2, channel3 =
-000049a0: 2063 6f70 792e 6465 6570 636f 7079 2873   copy.deepcopy(s
-000049b0: 656c 662e 6e65 6761 7469 7665 5f63 6c61  elf.negative_cla
-000049c0: 7373 5b3a 2c3a 2c3a 2c30 5d29 2c20 636f  ss[:,:,:,0]), co
-000049d0: 7079 2e64 6565 7063 6f70 7928 7365 6c66  py.deepcopy(self
-000049e0: 2e6e 6567 6174 6976 655f 636c 6173 735b  .negative_class[
-000049f0: 3a2c 3a2c 3a2c 315d 292c 204e 6f6e 6520  :,:,:,1]), None 
-00004a00: 0a20 2020 2020 2020 2020 2020 2065 6c69  .            eli
-00004a10: 6620 7365 6c66 2e69 6d67 5f6e 756d 5f63  f self.img_num_c
-00004a20: 6861 6e6e 656c 7320 3d3d 2033 3a0a 2020  hannels == 3:.  
-00004a30: 2020 2020 2020 2020 2020 2020 2020 6368                ch
-00004a40: 616e 6e65 6c31 2c20 6368 616e 6e65 6c32  annel1, channel2
-00004a50: 2c20 6368 616e 6e65 6c33 203d 2063 6f70  , channel3 = cop
-00004a60: 792e 6465 6570 636f 7079 2873 656c 662e  y.deepcopy(self.
-00004a70: 6e65 6761 7469 7665 5f63 6c61 7373 5b3a  negative_class[:
-00004a80: 2c3a 2c3a 2c30 5d29 2c20 636f 7079 2e64  ,:,:,0]), copy.d
-00004a90: 6565 7063 6f70 7928 7365 6c66 2e6e 6567  eepcopy(self.neg
-00004aa0: 6174 6976 655f 636c 6173 735b 3a2c 3a2c  ative_class[:,:,
-00004ab0: 3a2c 315d 292c 2063 6f70 792e 6465 6570  :,1]), copy.deep
-00004ac0: 636f 7079 2873 656c 662e 6e65 6761 7469  copy(self.negati
-00004ad0: 7665 5f63 6c61 7373 5b3a 2c3a 2c3a 2c32  ve_class[:,:,:,2
-00004ae0: 5d29 0a20 2020 2020 2020 2020 2020 200a  ]).            .
-00004af0: 2020 2020 2020 2020 2020 2020 6175 676d              augm
-00004b00: 656e 7465 645f 696d 6167 6573 5f6e 6567  ented_images_neg
-00004b10: 6174 6976 6520 3d20 6175 676d 656e 7461  ative = augmenta
-00004b20: 7469 6f6e 2863 6861 6e6e 656c 313d 6368  tion(channel1=ch
-00004b30: 616e 6e65 6c31 2c20 6368 616e 6e65 6c32  annel1, channel2
-00004b40: 3d63 6861 6e6e 656c 322c 2063 6861 6e6e  =channel2, chann
-00004b50: 656c 333d 6368 616e 6e65 6c33 2c20 6261  el3=channel3, ba
-00004b60: 7463 683d 7365 6c66 2e62 6174 6368 5f6f  tch=self.batch_o
-00004b70: 7468 6572 2c20 0a20 2020 2020 2020 2020  ther, .         
-00004b80: 2020 2020 2020 2077 6964 7468 5f73 6869         width_shi
-00004b90: 6674 3d73 656c 662e 7368 6966 742c 2068  ft=self.shift, h
-00004ba0: 6569 6768 745f 7368 6966 743d 7365 6c66  eight_shift=self
-00004bb0: 2e73 6869 6674 2c20 686f 7269 7a6f 6e74  .shift, horizont
-00004bc0: 616c 3d68 6f72 697a 6f6e 7461 6c2c 2076  al=horizontal, v
-00004bd0: 6572 7469 6361 6c3d 7665 7274 6963 616c  ertical=vertical
-00004be0: 2c20 726f 7461 7469 6f6e 3d72 6f74 6174  , rotation=rotat
-00004bf0: 696f 6e2c 200a 2020 2020 2020 2020 2020  ion, .          
-00004c00: 2020 2020 2020 696d 6167 655f 7369 7a65        image_size
-00004c10: 3d69 6d61 6765 5f73 697a 652c 206d 6173  =image_size, mas
-00004c20: 6b5f 7369 7a65 3d73 656c 662e 6d61 736b  k_size=self.mask
-00004c30: 5f73 697a 652c 206e 756d 5f6d 6173 6b73  _size, num_masks
-00004c40: 3d73 656c 662e 6e75 6d5f 6d61 736b 732c  =self.num_masks,
-00004c50: 2062 6c65 6e64 5f6d 756c 7469 706c 6965   blend_multiplie
-00004c60: 723d 7365 6c66 2e62 6c65 6e64 5f6f 7468  r=self.blend_oth
-00004c70: 6572 2c20 0a20 2020 2020 2020 2020 2020  er, .           
-00004c80: 2020 2020 2062 6c65 6e64 696e 675f 6675       blending_fu
-00004c90: 6e63 3d73 656c 662e 626c 656e 6469 6e67  nc=self.blending
-00004ca0: 5f66 756e 632c 206e 756d 5f69 6d61 6765  _func, num_image
-00004cb0: 735f 746f 5f62 6c65 6e64 3d73 656c 662e  s_to_blend=self.
-00004cc0: 6e75 6d5f 696d 6167 6573 5f74 6f5f 626c  num_images_to_bl
-00004cd0: 656e 642c 207a 6f6f 6d5f 7261 6e67 653d  end, zoom_range=
-00004ce0: 7365 6c66 2e7a 6f6f 6d5f 7261 6e67 652c  self.zoom_range,
-00004cf0: 2073 6b65 775f 616e 676c 653d 736b 6577   skew_angle=skew
-00004d00: 5f61 6e67 6c65 290a 0a20 2020 2020 2020  _angle)..       
-00004d10: 2020 2020 2023 5468 6520 6175 676d 656e       #The augmen
-00004d20: 7461 7469 6f6e 2072 6f75 7469 6e65 2072  tation routine r
-00004d30: 6574 7572 6e73 2061 6e20 6f75 7470 7574  eturns an output
-00004d40: 2066 6f72 2065 6163 6820 6669 6c74 6572   for each filter
-00004d50: 2c20 652e 672e 2033 206f 7574 7075 7473  , e.g. 3 outputs
-00004d60: 2066 6f72 2052 4742 0a20 2020 2020 2020   for RGB.       
-00004d70: 2020 2020 2069 6620 7365 6c66 2e69 6d67       if self.img
-00004d80: 5f6e 756d 5f63 6861 6e6e 656c 7320 3e20  _num_channels > 
-00004d90: 313a 0a20 2020 2020 2020 2020 2020 2020  1:.             
-00004da0: 2020 2063 6c61 7373 5f32 3d5b 5d0a 2020     class_2=[].  
-00004db0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00004dc0: 2073 656c 662e 696d 675f 6e75 6d5f 6368   self.img_num_ch
-00004dd0: 616e 6e65 6c73 203d 3d20 323a 0a20 2020  annels == 2:.   
-00004de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004df0: 2066 6f72 2069 2069 6e20 7261 6e67 6528   for i in range(
-00004e00: 6c65 6e28 6175 676d 656e 7465 645f 696d  len(augmented_im
-00004e10: 6167 6573 5f6e 6567 6174 6976 655b 305d  ages_negative[0]
-00004e20: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
-00004e30: 2020 2020 2020 2020 2020 2020 636c 6173              clas
-00004e40: 735f 322e 6170 7065 6e64 2864 6174 615f  s_2.append(data_
-00004e50: 7072 6f63 6573 7369 6e67 2e63 6f6e 6361  processing.conca
-00004e60: 745f 6368 616e 6e65 6c73 2861 7567 6d65  t_channels(augme
-00004e70: 6e74 6564 5f69 6d61 6765 735f 6e65 6761  nted_images_nega
-00004e80: 7469 7665 5b30 5d5b 695d 2c20 6175 676d  tive[0][i], augm
-00004e90: 656e 7465 645f 696d 6167 6573 5f6e 6567  ented_images_neg
-00004ea0: 6174 6976 655b 315d 5b69 5d29 290a 2020  ative[1][i])).  
-00004eb0: 2020 2020 2020 2020 2020 2020 2020 656c                el
-00004ec0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00004ed0: 2020 2020 2020 2020 666f 7220 6920 696e          for i in
-00004ee0: 2072 616e 6765 286c 656e 2861 7567 6d65   range(len(augme
-00004ef0: 6e74 6564 5f69 6d61 6765 735f 6e65 6761  nted_images_nega
-00004f00: 7469 7665 5b30 5d29 293a 0a20 2020 2020  tive[0])):.     
-00004f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004f20: 2020 2063 6c61 7373 5f32 2e61 7070 656e     class_2.appen
-00004f30: 6428 6461 7461 5f70 726f 6365 7373 696e  d(data_processin
-00004f40: 672e 636f 6e63 6174 5f63 6861 6e6e 656c  g.concat_channel
-00004f50: 7328 6175 676d 656e 7465 645f 696d 6167  s(augmented_imag
-00004f60: 6573 5f6e 6567 6174 6976 655b 305d 5b69  es_negative[0][i
-00004f70: 5d2c 2061 7567 6d65 6e74 6564 5f69 6d61  ], augmented_ima
-00004f80: 6765 735f 6e65 6761 7469 7665 5b31 5d5b  ges_negative[1][
-00004f90: 695d 2c20 6175 676d 656e 7465 645f 696d  i], augmented_im
-00004fa0: 6167 6573 5f6e 6567 6174 6976 655b 325d  ages_negative[2]
-00004fb0: 5b69 5d29 290a 2020 2020 2020 2020 2020  [i])).          
-00004fc0: 2020 2020 2020 636c 6173 735f 3220 3d20        class_2 = 
-00004fd0: 6e70 2e61 7272 6179 2863 6c61 7373 5f32  np.array(class_2
-00004fe0: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-00004ff0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00005000: 2020 2020 636c 6173 735f 3220 3d20 6175      class_2 = au
-00005010: 676d 656e 7465 645f 696d 6167 6573 5f6e  gmented_images_n
-00005020: 6567 6174 6976 650a 0a20 2020 2020 2020  egative..       
-00005030: 2020 2020 2023 4261 6c61 6e63 6520 7468       #Balance th
-00005040: 6520 636c 6173 7320 7369 7a65 7320 6966  e class sizes if
-00005050: 206e 6563 6573 7361 7279 0a20 2020 2020   necessary.     
-00005060: 2020 2020 2020 2069 6620 7365 6c66 2e62         if self.b
-00005070: 616c 616e 6365 3a0a 2020 2020 2020 2020  alance:.        
-00005080: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00005090: 6261 7463 685f 6f74 6865 7220 3e20 313a  batch_other > 1:
-000050a0: 2023 4d75 7374 2073 6875 6666 6c65 2061   #Must shuffle a
-000050b0: 7320 7468 6520 6175 676d 656e 7461 7469  s the augmentati
-000050c0: 6f6e 7320 7765 7265 2073 7461 636b 6564  ons were stacked
-000050d0: 2073 6571 7565 6e74 6961 6c6c 7921 2121   sequentially!!!
-000050e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000050f0: 2020 2020 2069 7820 3d20 6e70 2e72 616e       ix = np.ran
-00005100: 646f 6d2e 7065 726d 7574 6174 696f 6e28  dom.permutation(
-00005110: 6c65 6e28 636c 6173 735f 3229 290a 2020  len(class_2)).  
-00005120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005130: 2020 636c 6173 735f 3220 3d20 636c 6173    class_2 = clas
-00005140: 735f 325b 6978 5d0a 2020 2020 2020 2020  s_2[ix].        
-00005150: 2020 2020 2020 2020 636c 6173 735f 3220          class_2 
-00005160: 3d20 636c 6173 735f 325b 3a6c 656e 2863  = class_2[:len(c
-00005170: 6c61 7373 5f31 295d 0a20 2020 2020 2020  lass_1)].       
-00005180: 2020 2020 200a 2020 2020 2020 2020 2020       .          
-00005190: 2020 2352 6573 697a 6520 6966 206e 6563    #Resize if nec
-000051a0: 6573 7361 7279 2061 6e64 2063 6f6e 6361  essary and conca
-000051b0: 7420 7468 6520 6368 616e 6e65 6c73 0a20  t the channels. 
-000051c0: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-000051d0: 6c66 2e69 6d67 5f6e 756d 5f63 6861 6e6e  lf.img_num_chann
-000051e0: 656c 7320 3d3d 2031 3a0a 2020 2020 2020  els == 1:.      
-000051f0: 2020 2020 2020 2020 2020 636c 6173 735f            class_
-00005200: 3220 3d20 7265 7369 7a65 2863 6c61 7373  2 = resize(class
-00005210: 5f32 2c20 7369 7a65 3d69 6d61 6765 5f73  _2, size=image_s
-00005220: 697a 6529 0a20 2020 2020 2020 2020 2020  ize).           
-00005230: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-00005240: 2020 2020 2020 2063 6861 6e6e 656c 3120         channel1 
-00005250: 3d20 7265 7369 7a65 2863 6c61 7373 5f32  = resize(class_2
-00005260: 5b3a 2c3a 2c3a 2c30 5d2c 2073 697a 653d  [:,:,:,0], size=
-00005270: 696d 6167 655f 7369 7a65 290a 2020 2020  image_size).    
-00005280: 2020 2020 2020 2020 2020 2020 6368 616e              chan
-00005290: 6e65 6c32 203d 2072 6573 697a 6528 636c  nel2 = resize(cl
-000052a0: 6173 735f 325b 3a2c 3a2c 3a2c 315d 2c20  ass_2[:,:,:,1], 
-000052b0: 7369 7a65 3d69 6d61 6765 5f73 697a 6529  size=image_size)
-000052c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000052d0: 2069 6620 7365 6c66 2e69 6d67 5f6e 756d   if self.img_num
-000052e0: 5f63 6861 6e6e 656c 7320 3d3d 2032 3a0a  _channels == 2:.
-000052f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005300: 2020 2020 636c 6173 735f 3220 3d20 6461      class_2 = da
-00005310: 7461 5f70 726f 6365 7373 696e 672e 636f  ta_processing.co
-00005320: 6e63 6174 5f63 6861 6e6e 656c 7328 6368  ncat_channels(ch
-00005330: 616e 6e65 6c31 2c20 6368 616e 6e65 6c32  annel1, channel2
-00005340: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00005350: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00005360: 2020 2020 2020 2020 2020 2020 6368 616e              chan
-00005370: 6e65 6c33 203d 2072 6573 697a 6528 636c  nel3 = resize(cl
-00005380: 6173 735f 325b 3a2c 3a2c 3a2c 325d 2c20  ass_2[:,:,:,2], 
-00005390: 7369 7a65 3d69 6d61 6765 5f73 697a 6529  size=image_size)
-000053a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000053b0: 2020 2020 2063 6c61 7373 5f32 203d 2064       class_2 = d
-000053c0: 6174 615f 7072 6f63 6573 7369 6e67 2e63  ata_processing.c
-000053d0: 6f6e 6361 745f 6368 616e 6e65 6c73 2863  oncat_channels(c
-000053e0: 6861 6e6e 656c 312c 2063 6861 6e6e 656c  hannel1, channel
-000053f0: 322c 2063 6861 6e6e 656c 3329 0a0a 2020  2, channel3)..  
-00005400: 2020 2020 2020 2020 2020 234e 6565 6420            #Need 
-00005410: 746f 2061 6c73 6f20 6372 6f70 2074 6865  to also crop the
-00005420: 2076 616c 6964 6174 696f 6e20 696d 6167   validation imag
-00005430: 6573 0a20 2020 2020 2020 2020 2020 2069  es.            i
-00005440: 6620 7365 6c66 2e76 616c 5f70 6f73 6974  f self.val_posit
-00005450: 6976 6520 6973 206e 6f74 204e 6f6e 653a  ive is not None:
-00005460: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005470: 2069 6620 7365 6c66 2e69 6d67 5f6e 756d   if self.img_num
-00005480: 5f63 6861 6e6e 656c 7320 3d3d 2031 3a0a  _channels == 1:.
-00005490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000054a0: 2020 2020 7661 6c5f 636c 6173 735f 3120      val_class_1 
-000054b0: 3d20 7265 7369 7a65 2873 656c 662e 7661  = resize(self.va
-000054c0: 6c5f 706f 7369 7469 7665 2c20 7369 7a65  l_positive, size
-000054d0: 3d69 6d61 6765 5f73 697a 6529 0a20 2020  =image_size).   
-000054e0: 2020 2020 2020 2020 2020 2020 2065 6c73               els
-000054f0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-00005500: 2020 2020 2020 2076 616c 5f63 6861 6e6e         val_chann
-00005510: 656c 3120 3d20 7265 7369 7a65 2873 656c  el1 = resize(sel
-00005520: 662e 7661 6c5f 706f 7369 7469 7665 5b3a  f.val_positive[:
-00005530: 2c3a 2c3a 2c30 5d2c 2073 697a 653d 696d  ,:,:,0], size=im
-00005540: 6167 655f 7369 7a65 290a 2020 2020 2020  age_size).      
-00005550: 2020 2020 2020 2020 2020 2020 2020 7661                va
-00005560: 6c5f 6368 616e 6e65 6c32 203d 2072 6573  l_channel2 = res
-00005570: 697a 6528 7365 6c66 2e76 616c 5f70 6f73  ize(self.val_pos
-00005580: 6974 6976 655b 3a2c 3a2c 3a2c 315d 2c20  itive[:,:,:,1], 
-00005590: 7369 7a65 3d69 6d61 6765 5f73 697a 6529  size=image_size)
-000055a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000055b0: 2020 2020 2069 6620 7365 6c66 2e69 6d67       if self.img
-000055c0: 5f6e 756d 5f63 6861 6e6e 656c 7320 3d3d  _num_channels ==
-000055d0: 2032 3a0a 2020 2020 2020 2020 2020 2020   2:.            
-000055e0: 2020 2020 2020 2020 2020 2020 7661 6c5f              val_
-000055f0: 636c 6173 735f 3120 3d20 6461 7461 5f70  class_1 = data_p
-00005600: 726f 6365 7373 696e 672e 636f 6e63 6174  rocessing.concat
-00005610: 5f63 6861 6e6e 656c 7328 7661 6c5f 6368  _channels(val_ch
-00005620: 616e 6e65 6c31 2c20 7661 6c5f 6368 616e  annel1, val_chan
-00005630: 6e65 6c32 290a 2020 2020 2020 2020 2020  nel2).          
-00005640: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-00005650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005660: 2020 2020 2020 2020 7661 6c5f 6368 616e          val_chan
-00005670: 6e65 6c33 203d 2072 6573 697a 6528 7365  nel3 = resize(se
-00005680: 6c66 2e76 616c 5f70 6f73 6974 6976 655b  lf.val_positive[
-00005690: 3a2c 3a2c 3a2c 325d 2c20 7369 7a65 3d69  :,:,:,2], size=i
-000056a0: 6d61 6765 5f73 697a 6529 0a20 2020 2020  mage_size).     
-000056b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000056c0: 2020 2076 616c 5f63 6c61 7373 5f31 203d     val_class_1 =
-000056d0: 2064 6174 615f 7072 6f63 6573 7369 6e67   data_processing
-000056e0: 2e63 6f6e 6361 745f 6368 616e 6e65 6c73  .concat_channels
-000056f0: 2876 616c 5f63 6861 6e6e 656c 312c 2076  (val_channel1, v
-00005700: 616c 5f63 6861 6e6e 656c 322c 2076 616c  al_channel2, val
-00005710: 5f63 6861 6e6e 656c 3329 0a20 2020 2020  _channel3).     
-00005720: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-00005730: 2020 2020 2020 2020 2020 2020 2076 616c               val
-00005740: 5f63 6c61 7373 5f31 203d 204e 6f6e 6520  _class_1 = None 
-00005750: 0a0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-00005760: 2073 656c 662e 7661 6c5f 6e65 6761 7469   self.val_negati
-00005770: 7665 2069 7320 6e6f 7420 4e6f 6e65 3a0a  ve is not None:.
-00005780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005790: 6966 2073 656c 662e 696d 675f 6e75 6d5f  if self.img_num_
-000057a0: 6368 616e 6e65 6c73 203d 3d20 313a 0a20  channels == 1:. 
-000057b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000057c0: 2020 2076 616c 5f63 6c61 7373 5f32 203d     val_class_2 =
-000057d0: 2072 6573 697a 6528 7365 6c66 2e76 616c   resize(self.val
-000057e0: 5f6e 6567 6174 6976 652c 2073 697a 653d  _negative, size=
-000057f0: 696d 6167 655f 7369 7a65 290a 2020 2020  image_size).    
-00005800: 2020 2020 2020 2020 2020 2020 656c 6966              elif
-00005810: 2073 656c 662e 696d 675f 6e75 6d5f 6368   self.img_num_ch
-00005820: 616e 6e65 6c73 203e 2031 3a0a 2020 2020  annels > 1:.    
-00005830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005840: 7661 6c5f 6368 616e 6e65 6c31 203d 2072  val_channel1 = r
-00005850: 6573 697a 6528 7365 6c66 2e76 616c 5f6e  esize(self.val_n
-00005860: 6567 6174 6976 655b 3a2c 3a2c 3a2c 305d  egative[:,:,:,0]
-00005870: 2c20 7369 7a65 3d69 6d61 6765 5f73 697a  , size=image_siz
-00005880: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
-00005890: 2020 2020 2020 2076 616c 5f63 6861 6e6e         val_chann
-000058a0: 656c 3220 3d20 7265 7369 7a65 2873 656c  el2 = resize(sel
-000058b0: 662e 7661 6c5f 6e65 6761 7469 7665 5b3a  f.val_negative[:
-000058c0: 2c3a 2c3a 2c31 5d2c 2073 697a 653d 696d  ,:,:,1], size=im
-000058d0: 6167 655f 7369 7a65 290a 2020 2020 2020  age_size).      
-000058e0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-000058f0: 2073 656c 662e 696d 675f 6e75 6d5f 6368   self.img_num_ch
-00005900: 616e 6e65 6c73 203d 3d20 323a 0a20 2020  annels == 2:.   
-00005910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005920: 2020 2020 2076 616c 5f63 6c61 7373 5f32       val_class_2
-00005930: 203d 2064 6174 615f 7072 6f63 6573 7369   = data_processi
-00005940: 6e67 2e63 6f6e 6361 745f 6368 616e 6e65  ng.concat_channe
-00005950: 6c73 2876 616c 5f63 6861 6e6e 656c 312c  ls(val_channel1,
-00005960: 2076 616c 5f63 6861 6e6e 656c 3229 0a20   val_channel2). 
-00005970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005980: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00005990: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000059a0: 2076 616c 5f63 6861 6e6e 656c 3320 3d20   val_channel3 = 
-000059b0: 7265 7369 7a65 2873 656c 662e 7661 6c5f  resize(self.val_
-000059c0: 6e65 6761 7469 7665 5b3a 2c3a 2c3a 2c32  negative[:,:,:,2
-000059d0: 5d2c 2073 697a 653d 696d 6167 655f 7369  ], size=image_si
-000059e0: 7a65 290a 2020 2020 2020 2020 2020 2020  ze).            
-000059f0: 2020 2020 2020 2020 2020 2020 7661 6c5f              val_
-00005a00: 636c 6173 735f 3220 3d20 6461 7461 5f70  class_2 = data_p
-00005a10: 726f 6365 7373 696e 672e 636f 6e63 6174  rocessing.concat
-00005a20: 5f63 6861 6e6e 656c 7328 7661 6c5f 6368  _channels(val_ch
-00005a30: 616e 6e65 6c31 2c20 7661 6c5f 6368 616e  annel1, val_chan
-00005a40: 6e65 6c32 2c20 7661 6c5f 6368 616e 6e65  nel2, val_channe
-00005a50: 6c33 290a 2020 2020 2020 2020 2020 2020  l3).            
-00005a60: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00005a70: 2020 2020 2020 7661 6c5f 636c 6173 735f        val_class_
-00005a80: 3220 3d20 4e6f 6e65 200a 2020 2020 2020  2 = None .      
-00005a90: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00005aa0: 2020 2020 636c 6173 735f 312c 2063 6c61      class_1, cla
-00005ab0: 7373 5f32 203d 2073 656c 662e 706f 7369  ss_2 = self.posi
-00005ac0: 7469 7665 5f63 6c61 7373 2c20 7365 6c66  tive_class, self
-00005ad0: 2e6e 6567 6174 6976 655f 636c 6173 730a  .negative_class.
-00005ae0: 2020 2020 2020 2020 2020 2020 7661 6c5f              val_
-00005af0: 636c 6173 735f 312c 2076 616c 5f63 6c61  class_1, val_cla
-00005b00: 7373 5f32 203d 2073 656c 662e 7661 6c5f  ss_2 = self.val_
-00005b10: 706f 7369 7469 7665 2c20 7365 6c66 2e76  positive, self.v
-00005b20: 616c 5f6e 6567 6174 6976 650a 0a20 2020  al_negative..   
-00005b30: 2020 2020 2023 2323 204f 7074 696d 697a       ### Optimiz
-00005b40: 6520 7468 6520 6d61 7820 7069 7865 6c20  e the max pixel 
-00005b50: 746f 2075 7365 2066 6f72 2074 6865 206d  to use for the m
-00005b60: 696e 2d6d 6178 206e 6f72 6d61 6c69 7a61  in-max normaliza
-00005b70: 7469 6f6e 202d 2d20 4f4e 4520 5049 5820  tion -- ONE PIX 
-00005b80: 5045 5220 4241 4e44 2023 2323 0a20 2020  PER BAND ###.   
-00005b90: 2020 2020 2069 6620 7365 6c66 2e6f 7074       if self.opt
-00005ba0: 5f6d 6178 5f6d 696e 5f70 6978 2069 7320  _max_min_pix is 
-00005bb0: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-00005bc0: 2020 2020 2020 7365 6c66 2e6e 6f72 6d61        self.norma
-00005bd0: 6c69 7a65 203d 2054 7275 6520 234a 7573  lize = True #Jus
-00005be0: 7420 696e 2063 6173 6520 6974 2773 2073  t in case it's s
-00005bf0: 6574 2074 6f20 4661 6c73 6520 6279 2074  et to False by t
-00005c00: 6865 2075 7365 7220 0a20 2020 2020 2020  he user .       
-00005c10: 2020 2020 206d 696e 5f70 6978 2c20 6d61       min_pix, ma
-00005c20: 785f 7069 7820 3d20 302e 302c 205b 5d0a  x_pix = 0.0, [].
-00005c30: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-00005c40: 656c 662e 696d 675f 6e75 6d5f 6368 616e  elf.img_num_chan
-00005c50: 6e65 6c73 203e 3d20 313a 0a20 2020 2020  nels >= 1:.     
-00005c60: 2020 2020 2020 2020 2020 206d 6178 5f70             max_p
-00005c70: 6978 5f31 203d 2074 7269 616c 2e73 7567  ix_1 = trial.sug
-00005c80: 6765 7374 5f69 6e74 2827 6d61 785f 7069  gest_int('max_pi
-00005c90: 7865 6c5f 3127 2c20 7365 6c66 2e6f 7074  xel_1', self.opt
-00005ca0: 5f6d 6178 5f6d 696e 5f70 6978 2c20 7365  _max_min_pix, se
-00005cb0: 6c66 2e6f 7074 5f6d 6178 5f6d 6178 5f70  lf.opt_max_max_p
-00005cc0: 6978 2c20 7374 6570 3d31 293b 206d 6178  ix, step=1); max
-00005cd0: 5f70 6978 2e61 7070 656e 6428 6d61 785f  _pix.append(max_
-00005ce0: 7069 785f 3129 0a20 2020 2020 2020 2020  pix_1).         
-00005cf0: 2020 2069 6620 7365 6c66 2e69 6d67 5f6e     if self.img_n
-00005d00: 756d 5f63 6861 6e6e 656c 7320 3e3d 2032  um_channels >= 2
-00005d10: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00005d20: 2020 6d61 785f 7069 785f 3220 3d20 7472    max_pix_2 = tr
-00005d30: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
-00005d40: 276d 6178 5f70 6978 656c 5f32 272c 2073  'max_pixel_2', s
-00005d50: 656c 662e 6f70 745f 6d61 785f 6d69 6e5f  elf.opt_max_min_
-00005d60: 7069 782c 2073 656c 662e 6f70 745f 6d61  pix, self.opt_ma
-00005d70: 785f 6d61 785f 7069 782c 2073 7465 703d  x_max_pix, step=
-00005d80: 3129 3b20 6d61 785f 7069 782e 6170 7065  1); max_pix.appe
-00005d90: 6e64 286d 6178 5f70 6978 5f32 290a 2020  nd(max_pix_2).  
-00005da0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-00005db0: 662e 696d 675f 6e75 6d5f 6368 616e 6e65  f.img_num_channe
-00005dc0: 6c73 203d 3d20 333a 0a20 2020 2020 2020  ls == 3:.       
-00005dd0: 2020 2020 2020 2020 206d 6178 5f70 6978           max_pix
-00005de0: 5f33 203d 2074 7269 616c 2e73 7567 6765  _3 = trial.sugge
-00005df0: 7374 5f69 6e74 2827 6d61 785f 7069 7865  st_int('max_pixe
-00005e00: 6c5f 3327 2c20 7365 6c66 2e6f 7074 5f6d  l_3', self.opt_m
-00005e10: 6178 5f6d 696e 5f70 6978 2c20 7365 6c66  ax_min_pix, self
-00005e20: 2e6f 7074 5f6d 6178 5f6d 6178 5f70 6978  .opt_max_max_pix
-00005e30: 2c20 7374 6570 3d31 293b 206d 6178 5f70  , step=1); max_p
-00005e40: 6978 2e61 7070 656e 6428 6d61 785f 7069  ix.append(max_pi
-00005e50: 785f 3329 0a20 2020 2020 2020 2020 2020  x_3).           
-00005e60: 2065 6c69 6620 7365 6c66 2e69 6d67 5f6e   elif self.img_n
-00005e70: 756d 5f63 6861 6e6e 656c 7320 3e20 333a  um_channels > 3:
-00005e80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005e90: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-00005ea0: 7228 274f 6e6c 7920 7570 2074 6f20 7468  r('Only up to th
-00005eb0: 7265 6520 6368 616e 6e65 6c73 2061 7265  ree channels are
-00005ec0: 2063 7572 7265 6e74 6c79 2073 7570 706f   currently suppo
-00005ed0: 7274 6564 2127 290a 2020 2020 2020 2020  rted!').        
-00005ee0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00005ef0: 2020 6d69 6e5f 7069 782c 206d 6178 5f70    min_pix, max_p
-00005f00: 6978 203d 2073 656c 662e 6d69 6e5f 7069  ix = self.min_pi
-00005f10: 7865 6c2c 2073 656c 662e 6d61 785f 7069  xel, self.max_pi
-00005f20: 7865 6c0a 0a20 2020 2020 2020 2023 2323  xel..        ###
-00005f30: 2045 6172 6c79 2053 746f 7070 696e 6720   Early Stopping 
-00005f40: 616e 6420 5072 756e 696e 6720 4361 6c6c  and Pruning Call
-00005f50: 6261 636b 7320 2323 230a 2020 2020 2020  backs ###.      
-00005f60: 2020 6966 2073 656c 662e 7061 7469 656e    if self.patien
-00005f70: 6365 2021 3d20 303a 0a20 2020 2020 2020  ce != 0:.       
-00005f80: 2020 2020 206d 6f64 6520 3d20 276d 696e       mode = 'min
-00005f90: 2720 6966 2027 6c6f 7373 2720 696e 2073  ' if 'loss' in s
-00005fa0: 656c 662e 6d65 7472 6963 2065 6c73 6520  elf.metric else 
-00005fb0: 276d 6178 2720 234e 6565 6420 746f 206d  'max' #Need to m
-00005fc0: 696e 696d 697a 6520 7468 6520 6d65 7472  inimize the metr
-00005fd0: 6963 2069 6620 6576 616c 7561 7469 6e67  ic if evaluating
-00005fe0: 2074 6865 206c 6f73 7321 0a20 2020 2020   the loss!.     
-00005ff0: 2020 2020 2020 2069 6620 7365 6c66 2e6d         if self.m
-00006000: 6574 7269 6320 3d3d 2027 7661 6c5f 616c  etric == 'val_al
-00006010: 6c27 3a0a 2020 2020 2020 2020 2020 2020  l':.            
-00006020: 2020 2020 7072 696e 7428 293b 2070 7269      print(); pri
-00006030: 6e74 2822 2743 616e 6e6f 7420 7573 6520  nt("'Cannot use 
-00006040: 6561 726c 7920 7374 6f70 7069 6e67 2063  early stopping c
-00006050: 616c 6c62 6163 6b73 2069 6620 6176 6572  allbacks if aver
-00006060: 6167 696e 6720 6f75 7420 616c 6c20 7065  aging out all pe
-00006070: 7266 6f72 6d61 6e63 6520 6d65 7472 6963  rformance metric
-00006080: 7320 666f 7220 6576 616c 7561 7469 6f6e  s for evaluation
-00006090: 2120 4175 746f 6d61 7469 6361 6c6c 7920  ! Automatically 
-000060a0: 7365 7474 696e 6720 7468 6520 6d65 7472  setting the metr
-000060b0: 6963 2074 6f20 2776 616c 5f6c 6f73 7327  ic to 'val_loss'
-000060c0: 2e20 546f 2064 6973 6162 6c65 2c20 7365  . To disable, se
-000060d0: 7420 7061 7469 656e 6365 3d30 2e22 290a  t patience=0.").
-000060e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000060f0: 6361 6c6c 6261 636b 7320 3d20 5b45 6172  callbacks = [Ear
-00006100: 6c79 5374 6f70 7069 6e67 286d 6f6e 6974  lyStopping(monit
-00006110: 6f72 3d27 7661 6c5f 6c6f 7373 272c 206d  or='val_loss', m
-00006120: 6f64 653d 276d 696e 272c 2070 6174 6965  ode='min', patie
-00006130: 6e63 653d 7365 6c66 2e70 6174 6965 6e63  nce=self.patienc
-00006140: 6529 2c5d 0a20 2020 2020 2020 2020 2020  e),].           
-00006150: 2065 6c69 6620 7365 6c66 2e6d 6574 7269   elif self.metri
-00006160: 6320 3d3d 2027 616c 6c27 3a0a 2020 2020  c == 'all':.    
-00006170: 2020 2020 2020 2020 2020 2020 7072 696e              prin
-00006180: 7428 293b 2070 7269 6e74 2822 2743 616e  t(); print("'Can
-00006190: 6e6f 7420 7573 6520 6561 726c 7920 7374  not use early st
-000061a0: 6f70 7069 6e67 2063 616c 6c62 6163 6b73  opping callbacks
-000061b0: 2069 6620 6176 6572 6167 696e 6720 6f75   if averaging ou
-000061c0: 7420 616c 6c20 7065 7266 6f72 6d61 6e63  t all performanc
-000061d0: 6520 6d65 7472 6963 7320 666f 7220 6576  e metrics for ev
-000061e0: 616c 7561 7469 6f6e 2120 4175 746f 6d61  aluation! Automa
-000061f0: 7469 6361 6c6c 7920 7365 7474 696e 6720  tically setting 
-00006200: 7468 6520 6d65 7472 6963 2074 6f20 276c  the metric to 'l
-00006210: 6f73 7327 2e20 546f 2064 6973 6162 6c65  oss'. To disable
-00006220: 2c20 7365 7420 7061 7469 656e 6365 3d30  , set patience=0
-00006230: 2e22 290a 2020 2020 2020 2020 2020 2020  .").            
-00006240: 2020 2020 6361 6c6c 6261 636b 7320 3d20      callbacks = 
-00006250: 5b45 6172 6c79 5374 6f70 7069 6e67 286d  [EarlyStopping(m
-00006260: 6f6e 6974 6f72 3d27 6c6f 7373 272c 206d  onitor='loss', m
-00006270: 6f64 653d 276d 696e 272c 2070 6174 6965  ode='min', patie
-00006280: 6e63 653d 7365 6c66 2e70 6174 6965 6e63  nce=self.patienc
-00006290: 6529 2c5d 0a20 2020 2020 2020 2020 2020  e),].           
-000062a0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-000062b0: 2020 2020 2020 2063 616c 6c62 6163 6b73         callbacks
-000062c0: 203d 205b 4561 726c 7953 746f 7070 696e   = [EarlyStoppin
-000062d0: 6728 6d6f 6e69 746f 723d 7365 6c66 2e6d  g(monitor=self.m
-000062e0: 6574 7269 632c 206d 6f64 653d 6d6f 6465  etric, mode=mode
-000062f0: 2c20 7061 7469 656e 6365 3d73 656c 662e  , patience=self.
-00006300: 7061 7469 656e 6365 292c 5d20 2354 464b  patience),] #TFK
-00006310: 6572 6173 5072 756e 696e 6743 616c 6c62  erasPruningCallb
-00006320: 6163 6b28 7472 6961 6c2c 206d 6f6e 6974  ack(trial, monit
-00006330: 6f72 3d73 656c 662e 6d65 7472 6963 292c  or=self.metric),
-00006340: 0a20 2020 2020 2020 2020 2020 200a 2020  .            .  
-00006350: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-00006360: 662e 6d6f 6e69 746f 7231 2069 7320 6e6f  f.monitor1 is no
-00006370: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
-00006380: 2020 2020 2020 2020 6966 2063 616c 6c62          if callb
-00006390: 6163 6b73 2069 7320 6e6f 7420 4e6f 6e65  acks is not None
-000063a0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000063b0: 2020 2020 2020 6361 6c6c 6261 636b 732e        callbacks.
-000063c0: 6170 7065 6e64 284d 6f6e 6974 6f72 5f54  append(Monitor_T
-000063d0: 7261 636b 6572 286d 6f6e 6974 6f72 313d  racker(monitor1=
-000063e0: 7365 6c66 2e6d 6f6e 6974 6f72 312c 206d  self.monitor1, m
-000063f0: 6f6e 6974 6f72 323d 7365 6c66 2e6d 6f6e  onitor2=self.mon
-00006400: 6974 6f72 322c 206d 6f6e 6974 6f72 315f  itor2, monitor1_
-00006410: 7468 7265 7368 3d73 656c 662e 6d6f 6e69  thresh=self.moni
-00006420: 746f 7231 5f74 6872 6573 682c 206d 6f6e  tor1_thresh, mon
-00006430: 6974 6f72 325f 7468 7265 7368 3d73 656c  itor2_thresh=sel
-00006440: 662e 6d6f 6e69 746f 7232 5f74 6872 6573  f.monitor2_thres
-00006450: 6829 290a 2020 2020 2020 2020 2020 2020  h)).            
-00006460: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00006470: 2020 2020 2020 2020 2020 2020 2020 6361                ca
-00006480: 6c6c 6261 636b 7320 3d20 5b4d 6f6e 6974  llbacks = [Monit
-00006490: 6f72 5f54 7261 636b 6572 286d 6f6e 6974  or_Tracker(monit
-000064a0: 6f72 313d 7365 6c66 2e6d 6f6e 6974 6f72  or1=self.monitor
-000064b0: 312c 206d 6f6e 6974 6f72 323d 7365 6c66  1, monitor2=self
-000064c0: 2e6d 6f6e 6974 6f72 322c 206d 6f6e 6974  .monitor2, monit
-000064d0: 6f72 315f 7468 7265 7368 3d73 656c 662e  or1_thresh=self.
-000064e0: 6d6f 6e69 746f 7231 5f74 6872 6573 682c  monitor1_thresh,
-000064f0: 206d 6f6e 6974 6f72 325f 7468 7265 7368   monitor2_thresh
-00006500: 3d73 656c 662e 6d6f 6e69 746f 7232 5f74  =self.monitor2_t
-00006510: 6872 6573 6829 2c5d 0a20 2020 2020 2020  hresh),].       
-00006520: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-00006530: 2020 2069 6620 7365 6c66 2e6d 6f6e 6974     if self.monit
-00006540: 6f72 3120 6973 206e 6f74 204e 6f6e 653a  or1 is not None:
-00006550: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00006560: 2063 616c 6c62 6163 6b73 203d 205b 4d6f   callbacks = [Mo
-00006570: 6e69 746f 725f 5472 6163 6b65 7228 6d6f  nitor_Tracker(mo
-00006580: 6e69 746f 7231 3d73 656c 662e 6d6f 6e69  nitor1=self.moni
-00006590: 746f 7231 2c20 6d6f 6e69 746f 7232 3d73  tor1, monitor2=s
-000065a0: 656c 662e 6d6f 6e69 746f 7232 2c20 6d6f  elf.monitor2, mo
-000065b0: 6e69 746f 7231 5f74 6872 6573 683d 7365  nitor1_thresh=se
-000065c0: 6c66 2e6d 6f6e 6974 6f72 315f 7468 7265  lf.monitor1_thre
-000065d0: 7368 2c20 6d6f 6e69 746f 7232 5f74 6872  sh, monitor2_thr
-000065e0: 6573 683d 7365 6c66 2e6d 6f6e 6974 6f72  esh=self.monitor
-000065f0: 325f 7468 7265 7368 292c 5d0a 2020 2020  2_thresh),].    
-00006600: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00006610: 2020 2020 2020 2020 2020 2020 2020 6361                ca
-00006620: 6c6c 6261 636b 7320 3d20 4e6f 6e65 0a0a  llbacks = None..
-00006630: 2020 2020 2020 2020 2323 2320 2323 2320          ### ### 
-00006640: 2323 2320 2323 2320 2323 2320 2323 2320  ### ### ### ### 
-00006650: 2323 2320 2323 2320 2323 2320 0a20 2020  ### ### ### .   
-00006660: 2020 2020 2020 2020 2020 2323 204f 7074            ## Opt
-00006670: 696d 697a 6520 434e 4e20 4d6f 6465 6c20  imize CNN Model 
-00006680: 2323 0a20 2020 2020 2020 2023 2323 2023  ##.        ### #
-00006690: 2323 2023 2323 2023 2323 2023 2323 2023  ## ### ### ### #
-000066a0: 2323 2023 2323 2023 2323 2023 2323 200a  ## ### ### ### .
-000066b0: 0a20 2020 2020 2020 2023 2323 2042 6174  .        ### Bat
-000066c0: 6368 2053 697a 6520 2323 230a 2020 2020  ch Size ###.    
-000066d0: 2020 2020 2349 6e20 6361 7365 2075 7365      #In case use
-000066e0: 7220 7761 6e74 7320 746f 2066 6978 2074  r wants to fix t
-000066f0: 6865 2062 6174 6368 5f73 697a 652e 2e2e  he batch_size...
-00006700: 2061 6c74 686f 7567 6820 4f70 7475 6e61   although Optuna
-00006710: 2063 616e 206f 7074 696d 697a 6520 6120   can optimize a 
-00006720: 7061 7261 6d20 7261 6e67 696e 6720 6672  param ranging fr
-00006730: 6f6d 206f 6e65 2076 616c 7565 2074 6f20  om one value to 
-00006740: 7468 6520 7361 6d65 2076 616c 7565 2c20  the same value, 
-00006750: 7468 6520 696d 706f 7274 616e 6365 7320  the importances 
-00006760: 7769 6c6c 206e 6f74 2062 6520 6162 6c65  will not be able
-00006770: 2074 6f20 6265 2063 6f6d 7075 7465 6420   to be computed 
-00006780: 6166 7465 7277 6172 6473 2120 5468 6973  afterwards! This
-00006790: 2063 6f6e 6469 7469 6f6e 2069 7320 746f   condition is to
-000067a0: 2061 766f 6964 2074 6869 7320 6275 6721   avoid this bug!
-000067b0: 200a 2020 2020 2020 2020 6966 2073 656c   .        if sel
-000067c0: 662e 6261 7463 685f 7369 7a65 5f6d 696e  f.batch_size_min
-000067d0: 203d 3d20 7365 6c66 2e62 6174 6368 5f73   == self.batch_s
-000067e0: 697a 655f 6d61 783a 0a20 2020 2020 2020  ize_max:.       
-000067f0: 2020 2020 2062 6174 6368 5f73 697a 6520       batch_size 
-00006800: 3d20 7365 6c66 2e62 6174 6368 5f73 697a  = self.batch_siz
-00006810: 655f 6d61 7820 0a20 2020 2020 2020 2065  e_max .        e
-00006820: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00006830: 2062 6174 6368 5f73 697a 6520 3d20 7472   batch_size = tr
-00006840: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
-00006850: 2762 6174 6368 5f73 697a 6527 2c20 7365  'batch_size', se
-00006860: 6c66 2e62 6174 6368 5f73 697a 655f 6d69  lf.batch_size_mi
-00006870: 6e2c 2073 656c 662e 6261 7463 685f 7369  n, self.batch_si
-00006880: 7a65 5f6d 6178 2c20 7374 6570 3d31 290a  ze_max, step=1).
-00006890: 0a20 2020 2020 2020 2023 2323 204c 6561  .        ### Lea
-000068a0: 726e 696e 6720 5261 7465 2026 204f 7074  rning Rate & Opt
-000068b0: 696d 697a 6572 2023 2323 0a20 2020 2020  imizer ###.     
-000068c0: 2020 206c 7220 3d20 7472 6961 6c2e 7375     lr = trial.su
-000068d0: 6767 6573 745f 666c 6f61 7428 276c 7227  ggest_float('lr'
-000068e0: 2c20 3165 2d36 2c20 3165 2d33 2c20 7374  , 1e-6, 1e-3, st
-000068f0: 6570 3d35 652d 3629 200a 2020 2020 2020  ep=5e-6) .      
-00006900: 2020 6465 6361 793d 3020 2364 6563 6179    decay=0 #decay
-00006910: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-00006920: 5f66 6c6f 6174 2827 6465 6361 7927 2c20  _float('decay', 
-00006930: 302e 302c 2030 2e31 2c20 7374 6570 3d31  0.0, 0.1, step=1
-00006940: 652d 3329 0a20 2020 2020 2020 206f 7074  e-3).        opt
-00006950: 696d 697a 6572 203d 2074 7269 616c 2e73  imizer = trial.s
-00006960: 7567 6765 7374 5f63 6174 6567 6f72 6963  uggest_categoric
-00006970: 616c 2827 6f70 7469 6d69 7a65 7227 2c20  al('optimizer', 
-00006980: 5b27 7367 6427 2c20 2761 6461 6d27 2c20  ['sgd', 'adam', 
-00006990: 2761 6461 6d61 7827 2c20 276e 6164 616d  'adamax', 'nadam
-000069a0: 272c 2027 6164 6164 656c 7461 272c 2027  ', 'adadelta', '
-000069b0: 726d 7370 726f 7027 5d29 0a0a 2020 2020  rmsprop'])..    
-000069c0: 2020 2020 2341 6c6c 2075 7365 2069 6e76      #All use inv
-000069d0: 6572 7365 2074 696d 6520 6465 6361 792c  erse time decay,
-000069e0: 2061 2066 6577 2075 7365 2072 686f 2061   a few use rho a
-000069f0: 7320 7765 6c6c 2c20 616e 6420 4164 616d  s well, and Adam
-00006a00: 2d62 6173 6564 206f 7074 696d 697a 6572  -based optimizer
-00006a10: 7320 7573 6520 6265 7461 5f31 2061 6e64  s use beta_1 and
-00006a20: 2062 6574 615f 3220 0a20 2020 2020 2020   beta_2 .       
-00006a30: 2069 6620 6f70 7469 6d69 7a65 7220 3d3d   if optimizer ==
-00006a40: 2027 7367 6427 3a0a 2020 2020 2020 2020   'sgd':.        
-00006a50: 2020 2020 6d6f 6d65 6e74 756d 203d 2074      momentum = t
-00006a60: 7269 616c 2e73 7567 6765 7374 5f66 6c6f  rial.suggest_flo
-00006a70: 6174 2827 6d6f 6d65 6e74 756d 272c 2030  at('momentum', 0
-00006a80: 2e30 2c20 312e 302c 2073 7465 703d 3165  .0, 1.0, step=1e
-00006a90: 2d33 290a 2020 2020 2020 2020 2020 2020  -3).            
-00006aa0: 6e65 7374 6572 6f76 203d 2074 7269 616c  nesterov = trial
-00006ab0: 2e73 7567 6765 7374 5f63 6174 6567 6f72  .suggest_categor
-00006ac0: 6963 616c 2827 6e65 7374 6572 6f76 272c  ical('nesterov',
-00006ad0: 205b 5472 7565 2c20 4661 6c73 655d 290a   [True, False]).
-00006ae0: 2020 2020 2020 2020 2020 2020 6265 7461              beta
-00006af0: 5f31 203d 2062 6574 615f 3220 3d20 303b  _1 = beta_2 = 0;
-00006b00: 2061 6d73 6772 6164 203d 2046 616c 7365   amsgrad = False
-00006b10: 0a20 2020 2020 2020 2065 6c69 6620 6f70  .        elif op
-00006b20: 7469 6d69 7a65 7220 3d3d 2027 6164 616d  timizer == 'adam
-00006b30: 2720 6f72 206f 7074 696d 697a 6572 203d  ' or optimizer =
-00006b40: 3d20 2761 6461 6d61 7827 206f 7220 6f70  = 'adamax' or op
-00006b50: 7469 6d69 7a65 7220 3d3d 2027 6e61 6461  timizer == 'nada
-00006b60: 6d27 3a0a 2020 2020 2020 2020 2020 2020  m':.            
-00006b70: 6265 7461 5f31 203d 2074 7269 616c 2e73  beta_1 = trial.s
-00006b80: 7567 6765 7374 5f66 6c6f 6174 2827 6265  uggest_float('be
-00006b90: 7461 5f31 272c 2030 2e30 2c20 312e 302c  ta_1', 0.0, 1.0,
-00006ba0: 2073 7465 703d 3165 2d33 290a 2020 2020   step=1e-3).    
-00006bb0: 2020 2020 2020 2020 6265 7461 5f32 203d          beta_2 =
-00006bc0: 2074 7269 616c 2e73 7567 6765 7374 5f66   trial.suggest_f
-00006bd0: 6c6f 6174 2827 6265 7461 5f32 272c 2030  loat('beta_2', 0
-00006be0: 2e30 2c20 312e 302c 2073 7465 703d 3165  .0, 1.0, step=1e
-00006bf0: 2d33 290a 2020 2020 2020 2020 2020 2020  -3).            
-00006c00: 616d 7367 7261 6420 3d20 7472 6961 6c2e  amsgrad = trial.
-00006c10: 7375 6767 6573 745f 6361 7465 676f 7269  suggest_categori
-00006c20: 6361 6c28 2761 6d73 6772 6164 272c 205b  cal('amsgrad', [
-00006c30: 5472 7565 2c20 4661 6c73 655d 2920 6966  True, False]) if
-00006c40: 206f 7074 696d 697a 6572 203d 3d20 2761   optimizer == 'a
-00006c50: 6461 6d27 2065 6c73 6520 4661 6c73 650a  dam' else False.
-00006c60: 2020 2020 2020 2020 2020 2020 6d6f 6d65              mome
-00006c70: 6e74 756d 2c20 6e65 7374 6572 6f76 203d  ntum, nesterov =
-00006c80: 2030 2e30 2c20 4661 6c73 650a 2020 2020   0.0, False.    
-00006c90: 2020 2020 656c 6966 206f 7074 696d 697a      elif optimiz
-00006ca0: 6572 203d 3d20 2761 6461 6465 6c74 6127  er == 'adadelta'
-00006cb0: 206f 7220 6f70 7469 6d69 7a65 7220 3d3d   or optimizer ==
-00006cc0: 2027 726d 7370 726f 7027 3a0a 2020 2020   'rmsprop':.    
-00006cd0: 2020 2020 2020 2020 7268 6f20 3d20 7472          rho = tr
-00006ce0: 6961 6c2e 7375 6767 6573 745f 666c 6f61  ial.suggest_floa
-00006cf0: 7428 2772 686f 272c 2030 2c20 312c 2073  t('rho', 0, 1, s
-00006d00: 7465 703d 3165 2d33 290a 2020 2020 2020  tep=1e-3).      
-00006d10: 2020 2020 2020 6d6f 6d65 6e74 756d 203d        momentum =
-00006d20: 2062 6574 615f 3120 3d20 6265 7461 5f32   beta_1 = beta_2
-00006d30: 203d 2030 3b20 6e65 7374 6572 6f76 203d   = 0; nesterov =
-00006d40: 2061 6d73 6772 6164 203d 2046 616c 7365   amsgrad = False
-00006d50: 0a0a 2020 2020 2020 2020 636c 6561 725f  ..        clear_
-00006d60: 7365 7373 696f 6e28 290a 2020 2020 2020  session().      
-00006d70: 2020 6966 2073 656c 662e 6f70 745f 6d6f    if self.opt_mo
-00006d80: 6465 6c3a 0a20 2020 2020 2020 2020 2020  del:.           
-00006d90: 2022 2222 434e 4e20 4879 7065 7270 6172   """CNN Hyperpar
-00006da0: 616d 6574 6572 2053 6561 7263 6820 5370  ameter Search Sp
-00006db0: 6163 6522 2222 0a0a 2020 2020 2020 2020  ace"""..        
-00006dc0: 2020 2020 2323 2320 4163 7469 7661 7469      ### Activati
-00006dd0: 6f6e 2061 6e64 204c 6f73 7320 4675 6e63  on and Loss Func
-00006de0: 7469 6f6e 7320 2323 2320 0a20 2020 2020  tions ### .     
-00006df0: 2020 2020 2020 2061 6374 6976 6174 696f         activatio
-00006e00: 6e5f 636f 6e76 203d 2074 7269 616c 2e73  n_conv = trial.s
-00006e10: 7567 6765 7374 5f63 6174 6567 6f72 6963  uggest_categoric
-00006e20: 616c 2827 6163 7469 7661 7469 6f6e 5f63  al('activation_c
-00006e30: 6f6e 7627 2c20 5b27 7265 6c75 272c 2020  onv', ['relu',  
-00006e40: 2773 6967 6d6f 6964 272c 2027 7461 6e68  'sigmoid', 'tanh
-00006e50: 272c 2027 656c 7527 2c20 2773 656c 7527  ', 'elu', 'selu'
-00006e60: 5d29 2020 2020 2020 2020 2020 2020 0a20  ])            . 
-00006e70: 2020 2020 2020 2020 2020 2061 6374 6976             activ
-00006e80: 6174 696f 6e5f 6465 6e73 6520 3d20 7472  ation_dense = tr
-00006e90: 6961 6c2e 7375 6767 6573 745f 6361 7465  ial.suggest_cate
-00006ea0: 676f 7269 6361 6c28 2761 6374 6976 6174  gorical('activat
-00006eb0: 696f 6e5f 6465 6e73 6527 2c20 5b27 7265  ion_dense', ['re
-00006ec0: 6c75 272c 2027 7369 676d 6f69 6427 2c20  lu', 'sigmoid', 
-00006ed0: 2774 616e 6827 2c20 2765 6c75 272c 2027  'tanh', 'elu', '
-00006ee0: 7365 6c75 275d 290a 2020 2020 2020 2020  selu']).        
-00006ef0: 2020 2020 6c6f 7373 203d 2074 7269 616c      loss = trial
-00006f00: 2e73 7567 6765 7374 5f63 6174 6567 6f72  .suggest_categor
-00006f10: 6963 616c 2827 6c6f 7373 272c 205b 2762  ical('loss', ['b
-00006f20: 696e 6172 795f 6372 6f73 7365 6e74 726f  inary_crossentro
-00006f30: 7079 272c 2027 6869 6e67 6527 2c20 2773  py', 'hinge', 's
-00006f40: 7175 6172 6564 5f68 696e 6765 272c 2027  quared_hinge', '
-00006f50: 6b6c 6427 2c20 276c 6f67 636f 7368 275d  kld', 'logcosh']
-00006f60: 2923 2c20 2766 6f63 616c 5f6c 6f73 7327  )#, 'focal_loss'
-00006f70: 2c20 2764 6963 655f 6c6f 7373 272c 2027  , 'dice_loss', '
-00006f80: 6a61 6363 6172 645f 6c6f 7373 275d 290a  jaccard_loss']).
-00006f90: 0a20 2020 2020 2020 2020 2020 2023 2323  .            ###
-00006fa0: 204b 6572 6e65 6c20 496e 6974 6961 6c69   Kernel Initiali
-00006fb0: 7a65 7273 2023 2323 0a20 2020 2020 2020  zers ###.       
-00006fc0: 2020 2020 2063 6f6e 765f 696e 6974 203d       conv_init =
-00006fd0: 2074 7269 616c 2e73 7567 6765 7374 5f63   trial.suggest_c
-00006fe0: 6174 6567 6f72 6963 616c 2827 636f 6e76  ategorical('conv
-00006ff0: 5f69 6e69 7427 2c20 5b27 756e 6966 6f72  _init', ['unifor
-00007000: 6d5f 7363 616c 696e 6727 2c20 2754 7275  m_scaling', 'Tru
-00007010: 6e63 6174 6564 4e6f 726d 616c 272c 2027  ncatedNormal', '
-00007020: 6865 5f6e 6f72 6d61 6c27 2c20 276c 6563  he_normal', 'lec
-00007030: 756e 5f75 6e69 666f 726d 272c 2027 676c  un_uniform', 'gl
-00007040: 6f72 6f74 5f75 6e69 666f 726d 275d 2920  orot_uniform']) 
-00007050: 0a20 2020 2020 2020 2020 2020 2064 656e  .            den
-00007060: 7365 5f69 6e69 7420 3d20 7472 6961 6c2e  se_init = trial.
-00007070: 7375 6767 6573 745f 6361 7465 676f 7269  suggest_categori
-00007080: 6361 6c28 2764 656e 7365 5f69 6e69 7427  cal('dense_init'
-00007090: 2c20 5b27 756e 6966 6f72 6d5f 7363 616c  , ['uniform_scal
-000070a0: 696e 6727 2c20 2754 7275 6e63 6174 6564  ing', 'Truncated
-000070b0: 4e6f 726d 616c 272c 2768 655f 6e6f 726d  Normal','he_norm
-000070c0: 616c 272c 2027 6c65 6375 6e5f 756e 6966  al', 'lecun_unif
-000070d0: 6f72 6d27 2c20 2767 6c6f 726f 745f 756e  orm', 'glorot_un
-000070e0: 6966 6f72 6d27 5d29 200a 0a20 2020 2020  iform']) ..     
-000070f0: 2020 2020 2020 2070 7269 6e74 2829 0a20         print(). 
-00007100: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-00007110: 6c66 2e76 6572 626f 7365 203d 3d20 313a  lf.verbose == 1:
-00007120: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007130: 2069 6620 7365 6c66 2e6f 7074 5f63 7620   if self.opt_cv 
-00007140: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-00007150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007160: 2070 7269 6e74 2829 3b20 7072 696e 7428   print(); print(
-00007170: 272a 2a2a 2a2a 2a2a 2a2a 2a2a 2020 4356  '***********  CV
-00007180: 202d 2031 202a 2a2a 2a2a 2a2a 2a2a 2a2a   - 1 ***********
-00007190: 2729 3b20 7072 696e 7428 290a 2020 2020  '); print().    
-000071a0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-000071b0: 656c 662e 6f70 745f 6175 673a 0a20 2020  elf.opt_aug:.   
-000071c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000071d0: 2070 7269 6e74 2829 3b20 7072 696e 7428   print(); print(
-000071e0: 273d 3d3d 3d3d 3d3d 2049 6d61 6765 2050  '======= Image P
-000071f0: 6172 616d 6574 6572 7320 3d3d 3d3d 3d3d  arameters ======
-00007200: 2729 3b20 7072 696e 7428 293b 2070 7269  '); print(); pri
-00007210: 6e74 2827 4e75 6d20 4175 676d 656e 7461  nt('Num Augmenta
-00007220: 7469 6f6e 7320 3a27 2c20 6e75 6d5f 6175  tions :', num_au
-00007230: 6729 3b20 7072 696e 7428 2749 6d61 6765  g); print('Image
-00007240: 2053 697a 6520 3a20 272c 2069 6d61 6765   Size : ', image
-00007250: 5f73 697a 6529 3b20 7072 696e 7428 274d  _size); print('M
-00007260: 6178 2050 6978 656c 2873 2920 3a27 2c20  ax Pixel(s) :', 
-00007270: 6d61 785f 7069 7829 0a0a 2020 2020 2020  max_pix)..      
-00007280: 2020 2020 2020 6966 2073 656c 662e 636c        if self.cl
-00007290: 6620 3d3d 2027 616c 6578 6e65 7427 3a0a  f == 'alexnet':.
-000072a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000072b0: 2023 2323 2052 6567 756c 6172 697a 6174   ### Regularizat
-000072c0: 696f 6e20 5465 6368 6e69 7175 6520 2842  ion Technique (B
-000072d0: 4e20 6973 206e 6577 6572 2c20 416c 6578  N is newer, Alex
-000072e0: 4e65 7420 7573 6564 2074 776f 204c 6f63  Net used two Loc
-000072f0: 616c 2052 6573 706f 6e73 6520 4e6f 726d  al Response Norm
-00007300: 616c 697a 6174 696f 6e20 6c61 7965 7273  alization layers
-00007310: 2061 6674 6572 2074 6865 2066 6972 7374   after the first
-00007320: 2074 776f 2063 6f6e 7673 2920 2323 230a   two convs) ###.
-00007330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007340: 6d6f 6465 6c5f 7265 6720 3d20 7472 6961  model_reg = tria
-00007350: 6c2e 7375 6767 6573 745f 6361 7465 676f  l.suggest_catego
-00007360: 7269 6361 6c28 276d 6f64 656c 5f72 6567  rical('model_reg
-00007370: 272c 205b 4e6f 6e65 2c20 276c 6f63 616c  ', [None, 'local
-00007380: 5f72 6573 706f 6e73 6527 2c20 2762 6174  _response', 'bat
-00007390: 6368 5f6e 6f72 6d27 5d29 0a0a 2020 2020  ch_norm'])..    
-000073a0: 2020 2020 2020 2020 2020 2020 2323 2320              ### 
-000073b0: 506f 6f6c 696e 6720 5479 7065 2023 2323  Pooling Type ###
-000073c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000073d0: 2070 6f6f 6c69 6e67 5f31 203d 2074 7269   pooling_1 = tri
-000073e0: 616c 2e73 7567 6765 7374 5f63 6174 6567  al.suggest_categ
-000073f0: 6f72 6963 616c 2827 706f 6f6c 696e 675f  orical('pooling_
-00007400: 3127 2c20 5b27 6d69 6e27 2c20 276d 6178  1', ['min', 'max
-00007410: 272c 2027 6176 6572 6167 6527 5d29 0a20  ', 'average']). 
-00007420: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-00007430: 6f6f 6c69 6e67 5f32 203d 2074 7269 616c  ooling_2 = trial
-00007440: 2e73 7567 6765 7374 5f63 6174 6567 6f72  .suggest_categor
-00007450: 6963 616c 2827 706f 6f6c 696e 675f 3227  ical('pooling_2'
-00007460: 2c20 5b27 6d69 6e27 2c20 276d 6178 272c  , ['min', 'max',
-00007470: 2027 6176 6572 6167 6527 5d29 0a20 2020   'average']).   
-00007480: 2020 2020 2020 2020 2020 2020 2070 6f6f               poo
-00007490: 6c69 6e67 5f33 203d 2074 7269 616c 2e73  ling_3 = trial.s
-000074a0: 7567 6765 7374 5f63 6174 6567 6f72 6963  uggest_categoric
-000074b0: 616c 2827 706f 6f6c 696e 675f 3327 2c20  al('pooling_3', 
-000074c0: 5b27 6d69 6e27 2c20 276d 6178 272c 2027  ['min', 'max', '
-000074d0: 6176 6572 6167 6527 5d29 0a0a 2020 2020  average'])..    
-000074e0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-000074f0: 656c 662e 6c69 6d69 745f 7365 6172 6368  elf.limit_search
-00007500: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00007510: 2020 0a20 2020 2020 2020 2020 2020 2020    .             
-00007520: 2020 2020 2020 206d 6f64 656c 2c20 6869         model, hi
-00007530: 7374 6f72 7920 3d20 636e 6e5f 6d6f 6465  story = cnn_mode
-00007540: 6c2e 416c 6578 4e65 7428 636c 6173 735f  l.AlexNet(class_
-00007550: 312c 2063 6c61 7373 5f32 2c20 696d 675f  1, class_2, img_
-00007560: 6e75 6d5f 6368 616e 6e65 6c73 3d73 656c  num_channels=sel
-00007570: 662e 696d 675f 6e75 6d5f 6368 616e 6e65  f.img_num_channe
-00007580: 6c73 2c20 0a20 2020 2020 2020 2020 2020  ls, .           
-00007590: 2020 2020 2020 2020 2020 2020 206e 6f72               nor
-000075a0: 6d61 6c69 7a65 3d73 656c 662e 6e6f 726d  malize=self.norm
-000075b0: 616c 697a 652c 206d 696e 5f70 6978 656c  alize, min_pixel
-000075c0: 3d6d 696e 5f70 6978 2c20 6d61 785f 7069  =min_pix, max_pi
-000075d0: 7865 6c3d 6d61 785f 7069 782c 2076 616c  xel=max_pix, val
-000075e0: 5f70 6f73 6974 6976 653d 7661 6c5f 636c  _positive=val_cl
-000075f0: 6173 735f 312c 2076 616c 5f6e 6567 6174  ass_1, val_negat
-00007600: 6976 653d 7661 6c5f 636c 6173 735f 322c  ive=val_class_2,
-00007610: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-00007620: 2020 2020 2020 2020 2020 6570 6f63 6873            epochs
-00007630: 3d73 656c 662e 7472 6169 6e5f 6570 6f63  =self.train_epoc
-00007640: 6873 2c20 6261 7463 685f 7369 7a65 3d62  hs, batch_size=b
-00007650: 6174 6368 5f73 697a 652c 206f 7074 696d  atch_size, optim
-00007660: 697a 6572 3d6f 7074 696d 697a 6572 2c20  izer=optimizer, 
-00007670: 6c72 3d6c 722c 2064 6563 6179 3d64 6563  lr=lr, decay=dec
-00007680: 6179 2c20 6d6f 6d65 6e74 756d 3d6d 6f6d  ay, momentum=mom
-00007690: 656e 7475 6d2c 206e 6573 7465 726f 763d  entum, nesterov=
-000076a0: 6e65 7374 6572 6f76 2c20 0a20 2020 2020  nesterov, .     
-000076b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000076c0: 2020 2062 6574 615f 313d 6265 7461 5f31     beta_1=beta_1
-000076d0: 2c20 6265 7461 5f32 3d62 6574 615f 322c  , beta_2=beta_2,
-000076e0: 2061 6d73 6772 6164 3d61 6d73 6772 6164   amsgrad=amsgrad
-000076f0: 2c20 6c6f 7373 3d6c 6f73 732c 2061 6374  , loss=loss, act
-00007700: 6976 6174 696f 6e5f 636f 6e76 3d61 6374  ivation_conv=act
-00007710: 6976 6174 696f 6e5f 636f 6e76 2c20 6163  ivation_conv, ac
-00007720: 7469 7661 7469 6f6e 5f64 656e 7365 3d61  tivation_dense=a
-00007730: 6374 6976 6174 696f 6e5f 6465 6e73 652c  ctivation_dense,
-00007740: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-00007750: 2020 2020 2020 2020 2020 636f 6e76 5f69            conv_i
-00007760: 6e69 743d 636f 6e76 5f69 6e69 742c 2064  nit=conv_init, d
-00007770: 656e 7365 5f69 6e69 743d 6465 6e73 655f  ense_init=dense_
-00007780: 696e 6974 2c20 6d6f 6465 6c5f 7265 673d  init, model_reg=
-00007790: 6d6f 6465 6c5f 7265 672c 2070 6f6f 6c69  model_reg, pooli
-000077a0: 6e67 5f31 3d70 6f6f 6c69 6e67 5f31 2c20  ng_1=pooling_1, 
-000077b0: 706f 6f6c 696e 675f 323d 706f 6f6c 696e  pooling_2=poolin
-000077c0: 675f 322c 2070 6f6f 6c69 6e67 5f33 3d70  g_2, pooling_3=p
-000077d0: 6f6f 6c69 6e67 5f33 2c20 0a20 2020 2020  ooling_3, .     
-000077e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000077f0: 2020 2073 6d6f 7465 5f73 616d 706c 696e     smote_samplin
-00007800: 673d 7365 6c66 2e73 6d6f 7465 5f73 616d  g=self.smote_sam
-00007810: 706c 696e 672c 2065 6172 6c79 5f73 746f  pling, early_sto
-00007820: 705f 6361 6c6c 6261 636b 3d63 616c 6c62  p_callback=callb
-00007830: 6163 6b73 2c20 6368 6563 6b70 6f69 6e74  acks, checkpoint
-00007840: 3d46 616c 7365 2c20 7665 7262 6f73 653d  =False, verbose=
-00007850: 7365 6c66 2e76 6572 626f 7365 290a 2020  self.verbose).  
-00007860: 2020 2020 2020 2020 2020 2020 2020 656c                el
-00007870: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00007880: 2020 2020 2020 2020 2323 2320 4669 6c74          ### Filt
-00007890: 6572 2061 6e64 204c 6179 6572 2043 6861  er and Layer Cha
-000078a0: 7261 6374 6572 7374 6963 7320 2323 230a  racterstics ###.
-000078b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000078c0: 2020 2020 6669 6c74 6572 5f31 203d 2074      filter_1 = t
-000078d0: 7269 616c 2e73 7567 6765 7374 5f69 6e74  rial.suggest_int
-000078e0: 2827 6669 6c74 6572 5f31 272c 2031 322c  ('filter_1', 12,
-000078f0: 2035 3136 2c20 7374 6570 3d31 3229 0a20   516, step=12). 
-00007900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007910: 2020 2066 696c 7465 725f 7369 7a65 5f31     filter_size_1
-00007920: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-00007930: 5f69 6e74 2827 6669 6c74 6572 5f73 697a  _int('filter_siz
-00007940: 655f 3127 2c20 312c 2031 312c 2073 7465  e_1', 1, 11, ste
-00007950: 703d 3229 0a20 2020 2020 2020 2020 2020  p=2).           
-00007960: 2020 2020 2020 2020 2073 7472 6964 6573           strides
-00007970: 5f31 203d 2074 7269 616c 2e73 7567 6765  _1 = trial.sugge
-00007980: 7374 5f69 6e74 2827 7374 7269 6465 735f  st_int('strides_
-00007990: 3127 2c20 312c 2033 2c20 7374 6570 3d31  1', 1, 3, step=1
-000079a0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-000079b0: 2020 2020 2020 706f 6f6c 5f73 697a 655f        pool_size_
-000079c0: 3120 3d20 7472 6961 6c2e 7375 6767 6573  1 = trial.sugges
-000079d0: 745f 696e 7428 2770 6f6f 6c5f 7369 7a65  t_int('pool_size
-000079e0: 5f31 272c 2031 2c20 372c 2073 7465 703d  _1', 1, 7, step=
-000079f0: 3129 0a20 2020 2020 2020 2020 2020 2020  1).             
-00007a00: 2020 2020 2020 2070 6f6f 6c5f 7374 7269         pool_stri
-00007a10: 6465 5f31 203d 2074 7269 616c 2e73 7567  de_1 = trial.sug
-00007a20: 6765 7374 5f69 6e74 2827 706f 6f6c 5f73  gest_int('pool_s
-00007a30: 7472 6964 655f 3127 2c20 312c 2033 2c20  tride_1', 1, 3, 
-00007a40: 7374 6570 3d31 290a 0a20 2020 2020 2020  step=1)..       
-00007a50: 2020 2020 2020 2020 2020 2020 2066 696c               fil
-00007a60: 7465 725f 3220 3d20 7472 6961 6c2e 7375  ter_2 = trial.su
-00007a70: 6767 6573 745f 696e 7428 2766 696c 7465  ggest_int('filte
-00007a80: 725f 3227 2c20 3132 2c20 3531 362c 2073  r_2', 12, 516, s
-00007a90: 7465 703d 3132 290a 2020 2020 2020 2020  tep=12).        
-00007aa0: 2020 2020 2020 2020 2020 2020 6669 6c74              filt
-00007ab0: 6572 5f73 697a 655f 3220 3d20 7472 6961  er_size_2 = tria
-00007ac0: 6c2e 7375 6767 6573 745f 696e 7428 2766  l.suggest_int('f
-00007ad0: 696c 7465 725f 7369 7a65 5f32 272c 2031  ilter_size_2', 1
-00007ae0: 2c20 372c 2073 7465 703d 3229 0a20 2020  , 7, step=2).   
-00007af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007b00: 2073 7472 6964 6573 5f32 203d 2074 7269   strides_2 = tri
-00007b10: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-00007b20: 7374 7269 6465 735f 3227 2c20 312c 2033  strides_2', 1, 3
-00007b30: 2c20 7374 6570 3d31 290a 2020 2020 2020  , step=1).      
-00007b40: 2020 2020 2020 2020 2020 2020 2020 706f                po
-00007b50: 6f6c 5f73 697a 655f 3220 3d20 7472 6961  ol_size_2 = tria
-00007b60: 6c2e 7375 6767 6573 745f 696e 7428 2770  l.suggest_int('p
-00007b70: 6f6f 6c5f 7369 7a65 5f32 272c 2031 2c20  ool_size_2', 1, 
-00007b80: 372c 2073 7465 703d 3129 0a20 2020 2020  7, step=1).     
-00007b90: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-00007ba0: 6f6f 6c5f 7374 7269 6465 5f32 203d 2074  ool_stride_2 = t
-00007bb0: 7269 616c 2e73 7567 6765 7374 5f69 6e74  rial.suggest_int
-00007bc0: 2827 706f 6f6c 5f73 7472 6964 655f 3227  ('pool_stride_2'
-00007bd0: 2c20 312c 2033 2c20 7374 6570 3d31 290a  , 1, 3, step=1).
-00007be0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007bf0: 2020 2020 2066 696c 7465 725f 3320 3d20       filter_3 = 
-00007c00: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
-00007c10: 7428 2766 696c 7465 725f 3327 2c20 3132  t('filter_3', 12
-00007c20: 2c20 3531 362c 2073 7465 703d 3132 290a  , 516, step=12).
-00007c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007c40: 2020 2020 6669 6c74 6572 5f73 697a 655f      filter_size_
-00007c50: 3320 3d20 7472 6961 6c2e 7375 6767 6573  3 = trial.sugges
-00007c60: 745f 696e 7428 2766 696c 7465 725f 7369  t_int('filter_si
-00007c70: 7a65 5f33 272c 2031 2c20 372c 2073 7465  ze_3', 1, 7, ste
-00007c80: 703d 3229 0a20 2020 2020 2020 2020 2020  p=2).           
-00007c90: 2020 2020 2020 2020 2073 7472 6964 6573           strides
-00007ca0: 5f33 203d 2074 7269 616c 2e73 7567 6765  _3 = trial.sugge
-00007cb0: 7374 5f69 6e74 2827 7374 7269 6465 735f  st_int('strides_
-00007cc0: 3327 2c20 312c 2033 2c20 7374 6570 3d31  3', 1, 3, step=1
-00007cd0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00007ce0: 2020 2020 2020 706f 6f6c 5f73 697a 655f        pool_size_
-00007cf0: 3320 3d20 7472 6961 6c2e 7375 6767 6573  3 = trial.sugges
-00007d00: 745f 696e 7428 2770 6f6f 6c5f 7369 7a65  t_int('pool_size
-00007d10: 5f33 272c 2031 2c20 372c 2073 7465 703d  _3', 1, 7, step=
-00007d20: 3129 0a20 2020 2020 2020 2020 2020 2020  1).             
-00007d30: 2020 2020 2020 2070 6f6f 6c5f 7374 7269         pool_stri
-00007d40: 6465 5f33 203d 2074 7269 616c 2e73 7567  de_3 = trial.sug
-00007d50: 6765 7374 5f69 6e74 2827 706f 6f6c 5f73  gest_int('pool_s
-00007d60: 7472 6964 655f 3327 2c20 312c 2033 2c20  tride_3', 1, 3, 
-00007d70: 7374 6570 3d31 290a 0a20 2020 2020 2020  step=1)..       
-00007d80: 2020 2020 2020 2020 2020 2020 2066 696c               fil
-00007d90: 7465 725f 3420 3d20 7472 6961 6c2e 7375  ter_4 = trial.su
-00007da0: 6767 6573 745f 696e 7428 2766 696c 7465  ggest_int('filte
-00007db0: 725f 3427 2c20 3132 2c20 3531 362c 2073  r_4', 12, 516, s
-00007dc0: 7465 703d 3132 290a 2020 2020 2020 2020  tep=12).        
-00007dd0: 2020 2020 2020 2020 2020 2020 6669 6c74              filt
-00007de0: 6572 5f73 697a 655f 3420 3d20 7472 6961  er_size_4 = tria
-00007df0: 6c2e 7375 6767 6573 745f 696e 7428 2766  l.suggest_int('f
-00007e00: 696c 7465 725f 7369 7a65 5f34 272c 2031  ilter_size_4', 1
-00007e10: 2c20 372c 2073 7465 703d 3229 0a20 2020  , 7, step=2).   
-00007e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007e30: 2073 7472 6964 6573 5f34 203d 2074 7269   strides_4 = tri
-00007e40: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-00007e50: 7374 7269 6465 735f 3427 2c20 312c 2033  strides_4', 1, 3
-00007e60: 2c20 7374 6570 3d31 290a 0a20 2020 2020  , step=1)..     
-00007e70: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00007e80: 696c 7465 725f 3520 3d20 7472 6961 6c2e  ilter_5 = trial.
-00007e90: 7375 6767 6573 745f 696e 7428 2766 696c  suggest_int('fil
-00007ea0: 7465 725f 3527 2c20 3132 2c20 3531 362c  ter_5', 12, 516,
-00007eb0: 2073 7465 703d 3132 290a 2020 2020 2020   step=12).      
-00007ec0: 2020 2020 2020 2020 2020 2020 2020 6669                fi
-00007ed0: 6c74 6572 5f73 697a 655f 3520 3d20 7472  lter_size_5 = tr
-00007ee0: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
-00007ef0: 2766 696c 7465 725f 7369 7a65 5f35 272c  'filter_size_5',
-00007f00: 2031 2c20 372c 2073 7465 703d 3229 0a20   1, 7, step=2). 
-00007f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007f20: 2020 2073 7472 6964 6573 5f35 203d 2074     strides_5 = t
-00007f30: 7269 616c 2e73 7567 6765 7374 5f69 6e74  rial.suggest_int
-00007f40: 2827 7374 7269 6465 735f 3527 2c20 312c  ('strides_5', 1,
-00007f50: 2033 2c20 7374 6570 3d31 2920 0a0a 2020   3, step=1) ..  
-00007f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007f70: 2020 2323 2320 4465 6e73 6520 4c61 7965    ### Dense Laye
-00007f80: 7273 2023 2323 0a20 2020 2020 2020 2020  rs ###.         
-00007f90: 2020 2020 2020 2020 2020 2064 656e 7365             dense
-00007fa0: 5f6e 6575 726f 6e73 5f31 203d 2074 7269  _neurons_1 = tri
-00007fb0: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-00007fc0: 6465 6e73 655f 6e65 7572 6f6e 735f 3127  dense_neurons_1'
-00007fd0: 2c20 3132 382c 2036 3430 302c 2073 7465  , 128, 6400, ste
-00007fe0: 703d 3132 3829 0a20 2020 2020 2020 2020  p=128).         
-00007ff0: 2020 2020 2020 2020 2020 2064 656e 7365             dense
-00008000: 5f6e 6575 726f 6e73 5f32 203d 2074 7269  _neurons_2 = tri
-00008010: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-00008020: 6465 6e73 655f 6e65 7572 6f6e 735f 3227  dense_neurons_2'
-00008030: 2c20 3132 382c 2036 3430 302c 2073 7465  , 128, 6400, ste
-00008040: 703d 3132 3829 0a20 2020 2020 2020 2020  p=128).         
-00008050: 2020 2020 2020 2020 2020 2064 726f 706f             dropo
-00008060: 7574 5f31 203d 2074 7269 616c 2e73 7567  ut_1 = trial.sug
-00008070: 6765 7374 5f66 6c6f 6174 2827 6472 6f70  gest_float('drop
-00008080: 6f75 745f 3127 2c20 302e 302c 2030 2e35  out_1', 0.0, 0.5
-00008090: 2c20 7374 6570 3d30 2e30 3129 0a20 2020  , step=0.01).   
-000080a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000080b0: 2064 726f 706f 7574 5f32 203d 2074 7269   dropout_2 = tri
-000080c0: 616c 2e73 7567 6765 7374 5f66 6c6f 6174  al.suggest_float
-000080d0: 2827 6472 6f70 6f75 745f 3227 2c20 302e  ('dropout_2', 0.
-000080e0: 302c 2030 2e35 2c20 7374 6570 3d30 2e30  0, 0.5, step=0.0
-000080f0: 3129 200a 0a20 2020 2020 2020 2020 2020  1) ..           
-00008100: 2020 2020 2020 2020 206d 6f64 656c 2c20           model, 
-00008110: 6869 7374 6f72 7920 3d20 636e 6e5f 6d6f  history = cnn_mo
-00008120: 6465 6c2e 416c 6578 4e65 7428 636c 6173  del.AlexNet(clas
-00008130: 735f 312c 2063 6c61 7373 5f32 2c20 696d  s_1, class_2, im
-00008140: 675f 6e75 6d5f 6368 616e 6e65 6c73 3d73  g_num_channels=s
-00008150: 656c 662e 696d 675f 6e75 6d5f 6368 616e  elf.img_num_chan
-00008160: 6e65 6c73 2c20 0a20 2020 2020 2020 2020  nels, .         
-00008170: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-00008180: 6f72 6d61 6c69 7a65 3d73 656c 662e 6e6f  ormalize=self.no
-00008190: 726d 616c 697a 652c 206d 696e 5f70 6978  rmalize, min_pix
-000081a0: 656c 3d6d 696e 5f70 6978 2c20 6d61 785f  el=min_pix, max_
-000081b0: 7069 7865 6c3d 6d61 785f 7069 782c 2076  pixel=max_pix, v
-000081c0: 616c 5f70 6f73 6974 6976 653d 7661 6c5f  al_positive=val_
-000081d0: 636c 6173 735f 312c 2076 616c 5f6e 6567  class_1, val_neg
-000081e0: 6174 6976 653d 7661 6c5f 636c 6173 735f  ative=val_class_
-000081f0: 322c 200a 2020 2020 2020 2020 2020 2020  2, .            
-00008200: 2020 2020 2020 2020 2020 2020 6570 6f63              epoc
-00008210: 6873 3d73 656c 662e 7472 6169 6e5f 6570  hs=self.train_ep
-00008220: 6f63 6873 2c20 6261 7463 685f 7369 7a65  ochs, batch_size
-00008230: 3d62 6174 6368 5f73 697a 652c 206f 7074  =batch_size, opt
-00008240: 696d 697a 6572 3d6f 7074 696d 697a 6572  imizer=optimizer
-00008250: 2c20 6c72 3d6c 722c 2064 6563 6179 3d64  , lr=lr, decay=d
-00008260: 6563 6179 2c20 6d6f 6d65 6e74 756d 3d6d  ecay, momentum=m
-00008270: 6f6d 656e 7475 6d2c 206e 6573 7465 726f  omentum, nestero
-00008280: 763d 6e65 7374 6572 6f76 2c20 0a20 2020  v=nesterov, .   
-00008290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000082a0: 2020 2020 2062 6574 615f 313d 6265 7461       beta_1=beta
-000082b0: 5f31 2c20 6265 7461 5f32 3d62 6574 615f  _1, beta_2=beta_
-000082c0: 322c 2061 6d73 6772 6164 3d61 6d73 6772  2, amsgrad=amsgr
-000082d0: 6164 2c20 6c6f 7373 3d6c 6f73 732c 2061  ad, loss=loss, a
-000082e0: 6374 6976 6174 696f 6e5f 636f 6e76 3d61  ctivation_conv=a
-000082f0: 6374 6976 6174 696f 6e5f 636f 6e76 2c20  ctivation_conv, 
-00008300: 6163 7469 7661 7469 6f6e 5f64 656e 7365  activation_dense
-00008310: 3d61 6374 6976 6174 696f 6e5f 6465 6e73  =activation_dens
-00008320: 652c 200a 2020 2020 2020 2020 2020 2020  e, .            
-00008330: 2020 2020 2020 2020 2020 2020 636f 6e76              conv
-00008340: 5f69 6e69 743d 636f 6e76 5f69 6e69 742c  _init=conv_init,
-00008350: 2064 656e 7365 5f69 6e69 743d 6465 6e73   dense_init=dens
-00008360: 655f 696e 6974 2c20 6d6f 6465 6c5f 7265  e_init, model_re
-00008370: 673d 6d6f 6465 6c5f 7265 672c 200a 2020  g=model_reg, .  
-00008380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008390: 2020 2020 2020 6669 6c74 6572 5f31 3d66        filter_1=f
-000083a0: 696c 7465 725f 312c 2066 696c 7465 725f  ilter_1, filter_
-000083b0: 7369 7a65 5f31 3d66 696c 7465 725f 7369  size_1=filter_si
-000083c0: 7a65 5f31 2c20 7374 7269 6465 735f 313d  ze_1, strides_1=
-000083d0: 7374 7269 6465 735f 312c 2070 6f6f 6c69  strides_1, pooli
-000083e0: 6e67 5f31 3d70 6f6f 6c69 6e67 5f31 2c20  ng_1=pooling_1, 
-000083f0: 706f 6f6c 5f73 697a 655f 313d 706f 6f6c  pool_size_1=pool
-00008400: 5f73 697a 655f 312c 2070 6f6f 6c5f 7374  _size_1, pool_st
-00008410: 7269 6465 5f31 3d70 6f6f 6c5f 7374 7269  ride_1=pool_stri
-00008420: 6465 5f31 2c0a 2020 2020 2020 2020 2020  de_1,.          
-00008430: 2020 2020 2020 2020 2020 2020 2020 6669                fi
-00008440: 6c74 6572 5f32 3d66 696c 7465 725f 322c  lter_2=filter_2,
-00008450: 2066 696c 7465 725f 7369 7a65 5f32 3d66   filter_size_2=f
-00008460: 696c 7465 725f 7369 7a65 5f32 2c20 7374  ilter_size_2, st
-00008470: 7269 6465 735f 323d 7374 7269 6465 735f  rides_2=strides_
-00008480: 322c 2070 6f6f 6c69 6e67 5f32 3d70 6f6f  2, pooling_2=poo
-00008490: 6c69 6e67 5f32 2c20 706f 6f6c 5f73 697a  ling_2, pool_siz
-000084a0: 655f 323d 706f 6f6c 5f73 697a 655f 322c  e_2=pool_size_2,
-000084b0: 2070 6f6f 6c5f 7374 7269 6465 5f32 3d70   pool_stride_2=p
-000084c0: 6f6f 6c5f 7374 7269 6465 5f32 2c0a 2020  ool_stride_2,.  
-000084d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000084e0: 2020 2020 2020 6669 6c74 6572 5f33 3d66        filter_3=f
-000084f0: 696c 7465 725f 332c 2066 696c 7465 725f  ilter_3, filter_
-00008500: 7369 7a65 5f33 3d66 696c 7465 725f 7369  size_3=filter_si
-00008510: 7a65 5f33 2c20 7374 7269 6465 735f 333d  ze_3, strides_3=
-00008520: 7374 7269 6465 735f 332c 2070 6f6f 6c69  strides_3, pooli
-00008530: 6e67 5f33 3d70 6f6f 6c69 6e67 5f33 2c20  ng_3=pooling_3, 
-00008540: 706f 6f6c 5f73 697a 655f 333d 706f 6f6c  pool_size_3=pool
-00008550: 5f73 697a 655f 332c 2070 6f6f 6c5f 7374  _size_3, pool_st
-00008560: 7269 6465 5f33 3d70 6f6f 6c5f 7374 7269  ride_3=pool_stri
-00008570: 6465 5f33 2c0a 2020 2020 2020 2020 2020  de_3,.          
-00008580: 2020 2020 2020 2020 2020 2020 2020 6669                fi
-00008590: 6c74 6572 5f34 3d66 696c 7465 725f 342c  lter_4=filter_4,
-000085a0: 2066 696c 7465 725f 7369 7a65 5f34 3d66   filter_size_4=f
-000085b0: 696c 7465 725f 7369 7a65 5f34 2c20 7374  ilter_size_4, st
-000085c0: 7269 6465 735f 343d 7374 7269 6465 735f  rides_4=strides_
-000085d0: 342c 200a 2020 2020 2020 2020 2020 2020  4, .            
-000085e0: 2020 2020 2020 2020 2020 2020 6669 6c74              filt
-000085f0: 6572 5f35 3d66 696c 7465 725f 352c 2066  er_5=filter_5, f
-00008600: 696c 7465 725f 7369 7a65 5f35 3d66 696c  ilter_size_5=fil
-00008610: 7465 725f 7369 7a65 5f35 2c20 7374 7269  ter_size_5, stri
-00008620: 6465 735f 353d 7374 7269 6465 735f 352c  des_5=strides_5,
-00008630: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00008640: 2020 2020 2020 2020 2064 656e 7365 5f6e           dense_n
-00008650: 6575 726f 6e73 5f31 3d64 656e 7365 5f6e  eurons_1=dense_n
-00008660: 6575 726f 6e73 5f31 2c20 6465 6e73 655f  eurons_1, dense_
-00008670: 6e65 7572 6f6e 735f 323d 6465 6e73 655f  neurons_2=dense_
-00008680: 6e65 7572 6f6e 735f 322c 2064 726f 706f  neurons_2, dropo
-00008690: 7574 5f31 3d64 726f 706f 7574 5f31 2c20  ut_1=dropout_1, 
-000086a0: 6472 6f70 6f75 745f 323d 6472 6f70 6f75  dropout_2=dropou
-000086b0: 745f 322c 200a 2020 2020 2020 2020 2020  t_2, .          
-000086c0: 2020 2020 2020 2020 2020 2020 2020 736d                sm
-000086d0: 6f74 655f 7361 6d70 6c69 6e67 3d73 656c  ote_sampling=sel
-000086e0: 662e 736d 6f74 655f 7361 6d70 6c69 6e67  f.smote_sampling
-000086f0: 2c20 6561 726c 795f 7374 6f70 5f63 616c  , early_stop_cal
-00008700: 6c62 6163 6b3d 6361 6c6c 6261 636b 732c  lback=callbacks,
-00008710: 2063 6865 636b 706f 696e 743d 4661 6c73   checkpoint=Fals
-00008720: 652c 2076 6572 626f 7365 3d73 656c 662e  e, verbose=self.
-00008730: 7665 7262 6f73 6529 0a0a 2020 2020 2020  verbose)..      
-00008740: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
-00008750: 636c 6620 3d3d 2027 7265 736e 6574 3138  clf == 'resnet18
-00008760: 273a 0a0a 2020 2020 2020 2020 2020 2020  ':..            
-00008770: 2020 2020 2323 2320 5265 6775 6c61 7269      ### Regulari
-00008780: 7a61 7469 6f6e 2054 6563 686e 6971 7565  zation Technique
-00008790: 2028 4e6f 7465 2074 6861 7420 6966 2075   (Note that if u
-000087a0: 7369 6e67 204c 524e 2c20 7468 656e 2074  sing LRN, then t
-000087b0: 6865 2062 6c6f 636b 7320 776f 6e27 7420  he blocks won't 
-000087c0: 6861 7665 2041 4e59 2072 6567 756c 6172  have ANY regular
-000087d0: 697a 6174 696f 6e20 7369 6e63 6520 7468  ization since th
-000087e0: 6520 6f6e 6c79 206f 7074 696f 6e20 6973  e only option is
-000087f0: 2027 6261 7463 685f 6e6f 726d 2720 666f   'batch_norm' fo
-00008800: 7220 7468 6520 626c 6f63 6b73 2920 2323  r the blocks) ##
-00008810: 230a 2020 2020 2020 2020 2020 2020 2020  #.              
-00008820: 2020 6d6f 6465 6c5f 7265 6720 3d20 7472    model_reg = tr
-00008830: 6961 6c2e 7375 6767 6573 745f 6361 7465  ial.suggest_cate
-00008840: 676f 7269 6361 6c28 276d 6f64 656c 5f72  gorical('model_r
-00008850: 6567 272c 205b 4e6f 6e65 2c20 276c 6f63  eg', [None, 'loc
-00008860: 616c 5f72 6573 706f 6e73 6527 2c20 2762  al_response', 'b
-00008870: 6174 6368 5f6e 6f72 6d27 5d29 0a0a 2020  atch_norm'])..  
-00008880: 2020 2020 2020 2020 2020 2020 2020 234f                #O
-00008890: 6e6c 7920 6f6e 6520 706f 6f6c 696e 6720  nly one pooling 
-000088a0: 6c61 7965 7220 6973 2075 7365 6420 6174  layer is used at
-000088b0: 2074 6865 2076 6572 7920 6265 6769 6e6e   the very beginn
-000088c0: 696e 6720 6f66 2074 6865 206d 6f64 656c  ing of the model
-000088d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000088e0: 2070 6f6f 6c69 6e67 203d 2074 7269 616c   pooling = trial
-000088f0: 2e73 7567 6765 7374 5f63 6174 6567 6f72  .suggest_categor
-00008900: 6963 616c 2827 706f 6f6c 696e 6727 2c20  ical('pooling', 
-00008910: 5b27 6d69 6e27 2c20 276d 6178 272c 2027  ['min', 'max', '
-00008920: 6176 6572 6167 6527 5d29 0a0a 2020 2020  average'])..    
-00008930: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-00008940: 656c 662e 6c69 6d69 745f 7365 6172 6368  elf.limit_search
-00008950: 3a20 2020 0a0a 2020 2020 2020 2020 2020  :   ..          
-00008960: 2020 2020 2020 2020 2020 6d6f 6465 6c2c            model,
-00008970: 2068 6973 746f 7279 203d 2063 6e6e 5f6d   history = cnn_m
-00008980: 6f64 656c 2e52 6573 6e65 7431 3828 636c  odel.Resnet18(cl
-00008990: 6173 735f 312c 2063 6c61 7373 5f32 2c20  ass_1, class_2, 
-000089a0: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
-000089b0: 3d73 656c 662e 696d 675f 6e75 6d5f 6368  =self.img_num_ch
-000089c0: 616e 6e65 6c73 2c20 0a20 2020 2020 2020  annels, .       
-000089d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000089e0: 206e 6f72 6d61 6c69 7a65 3d73 656c 662e   normalize=self.
-000089f0: 6e6f 726d 616c 697a 652c 206d 696e 5f70  normalize, min_p
-00008a00: 6978 656c 3d6d 696e 5f70 6978 2c20 6d61  ixel=min_pix, ma
-00008a10: 785f 7069 7865 6c3d 6d61 785f 7069 782c  x_pixel=max_pix,
-00008a20: 2076 616c 5f70 6f73 6974 6976 653d 7661   val_positive=va
-00008a30: 6c5f 636c 6173 735f 312c 2076 616c 5f6e  l_class_1, val_n
-00008a40: 6567 6174 6976 653d 7661 6c5f 636c 6173  egative=val_clas
-00008a50: 735f 322c 200a 2020 2020 2020 2020 2020  s_2, .          
-00008a60: 2020 2020 2020 2020 2020 2020 2020 6570                ep
-00008a70: 6f63 6873 3d73 656c 662e 7472 6169 6e5f  ochs=self.train_
-00008a80: 6570 6f63 6873 2c20 6261 7463 685f 7369  epochs, batch_si
-00008a90: 7a65 3d62 6174 6368 5f73 697a 652c 206f  ze=batch_size, o
-00008aa0: 7074 696d 697a 6572 3d6f 7074 696d 697a  ptimizer=optimiz
-00008ab0: 6572 2c20 6c72 3d6c 722c 2064 6563 6179  er, lr=lr, decay
-00008ac0: 3d64 6563 6179 2c20 6d6f 6d65 6e74 756d  =decay, momentum
-00008ad0: 3d6d 6f6d 656e 7475 6d2c 206e 6573 7465  =momentum, neste
-00008ae0: 726f 763d 6e65 7374 6572 6f76 2c20 0a20  rov=nesterov, . 
-00008af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008b00: 2020 2020 2020 2062 6574 615f 313d 6265         beta_1=be
-00008b10: 7461 5f31 2c20 6265 7461 5f32 3d62 6574  ta_1, beta_2=bet
-00008b20: 615f 322c 2061 6d73 6772 6164 3d61 6d73  a_2, amsgrad=ams
-00008b30: 6772 6164 2c20 6c6f 7373 3d6c 6f73 732c  grad, loss=loss,
-00008b40: 2061 6374 6976 6174 696f 6e5f 636f 6e76   activation_conv
-00008b50: 3d61 6374 6976 6174 696f 6e5f 636f 6e76  =activation_conv
-00008b60: 2c20 6163 7469 7661 7469 6f6e 5f64 656e  , activation_den
-00008b70: 7365 3d61 6374 6976 6174 696f 6e5f 6465  se=activation_de
-00008b80: 6e73 652c 200a 2020 2020 2020 2020 2020  nse, .          
-00008b90: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00008ba0: 6e76 5f69 6e69 743d 636f 6e76 5f69 6e69  nv_init=conv_ini
-00008bb0: 742c 2064 656e 7365 5f69 6e69 743d 6465  t, dense_init=de
-00008bc0: 6e73 655f 696e 6974 2c20 6d6f 6465 6c5f  nse_init, model_
-00008bd0: 7265 673d 6d6f 6465 6c5f 7265 672c 2070  reg=model_reg, p
-00008be0: 6f6f 6c69 6e67 3d70 6f6f 6c69 6e67 2c0a  ooling=pooling,.
-00008bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008c00: 2020 2020 2020 2020 736d 6f74 655f 7361          smote_sa
-00008c10: 6d70 6c69 6e67 3d73 656c 662e 736d 6f74  mpling=self.smot
-00008c20: 655f 7361 6d70 6c69 6e67 2c20 6561 726c  e_sampling, earl
-00008c30: 795f 7374 6f70 5f63 616c 6c62 6163 6b3d  y_stop_callback=
-00008c40: 6361 6c6c 6261 636b 732c 2063 6865 636b  callbacks, check
-00008c50: 706f 696e 743d 4661 6c73 652c 2076 6572  point=False, ver
-00008c60: 626f 7365 3d73 656c 662e 7665 7262 6f73  bose=self.verbos
-00008c70: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
-00008c80: 2020 2065 6c73 653a 0a0a 2020 2020 2020     else:..      
-00008c90: 2020 2020 2020 2020 2020 2020 2020 6669                fi
-00008ca0: 6c74 6572 7320 3d20 7472 6961 6c2e 7375  lters = trial.su
-00008cb0: 6767 6573 745f 696e 7428 2766 696c 7465  ggest_int('filte
-00008cc0: 7273 272c 2031 322c 2035 3136 2c20 7374  rs', 12, 516, st
-00008cd0: 6570 3d31 3229 0a20 2020 2020 2020 2020  ep=12).         
-00008ce0: 2020 2020 2020 2020 2020 2066 696c 7465             filte
-00008cf0: 725f 7369 7a65 203d 2074 7269 616c 2e73  r_size = trial.s
-00008d00: 7567 6765 7374 5f69 6e74 2827 6669 6c74  uggest_int('filt
-00008d10: 6572 5f73 697a 6527 2c20 312c 2037 2c20  er_size', 1, 7, 
-00008d20: 7374 6570 3d32 290a 2020 2020 2020 2020  step=2).        
-00008d30: 2020 2020 2020 2020 2020 2020 7374 7269              stri
-00008d40: 6465 7320 3d20 7472 6961 6c2e 7375 6767  des = trial.sugg
-00008d50: 6573 745f 696e 7428 2773 7472 6964 6573  est_int('strides
-00008d60: 272c 2031 2c20 332c 2073 7465 703d 3129  ', 1, 3, step=1)
-00008d70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00008d80: 2020 2020 2070 6f6f 6c5f 7369 7a65 203d       pool_size =
-00008d90: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
-00008da0: 6e74 2827 706f 6f6c 5f73 697a 6527 2c20  nt('pool_size', 
-00008db0: 312c 2037 2c20 7374 6570 3d32 290a 2020  1, 7, step=2).  
-00008dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008dd0: 2020 706f 6f6c 5f73 7472 6964 6520 3d20    pool_stride = 
-00008de0: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
-00008df0: 7428 2770 6f6f 6c5f 7374 7269 6465 272c  t('pool_stride',
-00008e00: 2031 2c20 332c 2073 7465 703d 3129 0a0a   1, 3, step=1)..
-00008e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008e20: 2020 2020 626c 6f63 6b5f 6669 6c74 6572      block_filter
-00008e30: 735f 3120 3d20 7472 6961 6c2e 7375 6767  s_1 = trial.sugg
-00008e40: 6573 745f 696e 7428 2762 6c6f 636b 5f66  est_int('block_f
-00008e50: 696c 7465 7273 5f31 272c 2031 322c 2035  ilters_1', 12, 5
-00008e60: 3136 2c20 7374 6570 3d31 3229 0a20 2020  16, step=12).   
-00008e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008e80: 2062 6c6f 636b 5f66 696c 7465 7273 5f32   block_filters_2
-00008e90: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-00008ea0: 5f69 6e74 2827 626c 6f63 6b5f 6669 6c74  _int('block_filt
-00008eb0: 6572 735f 3227 2c20 3132 2c20 3531 362c  ers_2', 12, 516,
-00008ec0: 2073 7465 703d 3132 2920 0a20 2020 2020   step=12) .     
-00008ed0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
-00008ee0: 6c6f 636b 5f66 696c 7465 7273 5f33 203d  lock_filters_3 =
-00008ef0: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
-00008f00: 6e74 2827 626c 6f63 6b5f 6669 6c74 6572  nt('block_filter
-00008f10: 735f 3327 2c20 3132 2c20 3531 362c 2073  s_3', 12, 516, s
-00008f20: 7465 703d 3132 290a 2020 2020 2020 2020  tep=12).        
-00008f30: 2020 2020 2020 2020 2020 2020 626c 6f63              bloc
-00008f40: 6b5f 6669 6c74 6572 735f 3420 3d20 7472  k_filters_4 = tr
-00008f50: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
-00008f60: 2762 6c6f 636b 5f66 696c 7465 7273 5f34  'block_filters_4
-00008f70: 272c 2031 322c 2035 3136 2c20 7374 6570  ', 12, 516, step
-00008f80: 3d31 3229 0a20 2020 2020 2020 2020 2020  =12).           
-00008f90: 2020 2020 2020 2020 2062 6c6f 636b 5f66           block_f
-00008fa0: 696c 7465 7273 5f73 697a 6520 3d20 7472  ilters_size = tr
-00008fb0: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
-00008fc0: 2762 6c6f 636b 5f66 696c 7465 7273 5f73  'block_filters_s
-00008fd0: 697a 6527 2c20 312c 2037 2c20 7374 6570  ize', 1, 7, step
-00008fe0: 3d32 290a 0a20 2020 2020 2020 2020 2020  =2)..           
-00008ff0: 2020 2020 2020 2020 206d 6f64 656c 2c20           model, 
-00009000: 6869 7374 6f72 7920 3d20 636e 6e5f 6d6f  history = cnn_mo
-00009010: 6465 6c2e 5265 736e 6574 3138 2863 6c61  del.Resnet18(cla
-00009020: 7373 5f31 2c20 636c 6173 735f 322c 2069  ss_1, class_2, i
-00009030: 6d67 5f6e 756d 5f63 6861 6e6e 656c 733d  mg_num_channels=
-00009040: 7365 6c66 2e69 6d67 5f6e 756d 5f63 6861  self.img_num_cha
-00009050: 6e6e 656c 732c 200a 2020 2020 2020 2020  nnels, .        
-00009060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009070: 6e6f 726d 616c 697a 653d 7365 6c66 2e6e  normalize=self.n
-00009080: 6f72 6d61 6c69 7a65 2c20 6d69 6e5f 7069  ormalize, min_pi
-00009090: 7865 6c3d 6d69 6e5f 7069 782c 206d 6178  xel=min_pix, max
-000090a0: 5f70 6978 656c 3d6d 6178 5f70 6978 2c20  _pixel=max_pix, 
-000090b0: 7661 6c5f 706f 7369 7469 7665 3d76 616c  val_positive=val
-000090c0: 5f63 6c61 7373 5f31 2c20 7661 6c5f 6e65  _class_1, val_ne
-000090d0: 6761 7469 7665 3d76 616c 5f63 6c61 7373  gative=val_class
-000090e0: 5f32 2c20 0a20 2020 2020 2020 2020 2020  _2, .           
-000090f0: 2020 2020 2020 2020 2020 2020 2065 706f               epo
-00009100: 6368 733d 7365 6c66 2e74 7261 696e 5f65  chs=self.train_e
-00009110: 706f 6368 732c 2062 6174 6368 5f73 697a  pochs, batch_siz
-00009120: 653d 6261 7463 685f 7369 7a65 2c20 6f70  e=batch_size, op
-00009130: 7469 6d69 7a65 723d 6f70 7469 6d69 7a65  timizer=optimize
-00009140: 722c 206c 723d 6c72 2c20 6465 6361 793d  r, lr=lr, decay=
-00009150: 6465 6361 792c 206d 6f6d 656e 7475 6d3d  decay, momentum=
-00009160: 6d6f 6d65 6e74 756d 2c20 6e65 7374 6572  momentum, nester
-00009170: 6f76 3d6e 6573 7465 726f 762c 200a 2020  ov=nesterov, .  
-00009180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009190: 2020 2020 2020 6265 7461 5f31 3d62 6574        beta_1=bet
-000091a0: 615f 312c 2062 6574 615f 323d 6265 7461  a_1, beta_2=beta
-000091b0: 5f32 2c20 616d 7367 7261 643d 616d 7367  _2, amsgrad=amsg
-000091c0: 7261 642c 206c 6f73 733d 6c6f 7373 2c20  rad, loss=loss, 
-000091d0: 6163 7469 7661 7469 6f6e 5f63 6f6e 763d  activation_conv=
-000091e0: 6163 7469 7661 7469 6f6e 5f63 6f6e 762c  activation_conv,
-000091f0: 2061 6374 6976 6174 696f 6e5f 6465 6e73   activation_dens
-00009200: 653d 6163 7469 7661 7469 6f6e 5f64 656e  e=activation_den
-00009210: 7365 2c20 0a20 2020 2020 2020 2020 2020  se, .           
-00009220: 2020 2020 2020 2020 2020 2020 2063 6f6e               con
-00009230: 765f 696e 6974 3d63 6f6e 765f 696e 6974  v_init=conv_init
-00009240: 2c20 6465 6e73 655f 696e 6974 3d64 656e  , dense_init=den
-00009250: 7365 5f69 6e69 742c 206d 6f64 656c 5f72  se_init, model_r
-00009260: 6567 3d6d 6f64 656c 5f72 6567 2c20 6669  eg=model_reg, fi
-00009270: 6c74 6572 733d 6669 6c74 6572 732c 2066  lters=filters, f
-00009280: 696c 7465 725f 7369 7a65 3d66 696c 7465  ilter_size=filte
-00009290: 725f 7369 7a65 2c20 7374 7269 6465 733d  r_size, strides=
-000092a0: 7374 7269 6465 732c 2020 0a20 2020 2020  strides,  .     
-000092b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000092c0: 2020 2070 6f6f 6c69 6e67 3d70 6f6f 6c69     pooling=pooli
-000092d0: 6e67 2c20 706f 6f6c 5f73 697a 653d 706f  ng, pool_size=po
-000092e0: 6f6c 5f73 697a 652c 2070 6f6f 6c5f 7374  ol_size, pool_st
-000092f0: 7269 6465 3d70 6f6f 6c5f 7374 7269 6465  ride=pool_stride
-00009300: 2c20 626c 6f63 6b5f 6669 6c74 6572 735f  , block_filters_
-00009310: 313d 626c 6f63 6b5f 6669 6c74 6572 735f  1=block_filters_
-00009320: 312c 2062 6c6f 636b 5f66 696c 7465 7273  1, block_filters
-00009330: 5f32 3d62 6c6f 636b 5f66 696c 7465 7273  _2=block_filters
-00009340: 5f32 2c20 0a20 2020 2020 2020 2020 2020  _2, .           
-00009350: 2020 2020 2020 2020 2020 2020 2062 6c6f               blo
-00009360: 636b 5f66 696c 7465 7273 5f33 3d62 6c6f  ck_filters_3=blo
-00009370: 636b 5f66 696c 7465 7273 5f33 2c20 626c  ck_filters_3, bl
-00009380: 6f63 6b5f 6669 6c74 6572 735f 343d 626c  ock_filters_4=bl
-00009390: 6f63 6b5f 6669 6c74 6572 735f 342c 2062  ock_filters_4, b
-000093a0: 6c6f 636b 5f66 696c 7465 7273 5f73 697a  lock_filters_siz
-000093b0: 653d 626c 6f63 6b5f 6669 6c74 6572 735f  e=block_filters_
-000093c0: 7369 7a65 2c20 0a20 2020 2020 2020 2020  size, .         
-000093d0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-000093e0: 6d6f 7465 5f73 616d 706c 696e 673d 7365  mote_sampling=se
-000093f0: 6c66 2e73 6d6f 7465 5f73 616d 706c 696e  lf.smote_samplin
-00009400: 672c 2065 6172 6c79 5f73 746f 705f 6361  g, early_stop_ca
-00009410: 6c6c 6261 636b 3d63 616c 6c62 6163 6b73  llback=callbacks
-00009420: 2c20 6368 6563 6b70 6f69 6e74 3d46 616c  , checkpoint=Fal
-00009430: 7365 2c20 7665 7262 6f73 653d 7365 6c66  se, verbose=self
-00009440: 2e76 6572 626f 7365 290a 0a20 2020 2020  .verbose)..     
-00009450: 2020 2020 2020 2065 6c69 6620 7365 6c66         elif self
-00009460: 2e63 6c66 203d 3d20 2763 7573 746f 6d5f  .clf == 'custom_
-00009470: 636e 6e27 3a0a 2020 2020 2020 2020 2020  cnn':.          
-00009480: 2020 2020 2020 6966 2073 656c 662e 6c69        if self.li
-00009490: 6d69 745f 7365 6172 6368 3a0a 2020 2020  mit_search:.    
-000094a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000094b0: 7072 696e 7428 2754 6865 7265 2069 7320  print('There is 
-000094c0: 6e6f 206c 696d 6974 5f73 6561 7263 6820  no limit_search 
-000094d0: 6f70 7469 6f6e 2069 6620 636c 663d 2263  option if clf="c
-000094e0: 7573 746f 6d5f 636e 6e22 2c20 6f70 7469  ustom_cnn", opti
-000094f0: 6d69 7a69 6e67 2061 6c6c 206c 6179 6572  mizing all layer
-00009500: 732e 2e2e 2729 0a0a 2020 2020 2020 2020  s...')..        
-00009510: 2020 2020 2020 2020 6d6f 6465 6c5f 7265          model_re
-00009520: 6720 3d20 7472 6961 6c2e 7375 6767 6573  g = trial.sugges
-00009530: 745f 6361 7465 676f 7269 6361 6c28 276d  t_categorical('m
-00009540: 6f64 656c 5f72 6567 272c 205b 4e6f 6e65  odel_reg', [None
-00009550: 2c20 276c 6f63 616c 5f72 6573 706f 6e73  , 'local_respons
-00009560: 6527 2c20 2762 6174 6368 5f6e 6f72 6d27  e', 'batch_norm'
-00009570: 5d29 0a20 2020 2020 2020 2020 2020 2020  ]).             
-00009580: 2020 2023 4375 7374 6f6d 2043 4e4e 2066     #Custom CNN f
-00009590: 756e 6374 696f 6e2c 2074 6865 2066 6972  unction, the fir
-000095a0: 7374 2043 4f4e 5620 6c61 7965 7220 6973  st CONV layer is
-000095b0: 2072 6571 7569 7265 642e 200a 2020 2020   required. .    
-000095c0: 2020 2020 2020 2020 2020 2020 6669 6c74              filt
-000095d0: 6572 5f31 203d 2074 7269 616c 2e73 7567  er_1 = trial.sug
-000095e0: 6765 7374 5f69 6e74 2827 6669 6c74 6572  gest_int('filter
-000095f0: 5f31 272c 2031 322c 2035 3136 2c20 7374  _1', 12, 516, st
-00009600: 6570 3d31 3229 0a20 2020 2020 2020 2020  ep=12).         
-00009610: 2020 2020 2020 2066 696c 7465 725f 7369         filter_si
-00009620: 7a65 5f31 203d 2074 7269 616c 2e73 7567  ze_1 = trial.sug
-00009630: 6765 7374 5f69 6e74 2827 6669 6c74 6572  gest_int('filter
-00009640: 5f73 697a 655f 3127 2c20 312c 2031 312c  _size_1', 1, 11,
-00009650: 2073 7465 703d 3229 0a20 2020 2020 2020   step=2).       
-00009660: 2020 2020 2020 2020 2070 6f6f 6c69 6e67           pooling
-00009670: 5f31 203d 2074 7269 616c 2e73 7567 6765  _1 = trial.sugge
-00009680: 7374 5f63 6174 6567 6f72 6963 616c 2827  st_categorical('
-00009690: 706f 6f6c 696e 675f 3127 2c20 5b27 6d69  pooling_1', ['mi
-000096a0: 6e27 2c20 276d 6178 272c 2027 6176 6572  n', 'max', 'aver
-000096b0: 6167 6527 5d29 0a20 2020 2020 2020 2020  age']).         
-000096c0: 2020 2020 2020 2070 6f6f 6c5f 7369 7a65         pool_size
-000096d0: 5f31 203d 2074 7269 616c 2e73 7567 6765  _1 = trial.sugge
-000096e0: 7374 5f69 6e74 2827 706f 6f6c 5f73 697a  st_int('pool_siz
-000096f0: 655f 3127 2c20 312c 2037 2c20 7374 6570  e_1', 1, 7, step
-00009700: 3d31 290a 2020 2020 2020 2020 2020 2020  =1).            
-00009710: 2020 2020 7374 7269 6465 735f 3120 3d20      strides_1 = 
-00009720: 706f 6f6c 5f73 7472 6964 655f 3120 3d20  pool_stride_1 = 
-00009730: 7374 7269 6465 735f 3220 3d20 706f 6f6c  strides_2 = pool
-00009740: 5f73 7472 6964 655f 3220 3d20 7374 7269  _stride_2 = stri
-00009750: 6465 735f 3320 3d20 706f 6f6c 5f73 7472  des_3 = pool_str
-00009760: 6964 655f 3320 3d20 310a 0a20 2020 2020  ide_3 = 1..     
-00009770: 2020 2020 2020 2020 2020 206e 756d 5f63             num_c
-00009780: 6f6e 765f 6c61 7965 7273 203d 2074 7269  onv_layers = tri
-00009790: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-000097a0: 6e75 6d5f 636f 6e76 5f6c 6179 6572 7327  num_conv_layers'
-000097b0: 2c20 312c 2033 2c20 7374 6570 3d31 290a  , 1, 3, step=1).
-000097c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000097d0: 2069 6620 6e75 6d5f 636f 6e76 5f6c 6179   if num_conv_lay
-000097e0: 6572 7320 3d3d 2031 3a0a 2020 2020 2020  ers == 1:.      
-000097f0: 2020 2020 2020 2020 2020 2020 2020 6669                fi
-00009800: 6c74 6572 5f32 203d 2066 696c 7465 725f  lter_2 = filter_
-00009810: 7369 7a65 5f32 203d 2070 6f6f 6c5f 7369  size_2 = pool_si
-00009820: 7a65 5f32 203d 2066 696c 7465 725f 3320  ze_2 = filter_3 
-00009830: 3d20 6669 6c74 6572 5f73 697a 655f 3320  = filter_size_3 
-00009840: 3d20 7374 7269 6465 735f 3320 3d20 706f  = strides_3 = po
-00009850: 6f6c 5f73 697a 655f 3320 3d20 303b 2070  ol_size_3 = 0; p
-00009860: 6f6f 6c69 6e67 5f32 203d 2070 6f6f 6c69  ooling_2 = pooli
-00009870: 6e67 5f33 203d 204e 6f6e 650a 2020 2020  ng_3 = None.    
-00009880: 2020 2020 2020 2020 2020 2020 6966 206e              if n
-00009890: 756d 5f63 6f6e 765f 6c61 7965 7273 203e  um_conv_layers >
-000098a0: 3d20 323a 0a20 2020 2020 2020 2020 2020  = 2:.           
-000098b0: 2020 2020 2020 2020 2066 696c 7465 725f           filter_
-000098c0: 3220 3d20 7472 6961 6c2e 7375 6767 6573  2 = trial.sugges
-000098d0: 745f 696e 7428 2766 696c 7465 725f 3227  t_int('filter_2'
-000098e0: 2c20 3132 2c20 3531 362c 2073 7465 703d  , 12, 516, step=
-000098f0: 3132 290a 2020 2020 2020 2020 2020 2020  12).            
-00009900: 2020 2020 2020 2020 6669 6c74 6572 5f73          filter_s
-00009910: 697a 655f 3220 3d20 7472 6961 6c2e 7375  ize_2 = trial.su
-00009920: 6767 6573 745f 696e 7428 2766 696c 7465  ggest_int('filte
-00009930: 725f 7369 7a65 5f32 272c 2031 2c20 372c  r_size_2', 1, 7,
-00009940: 2073 7465 703d 3229 0a20 2020 2020 2020   step=2).       
-00009950: 2020 2020 2020 2020 2020 2020 2070 6f6f               poo
-00009960: 6c69 6e67 5f32 203d 2074 7269 616c 2e73  ling_2 = trial.s
-00009970: 7567 6765 7374 5f63 6174 6567 6f72 6963  uggest_categoric
-00009980: 616c 2827 706f 6f6c 696e 675f 3227 2c20  al('pooling_2', 
-00009990: 5b27 6d69 6e27 2c20 276d 6178 272c 2027  ['min', 'max', '
-000099a0: 6176 6572 6167 6527 5d29 0a20 2020 2020  average']).     
-000099b0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-000099c0: 6f6f 6c5f 7369 7a65 5f32 203d 2074 7269  ool_size_2 = tri
-000099d0: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-000099e0: 706f 6f6c 5f73 697a 655f 3227 2c20 312c  pool_size_2', 1,
-000099f0: 2037 2c20 7374 6570 3d31 290a 2020 2020   7, step=1).    
-00009a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009a10: 6669 6c74 6572 5f33 203d 2066 696c 7465  filter_3 = filte
-00009a20: 725f 7369 7a65 5f33 203d 2070 6f6f 6c5f  r_size_3 = pool_
-00009a30: 7369 7a65 5f33 203d 2030 3b20 706f 6f6c  size_3 = 0; pool
-00009a40: 696e 675f 3320 3d20 4e6f 6e65 0a20 2020  ing_3 = None.   
-00009a50: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00009a60: 6e75 6d5f 636f 6e76 5f6c 6179 6572 7320  num_conv_layers 
-00009a70: 3d3d 2033 3a0a 2020 2020 2020 2020 2020  == 3:.          
-00009a80: 2020 2020 2020 2020 2020 6669 6c74 6572            filter
-00009a90: 5f33 203d 2074 7269 616c 2e73 7567 6765  _3 = trial.sugge
-00009aa0: 7374 5f69 6e74 2827 6669 6c74 6572 5f33  st_int('filter_3
-00009ab0: 272c 2031 322c 2035 3136 2c20 7374 6570  ', 12, 516, step
-00009ac0: 3d31 3229 0a20 2020 2020 2020 2020 2020  =12).           
-00009ad0: 2020 2020 2020 2020 2066 696c 7465 725f           filter_
-00009ae0: 7369 7a65 5f33 203d 2074 7269 616c 2e73  size_3 = trial.s
-00009af0: 7567 6765 7374 5f69 6e74 2827 6669 6c74  uggest_int('filt
-00009b00: 6572 5f73 697a 655f 3327 2c20 312c 2037  er_size_3', 1, 7
-00009b10: 2c20 7374 6570 3d32 290a 2020 2020 2020  , step=2).      
-00009b20: 2020 2020 2020 2020 2020 2020 2020 706f                po
-00009b30: 6f6c 696e 675f 3320 3d20 7472 6961 6c2e  oling_3 = trial.
-00009b40: 7375 6767 6573 745f 6361 7465 676f 7269  suggest_categori
-00009b50: 6361 6c28 2770 6f6f 6c69 6e67 5f33 272c  cal('pooling_3',
-00009b60: 205b 276d 696e 272c 2027 6d61 7827 2c20   ['min', 'max', 
-00009b70: 2761 7665 7261 6765 275d 290a 2020 2020  'average']).    
-00009b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009b90: 706f 6f6c 5f73 697a 655f 3320 3d20 7472  pool_size_3 = tr
-00009ba0: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
-00009bb0: 2770 6f6f 6c5f 7369 7a65 5f33 272c 2031  'pool_size_3', 1
-00009bc0: 2c20 372c 2073 7465 703d 3129 0a0a 2020  , 7, step=1)..  
-00009bd0: 2020 2020 2020 2020 2020 2020 2020 2323                ##
-00009be0: 2320 4465 6e73 6520 4c61 7965 7273 2023  # Dense Layers #
-00009bf0: 2323 0a0a 2020 2020 2020 2020 2020 2020  ##..            
-00009c00: 2020 2020 6465 6e73 655f 6e65 7572 6f6e      dense_neuron
-00009c10: 735f 3120 3d20 7472 6961 6c2e 7375 6767  s_1 = trial.sugg
-00009c20: 6573 745f 696e 7428 2764 656e 7365 5f6e  est_int('dense_n
-00009c30: 6575 726f 6e73 5f31 272c 2031 3238 2c20  eurons_1', 128, 
-00009c40: 3634 3030 2c20 7374 6570 3d31 3238 290a  6400, step=128).
-00009c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009c60: 6472 6f70 6f75 745f 3120 3d20 7472 6961  dropout_1 = tria
-00009c70: 6c2e 7375 6767 6573 745f 666c 6f61 7428  l.suggest_float(
-00009c80: 2764 726f 706f 7574 5f31 272c 2030 2e30  'dropout_1', 0.0
-00009c90: 2c20 302e 352c 2073 7465 703d 302e 3031  , 0.5, step=0.01
-00009ca0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00009cb0: 2020 6e75 6d5f 6465 6e73 655f 6c61 7965    num_dense_laye
-00009cc0: 7273 203d 2074 7269 616c 2e73 7567 6765  rs = trial.sugge
-00009cd0: 7374 5f69 6e74 2827 6e75 6d5f 6465 6e73  st_int('num_dens
-00009ce0: 655f 6c61 7965 7273 272c 2031 2c20 332c  e_layers', 1, 3,
-00009cf0: 2073 7465 703d 3129 0a0a 2020 2020 2020   step=1)..      
-00009d00: 2020 2020 2020 2020 2020 6966 206e 756d            if num
-00009d10: 5f64 656e 7365 5f6c 6179 6572 7320 3d3d  _dense_layers ==
-00009d20: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
-00009d30: 2020 2020 2020 2020 6465 6e73 655f 6e65          dense_ne
-00009d40: 7572 6f6e 735f 3220 3d20 6472 6f70 6f75  urons_2 = dropou
-00009d50: 745f 3220 3d20 6465 6e73 655f 6e65 7572  t_2 = dense_neur
-00009d60: 6f6e 735f 3320 3d20 6472 6f70 6f75 745f  ons_3 = dropout_
-00009d70: 3320 3d20 300a 2020 2020 2020 2020 2020  3 = 0.          
-00009d80: 2020 2020 2020 6966 206e 756d 5f64 656e        if num_den
-00009d90: 7365 5f6c 6179 6572 7320 3e3d 2032 3a0a  se_layers >= 2:.
-00009da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009db0: 2020 2020 6465 6e73 655f 6e65 7572 6f6e      dense_neuron
-00009dc0: 735f 3220 3d20 7472 6961 6c2e 7375 6767  s_2 = trial.sugg
-00009dd0: 6573 745f 696e 7428 2764 656e 7365 5f6e  est_int('dense_n
-00009de0: 6575 726f 6e73 5f32 272c 2031 3238 2c20  eurons_2', 128, 
-00009df0: 3634 3030 2c20 7374 6570 3d31 3238 290a  6400, step=128).
-00009e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009e10: 2020 2020 6472 6f70 6f75 745f 3220 3d20      dropout_2 = 
-00009e20: 7472 6961 6c2e 7375 6767 6573 745f 666c  trial.suggest_fl
-00009e30: 6f61 7428 2764 726f 706f 7574 5f32 272c  oat('dropout_2',
-00009e40: 2030 2e30 2c20 302e 352c 2073 7465 703d   0.0, 0.5, step=
-00009e50: 302e 3031 290a 2020 2020 2020 2020 2020  0.01).          
-00009e60: 2020 2020 2020 2020 2020 6465 6e73 655f            dense_
-00009e70: 6e65 7572 6f6e 735f 3320 3d20 6472 6f70  neurons_3 = drop
-00009e80: 6f75 745f 3320 3d20 300a 2020 2020 2020  out_3 = 0.      
-00009e90: 2020 2020 2020 2020 2020 6966 206e 756d            if num
-00009ea0: 5f64 656e 7365 5f6c 6179 6572 7320 3d3d  _dense_layers ==
-00009eb0: 2033 3a0a 2020 2020 2020 2020 2020 2020   3:.            
-00009ec0: 2020 2020 2020 2020 6465 6e73 655f 6e65          dense_ne
-00009ed0: 7572 6f6e 735f 3320 3d20 7472 6961 6c2e  urons_3 = trial.
-00009ee0: 7375 6767 6573 745f 696e 7428 2764 656e  suggest_int('den
-00009ef0: 7365 5f6e 6575 726f 6e73 5f33 272c 2031  se_neurons_3', 1
-00009f00: 3238 2c20 3634 3030 2c20 7374 6570 3d31  28, 6400, step=1
-00009f10: 3238 290a 2020 2020 2020 2020 2020 2020  28).            
-00009f20: 2020 2020 2020 2020 6472 6f70 6f75 745f          dropout_
-00009f30: 3320 3d20 7472 6961 6c2e 7375 6767 6573  3 = trial.sugges
-00009f40: 745f 666c 6f61 7428 2764 726f 706f 7574  t_float('dropout
-00009f50: 5f33 272c 2030 2e30 2c20 302e 352c 2073  _3', 0.0, 0.5, s
-00009f60: 7465 703d 302e 3031 290a 0a20 2020 2020  tep=0.01)..     
-00009f70: 2020 2020 2020 2020 2020 206d 6f64 656c             model
-00009f80: 2c20 6869 7374 6f72 7920 3d20 636e 6e5f  , history = cnn_
-00009f90: 6d6f 6465 6c2e 6375 7374 6f6d 5f6d 6f64  model.custom_mod
-00009fa0: 656c 2863 6c61 7373 5f31 2c20 636c 6173  el(class_1, clas
-00009fb0: 735f 322c 2069 6d67 5f6e 756d 5f63 6861  s_2, img_num_cha
-00009fc0: 6e6e 656c 733d 7365 6c66 2e69 6d67 5f6e  nnels=self.img_n
-00009fd0: 756d 5f63 6861 6e6e 656c 732c 200a 2020  um_channels, .  
-00009fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009ff0: 2020 6e6f 726d 616c 697a 653d 7365 6c66    normalize=self
-0000a000: 2e6e 6f72 6d61 6c69 7a65 2c20 6d69 6e5f  .normalize, min_
-0000a010: 7069 7865 6c3d 6d69 6e5f 7069 782c 206d  pixel=min_pix, m
-0000a020: 6178 5f70 6978 656c 3d6d 6178 5f70 6978  ax_pixel=max_pix
-0000a030: 2c20 7661 6c5f 706f 7369 7469 7665 3d76  , val_positive=v
-0000a040: 616c 5f63 6c61 7373 5f31 2c20 7661 6c5f  al_class_1, val_
-0000a050: 6e65 6761 7469 7665 3d76 616c 5f63 6c61  negative=val_cla
-0000a060: 7373 5f32 2c20 0a20 2020 2020 2020 2020  ss_2, .         
-0000a070: 2020 2020 2020 2020 2020 2065 706f 6368             epoch
-0000a080: 733d 7365 6c66 2e74 7261 696e 5f65 706f  s=self.train_epo
-0000a090: 6368 732c 2062 6174 6368 5f73 697a 653d  chs, batch_size=
-0000a0a0: 6261 7463 685f 7369 7a65 2c20 6f70 7469  batch_size, opti
-0000a0b0: 6d69 7a65 723d 6f70 7469 6d69 7a65 722c  mizer=optimizer,
-0000a0c0: 206c 723d 6c72 2c20 6465 6361 793d 6465   lr=lr, decay=de
-0000a0d0: 6361 792c 206d 6f6d 656e 7475 6d3d 6d6f  cay, momentum=mo
-0000a0e0: 6d65 6e74 756d 2c20 6e65 7374 6572 6f76  mentum, nesterov
-0000a0f0: 3d6e 6573 7465 726f 762c 200a 2020 2020  =nesterov, .    
-0000a100: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a110: 6265 7461 5f31 3d62 6574 615f 312c 2062  beta_1=beta_1, b
-0000a120: 6574 615f 323d 6265 7461 5f32 2c20 616d  eta_2=beta_2, am
-0000a130: 7367 7261 643d 616d 7367 7261 642c 206c  sgrad=amsgrad, l
-0000a140: 6f73 733d 6c6f 7373 2c20 6163 7469 7661  oss=loss, activa
-0000a150: 7469 6f6e 5f63 6f6e 763d 6163 7469 7661  tion_conv=activa
-0000a160: 7469 6f6e 5f63 6f6e 762c 2061 6374 6976  tion_conv, activ
-0000a170: 6174 696f 6e5f 6465 6e73 653d 6163 7469  ation_dense=acti
-0000a180: 7661 7469 6f6e 5f64 656e 7365 2c20 0a20  vation_dense, . 
-0000a190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a1a0: 2020 2063 6f6e 765f 696e 6974 3d63 6f6e     conv_init=con
-0000a1b0: 765f 696e 6974 2c20 6465 6e73 655f 696e  v_init, dense_in
-0000a1c0: 6974 3d64 656e 7365 5f69 6e69 742c 206d  it=dense_init, m
-0000a1d0: 6f64 656c 5f72 6567 3d6d 6f64 656c 5f72  odel_reg=model_r
-0000a1e0: 6567 2c20 0a20 2020 2020 2020 2020 2020  eg, .           
-0000a1f0: 2020 2020 2020 2020 2066 696c 7465 725f           filter_
-0000a200: 313d 6669 6c74 6572 5f31 2c20 6669 6c74  1=filter_1, filt
-0000a210: 6572 5f73 697a 655f 313d 6669 6c74 6572  er_size_1=filter
-0000a220: 5f73 697a 655f 312c 2073 7472 6964 6573  _size_1, strides
-0000a230: 5f31 3d73 7472 6964 6573 5f31 2c20 706f  _1=strides_1, po
-0000a240: 6f6c 696e 675f 313d 706f 6f6c 696e 675f  oling_1=pooling_
-0000a250: 312c 2070 6f6f 6c5f 7369 7a65 5f31 3d70  1, pool_size_1=p
-0000a260: 6f6f 6c5f 7369 7a65 5f31 2c20 706f 6f6c  ool_size_1, pool
-0000a270: 5f73 7472 6964 655f 313d 706f 6f6c 5f73  _stride_1=pool_s
-0000a280: 7472 6964 655f 312c 200a 2020 2020 2020  tride_1, .      
-0000a290: 2020 2020 2020 2020 2020 2020 2020 6669                fi
-0000a2a0: 6c74 6572 5f32 3d66 696c 7465 725f 322c  lter_2=filter_2,
-0000a2b0: 2066 696c 7465 725f 7369 7a65 5f32 3d66   filter_size_2=f
-0000a2c0: 696c 7465 725f 7369 7a65 5f32 2c20 7374  ilter_size_2, st
-0000a2d0: 7269 6465 735f 323d 7374 7269 6465 735f  rides_2=strides_
-0000a2e0: 322c 2070 6f6f 6c69 6e67 5f32 3d70 6f6f  2, pooling_2=poo
-0000a2f0: 6c69 6e67 5f32 2c20 706f 6f6c 5f73 697a  ling_2, pool_siz
-0000a300: 655f 323d 706f 6f6c 5f73 697a 655f 322c  e_2=pool_size_2,
-0000a310: 2070 6f6f 6c5f 7374 7269 6465 5f32 3d70   pool_stride_2=p
-0000a320: 6f6f 6c5f 7374 7269 6465 5f32 2c20 0a20  ool_stride_2, . 
-0000a330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a340: 2020 2066 696c 7465 725f 333d 6669 6c74     filter_3=filt
-0000a350: 6572 5f33 2c20 6669 6c74 6572 5f73 697a  er_3, filter_siz
-0000a360: 655f 333d 6669 6c74 6572 5f73 697a 655f  e_3=filter_size_
-0000a370: 332c 2073 7472 6964 6573 5f33 3d73 7472  3, strides_3=str
-0000a380: 6964 6573 5f33 2c20 706f 6f6c 696e 675f  ides_3, pooling_
-0000a390: 333d 706f 6f6c 696e 675f 332c 2070 6f6f  3=pooling_3, poo
-0000a3a0: 6c5f 7369 7a65 5f33 3d70 6f6f 6c5f 7369  l_size_3=pool_si
-0000a3b0: 7a65 5f33 2c20 706f 6f6c 5f73 7472 6964  ze_3, pool_strid
-0000a3c0: 655f 333d 706f 6f6c 5f73 7472 6964 655f  e_3=pool_stride_
-0000a3d0: 332c 200a 2020 2020 2020 2020 2020 2020  3, .            
-0000a3e0: 2020 2020 2020 2020 6465 6e73 655f 6e65          dense_ne
-0000a3f0: 7572 6f6e 735f 313d 6465 6e73 655f 6e65  urons_1=dense_ne
-0000a400: 7572 6f6e 735f 312c 2064 656e 7365 5f6e  urons_1, dense_n
-0000a410: 6575 726f 6e73 5f32 3d64 656e 7365 5f6e  eurons_2=dense_n
-0000a420: 6575 726f 6e73 5f32 2c20 6465 6e73 655f  eurons_2, dense_
-0000a430: 6e65 7572 6f6e 735f 333d 6465 6e73 655f  neurons_3=dense_
-0000a440: 6e65 7572 6f6e 735f 332c 200a 2020 2020  neurons_3, .    
-0000a450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a460: 6472 6f70 6f75 745f 313d 6472 6f70 6f75  dropout_1=dropou
-0000a470: 745f 312c 2064 726f 706f 7574 5f32 3d64  t_1, dropout_2=d
-0000a480: 726f 706f 7574 5f32 2c20 6472 6f70 6f75  ropout_2, dropou
-0000a490: 745f 333d 6472 6f70 6f75 745f 332c 2073  t_3=dropout_3, s
-0000a4a0: 6d6f 7465 5f73 616d 706c 696e 673d 7365  mote_sampling=se
-0000a4b0: 6c66 2e73 6d6f 7465 5f73 616d 706c 696e  lf.smote_samplin
-0000a4c0: 672c 2020 0a20 2020 2020 2020 2020 2020  g,  .           
-0000a4d0: 2020 2020 2020 2020 2065 6172 6c79 5f73           early_s
-0000a4e0: 746f 705f 6361 6c6c 6261 636b 3d63 616c  top_callback=cal
-0000a4f0: 6c62 6163 6b73 2c20 6368 6563 6b70 6f69  lbacks, checkpoi
-0000a500: 6e74 3d46 616c 7365 2c20 7665 7262 6f73  nt=False, verbos
-0000a510: 653d 7365 6c66 2e76 6572 626f 7365 290a  e=self.verbose).
-0000a520: 0a20 2020 2020 2020 2020 2020 2065 6c69  .            eli
-0000a530: 6620 7365 6c66 2e63 6c66 203d 3d20 2776  f self.clf == 'v
-0000a540: 6767 3136 273a 0a20 2020 2020 2020 2020  gg16':.         
-0000a550: 2020 2020 2020 2023 2323 2052 6567 756c         ### Regul
-0000a560: 6172 697a 6174 696f 6e20 5465 6368 6e69  arization Techni
-0000a570: 7175 6520 2842 4e20 6973 206e 6577 6572  que (BN is newer
-0000a580: 2c20 5647 4731 3620 7573 6564 204e 6f6e  , VGG16 used Non
-0000a590: 6529 2023 2323 0a20 2020 2020 2020 2020  e) ###.         
-0000a5a0: 2020 2020 2020 206d 6f64 656c 5f72 6567         model_reg
-0000a5b0: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-0000a5c0: 5f63 6174 6567 6f72 6963 616c 2827 6d6f  _categorical('mo
-0000a5d0: 6465 6c5f 7265 6727 2c20 5b4e 6f6e 652c  del_reg', [None,
-0000a5e0: 2027 6261 7463 685f 6e6f 726d 272c 2027   'batch_norm', '
-0000a5f0: 6c6f 6361 6c5f 7265 7370 6f6e 7365 275d  local_response']
-0000a600: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
-0000a610: 2020 2023 2323 204f 6e6c 7920 7468 6520     ### Only the 
-0000a620: 706f 6f6c 696e 6720 7479 7065 7320 6172  pooling types ar
-0000a630: 6520 6f70 7469 6d69 7a65 6420 6966 206c  e optimized if l
-0000a640: 696d 6974 5f73 6561 7263 683d 5472 7565  imit_search=True
-0000a650: 2023 2323 0a20 2020 2020 2020 2020 2020   ###.           
-0000a660: 2020 2020 2070 6f6f 6c69 6e67 5f31 203d       pooling_1 =
-0000a670: 2074 7269 616c 2e73 7567 6765 7374 5f63   trial.suggest_c
-0000a680: 6174 6567 6f72 6963 616c 2827 706f 6f6c  ategorical('pool
-0000a690: 696e 675f 3127 2c20 5b27 6d69 6e27 2c20  ing_1', ['min', 
-0000a6a0: 276d 6178 272c 2027 6176 6572 6167 6527  'max', 'average'
-0000a6b0: 5d29 0a20 2020 2020 2020 2020 2020 2020  ]).             
-0000a6c0: 2020 2070 6f6f 6c69 6e67 5f32 203d 2074     pooling_2 = t
-0000a6d0: 7269 616c 2e73 7567 6765 7374 5f63 6174  rial.suggest_cat
-0000a6e0: 6567 6f72 6963 616c 2827 706f 6f6c 696e  egorical('poolin
-0000a6f0: 675f 3227 2c20 5b27 6d69 6e27 2c20 276d  g_2', ['min', 'm
-0000a700: 6178 272c 2027 6176 6572 6167 6527 5d29  ax', 'average'])
-0000a710: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000a720: 2070 6f6f 6c69 6e67 5f33 203d 2074 7269   pooling_3 = tri
-0000a730: 616c 2e73 7567 6765 7374 5f63 6174 6567  al.suggest_categ
-0000a740: 6f72 6963 616c 2827 706f 6f6c 696e 675f  orical('pooling_
-0000a750: 3327 2c20 5b27 6d69 6e27 2c20 276d 6178  3', ['min', 'max
-0000a760: 272c 2027 6176 6572 6167 6527 5d29 0a20  ', 'average']). 
-0000a770: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-0000a780: 6f6f 6c69 6e67 5f34 203d 2074 7269 616c  ooling_4 = trial
-0000a790: 2e73 7567 6765 7374 5f63 6174 6567 6f72  .suggest_categor
-0000a7a0: 6963 616c 2827 706f 6f6c 696e 675f 3427  ical('pooling_4'
-0000a7b0: 2c20 5b27 6d69 6e27 2c20 276d 6178 272c  , ['min', 'max',
-0000a7c0: 2027 6176 6572 6167 6527 5d29 0a20 2020   'average']).   
-0000a7d0: 2020 2020 2020 2020 2020 2020 2070 6f6f               poo
-0000a7e0: 6c69 6e67 5f35 203d 2074 7269 616c 2e73  ling_5 = trial.s
-0000a7f0: 7567 6765 7374 5f63 6174 6567 6f72 6963  uggest_categoric
-0000a800: 616c 2827 706f 6f6c 696e 675f 3527 2c20  al('pooling_5', 
-0000a810: 5b27 6d69 6e27 2c20 276d 6178 272c 2027  ['min', 'max', '
-0000a820: 6176 6572 6167 6527 5d29 0a0a 2020 2020  average'])..    
-0000a830: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-0000a840: 656c 662e 6c69 6d69 745f 7365 6172 6368  elf.limit_search
-0000a850: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000a860: 2020 2020 2020 6d6f 6465 6c2c 2068 6973        model, his
-0000a870: 746f 7279 203d 2063 6e6e 5f6d 6f64 656c  tory = cnn_model
-0000a880: 2e56 4747 3136 2863 6c61 7373 5f31 2c20  .VGG16(class_1, 
-0000a890: 636c 6173 735f 322c 2069 6d67 5f6e 756d  class_2, img_num
-0000a8a0: 5f63 6861 6e6e 656c 733d 7365 6c66 2e69  _channels=self.i
-0000a8b0: 6d67 5f6e 756d 5f63 6861 6e6e 656c 732c  mg_num_channels,
-0000a8c0: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-0000a8d0: 2020 2020 2020 2020 2020 6e6f 726d 616c            normal
-0000a8e0: 697a 653d 7365 6c66 2e6e 6f72 6d61 6c69  ize=self.normali
-0000a8f0: 7a65 2c20 6d69 6e5f 7069 7865 6c3d 6d69  ze, min_pixel=mi
-0000a900: 6e5f 7069 782c 206d 6178 5f70 6978 656c  n_pix, max_pixel
-0000a910: 3d6d 6178 5f70 6978 2c20 7661 6c5f 706f  =max_pix, val_po
-0000a920: 7369 7469 7665 3d76 616c 5f63 6c61 7373  sitive=val_class
-0000a930: 5f31 2c20 7661 6c5f 6e65 6761 7469 7665  _1, val_negative
-0000a940: 3d76 616c 5f63 6c61 7373 5f32 2c20 0a20  =val_class_2, . 
-0000a950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a960: 2020 2020 2020 2065 706f 6368 733d 7365         epochs=se
-0000a970: 6c66 2e74 7261 696e 5f65 706f 6368 732c  lf.train_epochs,
-0000a980: 2062 6174 6368 5f73 697a 653d 6261 7463   batch_size=batc
-0000a990: 685f 7369 7a65 2c20 6f70 7469 6d69 7a65  h_size, optimize
-0000a9a0: 723d 6f70 7469 6d69 7a65 722c 206c 723d  r=optimizer, lr=
-0000a9b0: 6c72 2c20 6465 6361 793d 6465 6361 792c  lr, decay=decay,
-0000a9c0: 206d 6f6d 656e 7475 6d3d 6d6f 6d65 6e74   momentum=moment
-0000a9d0: 756d 2c20 6e65 7374 6572 6f76 3d6e 6573  um, nesterov=nes
-0000a9e0: 7465 726f 762c 200a 2020 2020 2020 2020  terov, .        
+00000080: 790a 696d 706f 7274 2067 632c 2073 656c  y.import gc, sel
+00000090: 6563 746f 7273 2c20 7465 726d 696f 730a  ectors, termios.
+000000a0: 6f73 2e65 6e76 6972 6f6e 5b27 5059 5448  os.environ['PYTH
+000000b0: 4f4e 4841 5348 5345 4544 275d 2c20 6f73  ONHASHSEED'], os
+000000c0: 2e65 6e76 6972 6f6e 5b22 5446 5f44 4554  .environ["TF_DET
+000000d0: 4552 4d49 4e49 5354 4943 5f4f 5053 225d  ERMINISTIC_OPS"]
+000000e0: 203d 2027 3027 2c20 2731 270a 696d 706f   = '0', '1'.impo
+000000f0: 7274 2074 656e 736f 7266 6c6f 7720 6173  rt tensorflow as
+00000100: 2074 660a 0a69 6d70 6f72 7420 6e75 6d70   tf..import nump
+00000110: 7920 6173 206e 700a 696d 706f 7274 2072  y as np.import r
+00000120: 616e 646f 6d20 6173 2070 7974 686f 6e5f  andom as python_
+00000130: 7261 6e64 6f6d 0a6e 702e 7261 6e64 6f6d  random.np.random
+00000140: 2e73 6565 6428 3139 3039 292c 2070 7974  .seed(1909), pyt
+00000150: 686f 6e5f 7261 6e64 6f6d 2e73 6565 6428  hon_random.seed(
+00000160: 3139 3039 292c 2074 662e 7261 6e64 6f6d  1909), tf.random
+00000170: 2e73 6574 5f73 6565 6428 3139 3039 2920  .set_seed(1909) 
+00000180: 2323 6874 7470 733a 2f2f 6b65 7261 732e  ##https://keras.
+00000190: 696f 2f67 6574 7469 6e67 5f73 7461 7274  io/getting_start
+000001a0: 6564 2f66 6171 2f23 686f 772d 6361 6e2d  ed/faq/#how-can-
+000001b0: 692d 6f62 7461 696e 2d72 6570 726f 6475  i-obtain-reprodu
+000001c0: 6369 626c 652d 7265 7375 6c74 732d 7573  cible-results-us
+000001d0: 696e 672d 6b65 7261 732d 6475 7269 6e67  ing-keras-during
+000001e0: 2d64 6576 656c 6f70 6d65 6e74 2323 0a66  -development##.f
+000001f0: 726f 6d20 7061 6e64 6173 2069 6d70 6f72  rom pandas impor
+00000200: 7420 4461 7461 4672 616d 650a 6672 6f6d  t DataFrame.from
+00000210: 2077 6172 6e69 6e67 7320 696d 706f 7274   warnings import
+00000220: 2066 696c 7465 7277 6172 6e69 6e67 730a   filterwarnings.
+00000230: 6669 6c74 6572 7761 726e 696e 6773 2822  filterwarnings("
+00000240: 6967 6e6f 7265 222c 2063 6174 6567 6f72  ignore", categor
+00000250: 793d 4675 7475 7265 5761 726e 696e 6729  y=FutureWarning)
+00000260: 0a66 726f 6d20 636f 6c6c 6563 7469 6f6e  .from collection
+00000270: 7320 696d 706f 7274 2043 6f75 6e74 6572  s import Counter
+00000280: 200a 696d 706f 7274 206a 6f62 6c69 6220   .import joblib 
+00000290: 2020 0a0a 696d 706f 7274 2073 6b6c 6561    ..import sklea
+000002a0: 726e 2e6e 6569 6768 626f 7273 2e5f 6261  rn.neighbors._ba
+000002b0: 7365 0a73 7973 2e6d 6f64 756c 6573 5b27  se.sys.modules['
+000002c0: 736b 6c65 6172 6e2e 6e65 6967 6862 6f72  sklearn.neighbor
+000002d0: 732e 6261 7365 275d 203d 2073 6b6c 6561  s.base'] = sklea
+000002e0: 726e 2e6e 6569 6768 626f 7273 2e5f 6261  rn.neighbors._ba
+000002f0: 7365 0a66 726f 6d20 736b 6c65 6172 6e2e  se.from sklearn.
+00000300: 696d 7075 7465 2069 6d70 6f72 7420 5369  impute import Si
+00000310: 6d70 6c65 496d 7075 7465 722c 204b 4e4e  mpleImputer, KNN
+00000320: 496d 7075 7465 720a 6672 6f6d 2073 6b6c  Imputer.from skl
+00000330: 6561 726e 2e65 6e73 656d 626c 6520 696d  earn.ensemble im
+00000340: 706f 7274 2052 616e 646f 6d46 6f72 6573  port RandomFores
+00000350: 7443 6c61 7373 6966 6965 720a 6672 6f6d  tClassifier.from
+00000360: 2073 6b6c 6561 726e 2e6e 6575 7261 6c5f   sklearn.neural_
+00000370: 6e65 7477 6f72 6b20 696d 706f 7274 204d  network import M
+00000380: 4c50 436c 6173 7369 6669 6572 0a66 726f  LPClassifier.fro
+00000390: 6d20 736b 6c65 6172 6e2e 6d65 7472 6963  m sklearn.metric
+000003a0: 7320 696d 706f 7274 2061 6363 7572 6163  s import accurac
+000003b0: 795f 7363 6f72 650a 6672 6f6d 2073 6b6c  y_score.from skl
+000003c0: 6561 726e 2e6d 6f64 656c 5f73 656c 6563  earn.model_selec
+000003d0: 7469 6f6e 2069 6d70 6f72 7420 7472 6169  tion import trai
+000003e0: 6e5f 7465 7374 5f73 706c 6974 2c20 6372  n_test_split, cr
+000003f0: 6f73 735f 7661 6c69 6461 7465 2c20 6372  oss_validate, cr
+00000400: 6f73 735f 7661 6c5f 7363 6f72 650a 0a66  oss_val_score..f
+00000410: 726f 6d20 736b 6f70 7420 696d 706f 7274  rom skopt import
+00000420: 2042 6179 6573 5365 6172 6368 4356 2c20   BayesSearchCV, 
+00000430: 706c 6f74 732c 2067 705f 6d69 6e69 6d69  plots, gp_minimi
+00000440: 7a65 0a66 726f 6d20 736b 6f70 742e 706c  ze.from skopt.pl
+00000450: 6f74 7320 696d 706f 7274 2070 6c6f 745f  ots import plot_
+00000460: 636f 6e76 6572 6765 6e63 652c 2070 6c6f  convergence, plo
+00000470: 745f 6f62 6a65 6374 6976 650a 6672 6f6d  t_objective.from
+00000480: 2073 6b6f 7074 2e73 7061 6365 2069 6d70   skopt.space imp
+00000490: 6f72 7420 5265 616c 2c20 496e 7465 6765  ort Real, Intege
+000004a0: 722c 2043 6174 6567 6f72 6963 616c 200a  r, Categorical .
+000004b0: 6672 6f6d 2074 656e 736f 7266 6c6f 772e  from tensorflow.
+000004c0: 6b65 7261 732e 6261 636b 656e 6420 696d  keras.backend im
+000004d0: 706f 7274 2063 6c65 6172 5f73 6573 7369  port clear_sessi
+000004e0: 6f6e 200a 6672 6f6d 2074 656e 736f 7266  on .from tensorf
+000004f0: 6c6f 772e 6b65 7261 732e 6361 6c6c 6261  low.keras.callba
+00000500: 636b 7320 696d 706f 7274 2045 6172 6c79  cks import Early
+00000510: 5374 6f70 7069 6e67 2c20 4361 6c6c 6261  Stopping, Callba
+00000520: 636b 0a66 726f 6d20 7465 6e73 6f72 666c  ck.from tensorfl
+00000530: 6f77 2e6b 6572 6173 2e6d 6f64 656c 7320  ow.keras.models 
+00000540: 696d 706f 7274 2073 6176 655f 6d6f 6465  import save_mode
+00000550: 6c0a 0a69 6d70 6f72 7420 6f70 7475 6e61  l..import optuna
+00000560: 0a66 726f 6d20 426f 7275 7461 5368 6170  .from BorutaShap
+00000570: 2069 6d70 6f72 7420 426f 7275 7461 5368   import BorutaSh
+00000580: 6170 0a66 726f 6d20 626f 7275 7461 2069  ap.from boruta i
+00000590: 6d70 6f72 7420 426f 7275 7461 5079 0a66  mport BorutaPy.f
+000005a0: 726f 6d20 7867 626f 6f73 7420 696d 706f  rom xgboost impo
+000005b0: 7274 2058 4742 436c 6173 7369 6669 6572  rt XGBClassifier
+000005c0: 2c20 444d 6174 7269 782c 2074 7261 696e  , DMatrix, train
+000005d0: 0a66 726f 6d20 6f70 7475 6e61 2e69 6e74  .from optuna.int
+000005e0: 6567 7261 7469 6f6e 2069 6d70 6f72 7420  egration import 
+000005f0: 5446 4b65 7261 7350 7275 6e69 6e67 4361  TFKerasPruningCa
+00000600: 6c6c 6261 636b 0a6f 7074 756e 612e 6c6f  llback.optuna.lo
+00000610: 6767 696e 672e 7365 745f 7665 7262 6f73  gging.set_verbos
+00000620: 6974 7928 6f70 7475 6e61 2e6c 6f67 6769  ity(optuna.loggi
+00000630: 6e67 2e57 4152 4e49 4e47 290a 6672 6f6d  ng.WARNING).from
+00000640: 204d 6963 726f 4c49 412e 6461 7461 5f61   MicroLIA.data_a
+00000650: 7567 6d65 6e74 6174 696f 6e20 696d 706f  ugmentation impo
+00000660: 7274 2061 7567 6d65 6e74 6174 696f 6e2c  rt augmentation,
+00000670: 2072 6573 697a 650a 6672 6f6d 204d 6963   resize.from Mic
+00000680: 726f 4c49 4120 696d 706f 7274 2064 6174  roLIA import dat
+00000690: 615f 7072 6f63 6573 7369 6e67 2c20 636e  a_processing, cn
+000006a0: 6e5f 6d6f 6465 6c0a 0a0a 636c 6173 7320  n_model...class 
+000006b0: 6f62 6a65 6374 6976 655f 636e 6e28 6f62  objective_cnn(ob
+000006c0: 6a65 6374 293a 0a20 2020 2022 2222 0a20  ject):.    """. 
+000006d0: 2020 204f 7074 696d 697a 6174 696f 6e20     Optimization 
+000006e0: 6f62 6a65 6374 6976 6520 6675 6e63 7469  objective functi
+000006f0: 6f6e 2066 6f72 204d 6963 726f 4c49 4127  on for MicroLIA'
+00000700: 7320 636f 6e76 6f6c 7574 696f 6e61 6c20  s convolutional 
+00000710: 6e65 7572 616c 206e 6574 776f 726b 732e  neural networks.
+00000720: 0a0a 2020 2020 5468 6973 2069 7320 7061  ..    This is pa
+00000730: 7373 6564 2074 6872 6f75 6768 2074 6865  ssed through the
+00000740: 2068 7970 6572 5f6f 7074 2829 2066 756e   hyper_opt() fun
+00000750: 6374 696f 6e20 7768 656e 206f 7074 696d  ction when optim
+00000760: 697a 696e 6720 7769 7468 0a20 2020 204f  izing with.    O
+00000770: 7074 756e 612e 2054 6865 204f 7074 756e  ptuna. The Optun
+00000780: 6120 736f 6674 7761 7265 2066 6f72 2068  a software for h
+00000790: 7970 6572 7061 7261 6d65 7465 7220 6f70  yperparameter op
+000007a0: 7469 6d69 7a61 7469 6f6e 2077 6173 2070  timization was p
+000007b0: 7562 6c69 7368 6564 2069 6e20 0a20 2020  ublished in .   
+000007c0: 2032 3031 3920 6279 2041 6b69 6261 2065   2019 by Akiba e
+000007d0: 7420 616c 2e20 5061 7065 723a 2068 7474  t al. Paper: htt
+000007e0: 7073 3a2f 2f61 7278 6976 2e6f 7267 2f61  ps://arxiv.org/a
+000007f0: 6273 2f31 3930 372e 3130 3930 320a 0a20  bs/1907.10902.. 
+00000800: 2020 2055 6e6c 696b 6520 7468 6520 6f62     Unlike the ob
+00000810: 6a65 6374 6976 6520 6675 6e63 7469 6f6e  jective function
+00000820: 7320 666f 7220 7468 6520 656e 7365 6d62  s for the ensemb
+00000830: 6c65 2061 6c67 6f72 6974 686d 732c 2074  le algorithms, t
+00000840: 6869 7320 7461 6b65 7320 6173 2069 6e70  his takes as inp
+00000850: 7574 0a20 2020 2074 6865 2074 776f 2063  ut.    the two c
+00000860: 6c61 7373 6573 2064 6972 6563 746c 792c  lasses directly,
+00000870: 2070 6f73 6974 6976 655f 636c 6173 7320   positive_class 
+00000880: 2620 6e65 6761 7469 7665 5f63 6c61 7373  & negative_class
+00000890: 2c20 696e 7374 6561 6420 6f66 2074 6865  , instead of the
+000008a0: 2074 7261 6469 7469 6f6e 616c 200a 2020   traditional .  
+000008b0: 2020 6461 7461 2028 6461 7461 5f78 2920    data (data_x) 
+000008c0: 616e 6420 6163 636f 6d70 616e 7969 6e67  and accompanying
+000008d0: 206c 6162 656c 2061 7272 6179 2028 6461   label array (da
+000008e0: 7461 5f79 292e 2054 6869 7320 6973 2062  ta_y). This is b
+000008f0: 6563 6175 7365 2074 6865 2063 6f6e 6669  ecause the confi
+00000900: 6775 7265 6420 434e 4e20 6d6f 6465 6c73  gured CNN models
+00000910: 200a 2020 2020 7461 6b65 2061 7320 696e   .    take as in
+00000920: 7075 7420 7468 6520 7477 6f20 636c 6173  put the two clas
+00000930: 7365 7320 7365 7061 7261 7465 6c79 2c20  ses separately, 
+00000940: 6166 7465 7220 7768 6963 6820 6974 2061  after which it a
+00000950: 7574 6f6d 6174 6963 616c 6c79 2061 7373  utomatically ass
+00000960: 6967 6e73 2074 6865 2031 2061 6e64 2030  igns the 1 and 0
+00000970: 206c 6162 656c 732c 2072 6573 7065 6374   labels, respect
+00000980: 6976 656c 792e 0a0a 2020 2020 4279 2064  ively...    By d
+00000990: 6566 6175 6c74 2c20 6f70 745f 6d6f 6465  efault, opt_mode
+000009a0: 6c3d 5472 7565 2061 6e64 206f 7074 5f61  l=True and opt_a
+000009b0: 7567 3d46 616c 7365 2e20 4966 206f 7074  ug=False. If opt
+000009c0: 5f61 7567 3d54 7275 652c 2074 6865 2069  _aug=True, the i
+000009d0: 6d61 6765 2073 697a 6520 616e 640a 2020  mage size and.  
+000009e0: 2020 6e75 6d62 6572 206f 6620 6175 676d    number of augm
+000009f0: 656e 7461 7469 6f6e 7320 746f 2070 6572  entations to per
+00000a00: 666f 726d 206f 6e20 6561 6368 2069 6d61  form on each ima
+00000a10: 6765 2077 696c 6c20 6265 2069 6e63 6c75  ge will be inclu
+00000a20: 6465 6420 6173 206f 7074 696d 697a 6162  ded as optimizab
+00000a30: 6c65 2076 6172 6961 626c 6573 2e0a 2020  le variables..  
+00000a40: 2020 4966 2074 6865 206f 7074 5f6d 6178    If the opt_max
+00000a50: 5f6d 696e 5f70 6978 2061 6e64 206f 7074  _min_pix and opt
+00000a60: 5f6d 6178 5f6d 6178 5f70 6978 2061 7265  _max_max_pix are
+00000a70: 2073 6574 2c20 7468 6520 6f70 7469 6d61   set, the optima
+00000a80: 6c20 6d61 7869 6d75 6d20 7069 7865 6c20  l maximum pixel 
+00000a90: 7661 6c75 6520 746f 2075 7365 0a20 2020  value to use.   
+00000aa0: 2077 6865 6e20 6d69 6e2d 6d61 7820 6e6f   when min-max no
+00000ab0: 726d 616c 697a 696e 6720 6561 6368 2062  rmalizing each b
+00000ac0: 616e 6420 7769 6c6c 2061 6c73 6f20 6265  and will also be
+00000ad0: 206f 7074 696d 697a 6162 6c65 2076 6172   optimizable var
+00000ae0: 6961 626c 6573 2074 6861 7420 7769 6c6c  iables that will
+00000af0: 2062 6520 7475 6e65 6420 616e 6420 7265   be tuned and re
+00000b00: 7475 726e 6564 2e0a 2020 2020 4966 206f  turned..    If o
+00000b10: 7074 5f6d 6f64 656c 3d54 7275 652c 2061  pt_model=True, a
+00000b20: 6464 6974 696f 6e61 6c20 6172 6368 6974  dditional archit
+00000b30: 6563 7475 7265 2070 6172 616d 6574 6572  ecture parameter
+00000b40: 7320 7769 6c6c 2061 6c73 6f20 6265 2074  s will also be t
+00000b50: 756e 6564 2e20 496e 2062 6f74 6820 696e  uned. In both in
+00000b60: 7374 616e 6365 7320 7468 6520 7472 6169  stances the trai
+00000b70: 6e69 6e67 2070 6172 616d 6574 6572 7320  ning parameters 
+00000b80: 0a20 2020 2077 696c 6c20 6265 206f 7074  .    will be opt
+00000b90: 696d 697a 6564 2c20 7768 6963 6820 696e  imized, which in
+00000ba0: 636c 7564 6520 7468 6520 6f70 7469 6d69  clude the optimi
+00000bb0: 7a65 722c 206c 6561 726e 696e 6720 7261  zer, learning ra
+00000bc0: 7465 2c20 6465 6361 792c 2061 6e64 206d  te, decay, and m
+00000bd0: 6f6d 656e 7475 6d2c 2069 6620 6170 706c  omentum, if appl
+00000be0: 6963 6162 6c65 2e0a 0a20 2020 204e 6f74  icable...    Not
+00000bf0: 653a 0a20 2020 2020 2020 2049 6620 6f70  e:.        If op
+00000c00: 745f 6175 6720 6973 2065 6e61 626c 6564  t_aug is enabled
+00000c10: 2c20 7468 656e 2074 6865 2070 6f73 6974  , then the posit
+00000c20: 6976 655f 636c 6173 7320 7361 6d70 6c65  ive_class sample
+00000c30: 2077 696c 6c20 6265 2074 6865 2064 6174   will be the dat
+00000c40: 6120 7468 6174 2077 696c 6c20 6175 676d  a that will augm
+00000c50: 656e 7465 642e 0a20 2020 2020 2020 2049  ented..        I
+00000c60: 7420 6973 2062 6573 7420 746f 206b 6565  t is best to kee
+00000c70: 7020 626f 7468 2063 6c61 7373 2073 697a  p both class siz
+00000c80: 6573 2074 6865 2073 616d 6520 6166 7465  es the same afte
+00000c90: 7220 6175 676d 656e 7461 7469 6f6e 2c20  r augmentation, 
+00000ca0: 7468 6572 6566 6f72 6520 6261 6c61 6e63  therefore balanc
+00000cb0: 653d 5472 7565 0a20 2020 2020 2020 2062  e=True.        b
+00000cc0: 7920 6465 6661 756c 742c 2077 6869 6368  y default, which
+00000cd0: 2077 696c 6c20 7472 756e 6361 7465 2074   will truncate t
+00000ce0: 6865 206e 6567 6174 6976 655f 636c 6173  he negative_clas
+00000cf0: 7320 7361 6d70 6c65 2074 6f20 6d61 7463  s sample to matc
+00000d00: 6820 7468 6520 6175 676d 656e 7465 6420  h the augmented 
+00000d10: 706f 7369 7469 7665 5f63 6c61 7373 2073  positive_class s
+00000d20: 697a 652e 0a20 2020 2020 2020 2054 6865  ize..        The
+00000d30: 206f 7468 6572 2063 6c61 7373 2077 696c   other class wil
+00000d40: 6c20 616c 736f 2075 6e64 6572 676f 2074  l also undergo t
+00000d50: 6865 2073 616d 6520 6461 7461 2061 7567  he same data aug
+00000d60: 6d65 6e74 6174 696f 6e20 7465 6368 6e69  mentation techni
+00000d70: 7175 6520 6275 7420 6f6e 6c79 206f 6e65  que but only one
+00000d80: 2069 6d61 6765 2077 696c 6c20 6265 2072   image will be r
+00000d90: 6574 7572 6e65 640a 2020 2020 2020 2020  eturned.        
+00000da0: 7065 7220 7361 6d70 6c65 2c20 7468 6973  per sample, this
+00000db0: 2069 7320 746f 2065 6e73 7572 6520 626f   is to ensure bo
+00000dc0: 7468 2063 6c61 7373 6573 2063 6f6e 7461  th classes conta
+00000dd0: 696e 2074 6865 2073 616d 6520 6c65 7665  in the same leve
+00000de0: 6c20 6f66 2076 6172 6961 7469 6f6e 2c20  l of variation, 
+00000df0: 6573 7065 6369 616c 6c79 2069 6d70 6f72  especially impor
+00000e00: 7461 6e74 0a20 2020 2020 2020 2077 6865  tant.        whe
+00000e10: 6e20 6170 706c 7969 6e67 2074 6865 206d  n applying the m
+00000e20: 6173 6b2d 6375 746f 7574 2074 6563 686e  ask-cutout techn
+00000e30: 6971 7565 2074 6f20 7468 6520 6175 676d  ique to the augm
+00000e40: 656e 7461 7469 6f6e 2070 726f 6365 6475  entation procedu
+00000e50: 7265 2e0a 0a20 2020 2020 2020 2053 696e  re...        Sin
+00000e60: 6365 2074 6865 206d 6178 696d 756d 206e  ce the maximum n
+00000e70: 756d 6265 7220 6f66 2061 7567 6d65 6e74  umber of augment
+00000e80: 6174 696f 6e73 2061 6c6c 6f77 6564 2069  ations allowed i
+00000e90: 7320 6261 7463 685f 6d61 7820 7065 7220  s batch_max per 
+00000ea0: 6561 6368 2073 616d 706c 652c 2069 6e20  each sample, in 
+00000eb0: 7072 6163 7469 6365 206e 6567 6174 6976  practice negativ
+00000ec0: 655f 636c 6173 7320 0a20 2020 2020 2020  e_class .       
+00000ed0: 2073 686f 756c 6420 636f 6e74 6169 6e20   should contain 
+00000ee0: 6261 7463 685f 6d61 7820 7469 6d65 7320  batch_max times 
+00000ef0: 7468 6520 7369 7a65 206f 6620 706f 7369  the size of posi
+00000f00: 7469 7665 5f63 6c61 7373 2e20 4475 7269  tive_class. Duri
+00000f10: 6e67 2074 6865 206f 7074 696d 697a 6174  ng the optimizat
+00000f20: 696f 6e20 7072 6f63 6564 7572 652c 2069  ion procedure, i
+00000f30: 6620 616e 200a 2020 2020 2020 2020 6175  f an .        au
+00000f40: 676d 656e 7461 7469 6f6e 2062 6174 6368  gmentation batch
+00000f50: 2073 697a 6520 6f66 2031 3030 2069 7320   size of 100 is 
+00000f60: 6173 7365 7365 6420 616e 6420 706f 7369  assesed and posi
+00000f70: 7469 7665 2063 6c61 7373 2063 6f6e 7461  tive class conta
+00000f80: 696e 7320 6e20 7361 6d70 6c65 732c 2074  ins n samples, t
+00000f90: 6865 6e20 3130 302a 6e20 6175 676d 656e  hen 100*n augmen
+00000fa0: 7465 6420 696d 6167 6573 2077 696c 6c20  ted images will 
+00000fb0: 6265 2063 7265 6174 6564 2c20 0a20 2020  be created, .   
+00000fc0: 2020 2020 2061 6e64 2074 6865 7265 666f       and therefo
+00000fd0: 7265 2064 7572 696e 6720 7468 6174 2070  re during that p
+00000fe0: 6172 7469 6375 6c61 7220 7472 6961 6c20  articular trial 
+00000ff0: 7468 6520 6669 7273 7420 3130 302a 6e20  the first 100*n 
+00001000: 7361 6d70 6c65 7320 6672 6f6d 206e 6567  samples from neg
+00001010: 6174 6976 655f 636c 6173 7320 7769 6c6c  ative_class will
+00001020: 2062 6520 7573 6564 2c20 6966 2061 7661   be used, if ava
+00001030: 696c 6162 6c65 2e20 0a20 2020 2020 2020  ilable. .       
+00001040: 2054 6f20 7573 6520 7468 6520 656e 7469   To use the enti
+00001050: 7265 206e 6567 6174 6976 655f 636c 6173  re negative_clas
+00001060: 7320 7361 6d70 6c65 2072 6567 6172 646c  s sample regardl
+00001070: 6573 7320 6f66 2074 6865 206e 756d 6265  ess of the numbe
+00001080: 7220 6175 676d 656e 7461 7469 6f6e 7320  r augmentations 
+00001090: 7065 7266 6f72 6d65 642c 2073 6574 2062  performed, set b
+000010a0: 616c 616e 6365 3d46 616c 7365 2e0a 2020  alance=False..  
+000010b0: 2020 0a20 2020 2020 2020 2054 6865 206d    .        The m
+000010c0: 696e 5f70 6978 656c 2061 6e64 206d 6178  in_pixel and max
+000010d0: 5f70 6978 656c 2076 616c 7565 2077 696c  _pixel value wil
+000010e0: 6c20 6265 2075 7365 6420 746f 206d 696e  l be used to min
+000010f0: 2d6d 6178 206e 6f72 6d61 6c69 7a65 2074  -max normalize t
+00001100: 6865 2069 6d61 6765 732c 2069 6620 6e6f  he images, if no
+00001110: 726d 616c 697a 653d 5472 7565 2e20 5468  rmalize=True. Th
+00001120: 6520 6f70 745f 6d61 785f 6d69 6e5f 7069  e opt_max_min_pi
+00001130: 780a 2020 2020 2020 2020 616e 6420 6f70  x.        and op
+00001140: 745f 6d61 785f 6d61 785f 7069 782c 2077  t_max_max_pix, w
+00001150: 6865 6e20 7365 742c 2077 696c 6c20 6265  hen set, will be
+00001160: 2075 7365 6420 696e 7374 6561 6420 6475   used instead du
+00001170: 7269 6e67 2074 6865 206f 7074 696d 697a  ring the optimiz
+00001180: 6174 696f 6e20 7072 6f63 6564 7572 652c  ation procedure,
+00001190: 2073 6f20 6173 2074 6f20 6465 7465 726d   so as to determ
+000011a0: 696e 650a 2020 2020 2020 2020 7768 6174  ine.        what
+000011b0: 206f 7074 696d 616c 206d 6178 696d 756d   optimal maximum
+000011c0: 2076 616c 7565 2074 6f20 7573 6520 7768   value to use wh
+000011d0: 656e 206e 6f72 6d61 6c69 7a69 6e67 2074  en normalizing t
+000011e0: 6865 2069 6d61 6765 732e 2054 6869 7320  he images. This 
+000011f0: 6973 2069 6d70 6f72 7461 6e74 2077 6865  is important whe
+00001200: 6e20 6465 616c 696e 6720 7769 7468 2064  n dealing with d
+00001210: 6565 702d 7375 7276 6579 2064 6174 612e  eep-survey data.
+00001220: 200a 2020 2020 2020 2020 4966 206f 7074   .        If opt
+00001230: 696d 697a 696e 6720 7468 6520 6e6f 726d  imizing the norm
+00001240: 616c 697a 6174 696f 6e20 7363 6865 6d65  alization scheme
+00001250: 2c20 7468 6520 6465 6661 756c 7420 6d69  , the default mi
+00001260: 6e5f 7069 7865 6c20 7769 6c6c 2062 6520  n_pixel will be 
+00001270: 7365 7420 746f 207a 6572 6f2c 2061 7320  set to zero, as 
+00001280: 7375 6368 206f 6e6c 7920 7468 6520 6f70  such only the op
+00001290: 7469 6d61 6c20 6d61 785f 7069 7865 6c20  timal max_pixel 
+000012a0: 0a20 2020 2020 2020 2066 6f72 2065 7665  .        for eve
+000012b0: 7279 2062 616e 6420 7769 6c6c 2062 6520  ry band will be 
+000012c0: 6f75 7470 7574 2e0a 0a20 2020 2041 7267  output...    Arg
+000012d0: 733a 0a20 2020 2020 2020 2070 6f73 6974  s:.        posit
+000012e0: 6976 655f 636c 6173 7320 286e 6461 7272  ive_class (ndarr
+000012f0: 6179 293a 2054 6865 2073 616d 706c 6573  ay): The samples
+00001300: 2066 6f72 2074 6865 2066 6972 7374 2063   for the first c
+00001310: 6c61 7373 2073 686f 756c 6420 6265 2070  lass should be p
+00001320: 6173 7365 642c 2077 6869 6368 2077 696c  assed, which wil
+00001330: 6c20 6175 746f 6d61 7469 6361 6c6c 7920  l automatically 
+00001340: 0a20 2020 2020 2020 2020 2020 2062 6520  .            be 
+00001350: 6173 7369 676e 6564 2074 6865 2070 6f73  assigned the pos
+00001360: 6974 6976 6520 6c61 6265 6c20 2731 272e  itive label '1'.
+00001370: 0a20 2020 2020 2020 206e 6567 6174 6976  .        negativ
+00001380: 655f 636c 6173 7320 286e 6461 7272 6179  e_class (ndarray
+00001390: 293a 2054 6865 2073 616d 706c 6573 2066  ): The samples f
+000013a0: 6f72 2074 6865 2073 6563 6f6e 6420 636c  or the second cl
+000013b0: 6173 7320 7368 6f75 6c64 2062 6520 7061  ass should be pa
+000013c0: 7373 6564 2c20 7768 6963 6820 7769 6c6c  ssed, which will
+000013d0: 2061 7574 6f6d 6174 6963 616c 6c79 200a   automatically .
+000013e0: 2020 2020 2020 2020 2020 2020 6265 2061              be a
+000013f0: 7373 6967 6e65 6420 7468 6520 6e65 6761  ssigned the nega
+00001400: 7469 7665 206c 6162 656c 2027 3027 2e0a  tive label '0'..
+00001410: 2020 2020 2020 2020 696d 675f 6e75 6d5f          img_num_
+00001420: 6368 616e 6e65 6c73 2028 696e 7429 3a20  channels (int): 
+00001430: 5468 6520 6e75 6d62 6572 206f 6620 6669  The number of fi
+00001440: 6c74 6572 732e 2044 6566 6175 6c74 7320  lters. Defaults 
+00001450: 746f 2031 2e0a 2020 2020 2020 2020 6e6f  to 1..        no
+00001460: 726d 616c 697a 6520 2862 6f6f 6c2c 206f  rmalize (bool, o
+00001470: 7074 696f 6e61 6c29 3a20 4966 2054 7275  ptional): If Tru
+00001480: 6520 7468 6520 6461 7461 2077 696c 6c20  e the data will 
+00001490: 6265 206d 696e 2d6d 6178 206e 6f72 6d61  be min-max norma
+000014a0: 6c69 7a65 6420 7573 696e 6720 7468 6520  lized using the 
+000014b0: 0a20 2020 2020 2020 2020 2020 2069 6e70  .            inp
+000014c0: 7574 206d 696e 2061 6e64 206d 6178 2070  ut min and max p
+000014d0: 6978 656c 732e 2044 6566 6175 6c74 7320  ixels. Defaults 
+000014e0: 746f 2054 7275 652e 0a20 2020 2020 2020  to True..       
+000014f0: 206d 696e 5f70 6978 656c 2028 696e 742c   min_pixel (int,
+00001500: 206f 7074 696f 6e61 6c29 3a20 5468 6520   optional): The 
+00001510: 6d69 6e69 6d75 6d20 7069 7865 6c20 636f  minimum pixel co
+00001520: 756e 742c 2070 6978 656c 7320 7769 7468  unt, pixels with
+00001530: 2063 6f75 6e74 7320 0a20 2020 2020 2020   counts .       
+00001540: 2020 2020 2062 656c 6f77 2074 6869 7320       below this 
+00001550: 7468 7265 7368 6f6c 6420 7769 6c6c 2062  threshold will b
+00001560: 6520 7365 7420 746f 2074 6869 7320 6c69  e set to this li
+00001570: 6d69 742e 2044 6566 6175 6c74 7320 746f  mit. Defaults to
+00001580: 2030 2e0a 2020 2020 2020 2020 6d61 785f   0..        max_
+00001590: 7069 7865 6c20 2869 6e74 2c20 6c69 7374  pixel (int, list
+000015a0: 2c20 6f70 7469 6f6e 616c 293a 2054 6865  , optional): The
+000015b0: 206d 6178 696d 756d 2070 6978 656c 2063   maximum pixel c
+000015c0: 6f75 6e74 2c20 7069 7865 6c73 2077 6974  ount, pixels wit
+000015d0: 6820 636f 756e 7473 200a 2020 2020 2020  h counts .      
+000015e0: 2020 2020 2020 6162 6f76 6520 7468 6973        above this
+000015f0: 2074 6872 6573 686f 6c64 2077 696c 6c20   threshold will 
+00001600: 6265 2073 6574 2074 6f20 7468 6973 206c  be set to this l
+00001610: 696d 6974 2e20 4465 6661 756c 7473 2074  imit. Defaults t
+00001620: 6f20 3130 302e 2049 6620 696d 675f 6e75  o 100. If img_nu
+00001630: 6d5f 6368 616e 6e65 6c73 0a20 2020 2020  m_channels.     
+00001640: 2020 2020 2020 2069 7320 6e6f 7420 312c         is not 1,
+00001650: 2074 6865 206d 6178 5f70 6978 656c 2073   the max_pixel s
+00001660: 686f 756c 6420 6265 2061 206c 6973 7420  hould be a list 
+00001670: 636f 6e74 6169 6e69 6e67 2074 776f 2076  containing two v
+00001680: 616c 7565 732c 206f 6e65 2066 6f72 2065  alues, one for e
+00001690: 6163 6820 6261 6e64 2e0a 2020 2020 2020  ach band..      
+000016a0: 2020 7661 6c5f 706f 7369 7469 7665 2028    val_positive (
+000016b0: 6e64 6172 7261 792c 206f 7074 696f 6e61  ndarray, optiona
+000016c0: 6c29 3a20 506f 7369 7469 7665 2063 6c61  l): Positive cla
+000016d0: 7373 2064 6174 6120 746f 2062 6520 7573  ss data to be us
+000016e0: 6564 2066 6f72 2076 616c 6964 6174 696f  ed for validatio
+000016f0: 6e2e 2044 6566 6175 6c74 7320 746f 204e  n. Defaults to N
+00001700: 6f6e 652e 0a20 2020 2020 2020 2076 616c  one..        val
+00001710: 5f6e 6567 6174 6976 6520 286e 6461 7272  _negative (ndarr
+00001720: 6179 2c20 6f70 7469 6f6e 616c 293a 204e  ay, optional): N
+00001730: 6567 6174 6976 6520 636c 6173 7320 6461  egative class da
+00001740: 7461 2074 6f20 6265 2075 7365 6420 666f  ta to be used fo
+00001750: 7220 7661 6c69 6461 7469 6f6e 2e20 4465  r validation. De
+00001760: 6661 756c 7473 2074 6f20 4e6f 6e65 2e0a  faults to None..
+00001770: 2020 2020 2020 2020 7465 7374 5f70 6f73          test_pos
+00001780: 6974 6976 6520 286e 6461 7272 6179 2c20  itive (ndarray, 
+00001790: 6f70 7469 6f6e 616c 293a 2050 6f73 6974  optional): Posit
+000017a0: 6976 6520 636c 6173 7320 6461 7461 2074  ive class data t
+000017b0: 6f20 6265 2075 7365 6420 666f 7220 706f  o be used for po
+000017c0: 7374 2d74 7269 616c 2074 6573 7469 6e67  st-trial testing
+000017d0: 2e20 4465 6661 756c 7473 2074 6f20 4e6f  . Defaults to No
+000017e0: 6e65 2e0a 2020 2020 2020 2020 7465 7374  ne..        test
+000017f0: 5f6e 6567 6174 6976 6520 286e 6461 7272  _negative (ndarr
+00001800: 6179 2c20 6f70 7469 6f6e 616c 293a 204e  ay, optional): N
+00001810: 6567 6174 6976 6520 636c 6173 7320 6461  egative class da
+00001820: 7461 2074 6f20 6265 2075 7365 6420 666f  ta to be used fo
+00001830: 7220 706f 7374 2d74 7269 616c 2074 6573  r post-trial tes
+00001840: 7469 6e67 2e20 4465 6661 756c 7473 2074  ting. Defaults t
+00001850: 6f20 4e6f 6e65 2e0a 2020 2020 2020 2020  o None..        
+00001860: 7465 7374 5f61 6363 5f74 6872 6573 686f  test_acc_thresho
+00001870: 6c64 2028 666c 6f61 742c 206f 7074 696f  ld (float, optio
+00001880: 6e61 6c29 3a20 4966 2069 6e70 7574 2c20  nal): If input, 
+00001890: 6d6f 6465 6c73 2074 6861 7420 7969 656c  models that yiel
+000018a0: 6420 7465 7374 2061 6363 7572 6163 6965  d test accuracie
+000018b0: 7320 6c6f 7765 7220 7468 616e 2074 6865  s lower than the
+000018c0: 2074 6872 6573 686f 6c64 2077 696c 6c0a   threshold will.
+000018d0: 2020 2020 2020 2020 2020 2020 6265 2072              be r
+000018e0: 656a 6563 7465 6420 6279 2074 6865 206f  ejected by the o
+000018f0: 7074 696d 697a 6572 2e20 5468 6520 6163  ptimizer. The ac
+00001900: 6375 7261 6379 206f 6620 626f 7468 2074  curacy of both t
+00001910: 6865 2074 6573 745f 706f 7369 7469 7665  he test_positive
+00001920: 2061 6e64 2074 6573 745f 6e65 6761 7469   and test_negati
+00001930: 7665 2069 7320 6173 6573 7365 642c 2069  ve is asessed, i
+00001940: 6620 696e 7075 742e 0a20 2020 2020 2020  f input..       
+00001950: 2020 2020 2054 6869 7320 6973 2075 7365       This is use
+00001960: 6420 746f 2072 656a 6563 7420 6d6f 6465  d to reject mode
+00001970: 6c73 2074 6861 7420 6861 7665 206f 7665  ls that have ove
+00001980: 7220 6f72 2075 6e64 6572 2066 6974 2074  r or under fit t
+00001990: 6865 2074 7261 696e 696e 6720 6461 7461  he training data
+000019a0: 2e20 4465 6661 756c 7473 2074 6f20 4e6f  . Defaults to No
+000019b0: 6e65 2e0a 2020 2020 2020 2020 706f 7374  ne..        post
+000019c0: 5f6d 6574 7269 6320 2862 6f6f 6c29 3a20  _metric (bool): 
+000019d0: 4966 2054 7275 652c 2074 6865 2074 6573  If True, the tes
+000019e0: 745f 706f 7369 7469 7665 2061 6e64 2f6f  t_positive and/o
+000019f0: 7220 7465 7374 5f6e 6567 6174 6976 6520  r test_negative 
+00001a00: 696e 7075 7473 2077 696c 6c20 6265 2069  inputs will be i
+00001a10: 6e63 6c75 6465 6420 696e 2074 6865 2066  ncluded in the f
+00001a20: 696e 616c 206f 7074 696d 697a 6174 696f  inal optimizatio
+00001a30: 6e20 7363 6f72 652e 0a20 2020 2020 2020  n score..       
+00001a40: 2020 2020 2054 6869 7320 7769 6c6c 2062       This will b
+00001a50: 6520 7468 6520 6176 6572 6167 6564 206f  e the averaged o
+00001a60: 7574 206d 6574 7269 632e 2044 6566 6175  ut metric. Defau
+00001a70: 6c74 7320 746f 2054 7275 652e 2043 616e  lts to True. Can
+00001a80: 2062 6520 7365 7420 746f 2046 616c 7365   be set to False
+00001a90: 2074 6f20 6f6e 6c79 2061 7070 6c79 2074   to only apply t
+00001aa0: 6865 2074 6573 745f 6163 635f 7468 7265  he test_acc_thre
+00001ab0: 7368 6f6c 642e 0a20 2020 2020 2020 2074  shold..        t
+00001ac0: 7261 696e 5f65 706f 6368 7320 2869 6e74  rain_epochs (int
+00001ad0: 293a 204e 756d 6265 7220 6f66 2065 706f  ): Number of epo
+00001ae0: 6368 7320 746f 2074 6865 2074 7261 696e  chs to the train
+00001af0: 2074 6865 2043 4e4e 2074 6f20 6475 7269   the CNN to duri
+00001b00: 6e67 2074 6865 206f 7074 696d 697a 6174  ng the optimizat
+00001b10: 696f 6e20 7472 6961 6c73 2e20 4465 6661  ion trials. Defa
+00001b20: 756c 7473 2074 6f20 3235 2e0a 2020 2020  ults to 25..    
+00001b30: 2020 2020 6d65 7472 6963 2028 7374 7229      metric (str)
+00001b40: 3a20 4173 7365 736d 656e 7420 6d65 7472  : Assesment metr
+00001b50: 6963 2074 6f20 7573 6520 7768 656e 2062  ic to use when b
+00001b60: 6f74 6820 7072 756e 696e 6720 616e 6420  oth pruning and 
+00001b70: 7363 6f72 696e 6720 7468 6520 6879 7065  scoring the hype
+00001b80: 7270 6172 616d 6574 6572 206f 7074 696d  rparameter optim
+00001b90: 697a 6174 696f 6e20 7472 6961 6c2e 0a20  ization trial.. 
+00001ba0: 2020 2020 2020 2020 2020 2044 6566 6175             Defau
+00001bb0: 6c74 7320 746f 2027 6c6f 7373 272e 204f  lts to 'loss'. O
+00001bc0: 7074 696f 6e73 2069 6e63 6c75 6465 3a20  ptions include: 
+00001bd0: 276c 6f73 7327 2027 6269 6e61 7279 5f61  'loss' 'binary_a
+00001be0: 6363 7572 6163 7927 2c20 2766 315f 7363  ccuracy', 'f1_sc
+00001bf0: 6f72 6527 2027 616c 6c27 206f 7220 7468  ore' 'all' or th
+00001c00: 6520 7661 6c69 6461 7469 6f6e 2065 7175  e validation equ
+00001c10: 6976 616c 656e 7473 2028 652e 672e 2027  ivalents (e.g. '
+00001c20: 7661 6c5f 6c6f 7373 2729 2e0a 2020 2020  val_loss')..    
+00001c30: 2020 2020 6d65 7472 6963 3220 2873 7472      metric2 (str
+00001c40: 2c20 6f70 7469 6f6e 616c 293a 2041 6464  , optional): Add
+00001c50: 6974 696f 6e61 6c20 6d65 7472 6963 2074  itional metric t
+00001c60: 6f20 6265 2075 7365 6420 736f 6c65 6c79  o be used solely
+00001c70: 2066 6f72 2065 6172 6c79 2d73 746f 7070   for early-stopp
+00001c80: 696e 6720 7075 7270 6f73 6573 2e20 4966  ing purposes. If
+00001c90: 2069 6e70 7574 2c20 7468 6520 7472 6961   input, the tria
+00001ca0: 6c20 7769 6c6c 2073 746f 7020 6966 2065  l will stop if e
+00001cb0: 6974 6865 720a 2020 2020 2020 2020 2020  ither.          
+00001cc0: 2020 6d65 7472 6963 206f 7220 6d65 7472    metric or metr
+00001cd0: 6963 3220 7374 6f70 2069 6d70 726f 7669  ic2 stop improvi
+00001ce0: 6e67 2061 6674 6572 2074 6865 2073 616d  ng after the sam
+00001cf0: 6520 7061 7469 656e 6365 206e 756d 6265  e patience numbe
+00001d00: 7220 6f66 2065 706f 6368 732c 2062 7574  r of epochs, but
+00001d10: 206f 6e6c 7920 7468 6520 7661 6c75 6520   only the value 
+00001d20: 6f66 206d 6574 7269 6320 6973 2075 7365  of metric is use
+00001d30: 6420 746f 2061 7373 6573 730a 2020 2020  d to assess.    
+00001d40: 2020 2020 2020 2020 7468 6520 7065 7266          the perf
+00001d50: 6f72 6d61 6e63 6520 6f66 2074 6865 206d  ormance of the m
+00001d60: 6f64 656c 2061 6674 6572 2065 6163 6820  odel after each 
+00001d70: 7472 6961 6c2e 2044 6566 6175 6c74 7320  trial. Defaults 
+00001d80: 746f 204e 6f6e 652e 0a20 2020 2020 2020  to None..       
+00001d90: 206d 6574 7269 6333 2028 7374 722c 206f   metric3 (str, o
+00001da0: 7074 696f 6e61 6c29 3a20 4164 6469 7469  ptional): Additi
+00001db0: 6f6e 616c 206d 6574 7269 6320 746f 2062  onal metric to b
+00001dc0: 6520 7573 6564 2073 6f6c 656c 7920 666f  e used solely fo
+00001dd0: 7220 6561 726c 792d 7374 6f70 7069 6e67  r early-stopping
+00001de0: 2070 7572 706f 7365 732e 2049 6620 696e   purposes. If in
+00001df0: 7075 742c 2074 6865 2074 7269 616c 2077  put, the trial w
+00001e00: 696c 6c20 7374 6f70 2069 6620 6569 7468  ill stop if eith
+00001e10: 6572 0a20 2020 2020 2020 2020 2020 206d  er.            m
+00001e20: 6574 7269 6320 6f72 206d 6574 7269 6333  etric or metric3
+00001e30: 2073 746f 7020 696d 7072 6f76 696e 6720   stop improving 
+00001e40: 6166 7465 7220 7468 6520 7361 6d65 2070  after the same p
+00001e50: 6174 6965 6e63 6520 6e75 6d62 6572 206f  atience number o
+00001e60: 6620 6570 6f63 6873 2c20 6275 7420 6f6e  f epochs, but on
+00001e70: 6c79 2074 6865 2076 616c 7565 206f 6620  ly the value of 
+00001e80: 6d65 7472 6963 2069 7320 7573 6564 2074  metric is used t
+00001e90: 6f20 6173 7365 7373 0a20 2020 2020 2020  o assess.       
+00001ea0: 2020 2020 2074 6865 2070 6572 666f 726d       the perform
+00001eb0: 616e 6365 206f 6620 7468 6520 6d6f 6465  ance of the mode
+00001ec0: 6c20 6166 7465 7220 6561 6368 2074 7269  l after each tri
+00001ed0: 616c 2e20 4465 6661 756c 7473 2074 6f20  al. Defaults to 
+00001ee0: 4e6f 6e65 2e0a 2020 2020 2020 2020 7061  None..        pa
+00001ef0: 7469 656e 6365 2028 696e 7429 3a20 4e75  tience (int): Nu
+00001f00: 6d62 6572 206f 6620 6570 6f63 6873 2077  mber of epochs w
+00001f10: 6974 686f 7574 2069 6d70 726f 7665 6d65  ithout improveme
+00001f20: 6e74 2062 6566 6f72 6520 7468 6520 6f70  nt before the op
+00001f30: 7469 6d69 7a61 7469 6f6e 2074 7269 616c  timization trial
+00001f40: 2069 7320 7465 726d 696e 6174 6564 2e20   is terminated. 
+00001f50: 4465 6661 756c 7473 2074 6f20 302c 2077  Defaults to 0, w
+00001f60: 6869 6368 0a20 2020 2020 2020 2020 2020  hich.           
+00001f70: 2064 6973 6162 6c65 7320 7468 6973 2066   disables this f
+00001f80: 6561 7475 7265 2e0a 2020 2020 2020 2020  eature..        
+00001f90: 6176 6572 6167 6520 2862 6f6f 6c29 3a20  average (bool): 
+00001fa0: 4966 2046 616c 7365 2c20 7468 6520 6465  If False, the de
+00001fb0: 7369 676e 6174 6564 206d 6574 7269 6320  signated metric 
+00001fc0: 7769 6c6c 2062 6520 6361 6c63 756c 6174  will be calculat
+00001fd0: 6564 2061 6363 6f72 6469 6e67 2074 6f20  ed according to 
+00001fe0: 6974 7320 7661 6c75 6520 6174 2074 6865  its value at the
+00001ff0: 2065 6e64 206f 6620 7468 6520 7472 6169   end of the trai
+00002000: 6e5f 6570 6f63 6873 2e20 0a20 2020 2020  n_epochs. .     
+00002010: 2020 2020 2020 2049 6620 5472 7565 2c20         If True, 
+00002020: 7468 6520 6d65 7472 6963 2077 696c 6c20  the metric will 
+00002030: 6265 2061 7665 7261 6765 6420 6f75 7420  be averaged out 
+00002040: 6163 726f 7373 2061 6c6c 2074 7261 696e  across all train
+00002050: 5f65 706f 6368 732e 2044 6566 6175 6c74  _epochs. Default
+00002060: 7320 746f 2054 7275 652e 0a20 2020 2020  s to True..     
+00002070: 2020 206f 7074 5f6d 6f64 656c 2028 626f     opt_model (bo
+00002080: 6f6c 293a 2049 6620 5472 7565 2c20 7468  ol): If True, th
+00002090: 6520 6172 6368 6974 6563 7475 7265 2070  e architecture p
+000020a0: 6172 616d 6574 6572 7320 7769 6c6c 2062  arameters will b
+000020b0: 6520 6f70 7469 6d69 7a65 642e 2044 6566  e optimized. Def
+000020c0: 6175 6c74 7320 746f 2054 7275 652e 0a20  aults to True.. 
+000020d0: 2020 2020 2020 206f 7074 5f61 7567 2028         opt_aug (
+000020e0: 626f 6f6c 293a 2049 6620 5472 7565 2c20  bool): If True, 
+000020f0: 7468 6520 6175 676d 656e 7461 7469 6f6e  the augmentation
+00002100: 2070 726f 6365 6475 7265 2077 696c 6c20   procedure will 
+00002110: 6265 206f 7074 696d 697a 6564 2e20 4465  be optimized. De
+00002120: 6661 756c 7473 2074 6f20 4661 6c73 652e  faults to False.
+00002130: 0a20 2020 2020 2020 2062 6174 6368 5f6d  .        batch_m
+00002140: 696e 2028 696e 7429 3a20 5468 6520 6d69  in (int): The mi
+00002150: 6e69 6d75 6d20 6e75 6d62 6572 206f 6620  nimum number of 
+00002160: 6175 676d 656e 7461 7469 6f6e 7320 746f  augmentations to
+00002170: 2070 6572 666f 726d 2070 6572 2069 6d61   perform per ima
+00002180: 6765 206f 6e20 7468 6520 706f 7369 7469  ge on the positi
+00002190: 7665 2063 6c61 7373 2c20 6f6e 6c79 2061  ve class, only a
+000021a0: 7070 6c69 6361 626c 6520 0a20 2020 2020  pplicable .     
+000021b0: 2020 2020 2020 2069 6620 6f70 745f 6175         if opt_au
+000021c0: 673d 5472 7565 2e20 4465 6661 756c 7473  g=True. Defaults
+000021d0: 2074 6f20 322e 0a20 2020 2020 2020 2062   to 2..        b
+000021e0: 6174 6368 5f6d 6178 2028 696e 7429 3a20  atch_max (int): 
+000021f0: 5468 6520 6d61 7869 6d75 6d20 6e75 6d62  The maximum numb
+00002200: 6572 206f 6620 6175 676d 656e 7461 7469  er of augmentati
+00002210: 6f6e 7320 746f 2070 6572 666f 726d 2070  ons to perform p
+00002220: 6572 2069 6d61 6765 206f 6e20 7468 6520  er image on the 
+00002230: 706f 7369 7469 7665 2063 6c61 7373 2c20  positive class, 
+00002240: 6f6e 6c79 2061 7070 6c69 6361 626c 6520  only applicable 
+00002250: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00002260: 6f70 745f 6175 673d 5472 7565 2e20 4465  opt_aug=True. De
+00002270: 6661 756c 7473 2074 6f20 3235 2e0a 2020  faults to 25..  
+00002280: 2020 2020 2020 6261 7463 685f 6f74 6865        batch_othe
+00002290: 7220 2869 6e74 293a 2054 6865 206e 756d  r (int): The num
+000022a0: 6265 7220 6f66 2061 7567 6d65 6e74 6174  ber of augmentat
+000022b0: 696f 6e73 2074 6f20 7065 7266 6f72 6d20  ions to perform 
+000022c0: 746f 2074 6865 206f 7468 6572 2063 6c61  to the other cla
+000022d0: 7373 2c20 7072 6573 756d 6564 2074 6f20  ss, presumed to 
+000022e0: 6265 2074 6865 206d 616a 6f72 6974 7920  be the majority 
+000022f0: 636c 6173 732e 0a20 2020 2020 2020 2020  class..         
+00002300: 2020 2044 6566 6175 6c74 7320 746f 2031     Defaults to 1
+00002310: 2e20 5468 6973 2069 7320 646f 6e65 2074  . This is done t
+00002320: 6f20 656e 7375 7265 2061 7567 6d65 6e74  o ensure augment
+00002330: 6174 696f 6e20 7465 6368 6e69 7175 6573  ation techniques
+00002340: 2061 7265 2061 7070 6c69 6564 2063 6f6e   are applied con
+00002350: 7369 7374 656e 746c 7920 6163 726f 7373  sistently across
+00002360: 2062 6f74 6820 636c 6173 7365 732e 0a20   both classes.. 
+00002370: 2020 2020 2020 2069 6d61 6765 5f73 697a         image_siz
+00002380: 655f 6d69 6e20 2869 6e74 293a 2054 6865  e_min (int): The
+00002390: 206d 696e 696d 756d 2069 6d61 6765 2073   minimum image s
+000023a0: 697a 6520 746f 2061 7373 6573 732c 206f  ize to assess, o
+000023b0: 6e6c 7920 6170 706c 6963 6162 6c65 2069  nly applicable i
+000023c0: 6620 6f70 745f 6175 673d 5472 7565 2e20  f opt_aug=True. 
+000023d0: 4465 6661 756c 7473 2074 6f20 3530 2e0a  Defaults to 50..
+000023e0: 2020 2020 2020 2020 696d 6167 655f 7369          image_si
+000023f0: 7a65 5f6d 6178 2028 696e 7429 3a20 5468  ze_max (int): Th
+00002400: 6520 6d61 7869 6d75 6d20 696d 6167 6520  e maximum image 
+00002410: 7369 7a65 2074 6f20 6173 7365 7373 2c20  size to assess, 
+00002420: 6f6e 6c79 2061 7070 6c69 6361 626c 6520  only applicable 
+00002430: 6966 206f 7074 5f61 7567 3d54 7275 652e  if opt_aug=True.
+00002440: 2044 6566 6175 6c74 7320 746f 2031 3030   Defaults to 100
+00002450: 2e0a 2020 2020 2020 2020 6f70 745f 6d61  ..        opt_ma
+00002460: 785f 6d69 6e5f 7069 7820 2869 6e74 2c20  x_min_pix (int, 
+00002470: 6f70 7469 6f6e 616c 293a 2054 6865 206d  optional): The m
+00002480: 696e 696d 756d 206d 6178 2070 6978 656c  inimum max pixel
+00002490: 2076 616c 7565 2074 6f20 7573 6520 7768   value to use wh
+000024a0: 656e 2074 756e 696e 6720 7468 6520 6e6f  en tuning the no
+000024b0: 726d 616c 697a 6174 696f 6e20 7072 6f63  rmalization proc
+000024c0: 6564 7572 652c 200a 2020 2020 2020 2020  edure, .        
+000024d0: 2020 2020 6f6e 6c79 2061 7070 6c69 6361      only applica
+000024e0: 626c 6520 6966 206f 7074 5f61 7567 3d54  ble if opt_aug=T
+000024f0: 7275 652e 2044 6566 6175 6c74 7320 746f  rue. Defaults to
+00002500: 204e 6f6e 652e 0a20 2020 2020 2020 206f   None..        o
+00002510: 7074 5f6d 6178 5f6d 6178 5f70 6978 2028  pt_max_max_pix (
+00002520: 696e 742c 206f 7074 696f 6e61 6c29 3a20  int, optional): 
+00002530: 5468 6520 6d61 7869 6d75 6d20 6d61 7820  The maximum max 
+00002540: 7069 7865 6c20 7661 6c75 6520 746f 2075  pixel value to u
+00002550: 7365 2077 6865 6e20 7475 6e69 6e67 2074  se when tuning t
+00002560: 6865 206e 6f72 6d61 6c69 7a61 7469 6f6e  he normalization
+00002570: 2070 726f 6365 6475 7265 2c20 0a20 2020   procedure, .   
+00002580: 2020 2020 2020 2020 206f 6e6c 7920 6170           only ap
+00002590: 706c 6963 6162 6c65 2069 6620 6f70 745f  plicable if opt_
+000025a0: 6175 673d 5472 7565 2e20 4465 6661 756c  aug=True. Defaul
+000025b0: 7473 2074 6f20 4e6f 6e65 2e0a 2020 2020  ts to None..    
+000025c0: 2020 2020 7368 6966 7420 2869 6e74 293a      shift (int):
+000025d0: 2054 6865 206d 6178 2061 6c6c 6f77 6564   The max allowed
+000025e0: 2076 6572 7469 6361 6c2f 686f 7269 7a6f   vertical/horizo
+000025f0: 6e74 616c 2073 6869 6674 7320 746f 2075  ntal shifts to u
+00002600: 7365 2064 7572 696e 6720 7468 6520 6461  se during the da
+00002610: 7461 2061 7567 6d65 6e74 6174 696f 6e20  ta augmentation 
+00002620: 726f 7574 696e 652c 206f 6e6c 7920 6170  routine, only ap
+00002630: 706c 6963 6162 6c65 0a20 2020 2020 2020  plicable.       
+00002640: 2020 2020 2069 6620 6f70 745f 6175 673d       if opt_aug=
+00002650: 5472 7565 2e20 4465 6661 756c 7473 2074  True. Defaults t
+00002660: 6f20 3130 2070 6978 656c 732e 0a20 2020  o 10 pixels..   
+00002670: 2020 2020 206d 6173 6b5f 7369 7a65 2028       mask_size (
+00002680: 696e 742c 206f 7074 696f 6e61 6c29 3a20  int, optional): 
+00002690: 4966 2065 6e61 626c 6564 2c20 7468 6973  If enabled, this
+000026a0: 2077 696c 6c20 7365 7420 7468 6520 7069   will set the pi
+000026b0: 7865 6c20 6c65 6e67 7468 206f 6620 6120  xel length of a 
+000026c0: 7371 7561 7265 2063 7574 6f75 742c 2074  square cutout, t
+000026d0: 6f20 6265 2072 616e 646f 6d6c 7920 706c  o be randomly pl
+000026e0: 6163 6564 0a20 2020 2020 2020 2020 2020  aced.           
+000026f0: 2073 6f6d 6577 6865 7265 2069 6e20 7468   somewhere in th
+00002700: 6520 6175 676d 656e 7465 6420 696d 6167  e augmented imag
+00002710: 652e 2054 6869 7320 6375 746f 7574 2077  e. This cutout w
+00002720: 696c 6c20 7265 706c 6163 6520 7468 6520  ill replace the 
+00002730: 696d 6167 6520 7661 6c75 6573 2077 6974  image values wit
+00002740: 6820 302c 2074 6865 7265 666f 7265 2073  h 0, therefore s
+00002750: 6572 7669 6e67 2061 7320 6120 0a20 2020  erving as a .   
+00002760: 2020 2020 2020 2020 2072 6567 756c 6172           regular
+00002770: 697a 6572 2e20 4f6e 6c79 2061 7070 6c69  izer. Only appli
+00002780: 6361 626c 6520 6966 206f 7074 5f61 7567  cable if opt_aug
+00002790: 3d54 7275 652e 2054 6869 7320 7661 6c75  =True. This valu
+000027a0: 6520 6361 6e20 6569 7468 6572 2062 6520  e can either be 
+000027b0: 616e 2069 6e74 6567 6572 2074 6f20 6861  an integer to ha
+000027c0: 7264 2d73 6574 2074 6865 206d 6173 6b20  rd-set the mask 
+000027d0: 7369 7a65 2065 7665 7279 7469 6d65 2c0a  size everytime,.
+000027e0: 2020 2020 2020 2020 2020 2020 6f72 2063              or c
+000027f0: 616e 2062 6520 6120 7475 706c 6520 7265  an be a tuple re
+00002800: 7072 6573 656e 7469 6e67 2074 6865 206c  presenting the l
+00002810: 6f77 6572 2061 6e64 2075 7070 6572 2062  ower and upper b
+00002820: 6f75 6e64 732c 2072 6573 7065 6374 6976  ounds, respectiv
+00002830: 656c 792c 2069 6e20 7768 6963 6820 6361  ely, in which ca
+00002840: 7365 2074 6865 206d 6173 6b20 7369 7a65  se the mask size
+00002850: 2077 696c 6c20 6265 206f 7074 696d 697a   will be optimiz
+00002860: 6564 2e20 0a20 2020 2020 2020 2020 2020  ed. .           
+00002870: 2044 6566 6175 6c74 7320 746f 204e 6f6e   Defaults to Non
+00002880: 652e 0a20 2020 2020 2020 206e 756d 5f6d  e..        num_m
+00002890: 6173 6b73 2028 696e 742c 206f 7074 696f  asks (int, optio
+000028a0: 6e61 6c29 3a20 5468 6520 6e75 6d62 6572  nal): The number
+000028b0: 206f 6620 6d61 736b 7320 746f 2063 7265   of masks to cre
+000028c0: 6174 652c 2074 6f20 6265 2075 7365 6420  ate, to be used 
+000028d0: 616c 6f6e 6773 6964 6520 7468 6520 6d61  alongside the ma
+000028e0: 736b 5f73 697a 6520 7061 7261 6d65 7465  sk_size paramete
+000028f0: 722e 204e 6f74 6520 7468 6174 2069 6620  r. Note that if 
+00002900: 0a20 2020 2020 2020 2020 2020 2074 6869  .            thi
+00002910: 7320 6973 2073 6574 2074 6f20 6120 7661  s is set to a va
+00002920: 6c75 6520 6772 6561 7465 7220 7468 616e  lue greater than
+00002930: 206f 6e65 2c20 6f76 6572 6c61 7020 6d61   one, overlap ma
+00002940: 7920 6f63 6375 722e 2054 6869 7320 7661  y occur. This va
+00002950: 6c75 6520 6361 6e20 6569 7468 6572 2062  lue can either b
+00002960: 6520 616e 2069 6e74 6567 6572 2074 6f20  e an integer to 
+00002970: 6861 7264 2d73 6574 2074 6865 206e 756d  hard-set the num
+00002980: 6265 720a 2020 2020 2020 2020 2020 2020  ber.            
+00002990: 6f66 206d 6173 6b73 2065 7665 7279 7469  of masks everyti
+000029a0: 6d65 2c20 6f72 2069 7420 6361 6e20 6265  me, or it can be
+000029b0: 2061 2074 7570 6c65 2072 6570 7265 7365   a tuple represe
+000029c0: 6e74 696e 6720 7468 6520 6c6f 7765 7220  nting the lower 
+000029d0: 616e 6420 7570 7065 7220 626f 756e 6473  and upper bounds
+000029e0: 2c20 7265 7370 6563 7469 7665 6c79 2c20  , respectively, 
+000029f0: 696e 2077 6869 6368 2063 6173 6520 7468  in which case th
+00002a00: 6520 6e75 6d62 6572 0a20 2020 2020 2020  e number.       
+00002a10: 2020 2020 206f 6620 6d61 736b 7320 7769       of masks wi
+00002a20: 6c6c 2062 6520 6f70 7469 6d69 7a65 642e  ll be optimized.
+00002a30: 2044 6566 6175 6c74 7320 746f 204e 6f6e   Defaults to Non
+00002a40: 652e 0a20 2020 2020 2020 2076 6572 626f  e..        verbo
+00002a50: 7365 2028 696e 7429 3a20 436f 6e74 726f  se (int): Contro
+00002a60: 6c73 2074 6865 2061 6d6f 756e 7420 6f66  ls the amount of
+00002a70: 206f 7574 7075 7420 7072 696e 7465 6420   output printed 
+00002a80: 6475 7269 6e67 2074 6865 2074 7261 696e  during the train
+00002a90: 696e 6720 7072 6f63 6573 732e 2041 2076  ing process. A v
+00002aa0: 616c 7565 206f 6620 3020 6973 2066 6f72  alue of 0 is for
+00002ab0: 2073 696c 656e 7420 6d6f 6465 2c20 0a20   silent mode, . 
+00002ac0: 2020 2020 2020 2020 2020 2061 2076 616c             a val
+00002ad0: 7565 206f 6620 3120 6973 2075 7365 6420  ue of 1 is used 
+00002ae0: 666f 7220 7072 6f67 7265 7373 2062 6172  for progress bar
+00002af0: 206d 6f64 652c 2061 6e64 2032 2066 6f72   mode, and 2 for
+00002b00: 206f 6e65 206c 696e 6520 7065 7220 6570   one line per ep
+00002b10: 6f63 6820 6d6f 6465 2e20 4465 6661 756c  och mode. Defaul
+00002b20: 7473 2074 6f20 312e 0a20 2020 2020 2020  ts to 1..       
+00002b30: 206f 7074 5f63 7620 2869 6e74 293a 2043   opt_cv (int): C
+00002b40: 726f 7373 2d76 616c 6964 6174 696f 6e73  ross-validations
+00002b50: 2074 6f20 7065 7266 6f72 6d20 7768 656e   to perform when
+00002b60: 2061 7373 6573 7369 6e67 2074 6865 2070   assessing the p
+00002b70: 6572 666f 726d 616e 6365 2061 7420 6561  erformance at ea
+00002b80: 6368 0a20 2020 2020 2020 2020 2020 2068  ch.            h
+00002b90: 7970 6572 7061 7261 6d65 7465 7220 6f70  yperparameter op
+00002ba0: 7469 6d69 7a61 7469 6f6e 2074 7269 616c  timization trial
+00002bb0: 2e20 466f 7220 6578 616d 706c 652c 2069  . For example, i
+00002bc0: 6620 6376 3d33 2c20 7468 656e 2065 6163  f cv=3, then eac
+00002bd0: 6820 6f70 7469 6d69 7a61 7469 6f6e 2074  h optimization t
+00002be0: 7269 616c 0a20 2020 2020 2020 2020 2020  rial.           
+00002bf0: 2077 696c 6c20 6265 2061 7373 6573 7365   will be assesse
+00002c00: 6420 6163 636f 7264 696e 6720 746f 2074  d according to t
+00002c10: 6865 2033 2d66 6f6c 6420 6372 6f73 7320  he 3-fold cross 
+00002c20: 7661 6c69 6461 7469 6f6e 2061 6363 7572  validation accur
+00002c30: 6163 792e 2044 6566 6175 6c74 7320 746f  acy. Defaults to
+00002c40: 2031 302e 0a20 2020 2020 2020 2020 2020   10..           
+00002c50: 204e 4f54 453a 2054 6865 2068 6967 6865   NOTE: The highe
+00002c60: 7220 7468 6973 206e 756d 6265 722c 2074  r this number, t
+00002c70: 6865 206c 6f6e 6765 7220 7468 6520 6f70  he longer the op
+00002c80: 7469 6d69 7a61 7469 6f6e 2077 696c 6c20  timization will 
+00002c90: 7461 6b65 2e0a 2020 2020 2020 2020 6261  take..        ba
+00002ca0: 6c61 6e63 6520 2862 6f6f 6c2c 206f 7074  lance (bool, opt
+00002cb0: 696f 6e61 6c29 3a20 5468 6973 2077 696c  ional): This wil
+00002cc0: 6c20 6465 7465 726d 696e 6520 7768 6574  l determine whet
+00002cd0: 6865 7220 7468 6520 7477 6f20 636c 6173  her the two clas
+00002ce0: 7365 730a 2020 2020 2020 2020 2020 2020  ses.            
+00002cf0: 6172 6520 6b65 7074 2074 6865 2073 616d  are kept the sam
+00002d00: 6520 7369 7a65 2064 7572 696e 6720 6f70  e size during op
+00002d10: 7469 6d69 7a61 7469 6f6e 2c20 6170 706c  timization, appl
+00002d20: 6963 6162 6c65 2069 6620 7475 6e69 6e67  icable if tuning
+00002d30: 2074 6865 2061 7567 6d65 6e74 6174 696f   the augmentatio
+00002d40: 6e0a 2020 2020 2020 2020 2020 2020 7061  n.            pa
+00002d50: 7261 6d65 7465 7273 2e20 4465 6661 756c  rameters. Defaul
+00002d60: 7473 2074 6f20 5472 7565 2e0a 2020 2020  ts to True..    
+00002d70: 2020 2020 636c 6620 2873 7472 293a 2043      clf (str): C
+00002d80: 616e 2062 6520 2761 6c65 786e 6574 2720  an be 'alexnet' 
+00002d90: 6f72 2027 6375 7374 6f6d 5f63 6e6e 2720  or 'custom_cnn' 
+00002da0: 666f 7220 7468 6520 6375 7374 6f6d 6c79  for the customly
+00002db0: 2063 6f6e 6669 6775 7265 642c 2073 6861   configured, sha
+00002dc0: 6c6c 6f77 6572 206d 6f64 656c 2e20 4361  llower model. Ca
+00002dd0: 6e20 616c 736f 2062 6520 0a20 2020 2020  n also be .     
+00002de0: 2020 2020 2020 2027 7667 6731 3627 206f         'vgg16' o
+00002df0: 7220 2772 6573 6e65 7431 3827 2e0a 2020  r 'resnet18'..  
+00002e00: 2020 2020 2020 6c69 6d69 745f 7365 6172        limit_sear
+00002e10: 6368 2028 626f 6f6c 293a 2057 6865 7468  ch (bool): Wheth
+00002e20: 6572 2074 6f20 6578 7061 6e64 2074 6865  er to expand the
+00002e30: 2068 7970 6572 7061 7261 6d65 7465 7220   hyperparameter 
+00002e40: 7365 6172 6368 2073 7061 6365 2c20 6f6e  search space, on
+00002e50: 6c79 2069 6620 6170 706c 6963 6162 6c65  ly if applicable
+00002e60: 2069 6620 636c 663d 2761 6c65 786e 6574   if clf='alexnet
+00002e70: 272c 2066 6f72 2065 7861 6d70 6c65 2c0a  ', for example,.
+00002e80: 2020 2020 2020 2020 2020 2020 7468 6973              this
+00002e90: 2077 696c 6c20 696e 636c 7564 6520 7468   will include th
+00002ea0: 6520 7475 6e69 6e67 206f 6620 7468 6520  e tuning of the 
+00002eb0: 696e 6469 7669 6475 616c 206c 6179 6572  individual layer
+00002ec0: 2070 6172 616d 6574 6572 7320 7375 6368   parameters such
+00002ed0: 2061 7320 7468 6520 6e75 6d62 6572 206f   as the number o
+00002ee0: 6620 6669 6c74 6572 2c20 7369 7a65 2026  f filter, size &
+00002ef0: 2073 7472 6964 652e 0a20 2020 2020 2020   stride..       
+00002f00: 2020 2020 2044 6566 6175 6c74 7320 746f       Defaults to
+00002f10: 2054 7275 6520 6475 6520 746f 206d 656d   True due to mem
+00002f20: 6f72 7920 616c 6c6f 6361 7469 6f6e 2069  ory allocation i
+00002f30: 7373 7565 7320 7768 656e 2068 616e 646c  ssues when handl
+00002f40: 696e 6720 6c6f 7473 206f 6620 7475 6e61  ing lots of tuna
+00002f50: 626c 6520 7061 7261 6d65 7465 7273 2e0a  ble parameters..
+00002f60: 2020 2020 2020 2020 6261 7463 685f 7369          batch_si
+00002f70: 7a65 5f6d 696e 2028 696e 7429 3a20 5468  ze_min (int): Th
+00002f80: 6520 6d69 6e69 6d75 6d20 6261 7463 6820  e minimum batch 
+00002f90: 7369 7a65 2074 6f20 7573 6520 6475 7269  size to use duri
+00002fa0: 6e67 2074 7261 696e 696e 672e 2053 686f  ng training. Sho
+00002fb0: 756c 6420 6265 206d 756c 7469 706c 6573  uld be multiples
+00002fc0: 206f 6620 3136 2066 6f72 206f 7074 696d   of 16 for optim
+00002fd0: 616c 2068 6172 6477 6172 6520 7573 653f  al hardware use?
+00002fe0: 3f20 4465 6661 756c 7473 2074 6f20 3136  ? Defaults to 16
+00002ff0: 2e0a 2020 2020 2020 2020 6261 7463 685f  ..        batch_
+00003000: 7369 7a65 5f6d 6178 2028 696e 7429 3a20  size_max (int): 
+00003010: 5468 6520 4d61 7869 6d75 6d20 6261 7463  The Maximum batc
+00003020: 6820 7369 7a65 2074 6f20 7573 6520 6475  h size to use du
+00003030: 7269 6e67 2074 7261 696e 696e 672e 2053  ring training. S
+00003040: 686f 756c 6420 6265 206d 756c 7469 706c  hould be multipl
+00003050: 6573 206f 6620 3136 2066 6f72 206f 7074  es of 16 for opt
+00003060: 696d 616c 2068 6172 6477 6172 6520 7573  imal hardware us
+00003070: 653f 3f20 4465 6661 756c 7473 2074 6f20  e?? Defaults to 
+00003080: 3634 2e0a 2020 2020 2020 2020 6d6f 6e69  64..        moni
+00003090: 746f 7231 2028 7374 722c 206f 7074 696f  tor1 (str, optio
+000030a0: 6e61 6c29 3a20 5468 6520 6669 7273 7420  nal): The first 
+000030b0: 6d65 7472 6963 2074 6f20 6d6f 6e69 746f  metric to monito
+000030c0: 722c 2063 616e 2074 616b 6520 7468 6520  r, can take the 
+000030d0: 7361 6d65 2076 616c 7565 7320 6173 2074  same values as t
+000030e0: 6865 206d 6574 7269 6320 6172 6775 6d65  he metric argume
+000030f0: 6e74 2e20 4465 6661 756c 7473 2074 6f20  nt. Defaults to 
+00003100: 4e6f 6e65 2e0a 2020 2020 2020 2020 6d6f  None..        mo
+00003110: 6e69 746f 7232 2028 7374 722c 206f 7074  nitor2 (str, opt
+00003120: 696f 6e61 6c29 3a20 5468 6520 7365 636f  ional): The seco
+00003130: 6e64 206d 6574 7269 6320 746f 206d 6f6e  nd metric to mon
+00003140: 6974 6f72 2c20 6361 6e20 7461 6b65 2074  itor, can take t
+00003150: 6865 2073 616d 6520 7661 6c75 6573 2061  he same values a
+00003160: 7320 7468 6520 6d65 7472 6963 2061 7267  s the metric arg
+00003170: 756d 656e 742e 2044 6566 6175 6c74 7320  ument. Defaults 
+00003180: 746f 204e 6f6e 652e 0a20 2020 2020 2020  to None..       
+00003190: 206d 6f6e 6974 6f72 315f 7468 7265 7368   monitor1_thresh
+000031a0: 2028 666c 6f61 742c 206f 7074 696f 6e61   (float, optiona
+000031b0: 6c29 3a20 5468 6520 7468 7265 7368 6f6c  l): The threshol
+000031c0: 6420 7661 6c75 6520 6f66 2074 6865 2066  d value of the f
+000031d0: 6972 7374 206d 6f6e 6974 6f72 206d 6574  irst monitor met
+000031e0: 7269 632e 2049 6620 7468 6520 6d65 7472  ric. If the metr
+000031f0: 6963 2069 7320 6c6f 7373 2d72 656c 6174  ic is loss-relat
+00003200: 6564 0a20 2020 2020 2020 2020 2020 2074  ed.            t
+00003210: 6865 2074 7261 696e 696e 6720 7769 6c6c  he training will
+00003220: 2073 746f 7020 6561 726c 7920 6966 2074   stop early if t
+00003230: 6865 2076 616c 7565 2066 616c 6c73 2062  he value falls b
+00003240: 656c 6f77 2074 6869 7320 7468 7265 7368  elow this thresh
+00003250: 6f6c 642e 2053 696d 696c 6172 6c79 2c20  old. Similarly, 
+00003260: 6966 2074 6865 206d 6574 7269 6320 6973  if the metric is
+00003270: 2061 6363 7572 6163 792d 7265 6c61 7465   accuracy-relate
+00003280: 642c 0a20 2020 2020 2020 2020 2020 2074  d,.            t
+00003290: 6865 6e20 7468 6520 7472 6169 6e69 6e67  hen the training
+000032a0: 2077 696c 6c20 7374 6f70 2065 6172 6c79   will stop early
+000032b0: 2069 6620 7468 6520 7661 6c75 6520 6661   if the value fa
+000032c0: 6c6c 7320 6162 6f76 6520 7468 6973 2074  lls above this t
+000032d0: 6872 6573 686f 6c64 2e20 4465 6661 756c  hreshold. Defaul
+000032e0: 7473 2074 6f20 4e6f 6e65 2e0a 2020 2020  ts to None..    
+000032f0: 2020 2020 6d6f 6e69 746f 7232 5f74 6872      monitor2_thr
+00003300: 6573 6820 2866 6c6f 6174 2c20 6f70 7469  esh (float, opti
+00003310: 6f6e 616c 293a 2054 6865 2074 6872 6573  onal): The thres
+00003320: 686f 6c64 2076 616c 7565 206f 6620 7468  hold value of th
+00003330: 6520 7365 636f 6e64 206d 6f6e 6974 6f72  e second monitor
+00003340: 206d 6574 7269 632e 2049 6620 7468 6520   metric. If the 
+00003350: 6d65 7472 6963 2069 7320 6c6f 7373 2d72  metric is loss-r
+00003360: 656c 6174 6564 0a20 2020 2020 2020 2020  elated.         
+00003370: 2020 2074 6865 2074 7261 696e 696e 6720     the training 
+00003380: 7769 6c6c 2073 746f 7020 6561 726c 7920  will stop early 
+00003390: 6966 2074 6865 2076 616c 7565 2066 616c  if the value fal
+000033a0: 6c73 2062 656c 6f77 2074 6869 7320 7468  ls below this th
+000033b0: 7265 7368 6f6c 642e 2053 696d 696c 6172  reshold. Similar
+000033c0: 6c79 2c20 6966 2074 6865 206d 6574 7269  ly, if the metri
+000033d0: 6320 6973 2061 6363 7572 6163 792d 7265  c is accuracy-re
+000033e0: 6c61 7465 642c 0a20 2020 2020 2020 2020  lated,.         
+000033f0: 2020 2074 6865 6e20 7468 6520 7472 6169     then the trai
+00003400: 6e69 6e67 2077 696c 6c20 7374 6f70 2065  ning will stop e
+00003410: 6172 6c79 2069 6620 7468 6520 7661 6c75  arly if the valu
+00003420: 6520 6661 6c6c 7320 6162 6f76 6520 7468  e falls above th
+00003430: 6973 2074 6872 6573 686f 6c64 2e20 4465  is threshold. De
+00003440: 6661 756c 7473 2074 6f20 4e6f 6e65 2e0a  faults to None..
+00003450: 2020 2020 2020 2020 736d 6f74 655f 7361          smote_sa
+00003460: 6d70 6c69 6e67 2028 666c 6f61 7429 3a20  mpling (float): 
+00003470: 5468 6520 736d 6f74 655f 7361 6d70 6c69  The smote_sampli
+00003480: 6e67 2070 6172 616d 6574 6572 2069 7320  ng parameter is 
+00003490: 7573 6564 2069 6e20 7468 6520 534d 4f54  used in the SMOT
+000034a0: 4520 616c 676f 7269 7468 6d20 746f 2073  E algorithm to s
+000034b0: 7065 6369 6679 2074 6865 2064 6573 6972  pecify the desir
+000034c0: 6564 200a 2020 2020 2020 2020 2020 2020  ed .            
+000034d0: 7261 7469 6f20 6f66 2074 6865 206d 696e  ratio of the min
+000034e0: 6f72 6974 7920 636c 6173 7320 746f 2074  ority class to t
+000034f0: 6865 206d 616a 6f72 6974 7920 636c 6173  he majority clas
+00003500: 732e 2044 6566 6175 6c74 7320 746f 2030  s. Defaults to 0
+00003510: 2077 6869 6368 2064 6973 6162 6c65 7320   which disables 
+00003520: 7468 6520 7072 6f63 6564 7572 652e 2046  the procedure. F
+00003530: 6f72 206d 6f72 650a 2020 2020 2020 2020  or more.        
+00003540: 2020 2020 696e 666f 726d 6174 696f 6e20      information 
+00003550: 7265 6665 7220 746f 2074 6865 2065 6e73  refer to the ens
+00003560: 656d 626c 655f 6d6f 6465 6c20 6d6f 6475  emble_model modu
+00003570: 6c65 2e0a 2020 2020 2020 2020 626c 656e  le..        blen
+00003580: 645f 6d61 7820 2866 6c6f 6174 293a 2049  d_max (float): I
+00003590: 6620 7573 6564 2074 6869 7320 7769 6c6c  f used this will
+000035a0: 2061 7070 6c79 2062 6c65 6e64 696e 6720   apply blending 
+000035b0: 6175 676d 656e 7461 7469 6f6e 200a 2020  augmentation .  
+000035c0: 2020 2020 2020 6e75 6d5f 696d 6167 6573        num_images
+000035d0: 5f74 6f5f 626c 656e 6420 2869 6e74 293a  _to_blend (int):
+000035e0: 0a20 2020 2020 2020 207a 6f6f 6d5f 7261  .        zoom_ra
+000035f0: 6e67 6520 2874 7570 6c65 293a 2057 696c  nge (tuple): Wil
+00003600: 6c20 7261 6e64 6f6d 6c79 2061 7070 6c79  l randomly apply
+00003610: 207a 6f6f 6d69 6e67 2069 6e2f 6f75 7420   zooming in/out 
+00003620: 6265 7477 6565 6e20 7468 6520 696e 7075  between the inpu
+00003630: 7420 7261 6e67 652c 2066 6f72 2065 7861  t range, for exa
+00003640: 6d70 6c65 2c20 6966 2073 6574 2074 6f20  mple, if set to 
+00003650: 2830 2e39 2c20 312e 3129 2069 7420 7769  (0.9, 1.1) it wi
+00003660: 6c6c 0a20 2020 2020 2020 2020 2020 2073  ll.            s
+00003670: 656c 6563 7420 6120 7261 6e64 6f6d 207a  elect a random z
+00003680: 6f6f 6d20 7661 6c75 6520 6265 7477 6565  oom value betwee
+00003690: 6e20 706c 7573 2061 6e64 206d 696e 7573  n plus and minus
+000036a0: 2031 3025 2074 6f20 6561 6368 2061 7567   10% to each aug
+000036b0: 6d65 6e74 6564 2069 6d61 6765 2e20 4465  mented image. De
+000036c0: 6661 756c 7473 2074 6f20 4e6f 6e65 2e0a  faults to None..
+000036d0: 2020 2020 2020 2020 6261 7463 685f 6f74          batch_ot
+000036e0: 6865 7220 2869 6e74 293a 2054 6865 206e  her (int): The n
+000036f0: 756d 6265 7220 6f66 2061 7567 6d65 6e74  umber of augment
+00003700: 6174 696f 6e73 2074 6f20 7065 7266 6f72  ations to perfor
+00003710: 6d20 746f 2074 6865 206e 6567 6174 6976  m to the negativ
+00003720: 6520 636c 6173 732e 2044 6566 6175 6c74  e class. Default
+00003730: 7320 746f 2030 2e0a 2020 2020 2020 2020  s to 0..        
+00003740: 626c 656e 6469 6e67 5f66 756e 6320 2873  blending_func (s
+00003750: 7472 293a 0a20 2020 2020 2020 2073 6b65  tr):.        ske
+00003760: 775f 616e 676c 6520 2866 6c6f 6174 293a  w_angle (float):
+00003770: 0a20 2020 2020 2020 2072 6f74 6174 696f  .        rotatio
+00003780: 6e20 2862 6f6f 6c29 3a0a 2020 2020 2020  n (bool):.      
+00003790: 2020 686f 7269 7a6f 6e74 616c 2028 626f    horizontal (bo
+000037a0: 6f6c 293a 0a20 2020 2020 2020 2076 6572  ol):.        ver
+000037b0: 7469 6361 6c20 2862 6f6f 6c29 3a20 0a20  tical (bool): . 
+000037c0: 2020 2020 2020 200a 2020 2020 5265 7475         .    Retu
+000037d0: 726e 733a 0a20 2020 2020 2020 2054 6865  rns:.        The
+000037e0: 2070 6572 666f 726d 616e 6365 206d 6574   performance met
+000037f0: 7269 632e 0a20 2020 2022 2222 0a0a 2020  ric..    """..  
+00003800: 2020 6465 6620 5f5f 696e 6974 5f5f 2873    def __init__(s
+00003810: 656c 662c 2070 6f73 6974 6976 655f 636c  elf, positive_cl
+00003820: 6173 732c 206e 6567 6174 6976 655f 636c  ass, negative_cl
+00003830: 6173 732c 2076 616c 5f70 6f73 6974 6976  ass, val_positiv
+00003840: 653d 4e6f 6e65 2c20 7661 6c5f 6e65 6761  e=None, val_nega
+00003850: 7469 7665 3d4e 6f6e 652c 2069 6d67 5f6e  tive=None, img_n
+00003860: 756d 5f63 6861 6e6e 656c 733d 312c 2063  um_channels=1, c
+00003870: 6c66 3d27 616c 6578 6e65 7427 2c20 0a20  lf='alexnet', . 
+00003880: 2020 2020 2020 206e 6f72 6d61 6c69 7a65         normalize
+00003890: 3d54 7275 652c 206d 696e 5f70 6978 656c  =True, min_pixel
+000038a0: 3d30 2c20 6d61 785f 7069 7865 6c3d 3130  =0, max_pixel=10
+000038b0: 3030 2c20 7061 7469 656e 6365 3d35 2c20  00, patience=5, 
+000038c0: 6d65 7472 6963 3d27 6c6f 7373 272c 206d  metric='loss', m
+000038d0: 6574 7269 6332 3d4e 6f6e 652c 206d 6574  etric2=None, met
+000038e0: 7269 6333 3d4e 6f6e 652c 2061 7665 7261  ric3=None, avera
+000038f0: 6765 3d54 7275 652c 200a 2020 2020 2020  ge=True, .      
+00003900: 2020 7465 7374 5f70 6f73 6974 6976 653d    test_positive=
+00003910: 4e6f 6e65 2c20 7465 7374 5f6e 6567 6174  None, test_negat
+00003920: 6976 653d 4e6f 6e65 2c20 706f 7374 5f6d  ive=None, post_m
+00003930: 6574 7269 633d 5472 7565 2c20 7465 7374  etric=True, test
+00003940: 5f61 6363 5f74 6872 6573 686f 6c64 3d4e  _acc_threshold=N
+00003950: 6f6e 652c 2062 6174 6368 5f73 697a 655f  one, batch_size_
+00003960: 6d69 6e3d 3136 2c20 6261 7463 685f 7369  min=16, batch_si
+00003970: 7a65 5f6d 6178 3d36 342c 200a 2020 2020  ze_max=64, .    
+00003980: 2020 2020 6f70 745f 6d6f 6465 6c3d 5472      opt_model=Tr
+00003990: 7565 2c20 7472 6169 6e5f 6570 6f63 6873  ue, train_epochs
+000039a0: 3d32 352c 206f 7074 5f63 763d 4e6f 6e65  =25, opt_cv=None
+000039b0: 2c20 6f70 745f 6175 673d 4661 6c73 652c  , opt_aug=False,
+000039c0: 2062 6174 6368 5f6d 696e 3d32 2c20 6261   batch_min=2, ba
+000039d0: 7463 685f 6d61 783d 3235 2c20 6261 7463  tch_max=25, batc
+000039e0: 685f 6f74 6865 723d 312c 200a 2020 2020  h_other=1, .    
+000039f0: 2020 2020 6261 6c61 6e63 653d 5472 7565      balance=True
+00003a00: 2c20 696d 6167 655f 7369 7a65 5f6d 696e  , image_size_min
+00003a10: 3d35 302c 2069 6d61 6765 5f73 697a 655f  =50, image_size_
+00003a20: 6d61 783d 3130 302c 2073 6869 6674 3d31  max=100, shift=1
+00003a30: 302c 206f 7074 5f6d 6178 5f6d 696e 5f70  0, opt_max_min_p
+00003a40: 6978 3d4e 6f6e 652c 206f 7074 5f6d 6178  ix=None, opt_max
+00003a50: 5f6d 6178 5f70 6978 3d4e 6f6e 652c 2072  _max_pix=None, r
+00003a60: 6f74 6174 696f 6e3d 4661 6c73 652c 2068  otation=False, h
+00003a70: 6f72 697a 6f6e 7461 6c3d 4661 6c73 652c  orizontal=False,
+00003a80: 0a20 2020 2020 2020 2076 6572 7469 6361  .        vertica
+00003a90: 6c3d 4661 6c73 652c 206d 6173 6b5f 7369  l=False, mask_si
+00003aa0: 7a65 3d4e 6f6e 652c 206e 756d 5f6d 6173  ze=None, num_mas
+00003ab0: 6b73 3d4e 6f6e 652c 2073 6d6f 7465 5f73  ks=None, smote_s
+00003ac0: 616d 706c 696e 673d 302c 2062 6c65 6e64  ampling=0, blend
+00003ad0: 5f6d 6178 3d30 2c20 6e75 6d5f 696d 6167  _max=0, num_imag
+00003ae0: 6573 5f74 6f5f 626c 656e 643d 322c 2062  es_to_blend=2, b
+00003af0: 6c65 6e64 696e 675f 6675 6e63 3d27 6d65  lending_func='me
+00003b00: 616e 272c 2062 6c65 6e64 5f6f 7468 6572  an', blend_other
+00003b10: 3d31 2c20 0a20 2020 2020 2020 2073 6b65  =1, .        ske
+00003b20: 775f 616e 676c 653d 302c 207a 6f6f 6d5f  w_angle=0, zoom_
+00003b30: 7261 6e67 653d 4e6f 6e65 2c20 6c69 6d69  range=None, limi
+00003b40: 745f 7365 6172 6368 3d54 7275 652c 206d  t_search=True, m
+00003b50: 6f6e 6974 6f72 313d 4e6f 6e65 2c20 6d6f  onitor1=None, mo
+00003b60: 6e69 746f 7232 3d4e 6f6e 652c 206d 6f6e  nitor2=None, mon
+00003b70: 6974 6f72 315f 7468 7265 7368 3d4e 6f6e  itor1_thresh=Non
+00003b80: 652c 206d 6f6e 6974 6f72 325f 7468 7265  e, monitor2_thre
+00003b90: 7368 3d4e 6f6e 652c 2076 6572 626f 7365  sh=None, verbose
+00003ba0: 3d30 293a 0a0a 2020 2020 2020 2020 7365  =0):..        se
+00003bb0: 6c66 2e70 6f73 6974 6976 655f 636c 6173  lf.positive_clas
+00003bc0: 7320 3d20 706f 7369 7469 7665 5f63 6c61  s = positive_cla
+00003bd0: 7373 0a20 2020 2020 2020 2073 656c 662e  ss.        self.
+00003be0: 6e65 6761 7469 7665 5f63 6c61 7373 203d  negative_class =
+00003bf0: 206e 6567 6174 6976 655f 636c 6173 730a   negative_class.
+00003c00: 2020 2020 2020 2020 7365 6c66 2e69 6d67          self.img
+00003c10: 5f6e 756d 5f63 6861 6e6e 656c 7320 3d20  _num_channels = 
+00003c20: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+00003c30: 0a20 2020 2020 2020 2073 656c 662e 6e6f  .        self.no
+00003c40: 726d 616c 697a 6520 3d20 6e6f 726d 616c  rmalize = normal
+00003c50: 697a 6520 0a20 2020 2020 2020 2073 656c  ize .        sel
+00003c60: 662e 6d69 6e5f 7069 7865 6c20 3d20 6d69  f.min_pixel = mi
+00003c70: 6e5f 7069 7865 6c0a 2020 2020 2020 2020  n_pixel.        
+00003c80: 7365 6c66 2e6d 6178 5f70 6978 656c 203d  self.max_pixel =
+00003c90: 206d 6178 5f70 6978 656c 0a20 2020 2020   max_pixel.     
+00003ca0: 2020 2073 656c 662e 7661 6c5f 706f 7369     self.val_posi
+00003cb0: 7469 7665 203d 2076 616c 5f70 6f73 6974  tive = val_posit
+00003cc0: 6976 650a 2020 2020 2020 2020 7365 6c66  ive.        self
+00003cd0: 2e76 616c 5f6e 6567 6174 6976 6520 3d20  .val_negative = 
+00003ce0: 7661 6c5f 6e65 6761 7469 7665 0a20 2020  val_negative.   
+00003cf0: 2020 2020 2073 656c 662e 7465 7374 5f70       self.test_p
+00003d00: 6f73 6974 6976 6520 3d20 7465 7374 5f70  ositive = test_p
+00003d10: 6f73 6974 6976 650a 2020 2020 2020 2020  ositive.        
+00003d20: 7365 6c66 2e74 6573 745f 6e65 6761 7469  self.test_negati
+00003d30: 7665 203d 2074 6573 745f 6e65 6761 7469  ve = test_negati
+00003d40: 7665 0a20 2020 2020 2020 2073 656c 662e  ve.        self.
+00003d50: 706f 7374 5f6d 6574 7269 6320 3d20 706f  post_metric = po
+00003d60: 7374 5f6d 6574 7269 630a 2020 2020 2020  st_metric.      
+00003d70: 2020 7365 6c66 2e74 6573 745f 6163 635f    self.test_acc_
+00003d80: 7468 7265 7368 6f6c 6420 3d20 7465 7374  threshold = test
+00003d90: 5f61 6363 5f74 6872 6573 686f 6c64 0a0a  _acc_threshold..
+00003da0: 2020 2020 2020 2020 7365 6c66 2e62 6174          self.bat
+00003db0: 6368 5f73 697a 655f 6d69 6e20 3d20 6261  ch_size_min = ba
+00003dc0: 7463 685f 7369 7a65 5f6d 696e 0a20 2020  tch_size_min.   
+00003dd0: 2020 2020 2073 656c 662e 6261 7463 685f       self.batch_
+00003de0: 7369 7a65 5f6d 6178 203d 2062 6174 6368  size_max = batch
+00003df0: 5f73 697a 655f 6d61 780a 2020 2020 2020  _size_max.      
+00003e00: 2020 7365 6c66 2e74 7261 696e 5f65 706f    self.train_epo
+00003e10: 6368 7320 3d20 7472 6169 6e5f 6570 6f63  chs = train_epoc
+00003e20: 6873 0a20 2020 2020 2020 2073 656c 662e  hs.        self.
+00003e30: 7061 7469 656e 6365 203d 2070 6174 6965  patience = patie
+00003e40: 6e63 6520 0a20 2020 2020 2020 2073 656c  nce .        sel
+00003e50: 662e 6f70 745f 6d6f 6465 6c20 3d20 6f70  f.opt_model = op
+00003e60: 745f 6d6f 6465 6c20 200a 2020 2020 2020  t_model  .      
+00003e70: 2020 7365 6c66 2e6f 7074 5f61 7567 203d    self.opt_aug =
+00003e80: 206f 7074 5f61 7567 0a20 2020 2020 2020   opt_aug.       
+00003e90: 2073 656c 662e 6261 7463 685f 6d69 6e20   self.batch_min 
+00003ea0: 3d20 6261 7463 685f 6d69 6e20 0a20 2020  = batch_min .   
+00003eb0: 2020 2020 2073 656c 662e 6261 7463 685f       self.batch_
+00003ec0: 6d61 7820 3d20 6261 7463 685f 6d61 7820  max = batch_max 
+00003ed0: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
+00003ee0: 7463 685f 6f74 6865 7220 3d20 6261 7463  tch_other = batc
+00003ef0: 685f 6f74 6865 720a 2020 2020 2020 2020  h_other.        
+00003f00: 7365 6c66 2e69 6d61 6765 5f73 697a 655f  self.image_size_
+00003f10: 6d69 6e20 3d20 696d 6167 655f 7369 7a65  min = image_size
+00003f20: 5f6d 696e 0a20 2020 2020 2020 2073 656c  _min.        sel
+00003f30: 662e 696d 6167 655f 7369 7a65 5f6d 6178  f.image_size_max
+00003f40: 203d 2069 6d61 6765 5f73 697a 655f 6d61   = image_size_ma
+00003f50: 780a 2020 2020 2020 2020 7365 6c66 2e62  x.        self.b
+00003f60: 616c 616e 6365 203d 2062 616c 616e 6365  alance = balance
+00003f70: 0a20 2020 2020 2020 2073 656c 662e 6f70  .        self.op
+00003f80: 745f 6d61 785f 6d69 6e5f 7069 7820 3d20  t_max_min_pix = 
+00003f90: 6f70 745f 6d61 785f 6d69 6e5f 7069 780a  opt_max_min_pix.
+00003fa0: 2020 2020 2020 2020 7365 6c66 2e6f 7074          self.opt
+00003fb0: 5f6d 6178 5f6d 6178 5f70 6978 203d 206f  _max_max_pix = o
+00003fc0: 7074 5f6d 6178 5f6d 6178 5f70 6978 0a20  pt_max_max_pix. 
+00003fd0: 2020 2020 2020 2073 656c 662e 6d65 7472         self.metr
+00003fe0: 6963 203d 206d 6574 7269 6320 0a20 2020  ic = metric .   
+00003ff0: 2020 2020 2073 656c 662e 6d65 7472 6963       self.metric
+00004000: 3220 3d20 6d65 7472 6963 320a 2020 2020  2 = metric2.    
+00004010: 2020 2020 7365 6c66 2e6d 6574 7269 6333      self.metric3
+00004020: 203d 206d 6574 7269 6333 0a20 2020 2020   = metric3.     
+00004030: 2020 2073 656c 662e 6176 6572 6167 6520     self.average 
+00004040: 3d20 6176 6572 6167 650a 2020 2020 2020  = average.      
+00004050: 2020 7365 6c66 2e73 6869 6674 203d 2073    self.shift = s
+00004060: 6869 6674 200a 2020 2020 2020 2020 7365  hift .        se
+00004070: 6c66 2e6f 7074 5f63 7620 3d20 6f70 745f  lf.opt_cv = opt_
+00004080: 6376 0a20 2020 2020 2020 2073 656c 662e  cv.        self.
+00004090: 7665 7262 6f73 6520 3d20 7665 7262 6f73  verbose = verbos
+000040a0: 650a 2020 2020 2020 2020 7365 6c66 2e6d  e.        self.m
+000040b0: 6173 6b5f 7369 7a65 203d 206d 6173 6b5f  ask_size = mask_
+000040c0: 7369 7a65 0a20 2020 2020 2020 2073 656c  size.        sel
+000040d0: 662e 6e75 6d5f 6d61 736b 7320 3d20 6e75  f.num_masks = nu
+000040e0: 6d5f 6d61 736b 730a 2020 2020 2020 2020  m_masks.        
+000040f0: 7365 6c66 2e6c 696d 6974 5f73 6561 7263  self.limit_searc
+00004100: 6820 3d20 6c69 6d69 745f 7365 6172 6368  h = limit_search
+00004110: 0a20 2020 2020 2020 2073 656c 662e 636c  .        self.cl
+00004120: 6620 3d20 636c 660a 0a20 2020 2020 2020  f = clf..       
+00004130: 2073 656c 662e 6d6f 6e69 746f 7231 203d   self.monitor1 =
+00004140: 206d 6f6e 6974 6f72 310a 2020 2020 2020   monitor1.      
+00004150: 2020 7365 6c66 2e6d 6f6e 6974 6f72 3220    self.monitor2 
+00004160: 3d20 6d6f 6e69 746f 7232 0a20 2020 2020  = monitor2.     
+00004170: 2020 2073 656c 662e 6d6f 6e69 746f 7231     self.monitor1
+00004180: 5f74 6872 6573 6820 3d20 6d6f 6e69 746f  _thresh = monito
+00004190: 7231 5f74 6872 6573 680a 2020 2020 2020  r1_thresh.      
+000041a0: 2020 7365 6c66 2e6d 6f6e 6974 6f72 325f    self.monitor2_
+000041b0: 7468 7265 7368 203d 206d 6f6e 6974 6f72  thresh = monitor
+000041c0: 325f 7468 7265 7368 0a20 2020 2020 2020  2_thresh.       
+000041d0: 2073 656c 662e 736d 6f74 655f 7361 6d70   self.smote_samp
+000041e0: 6c69 6e67 203d 2073 6d6f 7465 5f73 616d  ling = smote_sam
+000041f0: 706c 696e 670a 2020 2020 2020 2020 7365  pling.        se
+00004200: 6c66 2e62 6c65 6e64 5f6d 6178 203d 2062  lf.blend_max = b
+00004210: 6c65 6e64 5f6d 6178 0a20 2020 2020 2020  lend_max.       
+00004220: 2073 656c 662e 6e75 6d5f 696d 6167 6573   self.num_images
+00004230: 5f74 6f5f 626c 656e 6420 3d20 6e75 6d5f  _to_blend = num_
+00004240: 696d 6167 6573 5f74 6f5f 626c 656e 640a  images_to_blend.
+00004250: 2020 2020 2020 2020 7365 6c66 2e62 6c65          self.ble
+00004260: 6e64 696e 675f 6675 6e63 203d 2062 6c65  nding_func = ble
+00004270: 6e64 696e 675f 6675 6e63 0a20 2020 2020  nding_func.     
+00004280: 2020 2073 656c 662e 626c 656e 645f 6f74     self.blend_ot
+00004290: 6865 7220 3d20 626c 656e 645f 6f74 6865  her = blend_othe
+000042a0: 720a 2020 2020 2020 2020 7365 6c66 2e7a  r.        self.z
+000042b0: 6f6f 6d5f 7261 6e67 6520 3d20 7a6f 6f6d  oom_range = zoom
+000042c0: 5f72 616e 6765 0a20 2020 2020 2020 2073  _range.        s
+000042d0: 656c 662e 736b 6577 5f61 6e67 6c65 203d  elf.skew_angle =
+000042e0: 2073 6b65 775f 616e 676c 650a 2020 2020   skew_angle.    
+000042f0: 2020 2020 7365 6c66 2e72 6f74 6174 696f      self.rotatio
+00004300: 6e20 3d20 726f 7461 7469 6f6e 0a20 2020  n = rotation.   
+00004310: 2020 2020 2073 656c 662e 686f 7269 7a6f       self.horizo
+00004320: 6e74 616c 203d 2068 6f72 697a 6f6e 7461  ntal = horizonta
+00004330: 6c0a 2020 2020 2020 2020 7365 6c66 2e76  l.        self.v
+00004340: 6572 7469 6361 6c20 3d20 7665 7274 6963  ertical = vertic
+00004350: 616c 0a0a 2020 2020 2020 2020 6966 2027  al..        if '
+00004360: 616c 6c27 206e 6f74 2069 6e20 7365 6c66  all' not in self
+00004370: 2e6d 6574 7269 6320 616e 6420 276c 6f73  .metric and 'los
+00004380: 7327 206e 6f74 2069 6e20 7365 6c66 2e6d  s' not in self.m
+00004390: 6574 7269 6320 616e 6420 2766 315f 7363  etric and 'f1_sc
+000043a0: 6f72 6527 206e 6f74 2069 6e20 7365 6c66  ore' not in self
+000043b0: 2e6d 6574 7269 6320 616e 6420 2762 696e  .metric and 'bin
+000043c0: 6172 795f 6163 6375 7261 6379 2720 6e6f  ary_accuracy' no
+000043d0: 7420 696e 2073 656c 662e 6d65 7472 6963  t in self.metric
+000043e0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+000043f0: 6973 6520 5661 6c75 6545 7272 6f72 2822  ise ValueError("
+00004400: 496e 7661 6c69 6420 6d65 7472 6963 2069  Invalid metric i
+00004410: 6e70 7574 2c20 6f70 7469 6f6e 7320 6172  nput, options ar
+00004420: 653a 2027 6c6f 7373 272c 2027 6269 6e61  e: 'loss', 'bina
+00004430: 7279 5f61 6363 7572 6163 7927 2c20 2766  ry_accuracy', 'f
+00004440: 315f 7363 6f72 6527 2c20 6f72 2027 616c  1_score', or 'al
+00004450: 6c27 2c20 616e 6420 7468 6520 7661 6c69  l', and the vali
+00004460: 6461 7469 6f6e 2065 7175 6976 616c 656e  dation equivalen
+00004470: 7473 2028 6164 6420 7661 6c5f 2061 7420  ts (add val_ at 
+00004480: 7468 6520 6265 6769 6e6e 696e 6729 2e22  the beginning)."
+00004490: 290a 2020 2020 2020 2020 0a20 2020 2020  ).        .     
+000044a0: 2020 2069 6620 7365 6c66 2e6d 6574 7269     if self.metri
+000044b0: 6320 3d3d 2027 7661 6c5f 6c6f 7373 2720  c == 'val_loss' 
+000044c0: 6f72 2073 656c 662e 6d65 7472 6963 203d  or self.metric =
+000044d0: 3d20 2776 616c 5f62 696e 6172 795f 6163  = 'val_binary_ac
+000044e0: 6375 7261 6379 273a 0a20 2020 2020 2020  curacy':.       
+000044f0: 2020 2020 2069 6620 7365 6c66 2e76 616c       if self.val
+00004500: 5f70 6f73 6974 6976 6520 6973 204e 6f6e  _positive is Non
+00004510: 6520 616e 6420 7365 6c66 2e76 616c 5f6e  e and self.val_n
+00004520: 6567 6174 6976 6520 6973 204e 6f6e 653a  egative is None:
+00004530: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00004540: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00004550: 7228 274e 6f20 7661 6c69 6461 7469 6f6e  r('No validation
+00004560: 2064 6174 6120 696e 7075 742c 2063 6861   data input, cha
+00004570: 6e67 6520 7468 6520 6d65 7472 6963 2074  nge the metric t
+00004580: 6f20 6569 7468 6572 2022 6c6f 7373 222c  o either "loss",
+00004590: 2022 6269 6e61 7279 5f61 6363 7572 6163   "binary_accurac
+000045a0: 7922 2c20 2266 315f 7363 6f72 6522 2c20  y", "f1_score", 
+000045b0: 6f72 2022 616c 6c22 2e27 290a 0a20 2020  or "all".')..   
+000045c0: 2020 2020 2069 6620 7365 6c66 2e6f 7074       if self.opt
+000045d0: 5f6d 6178 5f6d 696e 5f70 6978 2069 7320  _max_min_pix is 
+000045e0: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+000045f0: 2020 2020 2020 6966 2073 656c 662e 6f70        if self.op
+00004600: 745f 6d61 785f 6d61 785f 7069 7820 6973  t_max_max_pix is
+00004610: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00004620: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+00004630: 7565 4572 726f 7228 2754 6f20 6f70 7469  ueError('To opti
+00004640: 6d69 7a65 206d 696e 2f6d 6178 206e 6f72  mize min/max nor
+00004650: 6d61 6c69 7a61 7469 6f6e 2070 6978 656c  malization pixel
+00004660: 2076 616c 7565 2c20 626f 7468 206f 7074   value, both opt
+00004670: 5f6d 696e 5f70 6978 2061 6e64 206f 7074  _min_pix and opt
+00004680: 5f6d 6178 5f70 6978 206d 7573 7420 6265  _max_pix must be
+00004690: 2069 6e70 7574 2729 0a0a 2020 2020 2020   input')..      
+000046a0: 2020 6966 2073 656c 662e 6f70 745f 6d61    if self.opt_ma
+000046b0: 785f 6d61 785f 7069 7820 6973 206e 6f74  x_max_pix is not
+000046c0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+000046d0: 2020 2069 6620 7365 6c66 2e6f 7074 5f6d     if self.opt_m
+000046e0: 6178 5f6d 696e 5f70 6978 2069 7320 4e6f  ax_min_pix is No
+000046f0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+00004700: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+00004710: 7272 6f72 2827 546f 206f 7074 696d 697a  rror('To optimiz
+00004720: 6520 6d69 6e2f 6d61 7820 6e6f 726d 616c  e min/max normal
+00004730: 697a 6174 696f 6e20 7069 7865 6c20 7661  ization pixel va
+00004740: 6c75 652c 2062 6f74 6820 6f70 745f 6d69  lue, both opt_mi
+00004750: 6e5f 7069 7820 616e 6420 6f70 745f 6d61  n_pix and opt_ma
+00004760: 785f 7069 7820 6d75 7374 2062 6520 696e  x_pix must be in
+00004770: 7075 7427 290a 0a20 2020 2020 2020 2069  put')..        i
+00004780: 6620 6e6f 7420 6973 696e 7374 616e 6365  f not isinstance
+00004790: 2873 656c 662e 6d61 736b 5f73 697a 652c  (self.mask_size,
+000047a0: 2069 6e74 2920 616e 6420 6e6f 7420 6973   int) and not is
+000047b0: 696e 7374 616e 6365 2873 656c 662e 6d61  instance(self.ma
+000047c0: 736b 5f73 697a 652c 2074 7570 6c65 2920  sk_size, tuple) 
+000047d0: 616e 6420 7365 6c66 2e6d 6173 6b5f 7369  and self.mask_si
+000047e0: 7a65 2069 7320 6e6f 7420 4e6f 6e65 3a0a  ze is not None:.
+000047f0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00004800: 6520 5661 6c75 6545 7272 6f72 2827 5468  e ValueError('Th
+00004810: 6520 6d61 736b 5f73 697a 6520 7061 7261  e mask_size para
+00004820: 6d65 7465 7220 6d75 7374 2065 6974 6865  meter must eithe
+00004830: 7220 6265 2061 6e20 696e 7465 6765 722c  r be an integer,
+00004840: 2074 7570 6c65 2c20 6f72 204e 6f6e 6521   tuple, or None!
+00004850: 2729 0a0a 2020 2020 2020 2020 6966 206e  ')..        if n
+00004860: 6f74 2069 7369 6e73 7461 6e63 6528 7365  ot isinstance(se
+00004870: 6c66 2e6e 756d 5f6d 6173 6b73 2c20 696e  lf.num_masks, in
+00004880: 7429 2061 6e64 206e 6f74 2069 7369 6e73  t) and not isins
+00004890: 7461 6e63 6528 7365 6c66 2e6e 756d 5f6d  tance(self.num_m
+000048a0: 6173 6b73 2c20 7475 706c 6529 2061 6e64  asks, tuple) and
+000048b0: 2073 656c 662e 6e75 6d5f 6d61 736b 7320   self.num_masks 
+000048c0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
+000048d0: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
+000048e0: 616c 7565 4572 726f 7228 2754 6865 206e  alueError('The n
+000048f0: 756d 5f6d 6173 6b73 2070 6172 616d 6574  um_masks paramet
+00004900: 6572 206d 7573 7420 6569 7468 6572 2062  er must either b
+00004910: 6520 616e 2069 6e74 6567 6572 6c2c 2074  e an integerl, t
+00004920: 7570 6c65 2c20 6f72 204e 6f6e 6521 2729  uple, or None!')
+00004930: 0a0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
+00004940: 662e 6261 6c61 6e63 6520 616e 6420 7365  f.balance and se
+00004950: 6c66 2e73 6d6f 7465 5f73 616d 706c 696e  lf.smote_samplin
+00004960: 6720 3e20 303a 0a20 2020 2020 2020 2020  g > 0:.         
+00004970: 2020 2070 7269 6e74 2827 5741 524e 494e     print('WARNIN
+00004980: 473a 2062 616c 616e 6365 3d54 7275 6520  G: balance=True 
+00004990: 6275 7420 534d 4f54 4520 7361 6d70 6c69  but SMOTE sampli
+000049a0: 6e67 2077 696c 6c20 6e6f 7420 6265 2061  ng will not be a
+000049b0: 7070 6c69 6564 2069 6620 7468 6520 636c  pplied if the cl
+000049c0: 6173 7365 7320 6172 6520 6261 6c61 6e63  asses are balanc
+000049d0: 6564 2e27 290a 0a20 2020 2020 2020 2069  ed.')..        i
+000049e0: 6620 7365 6c66 2e74 6573 745f 6163 635f  f self.test_acc_
+000049f0: 7468 7265 7368 6f6c 6420 6973 206e 6f74  threshold is not
+00004a00: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00004a10: 2020 2069 6620 7365 6c66 2e74 6573 745f     if self.test_
+00004a20: 6163 635f 7468 7265 7368 6f6c 6420 3c3d  acc_threshold <=
+00004a30: 2030 206f 7220 7365 6c66 2e74 6573 745f   0 or self.test_
+00004a40: 6163 635f 7468 7265 7368 6f6c 6420 3e20  acc_threshold > 
+00004a50: 313a 0a20 2020 2020 2020 2020 2020 2020  1:.             
+00004a60: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+00004a70: 726f 7228 2754 6865 2074 6573 745f 6163  ror('The test_ac
+00004a80: 635f 7468 7265 7368 6f6c 6420 7061 7261  c_threshold para
+00004a90: 6d65 7465 7220 6d75 7374 2062 6520 6772  meter must be gr
+00004aa0: 6561 7465 7220 7468 616e 2030 2061 6e64  eater than 0 and
+00004ab0: 206c 6573 7320 7468 616e 206f 7220 6571   less than or eq
+00004ac0: 7561 6c20 746f 2031 2127 290a 2020 2020  ual to 1!').    
+00004ad0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00004ae0: 7465 7374 5f70 6f73 6974 6976 6520 6973  test_positive is
+00004af0: 204e 6f6e 6520 616e 6420 7365 6c66 2e74   None and self.t
+00004b00: 6573 745f 6e65 6761 7469 7665 2069 7320  est_negative is 
+00004b10: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+00004b20: 2020 2020 2020 7072 696e 7428 2757 4152        print('WAR
+00004b30: 4e49 4e47 3a20 5468 6520 7465 7374 5f61  NING: The test_a
+00004b40: 6363 5f74 6872 6573 686f 6c64 2068 6173  cc_threshold has
+00004b50: 2062 6565 6e20 636f 6e66 6967 7572 6564   been configured
+00004b60: 2062 7574 206e 6f20 7465 7374 2064 6174   but no test dat
+00004b70: 6120 6861 7320 6265 656e 2069 6e70 7574  a has been input
+00004b80: 2120 5365 7474 696e 6720 7465 7374 5f61  ! Setting test_a
+00004b90: 6363 5f74 6872 6573 686f 6c64 3d4e 6f6e  cc_threshold=Non
+00004ba0: 652e 2e2e 2729 0a20 2020 2020 2020 2020  e...').         
+00004bb0: 2020 2020 2020 2073 656c 662e 7465 7374         self.test
+00004bc0: 5f61 6363 5f74 6872 6573 686f 6c64 203d  _acc_threshold =
+00004bd0: 204e 6f6e 6520 0a0a 2020 2020 6465 6620   None ..    def 
+00004be0: 5f5f 6361 6c6c 5f5f 2873 656c 662c 2074  __call__(self, t
+00004bf0: 7269 616c 293a 0a0a 2020 2020 2020 2020  rial):..        
+00004c00: 6966 2073 656c 662e 6f70 745f 6175 673a  if self.opt_aug:
+00004c10: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00004c20: 7365 6c66 2e69 6d67 5f6e 756d 5f63 6861  self.img_num_cha
+00004c30: 6e6e 656c 7320 3d3d 2031 3a0a 2020 2020  nnels == 1:.    
+00004c40: 2020 2020 2020 2020 2020 2020 6368 616e              chan
+00004c50: 6e65 6c31 2c20 6368 616e 6e65 6c32 2c20  nel1, channel2, 
+00004c60: 6368 616e 6e65 6c33 203d 2063 6f70 792e  channel3 = copy.
+00004c70: 6465 6570 636f 7079 2873 656c 662e 706f  deepcopy(self.po
+00004c80: 7369 7469 7665 5f63 6c61 7373 292c 204e  sitive_class), N
+00004c90: 6f6e 652c 204e 6f6e 6520 0a20 2020 2020  one, None .     
+00004ca0: 2020 2020 2020 2065 6c69 6620 7365 6c66         elif self
+00004cb0: 2e69 6d67 5f6e 756d 5f63 6861 6e6e 656c  .img_num_channel
+00004cc0: 7320 3d3d 2032 3a0a 2020 2020 2020 2020  s == 2:.        
+00004cd0: 2020 2020 2020 2020 6368 616e 6e65 6c31          channel1
+00004ce0: 2c20 6368 616e 6e65 6c32 2c20 6368 616e  , channel2, chan
+00004cf0: 6e65 6c33 203d 2063 6f70 792e 6465 6570  nel3 = copy.deep
+00004d00: 636f 7079 2873 656c 662e 706f 7369 7469  copy(self.positi
+00004d10: 7665 5f63 6c61 7373 5b3a 2c3a 2c3a 2c30  ve_class[:,:,:,0
+00004d20: 5d29 2c20 636f 7079 2e64 6565 7063 6f70  ]), copy.deepcop
+00004d30: 7928 7365 6c66 2e70 6f73 6974 6976 655f  y(self.positive_
+00004d40: 636c 6173 735b 3a2c 3a2c 3a2c 315d 292c  class[:,:,:,1]),
+00004d50: 204e 6f6e 6520 0a20 2020 2020 2020 2020   None .         
+00004d60: 2020 2065 6c69 6620 7365 6c66 2e69 6d67     elif self.img
+00004d70: 5f6e 756d 5f63 6861 6e6e 656c 7320 3d3d  _num_channels ==
+00004d80: 2033 3a0a 2020 2020 2020 2020 2020 2020   3:.            
+00004d90: 2020 2020 6368 616e 6e65 6c31 2c20 6368      channel1, ch
+00004da0: 616e 6e65 6c32 2c20 6368 616e 6e65 6c33  annel2, channel3
+00004db0: 203d 2063 6f70 792e 6465 6570 636f 7079   = copy.deepcopy
+00004dc0: 2873 656c 662e 706f 7369 7469 7665 5f63  (self.positive_c
+00004dd0: 6c61 7373 5b3a 2c3a 2c3a 2c30 5d29 2c20  lass[:,:,:,0]), 
+00004de0: 636f 7079 2e64 6565 7063 6f70 7928 7365  copy.deepcopy(se
+00004df0: 6c66 2e70 6f73 6974 6976 655f 636c 6173  lf.positive_clas
+00004e00: 735b 3a2c 3a2c 3a2c 315d 292c 2063 6f70  s[:,:,:,1]), cop
+00004e10: 792e 6465 6570 636f 7079 2873 656c 662e  y.deepcopy(self.
+00004e20: 706f 7369 7469 7665 5f63 6c61 7373 5b3a  positive_class[:
+00004e30: 2c3a 2c3a 2c32 5d29 0a20 2020 2020 2020  ,:,:,2]).       
+00004e40: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00004e50: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00004e60: 2056 616c 7565 4572 726f 7228 274f 6e6c   ValueError('Onl
+00004e70: 7920 7468 7265 6520 6669 6c74 6572 7320  y three filters 
+00004e80: 6172 6520 7375 7070 6f72 7465 6421 2729  are supported!')
+00004e90: 0a0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
+00004ea0: 662e 6f70 745f 6175 673a 0a20 2020 2020  f.opt_aug:.     
+00004eb0: 2020 2020 2020 206e 756d 5f61 7567 203d         num_aug =
+00004ec0: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+00004ed0: 6e74 2827 6e75 6d5f 6175 6727 2c20 7365  nt('num_aug', se
+00004ee0: 6c66 2e62 6174 6368 5f6d 696e 2c20 7365  lf.batch_min, se
+00004ef0: 6c66 2e62 6174 6368 5f6d 6178 2c20 7374  lf.batch_max, st
+00004f00: 6570 3d31 290a 2020 2020 2020 2020 2020  ep=1).          
+00004f10: 2020 626c 656e 645f 6d75 6c74 6970 6c69    blend_multipli
+00004f20: 6572 203d 2074 7269 616c 2e73 7567 6765  er = trial.sugge
+00004f30: 7374 5f66 6c6f 6174 2827 626c 656e 645f  st_float('blend_
+00004f40: 6d75 6c74 6970 6c69 6572 272c 2031 2e30  multiplier', 1.0
+00004f50: 2c20 7365 6c66 2e62 6c65 6e64 5f6d 6178  , self.blend_max
+00004f60: 2c20 7374 6570 3d30 2e30 3529 2069 6620  , step=0.05) if 
+00004f70: 7365 6c66 2e62 6c65 6e64 5f6d 6178 203e  self.blend_max >
+00004f80: 3d20 312e 3120 656c 7365 2030 0a20 2020  = 1.1 else 0.   
+00004f90: 2020 2020 2020 2020 2073 6b65 775f 616e           skew_an
+00004fa0: 676c 6520 3d20 7472 6961 6c2e 7375 6767  gle = trial.sugg
+00004fb0: 6573 745f 696e 7428 2773 6b65 775f 616e  est_int('skew_an
+00004fc0: 676c 6527 2c20 302c 2073 656c 662e 736b  gle', 0, self.sk
+00004fd0: 6577 5f61 6e67 6c65 2c20 7374 6570 3d31  ew_angle, step=1
+00004fe0: 2920 6966 2073 656c 662e 736b 6577 5f61  ) if self.skew_a
+00004ff0: 6e67 6c65 203e 2030 2065 6c73 6520 300a  ngle > 0 else 0.
+00005000: 2020 2020 2020 2020 2020 2020 696d 6167              imag
+00005010: 655f 7369 7a65 203d 2074 7269 616c 2e73  e_size = trial.s
+00005020: 7567 6765 7374 5f69 6e74 2827 696d 6167  uggest_int('imag
+00005030: 655f 7369 7a65 272c 2073 656c 662e 696d  e_size', self.im
+00005040: 6167 655f 7369 7a65 5f6d 696e 2c20 7365  age_size_min, se
+00005050: 6c66 2e69 6d61 6765 5f73 697a 655f 6d61  lf.image_size_ma
+00005060: 782c 2073 7465 703d 3129 0a20 2020 2020  x, step=1).     
+00005070: 2020 2020 2020 206d 6173 6b5f 7369 7a65         mask_size
+00005080: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
+00005090: 5f69 6e74 2827 6d61 736b 5f73 697a 6527  _int('mask_size'
+000050a0: 2c20 7365 6c66 2e6d 6173 6b5f 7369 7a65  , self.mask_size
+000050b0: 5b30 5d2c 2073 656c 662e 6d61 736b 5f73  [0], self.mask_s
+000050c0: 697a 655b 315d 2c20 7374 6570 3d31 2920  ize[1], step=1) 
+000050d0: 6966 2069 7369 6e73 7461 6e63 6528 7365  if isinstance(se
+000050e0: 6c66 2e6d 6173 6b5f 7369 7a65 2c20 7475  lf.mask_size, tu
+000050f0: 706c 6529 2065 6c73 6520 7365 6c66 2e6d  ple) else self.m
+00005100: 6173 6b5f 7369 7a65 0a20 2020 2020 2020  ask_size.       
+00005110: 2020 2020 206e 756d 5f6d 6173 6b73 203d       num_masks =
+00005120: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+00005130: 6e74 2827 6e75 6d5f 6d61 736b 7327 2c20  nt('num_masks', 
+00005140: 7365 6c66 2e6e 756d 5f6d 6173 6b73 5b30  self.num_masks[0
+00005150: 5d2c 2073 656c 662e 6e75 6d5f 6d61 736b  ], self.num_mask
+00005160: 735b 315d 2c20 7374 6570 3d31 2920 6966  s[1], step=1) if
+00005170: 2069 7369 6e73 7461 6e63 6528 7365 6c66   isinstance(self
+00005180: 2e6e 756d 5f6d 6173 6b73 2c20 7475 706c  .num_masks, tupl
+00005190: 6529 2065 6c73 6520 7365 6c66 2e6e 756d  e) else self.num
+000051a0: 5f6d 6173 6b73 0a0a 2020 2020 2020 2020  _masks..        
+000051b0: 2020 2020 6175 676d 656e 7465 645f 696d      augmented_im
+000051c0: 6167 6573 203d 2061 7567 6d65 6e74 6174  ages = augmentat
+000051d0: 696f 6e28 6368 616e 6e65 6c31 3d63 6861  ion(channel1=cha
+000051e0: 6e6e 656c 312c 2063 6861 6e6e 656c 323d  nnel1, channel2=
+000051f0: 6368 616e 6e65 6c32 2c20 6368 616e 6e65  channel2, channe
+00005200: 6c33 3d63 6861 6e6e 656c 332c 2062 6174  l3=channel3, bat
+00005210: 6368 3d6e 756d 5f61 7567 2c20 0a20 2020  ch=num_aug, .   
+00005220: 2020 2020 2020 2020 2020 2020 2077 6964               wid
+00005230: 7468 5f73 6869 6674 3d73 656c 662e 7368  th_shift=self.sh
+00005240: 6966 742c 2068 6569 6768 745f 7368 6966  ift, height_shif
+00005250: 743d 7365 6c66 2e73 6869 6674 2c20 686f  t=self.shift, ho
+00005260: 7269 7a6f 6e74 616c 3d73 656c 662e 686f  rizontal=self.ho
+00005270: 7269 7a6f 6e74 616c 2c20 7665 7274 6963  rizontal, vertic
+00005280: 616c 3d73 656c 662e 7665 7274 6963 616c  al=self.vertical
+00005290: 2c20 726f 7461 7469 6f6e 3d73 656c 662e  , rotation=self.
+000052a0: 726f 7461 7469 6f6e 2c20 0a20 2020 2020  rotation, .     
+000052b0: 2020 2020 2020 2020 2020 2069 6d61 6765             image
+000052c0: 5f73 697a 653d 696d 6167 655f 7369 7a65  _size=image_size
+000052d0: 2c20 6d61 736b 5f73 697a 653d 6d61 736b  , mask_size=mask
+000052e0: 5f73 697a 652c 206e 756d 5f6d 6173 6b73  _size, num_masks
+000052f0: 3d6e 756d 5f6d 6173 6b73 2c20 626c 656e  =num_masks, blen
+00005300: 645f 6d75 6c74 6970 6c69 6572 3d62 6c65  d_multiplier=ble
+00005310: 6e64 5f6d 756c 7469 706c 6965 722c 200a  nd_multiplier, .
+00005320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005330: 626c 656e 6469 6e67 5f66 756e 633d 7365  blending_func=se
+00005340: 6c66 2e62 6c65 6e64 696e 675f 6675 6e63  lf.blending_func
+00005350: 2c20 6e75 6d5f 696d 6167 6573 5f74 6f5f  , num_images_to_
+00005360: 626c 656e 643d 7365 6c66 2e6e 756d 5f69  blend=self.num_i
+00005370: 6d61 6765 735f 746f 5f62 6c65 6e64 2c20  mages_to_blend, 
+00005380: 7a6f 6f6d 5f72 616e 6765 3d73 656c 662e  zoom_range=self.
+00005390: 7a6f 6f6d 5f72 616e 6765 2c20 736b 6577  zoom_range, skew
+000053a0: 5f61 6e67 6c65 3d73 6b65 775f 616e 676c  _angle=skew_angl
+000053b0: 6529 0a0a 2020 2020 2020 2020 2020 2020  e)..            
+000053c0: 2343 6f6e 6361 7420 6368 616e 6e65 6c73  #Concat channels
+000053d0: 2073 696e 6365 2061 7567 6d65 6e74 6174   since augmentat
+000053e0: 696f 6e20 6675 6e63 7469 6f6e 2072 6574  ion function ret
+000053f0: 7572 6e73 2061 6e20 6f75 7470 7574 2066  urns an output f
+00005400: 6f72 2065 6163 6820 6669 6c74 6572 2c20  or each filter, 
+00005410: 652e 672e 2033 206f 7574 7075 7473 2066  e.g. 3 outputs f
+00005420: 6f72 2052 4742 0a20 2020 2020 2020 2020  or RGB.         
+00005430: 2020 2069 6620 7365 6c66 2e69 6d67 5f6e     if self.img_n
+00005440: 756d 5f63 6861 6e6e 656c 7320 3e20 313a  um_channels > 1:
+00005450: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005460: 2063 6c61 7373 5f31 3d5b 5d0a 2020 2020   class_1=[].    
+00005470: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00005480: 656c 662e 696d 675f 6e75 6d5f 6368 616e  elf.img_num_chan
+00005490: 6e65 6c73 203d 3d20 323a 0a20 2020 2020  nels == 2:.     
+000054a0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+000054b0: 6f72 2069 2069 6e20 7261 6e67 6528 6c65  or i in range(le
+000054c0: 6e28 6175 676d 656e 7465 645f 696d 6167  n(augmented_imag
+000054d0: 6573 5b30 5d29 293a 0a20 2020 2020 2020  es[0])):.       
+000054e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000054f0: 2063 6c61 7373 5f31 2e61 7070 656e 6428   class_1.append(
+00005500: 6461 7461 5f70 726f 6365 7373 696e 672e  data_processing.
+00005510: 636f 6e63 6174 5f63 6861 6e6e 656c 7328  concat_channels(
+00005520: 6175 676d 656e 7465 645f 696d 6167 6573  augmented_images
+00005530: 5b30 5d5b 695d 2c20 6175 676d 656e 7465  [0][i], augmente
+00005540: 645f 696d 6167 6573 5b31 5d5b 695d 2929  d_images[1][i]))
+00005550: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005560: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00005570: 2020 2020 2020 2020 2020 2066 6f72 2069             for i
+00005580: 2069 6e20 7261 6e67 6528 6c65 6e28 6175   in range(len(au
+00005590: 676d 656e 7465 645f 696d 6167 6573 5b30  gmented_images[0
+000055a0: 5d29 293a 0a20 2020 2020 2020 2020 2020  ])):.           
+000055b0: 2020 2020 2020 2020 2020 2020 2063 6c61               cla
+000055c0: 7373 5f31 2e61 7070 656e 6428 6461 7461  ss_1.append(data
+000055d0: 5f70 726f 6365 7373 696e 672e 636f 6e63  _processing.conc
+000055e0: 6174 5f63 6861 6e6e 656c 7328 6175 676d  at_channels(augm
+000055f0: 656e 7465 645f 696d 6167 6573 5b30 5d5b  ented_images[0][
+00005600: 695d 2c20 6175 676d 656e 7465 645f 696d  i], augmented_im
+00005610: 6167 6573 5b31 5d5b 695d 2c20 6175 676d  ages[1][i], augm
+00005620: 656e 7465 645f 696d 6167 6573 5b32 5d5b  ented_images[2][
+00005630: 695d 2929 0a20 2020 2020 2020 2020 2020  i])).           
+00005640: 2020 2020 2063 6c61 7373 5f31 203d 206e       class_1 = n
+00005650: 702e 6172 7261 7928 636c 6173 735f 3129  p.array(class_1)
+00005660: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
+00005670: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00005680: 2020 2063 6c61 7373 5f31 203d 2061 7567     class_1 = aug
+00005690: 6d65 6e74 6564 5f69 6d61 6765 730a 0a20  mented_images.. 
+000056a0: 2020 2020 2020 2020 2020 2023 5065 7266             #Perf
+000056b0: 6f72 6d20 7361 6d65 2061 7567 6d65 6e74  orm same augment
+000056c0: 6174 696f 6e20 7465 6368 6e69 7175 6573  ation techniques
+000056d0: 206f 6e20 6e65 6761 7469 7665 2063 6c61   on negative cla
+000056e0: 7373 2064 6174 6120 666f 7220 6261 6c61  ss data for bala
+000056f0: 6e63 6520 6275 7420 7573 6520 6261 7463  nce but use batc
+00005700: 683d 6261 7463 685f 6f74 6865 722c 206e  h=batch_other, n
+00005710: 756d 5f69 6d61 6765 735f 746f 5f62 6c65  um_images_to_ble
+00005720: 6e64 3d73 656c 662e 6e75 6d5f 696d 6167  nd=self.num_imag
+00005730: 6573 5f74 6f5f 626c 656e 6420 0a20 2020  es_to_blend .   
+00005740: 2020 2020 2020 2020 2023 5468 6973 2069           #This i
+00005750: 7320 646f 6e65 2073 6f20 7468 6174 2074  s done so that t
+00005760: 6865 2074 7261 696e 696e 6720 6461 7461  he training data
+00005770: 2061 6c73 6f20 696e 636c 7564 6573 2074   also includes t
+00005780: 6865 2073 616d 6520 6175 676d 656e 7461  he same augmenta
+00005790: 7469 6f6e 2074 6563 686e 6971 7565 732c  tion techniques,
+000057a0: 2069 6620 636f 6e66 6967 7572 6564 2e0a   if configured..
+000057b0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+000057c0: 656c 662e 696d 675f 6e75 6d5f 6368 616e  elf.img_num_chan
+000057d0: 6e65 6c73 203d 3d20 313a 0a20 2020 2020  nels == 1:.     
+000057e0: 2020 2020 2020 2020 2020 2063 6861 6e6e             chann
+000057f0: 656c 312c 2063 6861 6e6e 656c 322c 2063  el1, channel2, c
+00005800: 6861 6e6e 656c 3320 3d20 636f 7079 2e64  hannel3 = copy.d
+00005810: 6565 7063 6f70 7928 7365 6c66 2e6e 6567  eepcopy(self.neg
+00005820: 6174 6976 655f 636c 6173 7329 2c20 4e6f  ative_class), No
+00005830: 6e65 2c20 4e6f 6e65 200a 2020 2020 2020  ne, None .      
+00005840: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
+00005850: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+00005860: 203d 3d20 323a 0a20 2020 2020 2020 2020   == 2:.         
+00005870: 2020 2020 2020 2063 6861 6e6e 656c 312c         channel1,
+00005880: 2063 6861 6e6e 656c 322c 2063 6861 6e6e   channel2, chann
+00005890: 656c 3320 3d20 636f 7079 2e64 6565 7063  el3 = copy.deepc
+000058a0: 6f70 7928 7365 6c66 2e6e 6567 6174 6976  opy(self.negativ
+000058b0: 655f 636c 6173 735b 3a2c 3a2c 3a2c 305d  e_class[:,:,:,0]
+000058c0: 292c 2063 6f70 792e 6465 6570 636f 7079  ), copy.deepcopy
+000058d0: 2873 656c 662e 6e65 6761 7469 7665 5f63  (self.negative_c
+000058e0: 6c61 7373 5b3a 2c3a 2c3a 2c31 5d29 2c20  lass[:,:,:,1]), 
+000058f0: 4e6f 6e65 200a 2020 2020 2020 2020 2020  None .          
+00005900: 2020 656c 6966 2073 656c 662e 696d 675f    elif self.img_
+00005910: 6e75 6d5f 6368 616e 6e65 6c73 203d 3d20  num_channels == 
+00005920: 333a 0a20 2020 2020 2020 2020 2020 2020  3:.             
+00005930: 2020 2063 6861 6e6e 656c 312c 2063 6861     channel1, cha
+00005940: 6e6e 656c 322c 2063 6861 6e6e 656c 3320  nnel2, channel3 
+00005950: 3d20 636f 7079 2e64 6565 7063 6f70 7928  = copy.deepcopy(
+00005960: 7365 6c66 2e6e 6567 6174 6976 655f 636c  self.negative_cl
+00005970: 6173 735b 3a2c 3a2c 3a2c 305d 292c 2063  ass[:,:,:,0]), c
+00005980: 6f70 792e 6465 6570 636f 7079 2873 656c  opy.deepcopy(sel
+00005990: 662e 6e65 6761 7469 7665 5f63 6c61 7373  f.negative_class
+000059a0: 5b3a 2c3a 2c3a 2c31 5d29 2c20 636f 7079  [:,:,:,1]), copy
+000059b0: 2e64 6565 7063 6f70 7928 7365 6c66 2e6e  .deepcopy(self.n
+000059c0: 6567 6174 6976 655f 636c 6173 735b 3a2c  egative_class[:,
+000059d0: 3a2c 3a2c 325d 290a 2020 2020 2020 2020  :,:,2]).        
+000059e0: 2020 2020 0a20 2020 2020 2020 2020 2020      .           
+000059f0: 2061 7567 6d65 6e74 6564 5f69 6d61 6765   augmented_image
+00005a00: 735f 6e65 6761 7469 7665 203d 2061 7567  s_negative = aug
+00005a10: 6d65 6e74 6174 696f 6e28 6368 616e 6e65  mentation(channe
+00005a20: 6c31 3d63 6861 6e6e 656c 312c 2063 6861  l1=channel1, cha
+00005a30: 6e6e 656c 323d 6368 616e 6e65 6c32 2c20  nnel2=channel2, 
+00005a40: 6368 616e 6e65 6c33 3d63 6861 6e6e 656c  channel3=channel
+00005a50: 332c 2062 6174 6368 3d73 656c 662e 6261  3, batch=self.ba
+00005a60: 7463 685f 6f74 6865 722c 200a 2020 2020  tch_other, .    
+00005a70: 2020 2020 2020 2020 2020 2020 7769 6474              widt
+00005a80: 685f 7368 6966 743d 7365 6c66 2e73 6869  h_shift=self.shi
+00005a90: 6674 2c20 6865 6967 6874 5f73 6869 6674  ft, height_shift
+00005aa0: 3d73 656c 662e 7368 6966 742c 2068 6f72  =self.shift, hor
+00005ab0: 697a 6f6e 7461 6c3d 7365 6c66 2e68 6f72  izontal=self.hor
+00005ac0: 697a 6f6e 7461 6c2c 2076 6572 7469 6361  izontal, vertica
+00005ad0: 6c3d 7365 6c66 2e76 6572 7469 6361 6c2c  l=self.vertical,
+00005ae0: 2072 6f74 6174 696f 6e3d 7365 6c66 2e72   rotation=self.r
+00005af0: 6f74 6174 696f 6e2c 200a 2020 2020 2020  otation, .      
+00005b00: 2020 2020 2020 2020 2020 696d 6167 655f            image_
+00005b10: 7369 7a65 3d69 6d61 6765 5f73 697a 652c  size=image_size,
+00005b20: 206d 6173 6b5f 7369 7a65 3d6d 6173 6b5f   mask_size=mask_
+00005b30: 7369 7a65 2c20 6e75 6d5f 6d61 736b 733d  size, num_masks=
+00005b40: 6e75 6d5f 6d61 736b 732c 2062 6c65 6e64  num_masks, blend
+00005b50: 5f6d 756c 7469 706c 6965 723d 7365 6c66  _multiplier=self
+00005b60: 2e62 6c65 6e64 5f6f 7468 6572 2c20 0a20  .blend_other, . 
+00005b70: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+00005b80: 6c65 6e64 696e 675f 6675 6e63 3d73 656c  lending_func=sel
+00005b90: 662e 626c 656e 6469 6e67 5f66 756e 632c  f.blending_func,
+00005ba0: 206e 756d 5f69 6d61 6765 735f 746f 5f62   num_images_to_b
+00005bb0: 6c65 6e64 3d73 656c 662e 6e75 6d5f 696d  lend=self.num_im
+00005bc0: 6167 6573 5f74 6f5f 626c 656e 642c 207a  ages_to_blend, z
+00005bd0: 6f6f 6d5f 7261 6e67 653d 7365 6c66 2e7a  oom_range=self.z
+00005be0: 6f6f 6d5f 7261 6e67 652c 2073 6b65 775f  oom_range, skew_
+00005bf0: 616e 676c 653d 736b 6577 5f61 6e67 6c65  angle=skew_angle
+00005c00: 290a 0a20 2020 2020 2020 2020 2020 2023  )..            #
+00005c10: 5468 6520 6175 676d 656e 7461 7469 6f6e  The augmentation
+00005c20: 2072 6f75 7469 6e65 2072 6574 7572 6e73   routine returns
+00005c30: 2061 6e20 6f75 7470 7574 2066 6f72 2065   an output for e
+00005c40: 6163 6820 6669 6c74 6572 2c20 652e 672e  ach filter, e.g.
+00005c50: 2033 206f 7574 7075 7473 2066 6f72 2052   3 outputs for R
+00005c60: 4742 0a20 2020 2020 2020 2020 2020 2069  GB.            i
+00005c70: 6620 7365 6c66 2e69 6d67 5f6e 756d 5f63  f self.img_num_c
+00005c80: 6861 6e6e 656c 7320 3e20 313a 0a20 2020  hannels > 1:.   
+00005c90: 2020 2020 2020 2020 2020 2020 2063 6c61               cla
+00005ca0: 7373 5f32 3d5b 5d0a 2020 2020 2020 2020  ss_2=[].        
+00005cb0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00005cc0: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+00005cd0: 203d 3d20 323a 0a20 2020 2020 2020 2020   == 2:.         
+00005ce0: 2020 2020 2020 2020 2020 2066 6f72 2069             for i
+00005cf0: 2069 6e20 7261 6e67 6528 6c65 6e28 6175   in range(len(au
+00005d00: 676d 656e 7465 645f 696d 6167 6573 5f6e  gmented_images_n
+00005d10: 6567 6174 6976 655b 305d 2929 3a0a 2020  egative[0])):.  
+00005d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005d30: 2020 2020 2020 636c 6173 735f 322e 6170        class_2.ap
+00005d40: 7065 6e64 2864 6174 615f 7072 6f63 6573  pend(data_proces
+00005d50: 7369 6e67 2e63 6f6e 6361 745f 6368 616e  sing.concat_chan
+00005d60: 6e65 6c73 2861 7567 6d65 6e74 6564 5f69  nels(augmented_i
+00005d70: 6d61 6765 735f 6e65 6761 7469 7665 5b30  mages_negative[0
+00005d80: 5d5b 695d 2c20 6175 676d 656e 7465 645f  ][i], augmented_
+00005d90: 696d 6167 6573 5f6e 6567 6174 6976 655b  images_negative[
+00005da0: 315d 5b69 5d29 290a 2020 2020 2020 2020  1][i])).        
+00005db0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00005dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005dd0: 2020 666f 7220 6920 696e 2072 616e 6765    for i in range
+00005de0: 286c 656e 2861 7567 6d65 6e74 6564 5f69  (len(augmented_i
+00005df0: 6d61 6765 735f 6e65 6761 7469 7665 5b30  mages_negative[0
+00005e00: 5d29 293a 0a20 2020 2020 2020 2020 2020  ])):.           
+00005e10: 2020 2020 2020 2020 2020 2020 2063 6c61               cla
+00005e20: 7373 5f32 2e61 7070 656e 6428 6461 7461  ss_2.append(data
+00005e30: 5f70 726f 6365 7373 696e 672e 636f 6e63  _processing.conc
+00005e40: 6174 5f63 6861 6e6e 656c 7328 6175 676d  at_channels(augm
+00005e50: 656e 7465 645f 696d 6167 6573 5f6e 6567  ented_images_neg
+00005e60: 6174 6976 655b 305d 5b69 5d2c 2061 7567  ative[0][i], aug
+00005e70: 6d65 6e74 6564 5f69 6d61 6765 735f 6e65  mented_images_ne
+00005e80: 6761 7469 7665 5b31 5d5b 695d 2c20 6175  gative[1][i], au
+00005e90: 676d 656e 7465 645f 696d 6167 6573 5f6e  gmented_images_n
+00005ea0: 6567 6174 6976 655b 325d 5b69 5d29 290a  egative[2][i])).
+00005eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005ec0: 636c 6173 735f 3220 3d20 6e70 2e61 7272  class_2 = np.arr
+00005ed0: 6179 2863 6c61 7373 5f32 290a 2020 2020  ay(class_2).    
+00005ee0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00005ef0: 2020 2020 2020 2020 2020 2020 2020 636c                cl
+00005f00: 6173 735f 3220 3d20 6175 676d 656e 7465  ass_2 = augmente
+00005f10: 645f 696d 6167 6573 5f6e 6567 6174 6976  d_images_negativ
+00005f20: 650a 0a20 2020 2020 2020 2020 2020 2023  e..            #
+00005f30: 4261 6c61 6e63 6520 7468 6520 636c 6173  Balance the clas
+00005f40: 7320 7369 7a65 7320 6966 206e 6563 6573  s sizes if neces
+00005f50: 7361 7279 0a20 2020 2020 2020 2020 2020  sary.           
+00005f60: 2069 6620 7365 6c66 2e62 616c 616e 6365   if self.balance
+00005f70: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00005f80: 2020 6966 2073 656c 662e 6261 7463 685f    if self.batch_
+00005f90: 6f74 6865 7220 3e20 313a 2023 4d75 7374  other > 1: #Must
+00005fa0: 2073 6875 6666 6c65 2061 7320 7468 6520   shuffle as the 
+00005fb0: 6175 676d 656e 7461 7469 6f6e 7320 7765  augmentations we
+00005fc0: 7265 2073 7461 636b 6564 2073 6571 7565  re stacked seque
+00005fd0: 6e74 6961 6c6c 7921 2121 0a20 2020 2020  ntially!!!.     
+00005fe0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00005ff0: 7820 3d20 6e70 2e72 616e 646f 6d2e 7065  x = np.random.pe
+00006000: 726d 7574 6174 696f 6e28 6c65 6e28 636c  rmutation(len(cl
+00006010: 6173 735f 3229 290a 2020 2020 2020 2020  ass_2)).        
+00006020: 2020 2020 2020 2020 2020 2020 636c 6173              clas
+00006030: 735f 3220 3d20 636c 6173 735f 325b 6978  s_2 = class_2[ix
+00006040: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+00006050: 2020 636c 6173 735f 3220 3d20 636c 6173    class_2 = clas
+00006060: 735f 325b 3a6c 656e 2863 6c61 7373 5f31  s_2[:len(class_1
+00006070: 295d 0a20 2020 2020 2020 2020 2020 200a  )].            .
+00006080: 2020 2020 2020 2020 2020 2020 2352 6573              #Res
+00006090: 697a 6520 6966 206e 6563 6573 7361 7279  ize if necessary
+000060a0: 2061 6e64 2063 6f6e 6361 7420 7468 6520   and concat the 
+000060b0: 6368 616e 6e65 6c73 0a20 2020 2020 2020  channels.       
+000060c0: 2020 2020 2069 6620 7365 6c66 2e69 6d67       if self.img
+000060d0: 5f6e 756d 5f63 6861 6e6e 656c 7320 3d3d  _num_channels ==
+000060e0: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
+000060f0: 2020 2020 636c 6173 735f 3220 3d20 7265      class_2 = re
+00006100: 7369 7a65 2863 6c61 7373 5f32 2c20 7369  size(class_2, si
+00006110: 7a65 3d69 6d61 6765 5f73 697a 6529 0a20  ze=image_size). 
+00006120: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+00006130: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00006140: 2063 6861 6e6e 656c 3120 3d20 7265 7369   channel1 = resi
+00006150: 7a65 2863 6c61 7373 5f32 5b3a 2c3a 2c3a  ze(class_2[:,:,:
+00006160: 2c30 5d2c 2073 697a 653d 696d 6167 655f  ,0], size=image_
+00006170: 7369 7a65 290a 2020 2020 2020 2020 2020  size).          
+00006180: 2020 2020 2020 6368 616e 6e65 6c32 203d        channel2 =
+00006190: 2072 6573 697a 6528 636c 6173 735f 325b   resize(class_2[
+000061a0: 3a2c 3a2c 3a2c 315d 2c20 7369 7a65 3d69  :,:,:,1], size=i
+000061b0: 6d61 6765 5f73 697a 6529 0a20 2020 2020  mage_size).     
+000061c0: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+000061d0: 6c66 2e69 6d67 5f6e 756d 5f63 6861 6e6e  lf.img_num_chann
+000061e0: 656c 7320 3d3d 2032 3a0a 2020 2020 2020  els == 2:.      
+000061f0: 2020 2020 2020 2020 2020 2020 2020 636c                cl
+00006200: 6173 735f 3220 3d20 6461 7461 5f70 726f  ass_2 = data_pro
+00006210: 6365 7373 696e 672e 636f 6e63 6174 5f63  cessing.concat_c
+00006220: 6861 6e6e 656c 7328 6368 616e 6e65 6c31  hannels(channel1
+00006230: 2c20 6368 616e 6e65 6c32 290a 2020 2020  , channel2).    
+00006240: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00006250: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00006260: 2020 2020 2020 6368 616e 6e65 6c33 203d        channel3 =
+00006270: 2072 6573 697a 6528 636c 6173 735f 325b   resize(class_2[
+00006280: 3a2c 3a2c 3a2c 325d 2c20 7369 7a65 3d69  :,:,:,2], size=i
+00006290: 6d61 6765 5f73 697a 6529 0a20 2020 2020  mage_size).     
+000062a0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+000062b0: 6c61 7373 5f32 203d 2064 6174 615f 7072  lass_2 = data_pr
+000062c0: 6f63 6573 7369 6e67 2e63 6f6e 6361 745f  ocessing.concat_
+000062d0: 6368 616e 6e65 6c73 2863 6861 6e6e 656c  channels(channel
+000062e0: 312c 2063 6861 6e6e 656c 322c 2063 6861  1, channel2, cha
+000062f0: 6e6e 656c 3329 0a0a 2020 2020 2020 2020  nnel3)..        
+00006300: 2020 2020 234e 6565 6420 746f 2061 6c73      #Need to als
+00006310: 6f20 6372 6f70 2074 6865 2076 616c 6964  o crop the valid
+00006320: 6174 696f 6e20 696d 6167 6573 0a20 2020  ation images.   
+00006330: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+00006340: 2e76 616c 5f70 6f73 6974 6976 6520 6973  .val_positive is
+00006350: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+00006360: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+00006370: 6c66 2e69 6d67 5f6e 756d 5f63 6861 6e6e  lf.img_num_chann
+00006380: 656c 7320 3d3d 2031 3a0a 2020 2020 2020  els == 1:.      
+00006390: 2020 2020 2020 2020 2020 2020 2020 7661                va
+000063a0: 6c5f 636c 6173 735f 3120 3d20 7265 7369  l_class_1 = resi
+000063b0: 7a65 2873 656c 662e 7661 6c5f 706f 7369  ze(self.val_posi
+000063c0: 7469 7665 2c20 7369 7a65 3d69 6d61 6765  tive, size=image
+000063d0: 5f73 697a 6529 0a20 2020 2020 2020 2020  _size).         
+000063e0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+000063f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006400: 2076 616c 5f63 6861 6e6e 656c 3120 3d20   val_channel1 = 
+00006410: 7265 7369 7a65 2873 656c 662e 7661 6c5f  resize(self.val_
+00006420: 706f 7369 7469 7665 5b3a 2c3a 2c3a 2c30  positive[:,:,:,0
+00006430: 5d2c 2073 697a 653d 696d 6167 655f 7369  ], size=image_si
+00006440: 7a65 290a 2020 2020 2020 2020 2020 2020  ze).            
+00006450: 2020 2020 2020 2020 7661 6c5f 6368 616e          val_chan
+00006460: 6e65 6c32 203d 2072 6573 697a 6528 7365  nel2 = resize(se
+00006470: 6c66 2e76 616c 5f70 6f73 6974 6976 655b  lf.val_positive[
+00006480: 3a2c 3a2c 3a2c 315d 2c20 7369 7a65 3d69  :,:,:,1], size=i
+00006490: 6d61 6765 5f73 697a 6529 0a20 2020 2020  mage_size).     
+000064a0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+000064b0: 6620 7365 6c66 2e69 6d67 5f6e 756d 5f63  f self.img_num_c
+000064c0: 6861 6e6e 656c 7320 3d3d 2032 3a0a 2020  hannels == 2:.  
+000064d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000064e0: 2020 2020 2020 7661 6c5f 636c 6173 735f        val_class_
+000064f0: 3120 3d20 6461 7461 5f70 726f 6365 7373  1 = data_process
+00006500: 696e 672e 636f 6e63 6174 5f63 6861 6e6e  ing.concat_chann
+00006510: 656c 7328 7661 6c5f 6368 616e 6e65 6c31  els(val_channel1
+00006520: 2c20 7661 6c5f 6368 616e 6e65 6c32 290a  , val_channel2).
+00006530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006540: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00006550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006560: 2020 7661 6c5f 6368 616e 6e65 6c33 203d    val_channel3 =
+00006570: 2072 6573 697a 6528 7365 6c66 2e76 616c   resize(self.val
+00006580: 5f70 6f73 6974 6976 655b 3a2c 3a2c 3a2c  _positive[:,:,:,
+00006590: 325d 2c20 7369 7a65 3d69 6d61 6765 5f73  2], size=image_s
+000065a0: 697a 6529 0a20 2020 2020 2020 2020 2020  ize).           
+000065b0: 2020 2020 2020 2020 2020 2020 2076 616c               val
+000065c0: 5f63 6c61 7373 5f31 203d 2064 6174 615f  _class_1 = data_
+000065d0: 7072 6f63 6573 7369 6e67 2e63 6f6e 6361  processing.conca
+000065e0: 745f 6368 616e 6e65 6c73 2876 616c 5f63  t_channels(val_c
+000065f0: 6861 6e6e 656c 312c 2076 616c 5f63 6861  hannel1, val_cha
+00006600: 6e6e 656c 322c 2076 616c 5f63 6861 6e6e  nnel2, val_chann
+00006610: 656c 3329 0a20 2020 2020 2020 2020 2020  el3).           
+00006620: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00006630: 2020 2020 2020 2076 616c 5f63 6c61 7373         val_class
+00006640: 5f31 203d 204e 6f6e 6520 0a0a 2020 2020  _1 = None ..    
+00006650: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00006660: 7661 6c5f 6e65 6761 7469 7665 2069 7320  val_negative is 
+00006670: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+00006680: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+00006690: 662e 696d 675f 6e75 6d5f 6368 616e 6e65  f.img_num_channe
+000066a0: 6c73 203d 3d20 313a 0a20 2020 2020 2020  ls == 1:.       
+000066b0: 2020 2020 2020 2020 2020 2020 2076 616c               val
+000066c0: 5f63 6c61 7373 5f32 203d 2072 6573 697a  _class_2 = resiz
+000066d0: 6528 7365 6c66 2e76 616c 5f6e 6567 6174  e(self.val_negat
+000066e0: 6976 652c 2073 697a 653d 696d 6167 655f  ive, size=image_
+000066f0: 7369 7a65 290a 2020 2020 2020 2020 2020  size).          
+00006700: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
+00006710: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+00006720: 203e 2031 3a0a 2020 2020 2020 2020 2020   > 1:.          
+00006730: 2020 2020 2020 2020 2020 7661 6c5f 6368            val_ch
+00006740: 616e 6e65 6c31 203d 2072 6573 697a 6528  annel1 = resize(
+00006750: 7365 6c66 2e76 616c 5f6e 6567 6174 6976  self.val_negativ
+00006760: 655b 3a2c 3a2c 3a2c 305d 2c20 7369 7a65  e[:,:,:,0], size
+00006770: 3d69 6d61 6765 5f73 697a 6529 0a20 2020  =image_size).   
+00006780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006790: 2076 616c 5f63 6861 6e6e 656c 3220 3d20   val_channel2 = 
+000067a0: 7265 7369 7a65 2873 656c 662e 7661 6c5f  resize(self.val_
+000067b0: 6e65 6761 7469 7665 5b3a 2c3a 2c3a 2c31  negative[:,:,:,1
+000067c0: 5d2c 2073 697a 653d 696d 6167 655f 7369  ], size=image_si
+000067d0: 7a65 290a 2020 2020 2020 2020 2020 2020  ze).            
+000067e0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+000067f0: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+00006800: 203d 3d20 323a 0a20 2020 2020 2020 2020   == 2:.         
+00006810: 2020 2020 2020 2020 2020 2020 2020 2076                 v
+00006820: 616c 5f63 6c61 7373 5f32 203d 2064 6174  al_class_2 = dat
+00006830: 615f 7072 6f63 6573 7369 6e67 2e63 6f6e  a_processing.con
+00006840: 6361 745f 6368 616e 6e65 6c73 2876 616c  cat_channels(val
+00006850: 5f63 6861 6e6e 656c 312c 2076 616c 5f63  _channel1, val_c
+00006860: 6861 6e6e 656c 3229 0a20 2020 2020 2020  hannel2).       
+00006870: 2020 2020 2020 2020 2020 2020 2065 6c73               els
+00006880: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00006890: 2020 2020 2020 2020 2020 2076 616c 5f63             val_c
+000068a0: 6861 6e6e 656c 3320 3d20 7265 7369 7a65  hannel3 = resize
+000068b0: 2873 656c 662e 7661 6c5f 6e65 6761 7469  (self.val_negati
+000068c0: 7665 5b3a 2c3a 2c3a 2c32 5d2c 2073 697a  ve[:,:,:,2], siz
+000068d0: 653d 696d 6167 655f 7369 7a65 290a 2020  e=image_size).  
+000068e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000068f0: 2020 2020 2020 7661 6c5f 636c 6173 735f        val_class_
+00006900: 3220 3d20 6461 7461 5f70 726f 6365 7373  2 = data_process
+00006910: 696e 672e 636f 6e63 6174 5f63 6861 6e6e  ing.concat_chann
+00006920: 656c 7328 7661 6c5f 6368 616e 6e65 6c31  els(val_channel1
+00006930: 2c20 7661 6c5f 6368 616e 6e65 6c32 2c20  , val_channel2, 
+00006940: 7661 6c5f 6368 616e 6e65 6c33 290a 2020  val_channel3).  
+00006950: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+00006960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006970: 7661 6c5f 636c 6173 735f 3220 3d20 4e6f  val_class_2 = No
+00006980: 6e65 200a 2020 2020 2020 2020 656c 7365  ne .        else
+00006990: 3a0a 2020 2020 2020 2020 2020 2020 636c  :.            cl
+000069a0: 6173 735f 312c 2063 6c61 7373 5f32 203d  ass_1, class_2 =
+000069b0: 2073 656c 662e 706f 7369 7469 7665 5f63   self.positive_c
+000069c0: 6c61 7373 2c20 7365 6c66 2e6e 6567 6174  lass, self.negat
+000069d0: 6976 655f 636c 6173 730a 2020 2020 2020  ive_class.      
+000069e0: 2020 2020 2020 7661 6c5f 636c 6173 735f        val_class_
+000069f0: 312c 2076 616c 5f63 6c61 7373 5f32 203d  1, val_class_2 =
+00006a00: 2073 656c 662e 7661 6c5f 706f 7369 7469   self.val_positi
+00006a10: 7665 2c20 7365 6c66 2e76 616c 5f6e 6567  ve, self.val_neg
+00006a20: 6174 6976 650a 0a20 2020 2020 2020 2023  ative..        #
+00006a30: 2323 204f 7074 696d 697a 6520 7468 6520  ## Optimize the 
+00006a40: 6d61 7820 7069 7865 6c20 746f 2075 7365  max pixel to use
+00006a50: 2066 6f72 2074 6865 206d 696e 2d6d 6178   for the min-max
+00006a60: 206e 6f72 6d61 6c69 7a61 7469 6f6e 202d   normalization -
+00006a70: 2d20 4f4e 4520 5049 5820 5045 5220 4241  - ONE PIX PER BA
+00006a80: 4e44 2023 2323 0a20 2020 2020 2020 2069  ND ###.        i
+00006a90: 6620 7365 6c66 2e6f 7074 5f6d 6178 5f6d  f self.opt_max_m
+00006aa0: 696e 5f70 6978 2069 7320 6e6f 7420 4e6f  in_pix is not No
+00006ab0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+00006ac0: 7365 6c66 2e6e 6f72 6d61 6c69 7a65 203d  self.normalize =
+00006ad0: 2054 7275 6520 234a 7573 7420 696e 2063   True #Just in c
+00006ae0: 6173 6520 6974 2773 2073 6574 2074 6f20  ase it's set to 
+00006af0: 4661 6c73 6520 6279 2074 6865 2075 7365  False by the use
+00006b00: 7220 0a20 2020 2020 2020 2020 2020 206d  r .            m
+00006b10: 696e 5f70 6978 2c20 6d61 785f 7069 7820  in_pix, max_pix 
+00006b20: 3d20 302e 302c 205b 5d0a 2020 2020 2020  = 0.0, [].      
+00006b30: 2020 2020 2020 6966 2073 656c 662e 696d        if self.im
+00006b40: 675f 6e75 6d5f 6368 616e 6e65 6c73 203e  g_num_channels >
+00006b50: 3d20 313a 0a20 2020 2020 2020 2020 2020  = 1:.           
+00006b60: 2020 2020 206d 6178 5f70 6978 5f31 203d       max_pix_1 =
+00006b70: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+00006b80: 6e74 2827 6d61 785f 7069 7865 6c5f 3127  nt('max_pixel_1'
+00006b90: 2c20 7365 6c66 2e6f 7074 5f6d 6178 5f6d  , self.opt_max_m
+00006ba0: 696e 5f70 6978 2c20 7365 6c66 2e6f 7074  in_pix, self.opt
+00006bb0: 5f6d 6178 5f6d 6178 5f70 6978 2c20 7374  _max_max_pix, st
+00006bc0: 6570 3d31 293b 206d 6178 5f70 6978 2e61  ep=1); max_pix.a
+00006bd0: 7070 656e 6428 6d61 785f 7069 785f 3129  ppend(max_pix_1)
+00006be0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00006bf0: 7365 6c66 2e69 6d67 5f6e 756d 5f63 6861  self.img_num_cha
+00006c00: 6e6e 656c 7320 3e3d 2032 3a0a 2020 2020  nnels >= 2:.    
+00006c10: 2020 2020 2020 2020 2020 2020 6d61 785f              max_
+00006c20: 7069 785f 3220 3d20 7472 6961 6c2e 7375  pix_2 = trial.su
+00006c30: 6767 6573 745f 696e 7428 276d 6178 5f70  ggest_int('max_p
+00006c40: 6978 656c 5f32 272c 2073 656c 662e 6f70  ixel_2', self.op
+00006c50: 745f 6d61 785f 6d69 6e5f 7069 782c 2073  t_max_min_pix, s
+00006c60: 656c 662e 6f70 745f 6d61 785f 6d61 785f  elf.opt_max_max_
+00006c70: 7069 782c 2073 7465 703d 3129 3b20 6d61  pix, step=1); ma
+00006c80: 785f 7069 782e 6170 7065 6e64 286d 6178  x_pix.append(max
+00006c90: 5f70 6978 5f32 290a 2020 2020 2020 2020  _pix_2).        
+00006ca0: 2020 2020 6966 2073 656c 662e 696d 675f      if self.img_
+00006cb0: 6e75 6d5f 6368 616e 6e65 6c73 203d 3d20  num_channels == 
+00006cc0: 333a 0a20 2020 2020 2020 2020 2020 2020  3:.             
+00006cd0: 2020 206d 6178 5f70 6978 5f33 203d 2074     max_pix_3 = t
+00006ce0: 7269 616c 2e73 7567 6765 7374 5f69 6e74  rial.suggest_int
+00006cf0: 2827 6d61 785f 7069 7865 6c5f 3327 2c20  ('max_pixel_3', 
+00006d00: 7365 6c66 2e6f 7074 5f6d 6178 5f6d 696e  self.opt_max_min
+00006d10: 5f70 6978 2c20 7365 6c66 2e6f 7074 5f6d  _pix, self.opt_m
+00006d20: 6178 5f6d 6178 5f70 6978 2c20 7374 6570  ax_max_pix, step
+00006d30: 3d31 293b 206d 6178 5f70 6978 2e61 7070  =1); max_pix.app
+00006d40: 656e 6428 6d61 785f 7069 785f 3329 0a20  end(max_pix_3). 
+00006d50: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+00006d60: 7365 6c66 2e69 6d67 5f6e 756d 5f63 6861  self.img_num_cha
+00006d70: 6e6e 656c 7320 3e20 333a 0a20 2020 2020  nnels > 3:.     
+00006d80: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00006d90: 2056 616c 7565 4572 726f 7228 274f 6e6c   ValueError('Onl
+00006da0: 7920 7570 2074 6f20 7468 7265 6520 6368  y up to three ch
+00006db0: 616e 6e65 6c73 2061 7265 2063 7572 7265  annels are curre
+00006dc0: 6e74 6c79 2073 7570 706f 7274 6564 2127  ntly supported!'
+00006dd0: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
+00006de0: 2020 2020 2020 2020 2020 2020 6d69 6e5f              min_
+00006df0: 7069 782c 206d 6178 5f70 6978 203d 2073  pix, max_pix = s
+00006e00: 656c 662e 6d69 6e5f 7069 7865 6c2c 2073  elf.min_pixel, s
+00006e10: 656c 662e 6d61 785f 7069 7865 6c0a 0a20  elf.max_pixel.. 
+00006e20: 2020 2020 2020 2023 2323 2045 6172 6c79         ### Early
+00006e30: 2053 746f 7070 696e 6720 616e 6420 5072   Stopping and Pr
+00006e40: 756e 696e 6720 4361 6c6c 6261 636b 7320  uning Callbacks 
+00006e50: 2323 230a 2020 2020 2020 2020 6966 2073  ###.        if s
+00006e60: 656c 662e 7061 7469 656e 6365 2021 3d20  elf.patience != 
+00006e70: 303a 0a20 2020 2020 2020 2020 2020 206d  0:.            m
+00006e80: 6f64 6520 3d20 276d 696e 2720 6966 2027  ode = 'min' if '
+00006e90: 6c6f 7373 2720 696e 2073 656c 662e 6d65  loss' in self.me
+00006ea0: 7472 6963 2065 6c73 6520 276d 6178 2720  tric else 'max' 
+00006eb0: 234e 6565 6420 746f 206d 696e 696d 697a  #Need to minimiz
+00006ec0: 6520 7468 6520 6d65 7472 6963 2069 6620  e the metric if 
+00006ed0: 6576 616c 7561 7469 6e67 2074 6865 206c  evaluating the l
+00006ee0: 6f73 7321 0a20 2020 2020 2020 2020 2020  oss!.           
+00006ef0: 2069 6620 7365 6c66 2e6d 6574 7269 6320   if self.metric 
+00006f00: 3d3d 2027 7661 6c5f 616c 6c27 3a0a 2020  == 'val_all':.  
+00006f10: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+00006f20: 696e 7428 293b 2070 7269 6e74 2822 2743  int(); print("'C
+00006f30: 616e 6e6f 7420 7573 6520 6561 726c 7920  annot use early 
+00006f40: 7374 6f70 7069 6e67 2063 616c 6c62 6163  stopping callbac
+00006f50: 6b73 2069 6620 6176 6572 6167 696e 6720  ks if averaging 
+00006f60: 6f75 7420 616c 6c20 7065 7266 6f72 6d61  out all performa
+00006f70: 6e63 6520 6d65 7472 6963 7320 666f 7220  nce metrics for 
+00006f80: 6576 616c 7561 7469 6f6e 2120 4175 746f  evaluation! Auto
+00006f90: 6d61 7469 6361 6c6c 7920 7365 7474 696e  matically settin
+00006fa0: 6720 7468 6520 6d65 7472 6963 2074 6f20  g the metric to 
+00006fb0: 2776 616c 5f6c 6f73 7327 2e20 546f 2064  'val_loss'. To d
+00006fc0: 6973 6162 6c65 2c20 7365 7420 7061 7469  isable, set pati
+00006fd0: 656e 6365 3d30 2e22 290a 2020 2020 2020  ence=0.").      
+00006fe0: 2020 2020 2020 2020 2020 6361 6c6c 6261            callba
+00006ff0: 636b 7320 3d20 5b45 6172 6c79 5374 6f70  cks = [EarlyStop
+00007000: 7069 6e67 286d 6f6e 6974 6f72 3d27 7661  ping(monitor='va
+00007010: 6c5f 6c6f 7373 272c 206d 6f64 653d 276d  l_loss', mode='m
+00007020: 696e 272c 2070 6174 6965 6e63 653d 7365  in', patience=se
+00007030: 6c66 2e70 6174 6965 6e63 6529 2c5d 0a20  lf.patience),]. 
+00007040: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+00007050: 7365 6c66 2e6d 6574 7269 6320 3d3d 2027  self.metric == '
+00007060: 616c 6c27 3a0a 2020 2020 2020 2020 2020  all':.          
+00007070: 2020 2020 2020 7072 696e 7428 293b 2070        print(); p
+00007080: 7269 6e74 2822 2743 616e 6e6f 7420 7573  rint("'Cannot us
+00007090: 6520 6561 726c 7920 7374 6f70 7069 6e67  e early stopping
+000070a0: 2063 616c 6c62 6163 6b73 2069 6620 6176   callbacks if av
+000070b0: 6572 6167 696e 6720 6f75 7420 616c 6c20  eraging out all 
+000070c0: 7065 7266 6f72 6d61 6e63 6520 6d65 7472  performance metr
+000070d0: 6963 7320 666f 7220 6576 616c 7561 7469  ics for evaluati
+000070e0: 6f6e 2120 4175 746f 6d61 7469 6361 6c6c  on! Automaticall
+000070f0: 7920 7365 7474 696e 6720 7468 6520 6d65  y setting the me
+00007100: 7472 6963 2074 6f20 276c 6f73 7327 2e20  tric to 'loss'. 
+00007110: 546f 2064 6973 6162 6c65 2c20 7365 7420  To disable, set 
+00007120: 7061 7469 656e 6365 3d30 2e22 290a 2020  patience=0.").  
+00007130: 2020 2020 2020 2020 2020 2020 2020 6361                ca
+00007140: 6c6c 6261 636b 7320 3d20 5b45 6172 6c79  llbacks = [Early
+00007150: 5374 6f70 7069 6e67 286d 6f6e 6974 6f72  Stopping(monitor
+00007160: 3d27 6c6f 7373 272c 206d 6f64 653d 276d  ='loss', mode='m
+00007170: 696e 272c 2070 6174 6965 6e63 653d 7365  in', patience=se
+00007180: 6c66 2e70 6174 6965 6e63 6529 2c5d 0a20  lf.patience),]. 
+00007190: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+000071a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000071b0: 2063 616c 6c62 6163 6b73 203d 205b 4561   callbacks = [Ea
+000071c0: 726c 7953 746f 7070 696e 6728 6d6f 6e69  rlyStopping(moni
+000071d0: 746f 723d 7365 6c66 2e6d 6574 7269 632c  tor=self.metric,
+000071e0: 206d 6f64 653d 6d6f 6465 2c20 7061 7469   mode=mode, pati
+000071f0: 656e 6365 3d73 656c 662e 7061 7469 656e  ence=self.patien
+00007200: 6365 292c 5d20 2354 464b 6572 6173 5072  ce),] #TFKerasPr
+00007210: 756e 696e 6743 616c 6c62 6163 6b28 7472  uningCallback(tr
+00007220: 6961 6c2c 206d 6f6e 6974 6f72 3d73 656c  ial, monitor=sel
+00007230: 662e 6d65 7472 6963 292c 0a20 2020 2020  f.metric),.     
+00007240: 2020 2020 2020 200a 2020 2020 2020 2020         .        
+00007250: 2020 2020 6966 2073 656c 662e 6d65 7472      if self.metr
+00007260: 6963 3220 6973 206e 6f74 204e 6f6e 653a  ic2 is not None:
+00007270: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007280: 206d 6f64 6532 203d 2027 6d69 6e27 2069   mode2 = 'min' i
+00007290: 6620 276c 6f73 7327 2069 6e20 7365 6c66  f 'loss' in self
+000072a0: 2e6d 6574 7269 6332 2065 6c73 6520 276d  .metric2 else 'm
+000072b0: 6178 270a 2020 2020 2020 2020 2020 2020  ax'.            
+000072c0: 2020 2020 6361 6c6c 6261 636b 732e 6170      callbacks.ap
+000072d0: 7065 6e64 2845 6172 6c79 5374 6f70 7069  pend(EarlyStoppi
+000072e0: 6e67 286d 6f6e 6974 6f72 3d73 656c 662e  ng(monitor=self.
+000072f0: 6d65 7472 6963 322c 206d 6f64 653d 6d6f  metric2, mode=mo
+00007300: 6465 322c 2070 6174 6965 6e63 653d 7365  de2, patience=se
+00007310: 6c66 2e70 6174 6965 6e63 6529 290a 2020  lf.patience)).  
+00007320: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+00007330: 696e 7428 2753 6574 7469 6e67 2061 6464  int('Setting add
+00007340: 6974 696f 6e61 6c20 6561 726c 7920 7374  itional early st
+00007350: 6f70 7069 6e67 2063 7269 7465 7269 613a  opping criteria:
+00007360: 207b 7d27 2e66 6f72 6d61 7428 7365 6c66   {}'.format(self
+00007370: 2e6d 6574 7269 6332 2929 0a20 2020 2020  .metric2)).     
+00007380: 2020 2020 2020 2069 6620 7365 6c66 2e6d         if self.m
+00007390: 6574 7269 6333 2069 7320 6e6f 7420 4e6f  etric3 is not No
+000073a0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+000073b0: 2020 2020 6d6f 6465 3320 3d20 276d 696e      mode3 = 'min
+000073c0: 2720 6966 2027 6c6f 7373 2720 696e 2073  ' if 'loss' in s
+000073d0: 656c 662e 6d65 7472 6963 3320 656c 7365  elf.metric3 else
+000073e0: 2027 6d61 7827 0a20 2020 2020 2020 2020   'max'.         
+000073f0: 2020 2020 2020 2063 616c 6c62 6163 6b73         callbacks
+00007400: 2e61 7070 656e 6428 4561 726c 7953 746f  .append(EarlySto
+00007410: 7070 696e 6728 6d6f 6e69 746f 723d 7365  pping(monitor=se
+00007420: 6c66 2e6d 6574 7269 6333 2c20 6d6f 6465  lf.metric3, mode
+00007430: 3d6d 6f64 6533 2c20 7061 7469 656e 6365  =mode3, patience
+00007440: 3d73 656c 662e 7061 7469 656e 6365 2929  =self.patience))
+00007450: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007460: 2070 7269 6e74 2827 5365 7474 696e 6720   print('Setting 
+00007470: 6164 6469 7469 6f6e 616c 2065 6172 6c79  additional early
+00007480: 2073 746f 7070 696e 6720 6372 6974 6572   stopping criter
+00007490: 6961 3a20 7b7d 272e 666f 726d 6174 2873  ia: {}'.format(s
+000074a0: 656c 662e 6d65 7472 6963 3329 290a 2020  elf.metric3)).  
+000074b0: 2020 2020 2020 2020 2020 2020 2020 0a20                . 
+000074c0: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+000074d0: 6c66 2e6d 6f6e 6974 6f72 3120 6973 206e  lf.monitor1 is n
+000074e0: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
+000074f0: 2020 2020 2020 2020 2069 6620 6361 6c6c           if call
+00007500: 6261 636b 7320 6973 206e 6f74 204e 6f6e  backs is not Non
+00007510: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00007520: 2020 2020 2020 2063 616c 6c62 6163 6b73         callbacks
+00007530: 2e61 7070 656e 6428 4d6f 6e69 746f 725f  .append(Monitor_
+00007540: 5472 6163 6b65 7228 6d6f 6e69 746f 7231  Tracker(monitor1
+00007550: 3d73 656c 662e 6d6f 6e69 746f 7231 2c20  =self.monitor1, 
+00007560: 6d6f 6e69 746f 7232 3d73 656c 662e 6d6f  monitor2=self.mo
+00007570: 6e69 746f 7232 2c20 6d6f 6e69 746f 7231  nitor2, monitor1
+00007580: 5f74 6872 6573 683d 7365 6c66 2e6d 6f6e  _thresh=self.mon
+00007590: 6974 6f72 315f 7468 7265 7368 2c20 6d6f  itor1_thresh, mo
+000075a0: 6e69 746f 7232 5f74 6872 6573 683d 7365  nitor2_thresh=se
+000075b0: 6c66 2e6d 6f6e 6974 6f72 325f 7468 7265  lf.monitor2_thre
+000075c0: 7368 2929 0a20 2020 2020 2020 2020 2020  sh)).           
+000075d0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+000075e0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+000075f0: 616c 6c62 6163 6b73 203d 205b 4d6f 6e69  allbacks = [Moni
+00007600: 746f 725f 5472 6163 6b65 7228 6d6f 6e69  tor_Tracker(moni
+00007610: 746f 7231 3d73 656c 662e 6d6f 6e69 746f  tor1=self.monito
+00007620: 7231 2c20 6d6f 6e69 746f 7232 3d73 656c  r1, monitor2=sel
+00007630: 662e 6d6f 6e69 746f 7232 2c20 6d6f 6e69  f.monitor2, moni
+00007640: 746f 7231 5f74 6872 6573 683d 7365 6c66  tor1_thresh=self
+00007650: 2e6d 6f6e 6974 6f72 315f 7468 7265 7368  .monitor1_thresh
+00007660: 2c20 6d6f 6e69 746f 7232 5f74 6872 6573  , monitor2_thres
+00007670: 683d 7365 6c66 2e6d 6f6e 6974 6f72 325f  h=self.monitor2_
+00007680: 7468 7265 7368 292c 5d0a 2020 2020 2020  thresh),].      
+00007690: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+000076a0: 2020 2020 6966 2073 656c 662e 6d6f 6e69      if self.moni
+000076b0: 746f 7231 2069 7320 6e6f 7420 4e6f 6e65  tor1 is not None
+000076c0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000076d0: 2020 6361 6c6c 6261 636b 7320 3d20 5b4d    callbacks = [M
+000076e0: 6f6e 6974 6f72 5f54 7261 636b 6572 286d  onitor_Tracker(m
+000076f0: 6f6e 6974 6f72 313d 7365 6c66 2e6d 6f6e  onitor1=self.mon
+00007700: 6974 6f72 312c 206d 6f6e 6974 6f72 323d  itor1, monitor2=
+00007710: 7365 6c66 2e6d 6f6e 6974 6f72 322c 206d  self.monitor2, m
+00007720: 6f6e 6974 6f72 315f 7468 7265 7368 3d73  onitor1_thresh=s
+00007730: 656c 662e 6d6f 6e69 746f 7231 5f74 6872  elf.monitor1_thr
+00007740: 6573 682c 206d 6f6e 6974 6f72 325f 7468  esh, monitor2_th
+00007750: 7265 7368 3d73 656c 662e 6d6f 6e69 746f  resh=self.monito
+00007760: 7232 5f74 6872 6573 6829 2c5d 0a20 2020  r2_thresh),].   
+00007770: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+00007780: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00007790: 616c 6c62 6163 6b73 203d 204e 6f6e 650a  allbacks = None.
+000077a0: 0a20 2020 2020 2020 2023 2323 2023 2323  .        ### ###
+000077b0: 2023 2323 2023 2323 2023 2323 2023 2323   ### ### ### ###
+000077c0: 2023 2323 2023 2323 2023 2323 200a 2020   ### ### ### .  
+000077d0: 2020 2020 2020 2020 2020 2023 2320 4f70             ## Op
+000077e0: 7469 6d69 7a65 2043 4e4e 204d 6f64 656c  timize CNN Model
+000077f0: 2023 230a 2020 2020 2020 2020 2323 2320   ##.        ### 
+00007800: 2323 2320 2323 2320 2323 2320 2323 2320  ### ### ### ### 
+00007810: 2323 2320 2323 2320 2323 2320 2323 2320  ### ### ### ### 
+00007820: 0a0a 2020 2020 2020 2020 2323 2320 4261  ..        ### Ba
+00007830: 7463 6820 5369 7a65 2023 2323 0a20 2020  tch Size ###.   
+00007840: 2020 2020 2023 496e 2063 6173 6520 7573       #In case us
+00007850: 6572 2077 616e 7473 2074 6f20 6669 7820  er wants to fix 
+00007860: 7468 6520 6261 7463 685f 7369 7a65 2e2e  the batch_size..
+00007870: 2e20 616c 7468 6f75 6768 204f 7074 756e  . although Optun
+00007880: 6120 6361 6e20 6f70 7469 6d69 7a65 2061  a can optimize a
+00007890: 2070 6172 616d 2072 616e 6769 6e67 2066   param ranging f
+000078a0: 726f 6d20 6f6e 6520 7661 6c75 6520 746f  rom one value to
+000078b0: 2074 6865 2073 616d 6520 7661 6c75 652c   the same value,
+000078c0: 2074 6865 2069 6d70 6f72 7461 6e63 6573   the importances
+000078d0: 2077 696c 6c20 6e6f 7420 6265 2061 626c   will not be abl
+000078e0: 6520 746f 2062 6520 636f 6d70 7574 6564  e to be computed
+000078f0: 2061 6674 6572 7761 7264 7321 2054 6869   afterwards! Thi
+00007900: 7320 636f 6e64 6974 696f 6e20 6973 2074  s condition is t
+00007910: 6f20 6176 6f69 6420 7468 6973 2062 7567  o avoid this bug
+00007920: 2120 0a20 2020 2020 2020 2069 6620 7365  ! .        if se
+00007930: 6c66 2e62 6174 6368 5f73 697a 655f 6d69  lf.batch_size_mi
+00007940: 6e20 3d3d 2073 656c 662e 6261 7463 685f  n == self.batch_
+00007950: 7369 7a65 5f6d 6178 3a0a 2020 2020 2020  size_max:.      
+00007960: 2020 2020 2020 6261 7463 685f 7369 7a65        batch_size
+00007970: 203d 2073 656c 662e 6261 7463 685f 7369   = self.batch_si
+00007980: 7a65 5f6d 6178 200a 2020 2020 2020 2020  ze_max .        
+00007990: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+000079a0: 2020 6261 7463 685f 7369 7a65 203d 2074    batch_size = t
+000079b0: 7269 616c 2e73 7567 6765 7374 5f69 6e74  rial.suggest_int
+000079c0: 2827 6261 7463 685f 7369 7a65 272c 2073  ('batch_size', s
+000079d0: 656c 662e 6261 7463 685f 7369 7a65 5f6d  elf.batch_size_m
+000079e0: 696e 2c20 7365 6c66 2e62 6174 6368 5f73  in, self.batch_s
+000079f0: 697a 655f 6d61 782c 2073 7465 703d 3129  ize_max, step=1)
+00007a00: 0a0a 2020 2020 2020 2020 2323 2320 4c65  ..        ### Le
+00007a10: 6172 6e69 6e67 2052 6174 6520 2620 4f70  arning Rate & Op
+00007a20: 7469 6d69 7a65 7220 2323 230a 2020 2020  timizer ###.    
+00007a30: 2020 2020 6c72 203d 2074 7269 616c 2e73      lr = trial.s
+00007a40: 7567 6765 7374 5f66 6c6f 6174 2827 6c72  uggest_float('lr
+00007a50: 272c 2031 652d 362c 2031 652d 332c 2073  ', 1e-6, 1e-3, s
+00007a60: 7465 703d 3565 2d36 2920 0a20 2020 2020  tep=5e-6) .     
+00007a70: 2020 2064 6563 6179 3d30 2023 6465 6361     decay=0 #deca
+00007a80: 7920 3d20 7472 6961 6c2e 7375 6767 6573  y = trial.sugges
+00007a90: 745f 666c 6f61 7428 2764 6563 6179 272c  t_float('decay',
+00007aa0: 2030 2e30 2c20 302e 312c 2073 7465 703d   0.0, 0.1, step=
+00007ab0: 3165 2d33 290a 2020 2020 2020 2020 6f70  1e-3).        op
+00007ac0: 7469 6d69 7a65 7220 3d20 7472 6961 6c2e  timizer = trial.
+00007ad0: 7375 6767 6573 745f 6361 7465 676f 7269  suggest_categori
+00007ae0: 6361 6c28 276f 7074 696d 697a 6572 272c  cal('optimizer',
+00007af0: 205b 2773 6764 272c 2027 6164 616d 272c   ['sgd', 'adam',
+00007b00: 2027 6164 616d 6178 272c 2027 6e61 6461   'adamax', 'nada
+00007b10: 6d27 2c20 2761 6461 6465 6c74 6127 2c20  m', 'adadelta', 
+00007b20: 2772 6d73 7072 6f70 275d 290a 0a20 2020  'rmsprop'])..   
+00007b30: 2020 2020 2023 416c 6c20 7573 6520 696e       #All use in
+00007b40: 7665 7273 6520 7469 6d65 2064 6563 6179  verse time decay
+00007b50: 2c20 6120 6665 7720 7573 6520 7268 6f20  , a few use rho 
+00007b60: 6173 2077 656c 6c2c 2061 6e64 2041 6461  as well, and Ada
+00007b70: 6d2d 6261 7365 6420 6f70 7469 6d69 7a65  m-based optimize
+00007b80: 7273 2075 7365 2062 6574 615f 3120 616e  rs use beta_1 an
+00007b90: 6420 6265 7461 5f32 200a 2020 2020 2020  d beta_2 .      
+00007ba0: 2020 6966 206f 7074 696d 697a 6572 203d    if optimizer =
+00007bb0: 3d20 2773 6764 273a 0a20 2020 2020 2020  = 'sgd':.       
+00007bc0: 2020 2020 206d 6f6d 656e 7475 6d20 3d20       momentum = 
+00007bd0: 7472 6961 6c2e 7375 6767 6573 745f 666c  trial.suggest_fl
+00007be0: 6f61 7428 276d 6f6d 656e 7475 6d27 2c20  oat('momentum', 
+00007bf0: 302e 302c 2031 2e30 2c20 7374 6570 3d31  0.0, 1.0, step=1
+00007c00: 652d 3329 0a20 2020 2020 2020 2020 2020  e-3).           
+00007c10: 206e 6573 7465 726f 7620 3d20 7472 6961   nesterov = tria
+00007c20: 6c2e 7375 6767 6573 745f 6361 7465 676f  l.suggest_catego
+00007c30: 7269 6361 6c28 276e 6573 7465 726f 7627  rical('nesterov'
+00007c40: 2c20 5b54 7275 652c 2046 616c 7365 5d29  , [True, False])
+00007c50: 0a20 2020 2020 2020 2020 2020 2062 6574  .            bet
+00007c60: 615f 3120 3d20 6265 7461 5f32 203d 2030  a_1 = beta_2 = 0
+00007c70: 3b20 616d 7367 7261 6420 3d20 4661 6c73  ; amsgrad = Fals
+00007c80: 650a 2020 2020 2020 2020 656c 6966 206f  e.        elif o
+00007c90: 7074 696d 697a 6572 203d 3d20 2761 6461  ptimizer == 'ada
+00007ca0: 6d27 206f 7220 6f70 7469 6d69 7a65 7220  m' or optimizer 
+00007cb0: 3d3d 2027 6164 616d 6178 2720 6f72 206f  == 'adamax' or o
+00007cc0: 7074 696d 697a 6572 203d 3d20 276e 6164  ptimizer == 'nad
+00007cd0: 616d 273a 0a20 2020 2020 2020 2020 2020  am':.           
+00007ce0: 2062 6574 615f 3120 3d20 7472 6961 6c2e   beta_1 = trial.
+00007cf0: 7375 6767 6573 745f 666c 6f61 7428 2762  suggest_float('b
+00007d00: 6574 615f 3127 2c20 302e 302c 2031 2e30  eta_1', 0.0, 1.0
+00007d10: 2c20 7374 6570 3d31 652d 3329 0a20 2020  , step=1e-3).   
+00007d20: 2020 2020 2020 2020 2062 6574 615f 3220           beta_2 
+00007d30: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+00007d40: 666c 6f61 7428 2762 6574 615f 3227 2c20  float('beta_2', 
+00007d50: 302e 302c 2031 2e30 2c20 7374 6570 3d31  0.0, 1.0, step=1
+00007d60: 652d 3329 0a20 2020 2020 2020 2020 2020  e-3).           
+00007d70: 2061 6d73 6772 6164 203d 2074 7269 616c   amsgrad = trial
+00007d80: 2e73 7567 6765 7374 5f63 6174 6567 6f72  .suggest_categor
+00007d90: 6963 616c 2827 616d 7367 7261 6427 2c20  ical('amsgrad', 
+00007da0: 5b54 7275 652c 2046 616c 7365 5d29 2069  [True, False]) i
+00007db0: 6620 6f70 7469 6d69 7a65 7220 3d3d 2027  f optimizer == '
+00007dc0: 6164 616d 2720 656c 7365 2046 616c 7365  adam' else False
+00007dd0: 0a20 2020 2020 2020 2020 2020 206d 6f6d  .            mom
+00007de0: 656e 7475 6d2c 206e 6573 7465 726f 7620  entum, nesterov 
+00007df0: 3d20 302e 302c 2046 616c 7365 0a20 2020  = 0.0, False.   
+00007e00: 2020 2020 2065 6c69 6620 6f70 7469 6d69       elif optimi
+00007e10: 7a65 7220 3d3d 2027 6164 6164 656c 7461  zer == 'adadelta
+00007e20: 2720 6f72 206f 7074 696d 697a 6572 203d  ' or optimizer =
+00007e30: 3d20 2772 6d73 7072 6f70 273a 0a20 2020  = 'rmsprop':.   
+00007e40: 2020 2020 2020 2020 2072 686f 203d 2074           rho = t
+00007e50: 7269 616c 2e73 7567 6765 7374 5f66 6c6f  rial.suggest_flo
+00007e60: 6174 2827 7268 6f27 2c20 302c 2031 2c20  at('rho', 0, 1, 
+00007e70: 7374 6570 3d31 652d 3329 0a20 2020 2020  step=1e-3).     
+00007e80: 2020 2020 2020 206d 6f6d 656e 7475 6d20         momentum 
+00007e90: 3d20 6265 7461 5f31 203d 2062 6574 615f  = beta_1 = beta_
+00007ea0: 3220 3d20 303b 206e 6573 7465 726f 7620  2 = 0; nesterov 
+00007eb0: 3d20 616d 7367 7261 6420 3d20 4661 6c73  = amsgrad = Fals
+00007ec0: 650a 0a20 2020 2020 2020 2063 6c65 6172  e..        clear
+00007ed0: 5f73 6573 7369 6f6e 2829 0a20 2020 2020  _session().     
+00007ee0: 2020 2069 6620 7365 6c66 2e6f 7074 5f6d     if self.opt_m
+00007ef0: 6f64 656c 3a0a 2020 2020 2020 2020 2020  odel:.          
+00007f00: 2020 2222 2243 4e4e 2048 7970 6572 7061    """CNN Hyperpa
+00007f10: 7261 6d65 7465 7220 5365 6172 6368 2053  rameter Search S
+00007f20: 7061 6365 2222 220a 0a20 2020 2020 2020  pace"""..       
+00007f30: 2020 2020 2023 2323 2041 6374 6976 6174       ### Activat
+00007f40: 696f 6e20 616e 6420 4c6f 7373 2046 756e  ion and Loss Fun
+00007f50: 6374 696f 6e73 2023 2323 200a 2020 2020  ctions ### .    
+00007f60: 2020 2020 2020 2020 6163 7469 7661 7469          activati
+00007f70: 6f6e 5f63 6f6e 7620 3d20 7472 6961 6c2e  on_conv = trial.
+00007f80: 7375 6767 6573 745f 6361 7465 676f 7269  suggest_categori
+00007f90: 6361 6c28 2761 6374 6976 6174 696f 6e5f  cal('activation_
+00007fa0: 636f 6e76 272c 205b 2772 656c 7527 2c20  conv', ['relu', 
+00007fb0: 2773 6967 6d6f 6964 272c 2027 7461 6e68  'sigmoid', 'tanh
+00007fc0: 272c 2027 656c 7527 2c20 2773 656c 7527  ', 'elu', 'selu'
+00007fd0: 5d29 2020 2020 2020 2020 2020 2020 0a20  ])            . 
+00007fe0: 2020 2020 2020 2020 2020 2061 6374 6976             activ
+00007ff0: 6174 696f 6e5f 6465 6e73 6520 3d20 7472  ation_dense = tr
+00008000: 6961 6c2e 7375 6767 6573 745f 6361 7465  ial.suggest_cate
+00008010: 676f 7269 6361 6c28 2761 6374 6976 6174  gorical('activat
+00008020: 696f 6e5f 6465 6e73 6527 2c20 5b27 7265  ion_dense', ['re
+00008030: 6c75 272c 2027 7369 676d 6f69 6427 2c20  lu', 'sigmoid', 
+00008040: 2774 616e 6827 2c20 2765 6c75 272c 2027  'tanh', 'elu', '
+00008050: 7365 6c75 275d 290a 2020 2020 2020 2020  selu']).        
+00008060: 2020 2020 6c6f 7373 203d 2074 7269 616c      loss = trial
+00008070: 2e73 7567 6765 7374 5f63 6174 6567 6f72  .suggest_categor
+00008080: 6963 616c 2827 6c6f 7373 272c 205b 2762  ical('loss', ['b
+00008090: 696e 6172 795f 6372 6f73 7365 6e74 726f  inary_crossentro
+000080a0: 7079 272c 2027 6869 6e67 6527 2c20 2773  py', 'hinge', 's
+000080b0: 7175 6172 6564 5f68 696e 6765 272c 2027  quared_hinge', '
+000080c0: 6b6c 6427 2c20 276c 6f67 636f 7368 275d  kld', 'logcosh']
+000080d0: 2923 2c20 2766 6f63 616c 5f6c 6f73 7327  )#, 'focal_loss'
+000080e0: 2c20 2764 6963 655f 6c6f 7373 272c 2027  , 'dice_loss', '
+000080f0: 6a61 6363 6172 645f 6c6f 7373 275d 290a  jaccard_loss']).
+00008100: 0a20 2020 2020 2020 2020 2020 2023 2323  .            ###
+00008110: 204b 6572 6e65 6c20 496e 6974 6961 6c69   Kernel Initiali
+00008120: 7a65 7273 2023 2323 0a20 2020 2020 2020  zers ###.       
+00008130: 2020 2020 2063 6f6e 765f 696e 6974 203d       conv_init =
+00008140: 2074 7269 616c 2e73 7567 6765 7374 5f63   trial.suggest_c
+00008150: 6174 6567 6f72 6963 616c 2827 636f 6e76  ategorical('conv
+00008160: 5f69 6e69 7427 2c20 5b27 756e 6966 6f72  _init', ['unifor
+00008170: 6d5f 7363 616c 696e 6727 2c20 2754 7275  m_scaling', 'Tru
+00008180: 6e63 6174 6564 4e6f 726d 616c 272c 2027  ncatedNormal', '
+00008190: 6865 5f6e 6f72 6d61 6c27 2c20 276c 6563  he_normal', 'lec
+000081a0: 756e 5f75 6e69 666f 726d 272c 2027 676c  un_uniform', 'gl
+000081b0: 6f72 6f74 5f75 6e69 666f 726d 275d 2920  orot_uniform']) 
+000081c0: 0a20 2020 2020 2020 2020 2020 2064 656e  .            den
+000081d0: 7365 5f69 6e69 7420 3d20 7472 6961 6c2e  se_init = trial.
+000081e0: 7375 6767 6573 745f 6361 7465 676f 7269  suggest_categori
+000081f0: 6361 6c28 2764 656e 7365 5f69 6e69 7427  cal('dense_init'
+00008200: 2c20 5b27 756e 6966 6f72 6d5f 7363 616c  , ['uniform_scal
+00008210: 696e 6727 2c20 2754 7275 6e63 6174 6564  ing', 'Truncated
+00008220: 4e6f 726d 616c 272c 2768 655f 6e6f 726d  Normal','he_norm
+00008230: 616c 272c 2027 6c65 6375 6e5f 756e 6966  al', 'lecun_unif
+00008240: 6f72 6d27 2c20 2767 6c6f 726f 745f 756e  orm', 'glorot_un
+00008250: 6966 6f72 6d27 5d29 200a 0a20 2020 2020  iform']) ..     
+00008260: 2020 2020 2020 2070 7269 6e74 2829 0a20         print(). 
+00008270: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+00008280: 6c66 2e76 6572 626f 7365 203d 3d20 313a  lf.verbose == 1:
+00008290: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000082a0: 2069 6620 7365 6c66 2e6f 7074 5f63 7620   if self.opt_cv 
+000082b0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
+000082c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000082d0: 2070 7269 6e74 2829 3b20 7072 696e 7428   print(); print(
+000082e0: 272a 2a2a 2a2a 2a2a 2a2a 2a2a 2020 4356  '***********  CV
+000082f0: 202d 2031 202a 2a2a 2a2a 2a2a 2a2a 2a2a   - 1 ***********
+00008300: 2729 3b20 7072 696e 7428 290a 2020 2020  '); print().    
+00008310: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00008320: 656c 662e 6f70 745f 6175 673a 0a20 2020  elf.opt_aug:.   
+00008330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008340: 2070 7269 6e74 2829 3b20 7072 696e 7428   print(); print(
+00008350: 273d 3d3d 3d3d 3d3d 2049 6d61 6765 2050  '======= Image P
+00008360: 6172 616d 6574 6572 7320 3d3d 3d3d 3d3d  arameters ======
+00008370: 2729 3b20 7072 696e 7428 293b 2070 7269  '); print(); pri
+00008380: 6e74 2827 4e75 6d20 4175 676d 656e 7461  nt('Num Augmenta
+00008390: 7469 6f6e 7320 3a27 2c20 6e75 6d5f 6175  tions :', num_au
+000083a0: 6729 3b20 7072 696e 7428 2749 6d61 6765  g); print('Image
+000083b0: 2053 697a 6520 3a20 272c 2069 6d61 6765   Size : ', image
+000083c0: 5f73 697a 6529 3b20 7072 696e 7428 274d  _size); print('M
+000083d0: 6178 2050 6978 656c 2873 2920 3a27 2c20  ax Pixel(s) :', 
+000083e0: 6d61 785f 7069 7829 3b20 7072 696e 7428  max_pix); print(
+000083f0: 274e 756d 204d 6173 6b73 203a 272c 206e  'Num Masks :', n
+00008400: 756d 5f6d 6173 6b73 293b 2070 7269 6e74  um_masks); print
+00008410: 2827 4d61 736b 2053 697a 6520 3a27 2c20  ('Mask Size :', 
+00008420: 6d61 736b 5f73 697a 6529 3b20 7072 696e  mask_size); prin
+00008430: 7428 2742 6c65 6e64 204d 756c 7469 706c  t('Blend Multipl
+00008440: 6965 7220 3a27 2c20 626c 656e 645f 6d75  ier :', blend_mu
+00008450: 6c74 6970 6c69 6572 293b 2070 7269 6e74  ltiplier); print
+00008460: 2827 536b 6577 2041 6e67 6c65 203a 272c  ('Skew Angle :',
+00008470: 2073 6b65 775f 616e 676c 6529 0a0a 2020   skew_angle)..  
+00008480: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+00008490: 662e 636c 6620 3d3d 2027 616c 6578 6e65  f.clf == 'alexne
+000084a0: 7427 3a0a 0a20 2020 2020 2020 2020 2020  t':..           
+000084b0: 2020 2020 2023 2323 2052 6567 756c 6172       ### Regular
+000084c0: 697a 6174 696f 6e20 5465 6368 6e69 7175  ization Techniqu
+000084d0: 6520 2842 4e20 6973 206e 6577 6572 2c20  e (BN is newer, 
+000084e0: 416c 6578 4e65 7420 7573 6564 2074 776f  AlexNet used two
+000084f0: 204c 6f63 616c 2052 6573 706f 6e73 6520   Local Response 
+00008500: 4e6f 726d 616c 697a 6174 696f 6e20 6c61  Normalization la
+00008510: 7965 7273 2061 6674 6572 2074 6865 2066  yers after the f
+00008520: 6972 7374 2074 776f 2063 6f6e 7673 2920  irst two convs) 
+00008530: 2323 230a 2020 2020 2020 2020 2020 2020  ###.            
+00008540: 2020 2020 6d6f 6465 6c5f 7265 6720 3d20      model_reg = 
+00008550: 7472 6961 6c2e 7375 6767 6573 745f 6361  trial.suggest_ca
+00008560: 7465 676f 7269 6361 6c28 276d 6f64 656c  tegorical('model
+00008570: 5f72 6567 272c 205b 4e6f 6e65 2c20 276c  _reg', [None, 'l
+00008580: 6f63 616c 5f72 6573 706f 6e73 6527 2c20  ocal_response', 
+00008590: 2762 6174 6368 5f6e 6f72 6d27 5d29 0a0a  'batch_norm'])..
+000085a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000085b0: 2323 2320 506f 6f6c 696e 6720 5479 7065  ### Pooling Type
+000085c0: 2023 2323 0a20 2020 2020 2020 2020 2020   ###.           
+000085d0: 2020 2020 2070 6f6f 6c69 6e67 5f31 203d       pooling_1 =
+000085e0: 2074 7269 616c 2e73 7567 6765 7374 5f63   trial.suggest_c
+000085f0: 6174 6567 6f72 6963 616c 2827 706f 6f6c  ategorical('pool
+00008600: 696e 675f 3127 2c20 5b27 6d69 6e27 2c20  ing_1', ['min', 
+00008610: 276d 6178 272c 2027 6176 6572 6167 6527  'max', 'average'
+00008620: 5d29 0a20 2020 2020 2020 2020 2020 2020  ]).             
+00008630: 2020 2070 6f6f 6c69 6e67 5f32 203d 2074     pooling_2 = t
+00008640: 7269 616c 2e73 7567 6765 7374 5f63 6174  rial.suggest_cat
+00008650: 6567 6f72 6963 616c 2827 706f 6f6c 696e  egorical('poolin
+00008660: 675f 3227 2c20 5b27 6d69 6e27 2c20 276d  g_2', ['min', 'm
+00008670: 6178 272c 2027 6176 6572 6167 6527 5d29  ax', 'average'])
+00008680: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00008690: 2070 6f6f 6c69 6e67 5f33 203d 2074 7269   pooling_3 = tri
+000086a0: 616c 2e73 7567 6765 7374 5f63 6174 6567  al.suggest_categ
+000086b0: 6f72 6963 616c 2827 706f 6f6c 696e 675f  orical('pooling_
+000086c0: 3327 2c20 5b27 6d69 6e27 2c20 276d 6178  3', ['min', 'max
+000086d0: 272c 2027 6176 6572 6167 6527 5d29 0a0a  ', 'average'])..
+000086e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000086f0: 6966 2073 656c 662e 6c69 6d69 745f 7365  if self.limit_se
+00008700: 6172 6368 3a0a 2020 2020 2020 2020 2020  arch:.          
+00008710: 2020 2020 2020 0a20 2020 2020 2020 2020        .         
+00008720: 2020 2020 2020 2020 2020 206d 6f64 656c             model
+00008730: 2c20 6869 7374 6f72 7920 3d20 636e 6e5f  , history = cnn_
+00008740: 6d6f 6465 6c2e 416c 6578 4e65 7428 636c  model.AlexNet(cl
+00008750: 6173 735f 312c 2063 6c61 7373 5f32 2c20  ass_1, class_2, 
+00008760: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+00008770: 3d73 656c 662e 696d 675f 6e75 6d5f 6368  =self.img_num_ch
+00008780: 616e 6e65 6c73 2c20 0a20 2020 2020 2020  annels, .       
+00008790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000087a0: 206e 6f72 6d61 6c69 7a65 3d73 656c 662e   normalize=self.
+000087b0: 6e6f 726d 616c 697a 652c 206d 696e 5f70  normalize, min_p
+000087c0: 6978 656c 3d6d 696e 5f70 6978 2c20 6d61  ixel=min_pix, ma
+000087d0: 785f 7069 7865 6c3d 6d61 785f 7069 782c  x_pixel=max_pix,
+000087e0: 2076 616c 5f70 6f73 6974 6976 653d 7661   val_positive=va
+000087f0: 6c5f 636c 6173 735f 312c 2076 616c 5f6e  l_class_1, val_n
+00008800: 6567 6174 6976 653d 7661 6c5f 636c 6173  egative=val_clas
+00008810: 735f 322c 200a 2020 2020 2020 2020 2020  s_2, .          
+00008820: 2020 2020 2020 2020 2020 2020 2020 6570                ep
+00008830: 6f63 6873 3d73 656c 662e 7472 6169 6e5f  ochs=self.train_
+00008840: 6570 6f63 6873 2c20 6261 7463 685f 7369  epochs, batch_si
+00008850: 7a65 3d62 6174 6368 5f73 697a 652c 206f  ze=batch_size, o
+00008860: 7074 696d 697a 6572 3d6f 7074 696d 697a  ptimizer=optimiz
+00008870: 6572 2c20 6c72 3d6c 722c 2064 6563 6179  er, lr=lr, decay
+00008880: 3d64 6563 6179 2c20 6d6f 6d65 6e74 756d  =decay, momentum
+00008890: 3d6d 6f6d 656e 7475 6d2c 206e 6573 7465  =momentum, neste
+000088a0: 726f 763d 6e65 7374 6572 6f76 2c20 0a20  rov=nesterov, . 
+000088b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000088c0: 2020 2020 2020 2062 6574 615f 313d 6265         beta_1=be
+000088d0: 7461 5f31 2c20 6265 7461 5f32 3d62 6574  ta_1, beta_2=bet
+000088e0: 615f 322c 2061 6d73 6772 6164 3d61 6d73  a_2, amsgrad=ams
+000088f0: 6772 6164 2c20 6c6f 7373 3d6c 6f73 732c  grad, loss=loss,
+00008900: 2061 6374 6976 6174 696f 6e5f 636f 6e76   activation_conv
+00008910: 3d61 6374 6976 6174 696f 6e5f 636f 6e76  =activation_conv
+00008920: 2c20 6163 7469 7661 7469 6f6e 5f64 656e  , activation_den
+00008930: 7365 3d61 6374 6976 6174 696f 6e5f 6465  se=activation_de
+00008940: 6e73 652c 200a 2020 2020 2020 2020 2020  nse, .          
+00008950: 2020 2020 2020 2020 2020 2020 2020 636f                co
+00008960: 6e76 5f69 6e69 743d 636f 6e76 5f69 6e69  nv_init=conv_ini
+00008970: 742c 2064 656e 7365 5f69 6e69 743d 6465  t, dense_init=de
+00008980: 6e73 655f 696e 6974 2c20 6d6f 6465 6c5f  nse_init, model_
+00008990: 7265 673d 6d6f 6465 6c5f 7265 672c 2070  reg=model_reg, p
+000089a0: 6f6f 6c69 6e67 5f31 3d70 6f6f 6c69 6e67  ooling_1=pooling
+000089b0: 5f31 2c20 706f 6f6c 696e 675f 323d 706f  _1, pooling_2=po
+000089c0: 6f6c 696e 675f 322c 2070 6f6f 6c69 6e67  oling_2, pooling
+000089d0: 5f33 3d70 6f6f 6c69 6e67 5f33 2c20 0a20  _3=pooling_3, . 
+000089e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000089f0: 2020 2020 2020 2073 6d6f 7465 5f73 616d         smote_sam
+00008a00: 706c 696e 673d 7365 6c66 2e73 6d6f 7465  pling=self.smote
+00008a10: 5f73 616d 706c 696e 672c 2065 6172 6c79  _sampling, early
+00008a20: 5f73 746f 705f 6361 6c6c 6261 636b 3d63  _stop_callback=c
+00008a30: 616c 6c62 6163 6b73 2c20 6368 6563 6b70  allbacks, checkp
+00008a40: 6f69 6e74 3d46 616c 7365 2c20 7665 7262  oint=False, verb
+00008a50: 6f73 653d 7365 6c66 2e76 6572 626f 7365  ose=self.verbose
+00008a60: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00008a70: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00008a80: 2020 2020 2020 2020 2020 2020 2323 2320              ### 
+00008a90: 4669 6c74 6572 2061 6e64 204c 6179 6572  Filter and Layer
+00008aa0: 2043 6861 7261 6374 6572 7374 6963 7320   Characterstics 
+00008ab0: 2323 230a 2020 2020 2020 2020 2020 2020  ###.            
+00008ac0: 2020 2020 2020 2020 6669 6c74 6572 5f31          filter_1
+00008ad0: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
+00008ae0: 5f69 6e74 2827 6669 6c74 6572 5f31 272c  _int('filter_1',
+00008af0: 2031 322c 2035 3136 2c20 7374 6570 3d31   12, 516, step=1
+00008b00: 3229 0a20 2020 2020 2020 2020 2020 2020  2).             
+00008b10: 2020 2020 2020 2066 696c 7465 725f 7369         filter_si
+00008b20: 7a65 5f31 203d 2074 7269 616c 2e73 7567  ze_1 = trial.sug
+00008b30: 6765 7374 5f69 6e74 2827 6669 6c74 6572  gest_int('filter
+00008b40: 5f73 697a 655f 3127 2c20 312c 2031 312c  _size_1', 1, 11,
+00008b50: 2073 7465 703d 3229 0a20 2020 2020 2020   step=2).       
+00008b60: 2020 2020 2020 2020 2020 2020 2073 7472               str
+00008b70: 6964 6573 5f31 203d 2074 7269 616c 2e73  ides_1 = trial.s
+00008b80: 7567 6765 7374 5f69 6e74 2827 7374 7269  uggest_int('stri
+00008b90: 6465 735f 3127 2c20 312c 2033 2c20 7374  des_1', 1, 3, st
+00008ba0: 6570 3d31 290a 2020 2020 2020 2020 2020  ep=1).          
+00008bb0: 2020 2020 2020 2020 2020 706f 6f6c 5f73            pool_s
+00008bc0: 697a 655f 3120 3d20 7472 6961 6c2e 7375  ize_1 = trial.su
+00008bd0: 6767 6573 745f 696e 7428 2770 6f6f 6c5f  ggest_int('pool_
+00008be0: 7369 7a65 5f31 272c 2031 2c20 372c 2073  size_1', 1, 7, s
+00008bf0: 7465 703d 3129 0a20 2020 2020 2020 2020  tep=1).         
+00008c00: 2020 2020 2020 2020 2020 2070 6f6f 6c5f             pool_
+00008c10: 7374 7269 6465 5f31 203d 2074 7269 616c  stride_1 = trial
+00008c20: 2e73 7567 6765 7374 5f69 6e74 2827 706f  .suggest_int('po
+00008c30: 6f6c 5f73 7472 6964 655f 3127 2c20 312c  ol_stride_1', 1,
+00008c40: 2033 2c20 7374 6570 3d31 290a 0a20 2020   3, step=1)..   
+00008c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008c60: 2066 696c 7465 725f 3220 3d20 7472 6961   filter_2 = tria
+00008c70: 6c2e 7375 6767 6573 745f 696e 7428 2766  l.suggest_int('f
+00008c80: 696c 7465 725f 3227 2c20 3132 2c20 3531  ilter_2', 12, 51
+00008c90: 362c 2073 7465 703d 3132 290a 2020 2020  6, step=12).    
+00008ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008cb0: 6669 6c74 6572 5f73 697a 655f 3220 3d20  filter_size_2 = 
+00008cc0: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
+00008cd0: 7428 2766 696c 7465 725f 7369 7a65 5f32  t('filter_size_2
+00008ce0: 272c 2031 2c20 372c 2073 7465 703d 3229  ', 1, 7, step=2)
+00008cf0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00008d00: 2020 2020 2073 7472 6964 6573 5f32 203d       strides_2 =
+00008d10: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+00008d20: 6e74 2827 7374 7269 6465 735f 3227 2c20  nt('strides_2', 
+00008d30: 312c 2033 2c20 7374 6570 3d31 290a 2020  1, 3, step=1).  
+00008d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008d50: 2020 706f 6f6c 5f73 697a 655f 3220 3d20    pool_size_2 = 
+00008d60: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
+00008d70: 7428 2770 6f6f 6c5f 7369 7a65 5f32 272c  t('pool_size_2',
+00008d80: 2031 2c20 372c 2073 7465 703d 3129 0a20   1, 7, step=1). 
+00008d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008da0: 2020 2070 6f6f 6c5f 7374 7269 6465 5f32     pool_stride_2
+00008db0: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
+00008dc0: 5f69 6e74 2827 706f 6f6c 5f73 7472 6964  _int('pool_strid
+00008dd0: 655f 3227 2c20 312c 2033 2c20 7374 6570  e_2', 1, 3, step
+00008de0: 3d31 290a 0a20 2020 2020 2020 2020 2020  =1)..           
+00008df0: 2020 2020 2020 2020 2066 696c 7465 725f           filter_
+00008e00: 3320 3d20 7472 6961 6c2e 7375 6767 6573  3 = trial.sugges
+00008e10: 745f 696e 7428 2766 696c 7465 725f 3327  t_int('filter_3'
+00008e20: 2c20 3132 2c20 3531 362c 2073 7465 703d  , 12, 516, step=
+00008e30: 3132 290a 2020 2020 2020 2020 2020 2020  12).            
+00008e40: 2020 2020 2020 2020 6669 6c74 6572 5f73          filter_s
+00008e50: 697a 655f 3320 3d20 7472 6961 6c2e 7375  ize_3 = trial.su
+00008e60: 6767 6573 745f 696e 7428 2766 696c 7465  ggest_int('filte
+00008e70: 725f 7369 7a65 5f33 272c 2031 2c20 372c  r_size_3', 1, 7,
+00008e80: 2073 7465 703d 3229 0a20 2020 2020 2020   step=2).       
+00008e90: 2020 2020 2020 2020 2020 2020 2073 7472               str
+00008ea0: 6964 6573 5f33 203d 2074 7269 616c 2e73  ides_3 = trial.s
+00008eb0: 7567 6765 7374 5f69 6e74 2827 7374 7269  uggest_int('stri
+00008ec0: 6465 735f 3327 2c20 312c 2033 2c20 7374  des_3', 1, 3, st
+00008ed0: 6570 3d31 290a 2020 2020 2020 2020 2020  ep=1).          
+00008ee0: 2020 2020 2020 2020 2020 706f 6f6c 5f73            pool_s
+00008ef0: 697a 655f 3320 3d20 7472 6961 6c2e 7375  ize_3 = trial.su
+00008f00: 6767 6573 745f 696e 7428 2770 6f6f 6c5f  ggest_int('pool_
+00008f10: 7369 7a65 5f33 272c 2031 2c20 372c 2073  size_3', 1, 7, s
+00008f20: 7465 703d 3129 0a20 2020 2020 2020 2020  tep=1).         
+00008f30: 2020 2020 2020 2020 2020 2070 6f6f 6c5f             pool_
+00008f40: 7374 7269 6465 5f33 203d 2074 7269 616c  stride_3 = trial
+00008f50: 2e73 7567 6765 7374 5f69 6e74 2827 706f  .suggest_int('po
+00008f60: 6f6c 5f73 7472 6964 655f 3327 2c20 312c  ol_stride_3', 1,
+00008f70: 2033 2c20 7374 6570 3d31 290a 0a20 2020   3, step=1)..   
+00008f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008f90: 2066 696c 7465 725f 3420 3d20 7472 6961   filter_4 = tria
+00008fa0: 6c2e 7375 6767 6573 745f 696e 7428 2766  l.suggest_int('f
+00008fb0: 696c 7465 725f 3427 2c20 3132 2c20 3531  ilter_4', 12, 51
+00008fc0: 362c 2073 7465 703d 3132 290a 2020 2020  6, step=12).    
+00008fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008fe0: 6669 6c74 6572 5f73 697a 655f 3420 3d20  filter_size_4 = 
+00008ff0: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
+00009000: 7428 2766 696c 7465 725f 7369 7a65 5f34  t('filter_size_4
+00009010: 272c 2031 2c20 372c 2073 7465 703d 3229  ', 1, 7, step=2)
+00009020: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00009030: 2020 2020 2073 7472 6964 6573 5f34 203d       strides_4 =
+00009040: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+00009050: 6e74 2827 7374 7269 6465 735f 3427 2c20  nt('strides_4', 
+00009060: 312c 2033 2c20 7374 6570 3d31 290a 0a20  1, 3, step=1).. 
+00009070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009080: 2020 2066 696c 7465 725f 3520 3d20 7472     filter_5 = tr
+00009090: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
+000090a0: 2766 696c 7465 725f 3527 2c20 3132 2c20  'filter_5', 12, 
+000090b0: 3531 362c 2073 7465 703d 3132 290a 2020  516, step=12).  
+000090c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000090d0: 2020 6669 6c74 6572 5f73 697a 655f 3520    filter_size_5 
+000090e0: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+000090f0: 696e 7428 2766 696c 7465 725f 7369 7a65  int('filter_size
+00009100: 5f35 272c 2031 2c20 372c 2073 7465 703d  _5', 1, 7, step=
+00009110: 3229 0a20 2020 2020 2020 2020 2020 2020  2).             
+00009120: 2020 2020 2020 2073 7472 6964 6573 5f35         strides_5
+00009130: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
+00009140: 5f69 6e74 2827 7374 7269 6465 735f 3527  _int('strides_5'
+00009150: 2c20 312c 2033 2c20 7374 6570 3d31 2920  , 1, 3, step=1) 
+00009160: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00009170: 2020 2020 2020 2323 2320 4465 6e73 6520        ### Dense 
+00009180: 4c61 7965 7273 2023 2323 0a20 2020 2020  Layers ###.     
+00009190: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+000091a0: 656e 7365 5f6e 6575 726f 6e73 5f31 203d  ense_neurons_1 =
+000091b0: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+000091c0: 6e74 2827 6465 6e73 655f 6e65 7572 6f6e  nt('dense_neuron
+000091d0: 735f 3127 2c20 3132 382c 2036 3430 302c  s_1', 128, 6400,
+000091e0: 2073 7465 703d 3132 3829 0a20 2020 2020   step=128).     
+000091f0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00009200: 656e 7365 5f6e 6575 726f 6e73 5f32 203d  ense_neurons_2 =
+00009210: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+00009220: 6e74 2827 6465 6e73 655f 6e65 7572 6f6e  nt('dense_neuron
+00009230: 735f 3227 2c20 3132 382c 2036 3430 302c  s_2', 128, 6400,
+00009240: 2073 7465 703d 3132 3829 0a20 2020 2020   step=128).     
+00009250: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00009260: 726f 706f 7574 5f31 203d 2074 7269 616c  ropout_1 = trial
+00009270: 2e73 7567 6765 7374 5f66 6c6f 6174 2827  .suggest_float('
+00009280: 6472 6f70 6f75 745f 3127 2c20 302e 302c  dropout_1', 0.0,
+00009290: 2030 2e35 2c20 7374 6570 3d30 2e30 3129   0.5, step=0.01)
+000092a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000092b0: 2020 2020 2064 726f 706f 7574 5f32 203d       dropout_2 =
+000092c0: 2074 7269 616c 2e73 7567 6765 7374 5f66   trial.suggest_f
+000092d0: 6c6f 6174 2827 6472 6f70 6f75 745f 3227  loat('dropout_2'
+000092e0: 2c20 302e 302c 2030 2e35 2c20 7374 6570  , 0.0, 0.5, step
+000092f0: 3d30 2e30 3129 200a 0a20 2020 2020 2020  =0.01) ..       
+00009300: 2020 2020 2020 2020 2020 2020 206d 6f64               mod
+00009310: 656c 2c20 6869 7374 6f72 7920 3d20 636e  el, history = cn
+00009320: 6e5f 6d6f 6465 6c2e 416c 6578 4e65 7428  n_model.AlexNet(
+00009330: 636c 6173 735f 312c 2063 6c61 7373 5f32  class_1, class_2
+00009340: 2c20 696d 675f 6e75 6d5f 6368 616e 6e65  , img_num_channe
+00009350: 6c73 3d73 656c 662e 696d 675f 6e75 6d5f  ls=self.img_num_
+00009360: 6368 616e 6e65 6c73 2c20 0a20 2020 2020  channels, .     
+00009370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009380: 2020 206e 6f72 6d61 6c69 7a65 3d73 656c     normalize=sel
+00009390: 662e 6e6f 726d 616c 697a 652c 206d 696e  f.normalize, min
+000093a0: 5f70 6978 656c 3d6d 696e 5f70 6978 2c20  _pixel=min_pix, 
+000093b0: 6d61 785f 7069 7865 6c3d 6d61 785f 7069  max_pixel=max_pi
+000093c0: 782c 2076 616c 5f70 6f73 6974 6976 653d  x, val_positive=
+000093d0: 7661 6c5f 636c 6173 735f 312c 2076 616c  val_class_1, val
+000093e0: 5f6e 6567 6174 6976 653d 7661 6c5f 636c  _negative=val_cl
+000093f0: 6173 735f 322c 200a 2020 2020 2020 2020  ass_2, .        
+00009400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009410: 6570 6f63 6873 3d73 656c 662e 7472 6169  epochs=self.trai
+00009420: 6e5f 6570 6f63 6873 2c20 6261 7463 685f  n_epochs, batch_
+00009430: 7369 7a65 3d62 6174 6368 5f73 697a 652c  size=batch_size,
+00009440: 206f 7074 696d 697a 6572 3d6f 7074 696d   optimizer=optim
+00009450: 697a 6572 2c20 6c72 3d6c 722c 2064 6563  izer, lr=lr, dec
+00009460: 6179 3d64 6563 6179 2c20 6d6f 6d65 6e74  ay=decay, moment
+00009470: 756d 3d6d 6f6d 656e 7475 6d2c 206e 6573  um=momentum, nes
+00009480: 7465 726f 763d 6e65 7374 6572 6f76 2c20  terov=nesterov, 
+00009490: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000094a0: 2020 2020 2020 2020 2062 6574 615f 313d           beta_1=
+000094b0: 6265 7461 5f31 2c20 6265 7461 5f32 3d62  beta_1, beta_2=b
+000094c0: 6574 615f 322c 2061 6d73 6772 6164 3d61  eta_2, amsgrad=a
+000094d0: 6d73 6772 6164 2c20 6c6f 7373 3d6c 6f73  msgrad, loss=los
+000094e0: 732c 2061 6374 6976 6174 696f 6e5f 636f  s, activation_co
+000094f0: 6e76 3d61 6374 6976 6174 696f 6e5f 636f  nv=activation_co
+00009500: 6e76 2c20 6163 7469 7661 7469 6f6e 5f64  nv, activation_d
+00009510: 656e 7365 3d61 6374 6976 6174 696f 6e5f  ense=activation_
+00009520: 6465 6e73 652c 200a 2020 2020 2020 2020  dense, .        
+00009530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009540: 636f 6e76 5f69 6e69 743d 636f 6e76 5f69  conv_init=conv_i
+00009550: 6e69 742c 2064 656e 7365 5f69 6e69 743d  nit, dense_init=
+00009560: 6465 6e73 655f 696e 6974 2c20 6d6f 6465  dense_init, mode
+00009570: 6c5f 7265 673d 6d6f 6465 6c5f 7265 672c  l_reg=model_reg,
+00009580: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+00009590: 2020 2020 2020 2020 2020 6669 6c74 6572            filter
+000095a0: 5f31 3d66 696c 7465 725f 312c 2066 696c  _1=filter_1, fil
+000095b0: 7465 725f 7369 7a65 5f31 3d66 696c 7465  ter_size_1=filte
+000095c0: 725f 7369 7a65 5f31 2c20 7374 7269 6465  r_size_1, stride
+000095d0: 735f 313d 7374 7269 6465 735f 312c 2070  s_1=strides_1, p
+000095e0: 6f6f 6c69 6e67 5f31 3d70 6f6f 6c69 6e67  ooling_1=pooling
+000095f0: 5f31 2c20 706f 6f6c 5f73 697a 655f 313d  _1, pool_size_1=
+00009600: 706f 6f6c 5f73 697a 655f 312c 2070 6f6f  pool_size_1, poo
+00009610: 6c5f 7374 7269 6465 5f31 3d70 6f6f 6c5f  l_stride_1=pool_
+00009620: 7374 7269 6465 5f31 2c0a 2020 2020 2020  stride_1,.      
+00009630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009640: 2020 6669 6c74 6572 5f32 3d66 696c 7465    filter_2=filte
+00009650: 725f 322c 2066 696c 7465 725f 7369 7a65  r_2, filter_size
+00009660: 5f32 3d66 696c 7465 725f 7369 7a65 5f32  _2=filter_size_2
+00009670: 2c20 7374 7269 6465 735f 323d 7374 7269  , strides_2=stri
+00009680: 6465 735f 322c 2070 6f6f 6c69 6e67 5f32  des_2, pooling_2
+00009690: 3d70 6f6f 6c69 6e67 5f32 2c20 706f 6f6c  =pooling_2, pool
+000096a0: 5f73 697a 655f 323d 706f 6f6c 5f73 697a  _size_2=pool_siz
+000096b0: 655f 322c 2070 6f6f 6c5f 7374 7269 6465  e_2, pool_stride
+000096c0: 5f32 3d70 6f6f 6c5f 7374 7269 6465 5f32  _2=pool_stride_2
+000096d0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000096e0: 2020 2020 2020 2020 2020 6669 6c74 6572            filter
+000096f0: 5f33 3d66 696c 7465 725f 332c 2066 696c  _3=filter_3, fil
+00009700: 7465 725f 7369 7a65 5f33 3d66 696c 7465  ter_size_3=filte
+00009710: 725f 7369 7a65 5f33 2c20 7374 7269 6465  r_size_3, stride
+00009720: 735f 333d 7374 7269 6465 735f 332c 2070  s_3=strides_3, p
+00009730: 6f6f 6c69 6e67 5f33 3d70 6f6f 6c69 6e67  ooling_3=pooling
+00009740: 5f33 2c20 706f 6f6c 5f73 697a 655f 333d  _3, pool_size_3=
+00009750: 706f 6f6c 5f73 697a 655f 332c 2070 6f6f  pool_size_3, poo
+00009760: 6c5f 7374 7269 6465 5f33 3d70 6f6f 6c5f  l_stride_3=pool_
+00009770: 7374 7269 6465 5f33 2c0a 2020 2020 2020  stride_3,.      
+00009780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009790: 2020 6669 6c74 6572 5f34 3d66 696c 7465    filter_4=filte
+000097a0: 725f 342c 2066 696c 7465 725f 7369 7a65  r_4, filter_size
+000097b0: 5f34 3d66 696c 7465 725f 7369 7a65 5f34  _4=filter_size_4
+000097c0: 2c20 7374 7269 6465 735f 343d 7374 7269  , strides_4=stri
+000097d0: 6465 735f 342c 200a 2020 2020 2020 2020  des_4, .        
+000097e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000097f0: 6669 6c74 6572 5f35 3d66 696c 7465 725f  filter_5=filter_
+00009800: 352c 2066 696c 7465 725f 7369 7a65 5f35  5, filter_size_5
+00009810: 3d66 696c 7465 725f 7369 7a65 5f35 2c20  =filter_size_5, 
+00009820: 7374 7269 6465 735f 353d 7374 7269 6465  strides_5=stride
+00009830: 735f 352c 0a20 2020 2020 2020 2020 2020  s_5,.           
+00009840: 2020 2020 2020 2020 2020 2020 2064 656e               den
+00009850: 7365 5f6e 6575 726f 6e73 5f31 3d64 656e  se_neurons_1=den
+00009860: 7365 5f6e 6575 726f 6e73 5f31 2c20 6465  se_neurons_1, de
+00009870: 6e73 655f 6e65 7572 6f6e 735f 323d 6465  nse_neurons_2=de
+00009880: 6e73 655f 6e65 7572 6f6e 735f 322c 2064  nse_neurons_2, d
+00009890: 726f 706f 7574 5f31 3d64 726f 706f 7574  ropout_1=dropout
+000098a0: 5f31 2c20 6472 6f70 6f75 745f 323d 6472  _1, dropout_2=dr
+000098b0: 6f70 6f75 745f 322c 200a 2020 2020 2020  opout_2, .      
+000098c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000098d0: 2020 736d 6f74 655f 7361 6d70 6c69 6e67    smote_sampling
+000098e0: 3d73 656c 662e 736d 6f74 655f 7361 6d70  =self.smote_samp
+000098f0: 6c69 6e67 2c20 6561 726c 795f 7374 6f70  ling, early_stop
+00009900: 5f63 616c 6c62 6163 6b3d 6361 6c6c 6261  _callback=callba
+00009910: 636b 732c 2063 6865 636b 706f 696e 743d  cks, checkpoint=
+00009920: 4661 6c73 652c 2076 6572 626f 7365 3d73  False, verbose=s
+00009930: 656c 662e 7665 7262 6f73 6529 0a0a 2020  elf.verbose)..  
+00009940: 2020 2020 2020 2020 2020 656c 6966 2073            elif s
+00009950: 656c 662e 636c 6620 3d3d 2027 7265 736e  elf.clf == 'resn
+00009960: 6574 3138 273a 0a0a 2020 2020 2020 2020  et18':..        
+00009970: 2020 2020 2020 2020 2323 2320 5265 6775          ### Regu
+00009980: 6c61 7269 7a61 7469 6f6e 2054 6563 686e  larization Techn
+00009990: 6971 7565 2028 4e6f 7465 2074 6861 7420  ique (Note that 
+000099a0: 6966 2075 7369 6e67 204c 524e 2c20 7468  if using LRN, th
+000099b0: 656e 2074 6865 2062 6c6f 636b 7320 776f  en the blocks wo
+000099c0: 6e27 7420 6861 7665 2041 4e59 2072 6567  n't have ANY reg
+000099d0: 756c 6172 697a 6174 696f 6e20 7369 6e63  ularization sinc
+000099e0: 6520 7468 6520 6f6e 6c79 206f 7074 696f  e the only optio
+000099f0: 6e20 6973 2027 6261 7463 685f 6e6f 726d  n is 'batch_norm
+00009a00: 2720 666f 7220 7468 6520 626c 6f63 6b73  ' for the blocks
+00009a10: 2920 2323 230a 2020 2020 2020 2020 2020  ) ###.          
+00009a20: 2020 2020 2020 6d6f 6465 6c5f 7265 6720        model_reg 
+00009a30: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+00009a40: 6361 7465 676f 7269 6361 6c28 276d 6f64  categorical('mod
+00009a50: 656c 5f72 6567 272c 205b 4e6f 6e65 2c20  el_reg', [None, 
+00009a60: 276c 6f63 616c 5f72 6573 706f 6e73 6527  'local_response'
+00009a70: 2c20 2762 6174 6368 5f6e 6f72 6d27 5d29  , 'batch_norm'])
+00009a80: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00009a90: 2020 234f 6e6c 7920 6f6e 6520 706f 6f6c    #Only one pool
+00009aa0: 696e 6720 6c61 7965 7220 6973 2075 7365  ing layer is use
+00009ab0: 6420 6174 2074 6865 2076 6572 7920 6265  d at the very be
+00009ac0: 6769 6e6e 696e 6720 6f66 2074 6865 206d  ginning of the m
+00009ad0: 6f64 656c 0a20 2020 2020 2020 2020 2020  odel.           
+00009ae0: 2020 2020 2070 6f6f 6c69 6e67 203d 2074       pooling = t
+00009af0: 7269 616c 2e73 7567 6765 7374 5f63 6174  rial.suggest_cat
+00009b00: 6567 6f72 6963 616c 2827 706f 6f6c 696e  egorical('poolin
+00009b10: 6727 2c20 5b27 6d69 6e27 2c20 276d 6178  g', ['min', 'max
+00009b20: 272c 2027 6176 6572 6167 6527 5d29 0a0a  ', 'average'])..
+00009b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009b40: 6966 2073 656c 662e 6c69 6d69 745f 7365  if self.limit_se
+00009b50: 6172 6368 3a20 2020 0a0a 2020 2020 2020  arch:   ..      
+00009b60: 2020 2020 2020 2020 2020 2020 2020 6d6f                mo
+00009b70: 6465 6c2c 2068 6973 746f 7279 203d 2063  del, history = c
+00009b80: 6e6e 5f6d 6f64 656c 2e52 6573 6e65 7431  nn_model.Resnet1
+00009b90: 3828 636c 6173 735f 312c 2063 6c61 7373  8(class_1, class
+00009ba0: 5f32 2c20 696d 675f 6e75 6d5f 6368 616e  _2, img_num_chan
+00009bb0: 6e65 6c73 3d73 656c 662e 696d 675f 6e75  nels=self.img_nu
+00009bc0: 6d5f 6368 616e 6e65 6c73 2c20 0a20 2020  m_channels, .   
+00009bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009be0: 2020 2020 206e 6f72 6d61 6c69 7a65 3d73       normalize=s
+00009bf0: 656c 662e 6e6f 726d 616c 697a 652c 206d  elf.normalize, m
+00009c00: 696e 5f70 6978 656c 3d6d 696e 5f70 6978  in_pixel=min_pix
+00009c10: 2c20 6d61 785f 7069 7865 6c3d 6d61 785f  , max_pixel=max_
+00009c20: 7069 782c 2076 616c 5f70 6f73 6974 6976  pix, val_positiv
+00009c30: 653d 7661 6c5f 636c 6173 735f 312c 2076  e=val_class_1, v
+00009c40: 616c 5f6e 6567 6174 6976 653d 7661 6c5f  al_negative=val_
+00009c50: 636c 6173 735f 322c 200a 2020 2020 2020  class_2, .      
+00009c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009c70: 2020 6570 6f63 6873 3d73 656c 662e 7472    epochs=self.tr
+00009c80: 6169 6e5f 6570 6f63 6873 2c20 6261 7463  ain_epochs, batc
+00009c90: 685f 7369 7a65 3d62 6174 6368 5f73 697a  h_size=batch_siz
+00009ca0: 652c 206f 7074 696d 697a 6572 3d6f 7074  e, optimizer=opt
+00009cb0: 696d 697a 6572 2c20 6c72 3d6c 722c 2064  imizer, lr=lr, d
+00009cc0: 6563 6179 3d64 6563 6179 2c20 6d6f 6d65  ecay=decay, mome
+00009cd0: 6e74 756d 3d6d 6f6d 656e 7475 6d2c 206e  ntum=momentum, n
+00009ce0: 6573 7465 726f 763d 6e65 7374 6572 6f76  esterov=nesterov
+00009cf0: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+00009d00: 2020 2020 2020 2020 2020 2062 6574 615f             beta_
+00009d10: 313d 6265 7461 5f31 2c20 6265 7461 5f32  1=beta_1, beta_2
+00009d20: 3d62 6574 615f 322c 2061 6d73 6772 6164  =beta_2, amsgrad
+00009d30: 3d61 6d73 6772 6164 2c20 6c6f 7373 3d6c  =amsgrad, loss=l
+00009d40: 6f73 732c 2061 6374 6976 6174 696f 6e5f  oss, activation_
+00009d50: 636f 6e76 3d61 6374 6976 6174 696f 6e5f  conv=activation_
+00009d60: 636f 6e76 2c20 6163 7469 7661 7469 6f6e  conv, activation
+00009d70: 5f64 656e 7365 3d61 6374 6976 6174 696f  _dense=activatio
+00009d80: 6e5f 6465 6e73 652c 200a 2020 2020 2020  n_dense, .      
+00009d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009da0: 2020 636f 6e76 5f69 6e69 743d 636f 6e76    conv_init=conv
+00009db0: 5f69 6e69 742c 2064 656e 7365 5f69 6e69  _init, dense_ini
+00009dc0: 743d 6465 6e73 655f 696e 6974 2c20 6d6f  t=dense_init, mo
+00009dd0: 6465 6c5f 7265 673d 6d6f 6465 6c5f 7265  del_reg=model_re
+00009de0: 672c 2070 6f6f 6c69 6e67 3d70 6f6f 6c69  g, pooling=pooli
+00009df0: 6e67 2c0a 2020 2020 2020 2020 2020 2020  ng,.            
+00009e00: 2020 2020 2020 2020 2020 2020 736d 6f74              smot
+00009e10: 655f 7361 6d70 6c69 6e67 3d73 656c 662e  e_sampling=self.
+00009e20: 736d 6f74 655f 7361 6d70 6c69 6e67 2c20  smote_sampling, 
+00009e30: 6561 726c 795f 7374 6f70 5f63 616c 6c62  early_stop_callb
+00009e40: 6163 6b3d 6361 6c6c 6261 636b 732c 2063  ack=callbacks, c
+00009e50: 6865 636b 706f 696e 743d 4661 6c73 652c  heckpoint=False,
+00009e60: 2076 6572 626f 7365 3d73 656c 662e 7665   verbose=self.ve
+00009e70: 7262 6f73 6529 0a20 2020 2020 2020 2020  rbose).         
+00009e80: 2020 2020 2020 2065 6c73 653a 0a0a 2020         else:..  
+00009e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009ea0: 2020 6669 6c74 6572 7320 3d20 7472 6961    filters = tria
+00009eb0: 6c2e 7375 6767 6573 745f 696e 7428 2766  l.suggest_int('f
+00009ec0: 696c 7465 7273 272c 2031 322c 2035 3136  ilters', 12, 516
+00009ed0: 2c20 7374 6570 3d31 3229 0a20 2020 2020  , step=12).     
+00009ee0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00009ef0: 696c 7465 725f 7369 7a65 203d 2074 7269  ilter_size = tri
+00009f00: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
+00009f10: 6669 6c74 6572 5f73 697a 6527 2c20 312c  filter_size', 1,
+00009f20: 2037 2c20 7374 6570 3d32 290a 2020 2020   7, step=2).    
+00009f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009f40: 7374 7269 6465 7320 3d20 7472 6961 6c2e  strides = trial.
+00009f50: 7375 6767 6573 745f 696e 7428 2773 7472  suggest_int('str
+00009f60: 6964 6573 272c 2031 2c20 332c 2073 7465  ides', 1, 3, ste
+00009f70: 703d 3129 0a20 2020 2020 2020 2020 2020  p=1).           
+00009f80: 2020 2020 2020 2020 2070 6f6f 6c5f 7369           pool_si
+00009f90: 7a65 203d 2074 7269 616c 2e73 7567 6765  ze = trial.sugge
+00009fa0: 7374 5f69 6e74 2827 706f 6f6c 5f73 697a  st_int('pool_siz
+00009fb0: 6527 2c20 312c 2037 2c20 7374 6570 3d32  e', 1, 7, step=2
+00009fc0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00009fd0: 2020 2020 2020 706f 6f6c 5f73 7472 6964        pool_strid
+00009fe0: 6520 3d20 7472 6961 6c2e 7375 6767 6573  e = trial.sugges
+00009ff0: 745f 696e 7428 2770 6f6f 6c5f 7374 7269  t_int('pool_stri
+0000a000: 6465 272c 2031 2c20 332c 2073 7465 703d  de', 1, 3, step=
+0000a010: 3129 0a0a 2020 2020 2020 2020 2020 2020  1)..            
+0000a020: 2020 2020 2020 2020 626c 6f63 6b5f 6669          block_fi
+0000a030: 6c74 6572 735f 3120 3d20 7472 6961 6c2e  lters_1 = trial.
+0000a040: 7375 6767 6573 745f 696e 7428 2762 6c6f  suggest_int('blo
+0000a050: 636b 5f66 696c 7465 7273 5f31 272c 2031  ck_filters_1', 1
+0000a060: 322c 2035 3136 2c20 7374 6570 3d31 3229  2, 516, step=12)
+0000a070: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a080: 2020 2020 2062 6c6f 636b 5f66 696c 7465       block_filte
+0000a090: 7273 5f32 203d 2074 7269 616c 2e73 7567  rs_2 = trial.sug
+0000a0a0: 6765 7374 5f69 6e74 2827 626c 6f63 6b5f  gest_int('block_
+0000a0b0: 6669 6c74 6572 735f 3227 2c20 3132 2c20  filters_2', 12, 
+0000a0c0: 3531 362c 2073 7465 703d 3132 2920 0a20  516, step=12) . 
+0000a0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a0e0: 2020 2062 6c6f 636b 5f66 696c 7465 7273     block_filters
+0000a0f0: 5f33 203d 2074 7269 616c 2e73 7567 6765  _3 = trial.sugge
+0000a100: 7374 5f69 6e74 2827 626c 6f63 6b5f 6669  st_int('block_fi
+0000a110: 6c74 6572 735f 3327 2c20 3132 2c20 3531  lters_3', 12, 51
+0000a120: 362c 2073 7465 703d 3132 290a 2020 2020  6, step=12).    
+0000a130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a140: 626c 6f63 6b5f 6669 6c74 6572 735f 3420  block_filters_4 
+0000a150: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+0000a160: 696e 7428 2762 6c6f 636b 5f66 696c 7465  int('block_filte
+0000a170: 7273 5f34 272c 2031 322c 2035 3136 2c20  rs_4', 12, 516, 
+0000a180: 7374 6570 3d31 3229 0a20 2020 2020 2020  step=12).       
+0000a190: 2020 2020 2020 2020 2020 2020 2062 6c6f               blo
+0000a1a0: 636b 5f66 696c 7465 7273 5f73 697a 6520  ck_filters_size 
+0000a1b0: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+0000a1c0: 696e 7428 2762 6c6f 636b 5f66 696c 7465  int('block_filte
+0000a1d0: 7273 5f73 697a 6527 2c20 312c 2037 2c20  rs_size', 1, 7, 
+0000a1e0: 7374 6570 3d32 290a 0a20 2020 2020 2020  step=2)..       
+0000a1f0: 2020 2020 2020 2020 2020 2020 206d 6f64               mod
+0000a200: 656c 2c20 6869 7374 6f72 7920 3d20 636e  el, history = cn
+0000a210: 6e5f 6d6f 6465 6c2e 5265 736e 6574 3138  n_model.Resnet18
+0000a220: 2863 6c61 7373 5f31 2c20 636c 6173 735f  (class_1, class_
+0000a230: 322c 2069 6d67 5f6e 756d 5f63 6861 6e6e  2, img_num_chann
+0000a240: 656c 733d 7365 6c66 2e69 6d67 5f6e 756d  els=self.img_num
+0000a250: 5f63 6861 6e6e 656c 732c 200a 2020 2020  _channels, .    
+0000a260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a270: 2020 2020 6e6f 726d 616c 697a 653d 7365      normalize=se
+0000a280: 6c66 2e6e 6f72 6d61 6c69 7a65 2c20 6d69  lf.normalize, mi
+0000a290: 6e5f 7069 7865 6c3d 6d69 6e5f 7069 782c  n_pixel=min_pix,
+0000a2a0: 206d 6178 5f70 6978 656c 3d6d 6178 5f70   max_pixel=max_p
+0000a2b0: 6978 2c20 7661 6c5f 706f 7369 7469 7665  ix, val_positive
+0000a2c0: 3d76 616c 5f63 6c61 7373 5f31 2c20 7661  =val_class_1, va
+0000a2d0: 6c5f 6e65 6761 7469 7665 3d76 616c 5f63  l_negative=val_c
+0000a2e0: 6c61 7373 5f32 2c20 0a20 2020 2020 2020  lass_2, .       
+0000a2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a300: 2065 706f 6368 733d 7365 6c66 2e74 7261   epochs=self.tra
+0000a310: 696e 5f65 706f 6368 732c 2062 6174 6368  in_epochs, batch
+0000a320: 5f73 697a 653d 6261 7463 685f 7369 7a65  _size=batch_size
+0000a330: 2c20 6f70 7469 6d69 7a65 723d 6f70 7469  , optimizer=opti
+0000a340: 6d69 7a65 722c 206c 723d 6c72 2c20 6465  mizer, lr=lr, de
+0000a350: 6361 793d 6465 6361 792c 206d 6f6d 656e  cay=decay, momen
+0000a360: 7475 6d3d 6d6f 6d65 6e74 756d 2c20 6e65  tum=momentum, ne
+0000a370: 7374 6572 6f76 3d6e 6573 7465 726f 762c  sterov=nesterov,
+0000a380: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+0000a390: 2020 2020 2020 2020 2020 6265 7461 5f31            beta_1
+0000a3a0: 3d62 6574 615f 312c 2062 6574 615f 323d  =beta_1, beta_2=
+0000a3b0: 6265 7461 5f32 2c20 616d 7367 7261 643d  beta_2, amsgrad=
+0000a3c0: 616d 7367 7261 642c 206c 6f73 733d 6c6f  amsgrad, loss=lo
+0000a3d0: 7373 2c20 6163 7469 7661 7469 6f6e 5f63  ss, activation_c
+0000a3e0: 6f6e 763d 6163 7469 7661 7469 6f6e 5f63  onv=activation_c
+0000a3f0: 6f6e 762c 2061 6374 6976 6174 696f 6e5f  onv, activation_
+0000a400: 6465 6e73 653d 6163 7469 7661 7469 6f6e  dense=activation
+0000a410: 5f64 656e 7365 2c20 0a20 2020 2020 2020  _dense, .       
+0000a420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a430: 2063 6f6e 765f 696e 6974 3d63 6f6e 765f   conv_init=conv_
+0000a440: 696e 6974 2c20 6465 6e73 655f 696e 6974  init, dense_init
+0000a450: 3d64 656e 7365 5f69 6e69 742c 206d 6f64  =dense_init, mod
+0000a460: 656c 5f72 6567 3d6d 6f64 656c 5f72 6567  el_reg=model_reg
+0000a470: 2c20 6669 6c74 6572 733d 6669 6c74 6572  , filters=filter
+0000a480: 732c 2066 696c 7465 725f 7369 7a65 3d66  s, filter_size=f
+0000a490: 696c 7465 725f 7369 7a65 2c20 7374 7269  ilter_size, stri
+0000a4a0: 6465 733d 7374 7269 6465 732c 2020 0a20  des=strides,  . 
+0000a4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a4c0: 2020 2020 2020 2070 6f6f 6c69 6e67 3d70         pooling=p
+0000a4d0: 6f6f 6c69 6e67 2c20 706f 6f6c 5f73 697a  ooling, pool_siz
+0000a4e0: 653d 706f 6f6c 5f73 697a 652c 2070 6f6f  e=pool_size, poo
+0000a4f0: 6c5f 7374 7269 6465 3d70 6f6f 6c5f 7374  l_stride=pool_st
+0000a500: 7269 6465 2c20 626c 6f63 6b5f 6669 6c74  ride, block_filt
+0000a510: 6572 735f 313d 626c 6f63 6b5f 6669 6c74  ers_1=block_filt
+0000a520: 6572 735f 312c 2062 6c6f 636b 5f66 696c  ers_1, block_fil
+0000a530: 7465 7273 5f32 3d62 6c6f 636b 5f66 696c  ters_2=block_fil
+0000a540: 7465 7273 5f32 2c20 0a20 2020 2020 2020  ters_2, .       
+0000a550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a560: 2062 6c6f 636b 5f66 696c 7465 7273 5f33   block_filters_3
+0000a570: 3d62 6c6f 636b 5f66 696c 7465 7273 5f33  =block_filters_3
+0000a580: 2c20 626c 6f63 6b5f 6669 6c74 6572 735f  , block_filters_
+0000a590: 343d 626c 6f63 6b5f 6669 6c74 6572 735f  4=block_filters_
+0000a5a0: 342c 2062 6c6f 636b 5f66 696c 7465 7273  4, block_filters
+0000a5b0: 5f73 697a 653d 626c 6f63 6b5f 6669 6c74  _size=block_filt
+0000a5c0: 6572 735f 7369 7a65 2c20 0a20 2020 2020  ers_size, .     
+0000a5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a5e0: 2020 2073 6d6f 7465 5f73 616d 706c 696e     smote_samplin
+0000a5f0: 673d 7365 6c66 2e73 6d6f 7465 5f73 616d  g=self.smote_sam
+0000a600: 706c 696e 672c 2065 6172 6c79 5f73 746f  pling, early_sto
+0000a610: 705f 6361 6c6c 6261 636b 3d63 616c 6c62  p_callback=callb
+0000a620: 6163 6b73 2c20 6368 6563 6b70 6f69 6e74  acks, checkpoint
+0000a630: 3d46 616c 7365 2c20 7665 7262 6f73 653d  =False, verbose=
+0000a640: 7365 6c66 2e76 6572 626f 7365 290a 0a20  self.verbose).. 
+0000a650: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+0000a660: 7365 6c66 2e63 6c66 203d 3d20 2763 7573  self.clf == 'cus
+0000a670: 746f 6d5f 636e 6e27 3a0a 2020 2020 2020  tom_cnn':.      
+0000a680: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+0000a690: 662e 6c69 6d69 745f 7365 6172 6368 3a0a  f.limit_search:.
+0000a6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a6b0: 2020 2020 7072 696e 7428 2754 6865 7265      print('There
+0000a6c0: 2069 7320 6e6f 206c 696d 6974 5f73 6561   is no limit_sea
+0000a6d0: 7263 6820 6f70 7469 6f6e 2069 6620 636c  rch option if cl
+0000a6e0: 663d 2263 7573 746f 6d5f 636e 6e22 2c20  f="custom_cnn", 
+0000a6f0: 6f70 7469 6d69 7a69 6e67 2061 6c6c 206c  optimizing all l
+0000a700: 6179 6572 732e 2e2e 2729 0a0a 2020 2020  ayers...')..    
+0000a710: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
+0000a720: 6c5f 7265 6720 3d20 7472 6961 6c2e 7375  l_reg = trial.su
+0000a730: 6767 6573 745f 6361 7465 676f 7269 6361  ggest_categorica
+0000a740: 6c28 276d 6f64 656c 5f72 6567 272c 205b  l('model_reg', [
+0000a750: 4e6f 6e65 2c20 276c 6f63 616c 5f72 6573  None, 'local_res
+0000a760: 706f 6e73 6527 2c20 2762 6174 6368 5f6e  ponse', 'batch_n
+0000a770: 6f72 6d27 5d29 0a20 2020 2020 2020 2020  orm']).         
+0000a780: 2020 2020 2020 2023 4375 7374 6f6d 2043         #Custom C
+0000a790: 4e4e 2066 756e 6374 696f 6e2c 2074 6865  NN function, the
+0000a7a0: 2066 6972 7374 2043 4f4e 5620 6c61 7965   first CONV laye
+0000a7b0: 7220 6973 2072 6571 7569 7265 642e 200a  r is required. .
+0000a7c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a7d0: 6669 6c74 6572 5f31 203d 2074 7269 616c  filter_1 = trial
+0000a7e0: 2e73 7567 6765 7374 5f69 6e74 2827 6669  .suggest_int('fi
+0000a7f0: 6c74 6572 5f31 272c 2031 322c 2035 3136  lter_1', 12, 516
+0000a800: 2c20 7374 6570 3d31 3229 0a20 2020 2020  , step=12).     
+0000a810: 2020 2020 2020 2020 2020 2066 696c 7465             filte
+0000a820: 725f 7369 7a65 5f31 203d 2074 7269 616c  r_size_1 = trial
+0000a830: 2e73 7567 6765 7374 5f69 6e74 2827 6669  .suggest_int('fi
+0000a840: 6c74 6572 5f73 697a 655f 3127 2c20 312c  lter_size_1', 1,
+0000a850: 2031 312c 2073 7465 703d 3229 0a20 2020   11, step=2).   
+0000a860: 2020 2020 2020 2020 2020 2020 2070 6f6f               poo
+0000a870: 6c69 6e67 5f31 203d 2074 7269 616c 2e73  ling_1 = trial.s
+0000a880: 7567 6765 7374 5f63 6174 6567 6f72 6963  uggest_categoric
+0000a890: 616c 2827 706f 6f6c 696e 675f 3127 2c20  al('pooling_1', 
+0000a8a0: 5b27 6d69 6e27 2c20 276d 6178 272c 2027  ['min', 'max', '
+0000a8b0: 6176 6572 6167 6527 5d29 0a20 2020 2020  average']).     
+0000a8c0: 2020 2020 2020 2020 2020 2070 6f6f 6c5f             pool_
+0000a8d0: 7369 7a65 5f31 203d 2074 7269 616c 2e73  size_1 = trial.s
+0000a8e0: 7567 6765 7374 5f69 6e74 2827 706f 6f6c  uggest_int('pool
+0000a8f0: 5f73 697a 655f 3127 2c20 312c 2037 2c20  _size_1', 1, 7, 
+0000a900: 7374 6570 3d31 290a 2020 2020 2020 2020  step=1).        
+0000a910: 2020 2020 2020 2020 7374 7269 6465 735f          strides_
+0000a920: 3120 3d20 706f 6f6c 5f73 7472 6964 655f  1 = pool_stride_
+0000a930: 3120 3d20 7374 7269 6465 735f 3220 3d20  1 = strides_2 = 
+0000a940: 706f 6f6c 5f73 7472 6964 655f 3220 3d20  pool_stride_2 = 
+0000a950: 7374 7269 6465 735f 3320 3d20 706f 6f6c  strides_3 = pool
+0000a960: 5f73 7472 6964 655f 3320 3d20 310a 0a20  _stride_3 = 1.. 
+0000a970: 2020 2020 2020 2020 2020 2020 2020 206e                 n
+0000a980: 756d 5f63 6f6e 765f 6c61 7965 7273 203d  um_conv_layers =
+0000a990: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+0000a9a0: 6e74 2827 6e75 6d5f 636f 6e76 5f6c 6179  nt('num_conv_lay
+0000a9b0: 6572 7327 2c20 312c 2033 2c20 7374 6570  ers', 1, 3, step
+0000a9c0: 3d31 290a 0a20 2020 2020 2020 2020 2020  =1)..           
+0000a9d0: 2020 2020 2069 6620 6e75 6d5f 636f 6e76       if num_conv
+0000a9e0: 5f6c 6179 6572 7320 3d3d 2031 3a0a 2020  _layers == 1:.  
 0000a9f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000aa00: 6265 7461 5f31 3d62 6574 615f 312c 2062  beta_1=beta_1, b
-0000aa10: 6574 615f 323d 6265 7461 5f32 2c20 616d  eta_2=beta_2, am
-0000aa20: 7367 7261 643d 616d 7367 7261 642c 206c  sgrad=amsgrad, l
-0000aa30: 6f73 733d 6c6f 7373 2c20 6163 7469 7661  oss=loss, activa
-0000aa40: 7469 6f6e 5f63 6f6e 763d 6163 7469 7661  tion_conv=activa
-0000aa50: 7469 6f6e 5f63 6f6e 762c 2061 6374 6976  tion_conv, activ
-0000aa60: 6174 696f 6e5f 6465 6e73 653d 6163 7469  ation_dense=acti
-0000aa70: 7661 7469 6f6e 5f64 656e 7365 2c20 0a20  vation_dense, . 
+0000aa00: 2020 6669 6c74 6572 5f32 203d 2066 696c    filter_2 = fil
+0000aa10: 7465 725f 7369 7a65 5f32 203d 2070 6f6f  ter_size_2 = poo
+0000aa20: 6c5f 7369 7a65 5f32 203d 2066 696c 7465  l_size_2 = filte
+0000aa30: 725f 3320 3d20 6669 6c74 6572 5f73 697a  r_3 = filter_siz
+0000aa40: 655f 3320 3d20 7374 7269 6465 735f 3320  e_3 = strides_3 
+0000aa50: 3d20 706f 6f6c 5f73 697a 655f 3320 3d20  = pool_size_3 = 
+0000aa60: 303b 2070 6f6f 6c69 6e67 5f32 203d 2070  0; pooling_2 = p
+0000aa70: 6f6f 6c69 6e67 5f33 203d 204e 6f6e 650a  ooling_3 = None.
 0000aa80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000aa90: 2020 2020 2020 2063 6f6e 765f 696e 6974         conv_init
-0000aaa0: 3d63 6f6e 765f 696e 6974 2c20 6465 6e73  =conv_init, dens
-0000aab0: 655f 696e 6974 3d64 656e 7365 5f69 6e69  e_init=dense_ini
-0000aac0: 742c 206d 6f64 656c 5f72 6567 3d6d 6f64  t, model_reg=mod
-0000aad0: 656c 5f72 6567 2c0a 2020 2020 2020 2020  el_reg,.        
-0000aae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000aaf0: 706f 6f6c 696e 675f 313d 706f 6f6c 696e  pooling_1=poolin
-0000ab00: 675f 312c 2070 6f6f 6c69 6e67 5f32 3d70  g_1, pooling_2=p
-0000ab10: 6f6f 6c69 6e67 5f32 2c20 706f 6f6c 696e  ooling_2, poolin
-0000ab20: 675f 333d 706f 6f6c 696e 675f 332c 2070  g_3=pooling_3, p
-0000ab30: 6f6f 6c69 6e67 5f34 3d70 6f6f 6c69 6e67  ooling_4=pooling
-0000ab40: 5f34 2c20 706f 6f6c 696e 675f 353d 706f  _4, pooling_5=po
-0000ab50: 6f6c 696e 675f 352c 0a20 2020 2020 2020  oling_5,.       
-0000ab60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ab70: 2073 6d6f 7465 5f73 616d 706c 696e 673d   smote_sampling=
-0000ab80: 7365 6c66 2e73 6d6f 7465 5f73 616d 706c  self.smote_sampl
-0000ab90: 696e 672c 2065 6172 6c79 5f73 746f 705f  ing, early_stop_
-0000aba0: 6361 6c6c 6261 636b 3d63 616c 6c62 6163  callback=callbac
-0000abb0: 6b73 2c20 6368 6563 6b70 6f69 6e74 3d46  ks, checkpoint=F
-0000abc0: 616c 7365 2c20 7665 7262 6f73 653d 7365  alse, verbose=se
-0000abd0: 6c66 2e76 6572 626f 7365 290a 2020 2020  lf.verbose).    
-0000abe0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-0000abf0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000ac00: 2020 2020 2020 2323 2320 4669 6c74 6572        ### Filter
-0000ac10: 2061 6e64 204c 6179 6572 2043 6861 7261   and Layer Chara
-0000ac20: 6374 6572 7374 6963 7320 2323 230a 2020  cterstics ###.  
-0000ac30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ac40: 2020 6669 6c74 6572 5f31 203d 2074 7269    filter_1 = tri
-0000ac50: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-0000ac60: 6669 6c74 6572 5f31 272c 2031 322c 2035  filter_1', 12, 5
-0000ac70: 3136 2c20 7374 6570 3d31 3229 0a20 2020  16, step=12).   
-0000ac80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ac90: 2066 696c 7465 725f 7369 7a65 5f31 203d   filter_size_1 =
-0000aca0: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
-0000acb0: 6e74 2827 6669 6c74 6572 5f73 697a 655f  nt('filter_size_
-0000acc0: 3127 2c20 312c 2031 312c 2073 7465 703d  1', 1, 11, step=
-0000acd0: 3229 0a20 2020 2020 2020 2020 2020 2020  2).             
-0000ace0: 2020 2020 2020 2073 7472 6964 6573 5f31         strides_1
-0000acf0: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-0000ad00: 5f69 6e74 2827 7374 7269 6465 735f 3127  _int('strides_1'
-0000ad10: 2c20 312c 2033 2c20 7374 6570 3d31 290a  , 1, 3, step=1).
+0000aa90: 6966 206e 756d 5f63 6f6e 765f 6c61 7965  if num_conv_laye
+0000aaa0: 7273 203e 3d20 323a 0a20 2020 2020 2020  rs >= 2:.       
+0000aab0: 2020 2020 2020 2020 2020 2020 2066 696c               fil
+0000aac0: 7465 725f 3220 3d20 7472 6961 6c2e 7375  ter_2 = trial.su
+0000aad0: 6767 6573 745f 696e 7428 2766 696c 7465  ggest_int('filte
+0000aae0: 725f 3227 2c20 3132 2c20 3531 362c 2073  r_2', 12, 516, s
+0000aaf0: 7465 703d 3132 290a 2020 2020 2020 2020  tep=12).        
+0000ab00: 2020 2020 2020 2020 2020 2020 6669 6c74              filt
+0000ab10: 6572 5f73 697a 655f 3220 3d20 7472 6961  er_size_2 = tria
+0000ab20: 6c2e 7375 6767 6573 745f 696e 7428 2766  l.suggest_int('f
+0000ab30: 696c 7465 725f 7369 7a65 5f32 272c 2031  ilter_size_2', 1
+0000ab40: 2c20 372c 2073 7465 703d 3229 0a20 2020  , 7, step=2).   
+0000ab50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ab60: 2070 6f6f 6c69 6e67 5f32 203d 2074 7269   pooling_2 = tri
+0000ab70: 616c 2e73 7567 6765 7374 5f63 6174 6567  al.suggest_categ
+0000ab80: 6f72 6963 616c 2827 706f 6f6c 696e 675f  orical('pooling_
+0000ab90: 3227 2c20 5b27 6d69 6e27 2c20 276d 6178  2', ['min', 'max
+0000aba0: 272c 2027 6176 6572 6167 6527 5d29 0a20  ', 'average']). 
+0000abb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000abc0: 2020 2070 6f6f 6c5f 7369 7a65 5f32 203d     pool_size_2 =
+0000abd0: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+0000abe0: 6e74 2827 706f 6f6c 5f73 697a 655f 3227  nt('pool_size_2'
+0000abf0: 2c20 312c 2037 2c20 7374 6570 3d31 290a  , 1, 7, step=1).
+0000ac00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ac10: 2020 2020 6669 6c74 6572 5f33 203d 2066      filter_3 = f
+0000ac20: 696c 7465 725f 7369 7a65 5f33 203d 2070  ilter_size_3 = p
+0000ac30: 6f6f 6c5f 7369 7a65 5f33 203d 2030 3b20  ool_size_3 = 0; 
+0000ac40: 706f 6f6c 696e 675f 3320 3d20 4e6f 6e65  pooling_3 = None
+0000ac50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ac60: 2069 6620 6e75 6d5f 636f 6e76 5f6c 6179   if num_conv_lay
+0000ac70: 6572 7320 3d3d 2033 3a0a 2020 2020 2020  ers == 3:.      
+0000ac80: 2020 2020 2020 2020 2020 2020 2020 6669                fi
+0000ac90: 6c74 6572 5f33 203d 2074 7269 616c 2e73  lter_3 = trial.s
+0000aca0: 7567 6765 7374 5f69 6e74 2827 6669 6c74  uggest_int('filt
+0000acb0: 6572 5f33 272c 2031 322c 2035 3136 2c20  er_3', 12, 516, 
+0000acc0: 7374 6570 3d31 3229 0a20 2020 2020 2020  step=12).       
+0000acd0: 2020 2020 2020 2020 2020 2020 2066 696c               fil
+0000ace0: 7465 725f 7369 7a65 5f33 203d 2074 7269  ter_size_3 = tri
+0000acf0: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
+0000ad00: 6669 6c74 6572 5f73 697a 655f 3327 2c20  filter_size_3', 
+0000ad10: 312c 2037 2c20 7374 6570 3d32 290a 2020  1, 7, step=2).  
 0000ad20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ad30: 2020 2020 706f 6f6c 5f73 697a 655f 3120      pool_size_1 
-0000ad40: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
-0000ad50: 696e 7428 2770 6f6f 6c5f 7369 7a65 5f31  int('pool_size_1
-0000ad60: 272c 2031 2c20 372c 2073 7465 703d 3129  ', 1, 7, step=1)
-0000ad70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ad80: 2020 2020 2070 6f6f 6c5f 7374 7269 6465       pool_stride
-0000ad90: 5f31 203d 2074 7269 616c 2e73 7567 6765  _1 = trial.sugge
-0000ada0: 7374 5f69 6e74 2827 706f 6f6c 5f73 7472  st_int('pool_str
-0000adb0: 6964 655f 3127 2c20 312c 2033 2c20 7374  ide_1', 1, 3, st
-0000adc0: 6570 3d31 290a 0a20 2020 2020 2020 2020  ep=1)..         
-0000add0: 2020 2020 2020 2020 2020 2066 696c 7465             filte
-0000ade0: 725f 3220 3d20 7472 6961 6c2e 7375 6767  r_2 = trial.sugg
-0000adf0: 6573 745f 696e 7428 2766 696c 7465 725f  est_int('filter_
-0000ae00: 3227 2c20 3132 2c20 3531 362c 2073 7465  2', 12, 516, ste
-0000ae10: 703d 3132 290a 2020 2020 2020 2020 2020  p=12).          
-0000ae20: 2020 2020 2020 2020 2020 6669 6c74 6572            filter
-0000ae30: 5f73 697a 655f 3220 3d20 7472 6961 6c2e  _size_2 = trial.
-0000ae40: 7375 6767 6573 745f 696e 7428 2766 696c  suggest_int('fil
-0000ae50: 7465 725f 7369 7a65 5f32 272c 2031 2c20  ter_size_2', 1, 
-0000ae60: 372c 2073 7465 703d 3229 0a20 2020 2020  7, step=2).     
-0000ae70: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0000ae80: 7472 6964 6573 5f32 203d 2074 7269 616c  trides_2 = trial
-0000ae90: 2e73 7567 6765 7374 5f69 6e74 2827 7374  .suggest_int('st
-0000aea0: 7269 6465 735f 3227 2c20 312c 2033 2c20  rides_2', 1, 3, 
-0000aeb0: 7374 6570 3d31 290a 2020 2020 2020 2020  step=1).        
-0000aec0: 2020 2020 2020 2020 2020 2020 706f 6f6c              pool
-0000aed0: 5f73 697a 655f 3220 3d20 7472 6961 6c2e  _size_2 = trial.
-0000aee0: 7375 6767 6573 745f 696e 7428 2770 6f6f  suggest_int('poo
-0000aef0: 6c5f 7369 7a65 5f32 272c 2031 2c20 372c  l_size_2', 1, 7,
-0000af00: 2073 7465 703d 3129 0a20 2020 2020 2020   step=1).       
-0000af10: 2020 2020 2020 2020 2020 2020 2070 6f6f               poo
-0000af20: 6c5f 7374 7269 6465 5f32 203d 2074 7269  l_stride_2 = tri
-0000af30: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-0000af40: 706f 6f6c 5f73 7472 6964 655f 3227 2c20  pool_stride_2', 
-0000af50: 312c 2033 2c20 7374 6570 3d31 290a 0a20  1, 3, step=1).. 
-0000af60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000af70: 2020 2066 696c 7465 725f 3320 3d20 7472     filter_3 = tr
-0000af80: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
-0000af90: 2766 696c 7465 725f 3327 2c20 3132 2c20  'filter_3', 12, 
-0000afa0: 3531 362c 2073 7465 703d 3132 290a 2020  516, step=12).  
-0000afb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000afc0: 2020 6669 6c74 6572 5f73 697a 655f 3320    filter_size_3 
-0000afd0: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
-0000afe0: 696e 7428 2766 696c 7465 725f 7369 7a65  int('filter_size
-0000aff0: 5f33 272c 2031 2c20 372c 2073 7465 703d  _3', 1, 7, step=
-0000b000: 3229 0a20 2020 2020 2020 2020 2020 2020  2).             
-0000b010: 2020 2020 2020 2073 7472 6964 6573 5f33         strides_3
-0000b020: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-0000b030: 5f69 6e74 2827 7374 7269 6465 735f 3327  _int('strides_3'
-0000b040: 2c20 312c 2033 2c20 7374 6570 3d31 290a  , 1, 3, step=1).
-0000b050: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b060: 2020 2020 706f 6f6c 5f73 697a 655f 3320      pool_size_3 
-0000b070: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
-0000b080: 696e 7428 2770 6f6f 6c5f 7369 7a65 5f33  int('pool_size_3
-0000b090: 272c 2031 2c20 372c 2073 7465 703d 3129  ', 1, 7, step=1)
-0000b0a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b0b0: 2020 2020 2070 6f6f 6c5f 7374 7269 6465       pool_stride
-0000b0c0: 5f33 203d 2074 7269 616c 2e73 7567 6765  _3 = trial.sugge
-0000b0d0: 7374 5f69 6e74 2827 706f 6f6c 5f73 7472  st_int('pool_str
-0000b0e0: 6964 655f 3327 2c20 312c 2033 2c20 7374  ide_3', 1, 3, st
-0000b0f0: 6570 3d31 290a 0a20 2020 2020 2020 2020  ep=1)..         
-0000b100: 2020 2020 2020 2020 2020 2066 696c 7465             filte
-0000b110: 725f 3420 3d20 7472 6961 6c2e 7375 6767  r_4 = trial.sugg
-0000b120: 6573 745f 696e 7428 2766 696c 7465 725f  est_int('filter_
-0000b130: 3427 2c20 3132 2c20 3531 362c 2073 7465  4', 12, 516, ste
-0000b140: 703d 3132 290a 2020 2020 2020 2020 2020  p=12).          
-0000b150: 2020 2020 2020 2020 2020 6669 6c74 6572            filter
-0000b160: 5f73 697a 655f 3420 3d20 7472 6961 6c2e  _size_4 = trial.
-0000b170: 7375 6767 6573 745f 696e 7428 2766 696c  suggest_int('fil
-0000b180: 7465 725f 7369 7a65 5f34 272c 2031 2c20  ter_size_4', 1, 
-0000b190: 372c 2073 7465 703d 3229 0a20 2020 2020  7, step=2).     
-0000b1a0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0000b1b0: 7472 6964 6573 5f34 203d 2074 7269 616c  trides_4 = trial
-0000b1c0: 2e73 7567 6765 7374 5f69 6e74 2827 7374  .suggest_int('st
-0000b1d0: 7269 6465 735f 3427 2c20 312c 2033 2c20  rides_4', 1, 3, 
-0000b1e0: 7374 6570 3d31 290a 2020 2020 2020 2020  step=1).        
-0000b1f0: 2020 2020 2020 2020 2020 2020 706f 6f6c              pool
-0000b200: 5f73 697a 655f 3420 3d20 7472 6961 6c2e  _size_4 = trial.
-0000b210: 7375 6767 6573 745f 696e 7428 2770 6f6f  suggest_int('poo
-0000b220: 6c5f 7369 7a65 5f34 272c 2031 2c20 372c  l_size_4', 1, 7,
-0000b230: 2073 7465 703d 3129 0a20 2020 2020 2020   step=1).       
-0000b240: 2020 2020 2020 2020 2020 2020 2070 6f6f               poo
-0000b250: 6c5f 7374 7269 6465 5f34 203d 2074 7269  l_stride_4 = tri
-0000b260: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-0000b270: 706f 6f6c 5f73 7472 6964 655f 3427 2c20  pool_stride_4', 
-0000b280: 312c 2033 2c20 7374 6570 3d31 290a 0a20  1, 3, step=1).. 
-0000b290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b2a0: 2020 2066 696c 7465 725f 3520 3d20 7472     filter_5 = tr
-0000b2b0: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
-0000b2c0: 2766 696c 7465 725f 3527 2c20 3132 2c20  'filter_5', 12, 
-0000b2d0: 3531 362c 2073 7465 703d 3132 290a 2020  516, step=12).  
-0000b2e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b2f0: 2020 6669 6c74 6572 5f73 697a 655f 3520    filter_size_5 
-0000b300: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
-0000b310: 696e 7428 2766 696c 7465 725f 7369 7a65  int('filter_size
-0000b320: 5f35 272c 2031 2c20 372c 2073 7465 703d  _5', 1, 7, step=
-0000b330: 3229 0a20 2020 2020 2020 2020 2020 2020  2).             
-0000b340: 2020 2020 2020 2073 7472 6964 6573 5f35         strides_5
-0000b350: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-0000b360: 5f69 6e74 2827 7374 7269 6465 735f 3527  _int('strides_5'
-0000b370: 2c20 312c 2033 2c20 7374 6570 3d31 2920  , 1, 3, step=1) 
-0000b380: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b390: 2020 2020 2070 6f6f 6c5f 7369 7a65 5f35       pool_size_5
-0000b3a0: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-0000b3b0: 5f69 6e74 2827 706f 6f6c 5f73 697a 655f  _int('pool_size_
-0000b3c0: 3527 2c20 312c 2037 2c20 7374 6570 3d31  5', 1, 7, step=1
-0000b3d0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-0000b3e0: 2020 2020 2020 706f 6f6c 5f73 7472 6964        pool_strid
-0000b3f0: 655f 3520 3d20 7472 6961 6c2e 7375 6767  e_5 = trial.sugg
-0000b400: 6573 745f 696e 7428 2770 6f6f 6c5f 7374  est_int('pool_st
-0000b410: 7269 6465 5f35 272c 2031 2c20 332c 2073  ride_5', 1, 3, s
-0000b420: 7465 703d 3129 0a0a 2020 2020 2020 2020  tep=1)..        
-0000b430: 2020 2020 2020 2020 2020 2020 2323 2320              ### 
-0000b440: 4465 6e73 6520 4c61 7965 7273 2023 2323  Dense Layers ###
-0000b450: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b460: 2020 2020 2064 656e 7365 5f6e 6575 726f       dense_neuro
-0000b470: 6e73 5f31 203d 2074 7269 616c 2e73 7567  ns_1 = trial.sug
-0000b480: 6765 7374 5f69 6e74 2827 6465 6e73 655f  gest_int('dense_
-0000b490: 6e65 7572 6f6e 735f 3127 2c20 3132 382c  neurons_1', 128,
-0000b4a0: 2036 3430 302c 2073 7465 703d 3132 3829   6400, step=128)
-0000b4b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b4c0: 2020 2020 2064 656e 7365 5f6e 6575 726f       dense_neuro
-0000b4d0: 6e73 5f32 203d 2074 7269 616c 2e73 7567  ns_2 = trial.sug
-0000b4e0: 6765 7374 5f69 6e74 2827 6465 6e73 655f  gest_int('dense_
-0000b4f0: 6e65 7572 6f6e 735f 3227 2c20 3132 382c  neurons_2', 128,
-0000b500: 2036 3430 302c 2073 7465 703d 3132 3829   6400, step=128)
-0000b510: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b520: 2020 2020 2064 726f 706f 7574 5f31 203d       dropout_1 =
-0000b530: 2074 7269 616c 2e73 7567 6765 7374 5f66   trial.suggest_f
-0000b540: 6c6f 6174 2827 6472 6f70 6f75 745f 3127  loat('dropout_1'
-0000b550: 2c20 302e 302c 2030 2e35 2c20 7374 6570  , 0.0, 0.5, step
-0000b560: 3d30 2e30 3129 0a20 2020 2020 2020 2020  =0.01).         
-0000b570: 2020 2020 2020 2020 2020 2064 726f 706f             dropo
-0000b580: 7574 5f32 203d 2074 7269 616c 2e73 7567  ut_2 = trial.sug
-0000b590: 6765 7374 5f66 6c6f 6174 2827 6472 6f70  gest_float('drop
-0000b5a0: 6f75 745f 3227 2c20 302e 302c 2030 2e35  out_2', 0.0, 0.5
-0000b5b0: 2c20 7374 6570 3d30 2e30 3129 200a 0a20  , step=0.01) .. 
-0000b5c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b5d0: 2020 206d 6f64 656c 2c20 6869 7374 6f72     model, histor
-0000b5e0: 7920 3d20 636e 6e5f 6d6f 6465 6c2e 5647  y = cnn_model.VG
-0000b5f0: 4731 3628 636c 6173 735f 312c 2063 6c61  G16(class_1, cla
-0000b600: 7373 5f32 2c20 696d 675f 6e75 6d5f 6368  ss_2, img_num_ch
-0000b610: 616e 6e65 6c73 3d73 656c 662e 696d 675f  annels=self.img_
-0000b620: 6e75 6d5f 6368 616e 6e65 6c73 2c20 0a20  num_channels, . 
-0000b630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b640: 2020 2020 2020 206e 6f72 6d61 6c69 7a65         normalize
-0000b650: 3d73 656c 662e 6e6f 726d 616c 697a 652c  =self.normalize,
-0000b660: 206d 696e 5f70 6978 656c 3d6d 696e 5f70   min_pixel=min_p
-0000b670: 6978 2c20 6d61 785f 7069 7865 6c3d 6d61  ix, max_pixel=ma
-0000b680: 785f 7069 782c 2076 616c 5f70 6f73 6974  x_pix, val_posit
-0000b690: 6976 653d 7661 6c5f 636c 6173 735f 312c  ive=val_class_1,
-0000b6a0: 2076 616c 5f6e 6567 6174 6976 653d 7661   val_negative=va
-0000b6b0: 6c5f 636c 6173 735f 322c 200a 2020 2020  l_class_2, .    
-0000b6c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b6d0: 2020 2020 6570 6f63 6873 3d73 656c 662e      epochs=self.
-0000b6e0: 7472 6169 6e5f 6570 6f63 6873 2c20 6261  train_epochs, ba
-0000b6f0: 7463 685f 7369 7a65 3d62 6174 6368 5f73  tch_size=batch_s
-0000b700: 697a 652c 206f 7074 696d 697a 6572 3d6f  ize, optimizer=o
-0000b710: 7074 696d 697a 6572 2c20 6c72 3d6c 722c  ptimizer, lr=lr,
-0000b720: 2064 6563 6179 3d64 6563 6179 2c20 6d6f   decay=decay, mo
-0000b730: 6d65 6e74 756d 3d6d 6f6d 656e 7475 6d2c  mentum=momentum,
-0000b740: 206e 6573 7465 726f 763d 6e65 7374 6572   nesterov=nester
-0000b750: 6f76 2c20 0a20 2020 2020 2020 2020 2020  ov, .           
-0000b760: 2020 2020 2020 2020 2020 2020 2062 6574               bet
-0000b770: 615f 313d 6265 7461 5f31 2c20 6265 7461  a_1=beta_1, beta
-0000b780: 5f32 3d62 6574 615f 322c 2061 6d73 6772  _2=beta_2, amsgr
-0000b790: 6164 3d61 6d73 6772 6164 2c20 6c6f 7373  ad=amsgrad, loss
-0000b7a0: 3d6c 6f73 732c 2061 6374 6976 6174 696f  =loss, activatio
-0000b7b0: 6e5f 636f 6e76 3d61 6374 6976 6174 696f  n_conv=activatio
-0000b7c0: 6e5f 636f 6e76 2c20 6163 7469 7661 7469  n_conv, activati
-0000b7d0: 6f6e 5f64 656e 7365 3d61 6374 6976 6174  on_dense=activat
-0000b7e0: 696f 6e5f 6465 6e73 652c 200a 2020 2020  ion_dense, .    
-0000b7f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b800: 2020 2020 636f 6e76 5f69 6e69 743d 636f      conv_init=co
-0000b810: 6e76 5f69 6e69 742c 2064 656e 7365 5f69  nv_init, dense_i
-0000b820: 6e69 743d 6465 6e73 655f 696e 6974 2c20  nit=dense_init, 
-0000b830: 6d6f 6465 6c5f 7265 673d 6d6f 6465 6c5f  model_reg=model_
-0000b840: 7265 672c 2020 2020 2020 2020 2020 2020  reg,            
-0000b850: 2020 2020 2020 2020 2020 0a20 2020 2020            .     
-0000b860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b870: 2020 2066 696c 7465 725f 313d 6669 6c74     filter_1=filt
-0000b880: 6572 5f31 2c20 6669 6c74 6572 5f73 697a  er_1, filter_siz
-0000b890: 655f 313d 6669 6c74 6572 5f73 697a 655f  e_1=filter_size_
-0000b8a0: 312c 2073 7472 6964 6573 5f31 3d73 7472  1, strides_1=str
-0000b8b0: 6964 6573 5f31 2c20 706f 6f6c 696e 675f  ides_1, pooling_
-0000b8c0: 313d 706f 6f6c 696e 675f 312c 2070 6f6f  1=pooling_1, poo
-0000b8d0: 6c5f 7369 7a65 5f31 3d70 6f6f 6c5f 7369  l_size_1=pool_si
-0000b8e0: 7a65 5f31 2c20 706f 6f6c 5f73 7472 6964  ze_1, pool_strid
-0000b8f0: 655f 313d 706f 6f6c 5f73 7472 6964 655f  e_1=pool_stride_
-0000b900: 312c 0a20 2020 2020 2020 2020 2020 2020  1,.             
-0000b910: 2020 2020 2020 2020 2020 2066 696c 7465             filte
-0000b920: 725f 323d 6669 6c74 6572 5f32 2c20 6669  r_2=filter_2, fi
-0000b930: 6c74 6572 5f73 697a 655f 323d 6669 6c74  lter_size_2=filt
-0000b940: 6572 5f73 697a 655f 322c 2073 7472 6964  er_size_2, strid
-0000b950: 6573 5f32 3d73 7472 6964 6573 5f32 2c20  es_2=strides_2, 
-0000b960: 706f 6f6c 696e 675f 323d 706f 6f6c 696e  pooling_2=poolin
-0000b970: 675f 322c 2070 6f6f 6c5f 7369 7a65 5f32  g_2, pool_size_2
-0000b980: 3d70 6f6f 6c5f 7369 7a65 5f32 2c20 706f  =pool_size_2, po
-0000b990: 6f6c 5f73 7472 6964 655f 323d 706f 6f6c  ol_stride_2=pool
-0000b9a0: 5f73 7472 6964 655f 322c 0a20 2020 2020  _stride_2,.     
-0000b9b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b9c0: 2020 2066 696c 7465 725f 333d 6669 6c74     filter_3=filt
-0000b9d0: 6572 5f33 2c20 6669 6c74 6572 5f73 697a  er_3, filter_siz
-0000b9e0: 655f 333d 6669 6c74 6572 5f73 697a 655f  e_3=filter_size_
-0000b9f0: 332c 2073 7472 6964 6573 5f33 3d73 7472  3, strides_3=str
-0000ba00: 6964 6573 5f33 2c20 706f 6f6c 696e 675f  ides_3, pooling_
-0000ba10: 333d 706f 6f6c 696e 675f 332c 2070 6f6f  3=pooling_3, poo
-0000ba20: 6c5f 7369 7a65 5f33 3d70 6f6f 6c5f 7369  l_size_3=pool_si
-0000ba30: 7a65 5f33 2c20 706f 6f6c 5f73 7472 6964  ze_3, pool_strid
-0000ba40: 655f 333d 706f 6f6c 5f73 7472 6964 655f  e_3=pool_stride_
-0000ba50: 332c 0a20 2020 2020 2020 2020 2020 2020  3,.             
-0000ba60: 2020 2020 2020 2020 2020 2066 696c 7465             filte
-0000ba70: 725f 343d 6669 6c74 6572 5f34 2c20 6669  r_4=filter_4, fi
-0000ba80: 6c74 6572 5f73 697a 655f 343d 6669 6c74  lter_size_4=filt
-0000ba90: 6572 5f73 697a 655f 342c 2073 7472 6964  er_size_4, strid
-0000baa0: 6573 5f34 3d73 7472 6964 6573 5f34 2c20  es_4=strides_4, 
-0000bab0: 706f 6f6c 696e 675f 343d 706f 6f6c 696e  pooling_4=poolin
-0000bac0: 675f 342c 2070 6f6f 6c5f 7369 7a65 5f34  g_4, pool_size_4
-0000bad0: 3d70 6f6f 6c5f 7369 7a65 5f34 2c20 706f  =pool_size_4, po
-0000bae0: 6f6c 5f73 7472 6964 655f 343d 706f 6f6c  ol_stride_4=pool
-0000baf0: 5f73 7472 6964 655f 342c 0a20 2020 2020  _stride_4,.     
-0000bb00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bb10: 2020 2066 696c 7465 725f 353d 6669 6c74     filter_5=filt
-0000bb20: 6572 5f35 2c20 6669 6c74 6572 5f73 697a  er_5, filter_siz
-0000bb30: 655f 353d 6669 6c74 6572 5f73 697a 655f  e_5=filter_size_
-0000bb40: 352c 2073 7472 6964 6573 5f35 3d73 7472  5, strides_5=str
-0000bb50: 6964 6573 5f35 2c20 706f 6f6c 696e 675f  ides_5, pooling_
-0000bb60: 353d 706f 6f6c 696e 675f 352c 2070 6f6f  5=pooling_5, poo
-0000bb70: 6c5f 7369 7a65 5f35 3d70 6f6f 6c5f 7369  l_size_5=pool_si
-0000bb80: 7a65 5f35 2c20 706f 6f6c 5f73 7472 6964  ze_5, pool_strid
-0000bb90: 655f 353d 706f 6f6c 5f73 7472 6964 655f  e_5=pool_stride_
-0000bba0: 352c 0a20 2020 2020 2020 2020 2020 2020  5,.             
-0000bbb0: 2020 2020 2020 2020 2020 2064 656e 7365             dense
-0000bbc0: 5f6e 6575 726f 6e73 5f31 3d64 656e 7365  _neurons_1=dense
-0000bbd0: 5f6e 6575 726f 6e73 5f31 2c20 6465 6e73  _neurons_1, dens
-0000bbe0: 655f 6e65 7572 6f6e 735f 323d 6465 6e73  e_neurons_2=dens
-0000bbf0: 655f 6e65 7572 6f6e 735f 322c 2064 726f  e_neurons_2, dro
-0000bc00: 706f 7574 5f31 3d64 726f 706f 7574 5f31  pout_1=dropout_1
-0000bc10: 2c20 6472 6f70 6f75 745f 323d 6472 6f70  , dropout_2=drop
-0000bc20: 6f75 745f 322c 200a 2020 2020 2020 2020  out_2, .        
-0000bc30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bc40: 736d 6f74 655f 7361 6d70 6c69 6e67 3d73  smote_sampling=s
-0000bc50: 656c 662e 736d 6f74 655f 7361 6d70 6c69  elf.smote_sampli
-0000bc60: 6e67 2c20 6561 726c 795f 7374 6f70 5f63  ng, early_stop_c
-0000bc70: 616c 6c62 6163 6b3d 6361 6c6c 6261 636b  allback=callback
-0000bc80: 732c 2063 6865 636b 706f 696e 743d 4661  s, checkpoint=Fa
-0000bc90: 6c73 652c 2076 6572 626f 7365 3d73 656c  lse, verbose=sel
-0000bca0: 662e 7665 7262 6f73 6529 0a0a 2020 2020  f.verbose)..    
-0000bcb0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-0000bcc0: 2020 2020 2020 6966 2073 656c 662e 6f70        if self.op
-0000bcd0: 745f 6376 2069 7320 6e6f 7420 4e6f 6e65  t_cv is not None
-0000bce0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000bcf0: 2020 7072 696e 7428 293b 2070 7269 6e74    print(); print
-0000bd00: 2827 2a2a 2a2a 2a2a 2a2a 2a2a 2a20 2043  ('***********  C
-0000bd10: 5620 2d20 3120 2a2a 2a2a 2a2a 2a2a 2a2a  V - 1 **********
-0000bd20: 2a27 293b 2070 7269 6e74 2829 0a20 2020  *'); print().   
-0000bd30: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-0000bd40: 2e6f 7074 5f61 7567 3a0a 2020 2020 2020  .opt_aug:.      
-0000bd50: 2020 2020 2020 2020 2020 7072 696e 7428            print(
-0000bd60: 293b 2070 7269 6e74 2827 3d3d 3d3d 3d3d  ); print('======
-0000bd70: 3d20 496d 6167 6520 5061 7261 6d65 7465  = Image Paramete
-0000bd80: 7273 203d 3d3d 3d3d 3d27 293b 2070 7269  rs ======'); pri
-0000bd90: 6e74 2829 0a20 2020 2020 2020 2020 2020  nt().           
-0000bda0: 2020 2020 2070 7269 6e74 2827 4e75 6d20       print('Num 
-0000bdb0: 4175 676d 656e 7461 7469 6f6e 7320 3a20  Augmentations : 
-0000bdc0: 272c 206e 756d 5f61 7567 290a 2020 2020  ', num_aug).    
-0000bdd0: 2020 2020 2020 2020 2020 2020 7072 696e              prin
-0000bde0: 7428 2749 6d61 6765 2053 697a 6520 3a20  t('Image Size : 
-0000bdf0: 272c 2069 6d61 6765 5f73 697a 6529 0a20  ', image_size). 
-0000be00: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-0000be10: 7269 6e74 2827 4d61 7820 5069 7865 6c28  rint('Max Pixel(
-0000be20: 7329 203a 2027 2c20 6d61 785f 7069 7829  s) : ', max_pix)
-0000be30: 0a0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-0000be40: 2073 656c 662e 636c 6620 3d3d 2027 616c   self.clf == 'al
-0000be50: 6578 6e65 7427 3a0a 2020 2020 2020 2020  exnet':.        
-0000be60: 2020 2020 2020 2020 6d6f 6465 6c2c 2068          model, h
-0000be70: 6973 746f 7279 203d 2063 6e6e 5f6d 6f64  istory = cnn_mod
-0000be80: 656c 2e41 6c65 784e 6574 2863 6c61 7373  el.AlexNet(class
-0000be90: 5f31 2c20 636c 6173 735f 322c 2069 6d67  _1, class_2, img
-0000bea0: 5f6e 756d 5f63 6861 6e6e 656c 733d 7365  _num_channels=se
-0000beb0: 6c66 2e69 6d67 5f6e 756d 5f63 6861 6e6e  lf.img_num_chann
-0000bec0: 656c 732c 200a 2020 2020 2020 2020 2020  els, .          
-0000bed0: 2020 2020 2020 2020 2020 6e6f 726d 616c            normal
-0000bee0: 697a 653d 7365 6c66 2e6e 6f72 6d61 6c69  ize=self.normali
-0000bef0: 7a65 2c20 6d69 6e5f 7069 7865 6c3d 6d69  ze, min_pixel=mi
-0000bf00: 6e5f 7069 782c 206d 6178 5f70 6978 656c  n_pix, max_pixel
-0000bf10: 3d6d 6178 5f70 6978 2c20 7661 6c5f 706f  =max_pix, val_po
-0000bf20: 7369 7469 7665 3d76 616c 5f63 6c61 7373  sitive=val_class
-0000bf30: 5f31 2c20 7661 6c5f 6e65 6761 7469 7665  _1, val_negative
-0000bf40: 3d76 616c 5f63 6c61 7373 5f32 2c20 0a20  =val_class_2, . 
-0000bf50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bf60: 2020 2065 706f 6368 733d 7365 6c66 2e74     epochs=self.t
-0000bf70: 7261 696e 5f65 706f 6368 732c 2062 6174  rain_epochs, bat
-0000bf80: 6368 5f73 697a 653d 6261 7463 685f 7369  ch_size=batch_si
-0000bf90: 7a65 2c20 6f70 7469 6d69 7a65 723d 6f70  ze, optimizer=op
-0000bfa0: 7469 6d69 7a65 722c 206c 723d 6c72 2c20  timizer, lr=lr, 
-0000bfb0: 6465 6361 793d 6465 6361 792c 206d 6f6d  decay=decay, mom
-0000bfc0: 656e 7475 6d3d 6d6f 6d65 6e74 756d 2c20  entum=momentum, 
-0000bfd0: 6e65 7374 6572 6f76 3d6e 6573 7465 726f  nesterov=nestero
-0000bfe0: 762c 200a 2020 2020 2020 2020 2020 2020  v, .            
-0000bff0: 2020 2020 2020 2020 6265 7461 5f31 3d62          beta_1=b
-0000c000: 6574 615f 312c 2062 6574 615f 323d 6265  eta_1, beta_2=be
-0000c010: 7461 5f32 2c20 616d 7367 7261 643d 616d  ta_2, amsgrad=am
-0000c020: 7367 7261 642c 2073 6d6f 7465 5f73 616d  sgrad, smote_sam
-0000c030: 706c 696e 673d 7365 6c66 2e73 6d6f 7465  pling=self.smote
-0000c040: 5f73 616d 706c 696e 672c 2065 6172 6c79  _sampling, early
-0000c050: 5f73 746f 705f 6361 6c6c 6261 636b 3d63  _stop_callback=c
-0000c060: 616c 6c62 6163 6b73 2c20 6368 6563 6b70  allbacks, checkp
-0000c070: 6f69 6e74 3d46 616c 7365 2c20 7665 7262  oint=False, verb
-0000c080: 6f73 653d 7365 6c66 2e76 6572 626f 7365  ose=self.verbose
-0000c090: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-0000c0a0: 6966 2073 656c 662e 636c 6620 3d3d 2027  if self.clf == '
-0000c0b0: 6375 7374 6f6d 5f63 6e6e 273a 0a20 2020  custom_cnn':.   
-0000c0c0: 2020 2020 2020 2020 2020 2020 206d 6f64               mod
-0000c0d0: 656c 2c20 6869 7374 6f72 7920 3d20 636e  el, history = cn
-0000c0e0: 6e5f 6d6f 6465 6c2e 6375 7374 6f6d 5f6d  n_model.custom_m
-0000c0f0: 6f64 656c 2863 6c61 7373 5f31 2c20 636c  odel(class_1, cl
-0000c100: 6173 735f 322c 2069 6d67 5f6e 756d 5f63  ass_2, img_num_c
-0000c110: 6861 6e6e 656c 733d 7365 6c66 2e69 6d67  hannels=self.img
-0000c120: 5f6e 756d 5f63 6861 6e6e 656c 732c 200a  _num_channels, .
-0000c130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c140: 2020 2020 6e6f 726d 616c 697a 653d 7365      normalize=se
-0000c150: 6c66 2e6e 6f72 6d61 6c69 7a65 2c20 6d69  lf.normalize, mi
-0000c160: 6e5f 7069 7865 6c3d 6d69 6e5f 7069 782c  n_pixel=min_pix,
-0000c170: 206d 6178 5f70 6978 656c 3d6d 6178 5f70   max_pixel=max_p
-0000c180: 6978 2c20 7661 6c5f 706f 7369 7469 7665  ix, val_positive
-0000c190: 3d76 616c 5f63 6c61 7373 5f31 2c20 7661  =val_class_1, va
-0000c1a0: 6c5f 6e65 6761 7469 7665 3d76 616c 5f63  l_negative=val_c
-0000c1b0: 6c61 7373 5f32 2c20 0a20 2020 2020 2020  lass_2, .       
-0000c1c0: 2020 2020 2020 2020 2020 2020 2065 706f               epo
-0000c1d0: 6368 733d 7365 6c66 2e74 7261 696e 5f65  chs=self.train_e
-0000c1e0: 706f 6368 732c 2062 6174 6368 5f73 697a  pochs, batch_siz
-0000c1f0: 653d 6261 7463 685f 7369 7a65 2c20 6f70  e=batch_size, op
-0000c200: 7469 6d69 7a65 723d 6f70 7469 6d69 7a65  timizer=optimize
-0000c210: 722c 206c 723d 6c72 2c20 6465 6361 793d  r, lr=lr, decay=
-0000c220: 6465 6361 792c 206d 6f6d 656e 7475 6d3d  decay, momentum=
-0000c230: 6d6f 6d65 6e74 756d 2c20 6e65 7374 6572  momentum, nester
-0000c240: 6f76 3d6e 6573 7465 726f 762c 200a 2020  ov=nesterov, .  
-0000c250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c260: 2020 6265 7461 5f31 3d62 6574 615f 312c    beta_1=beta_1,
-0000c270: 2062 6574 615f 323d 6265 7461 5f32 2c20   beta_2=beta_2, 
-0000c280: 616d 7367 7261 643d 616d 7367 7261 642c  amsgrad=amsgrad,
-0000c290: 2073 6d6f 7465 5f73 616d 706c 696e 673d   smote_sampling=
-0000c2a0: 7365 6c66 2e73 6d6f 7465 5f73 616d 706c  self.smote_sampl
-0000c2b0: 696e 672c 2065 6172 6c79 5f73 746f 705f  ing, early_stop_
-0000c2c0: 6361 6c6c 6261 636b 3d63 616c 6c62 6163  callback=callbac
-0000c2d0: 6b73 2c20 6368 6563 6b70 6f69 6e74 3d46  ks, checkpoint=F
-0000c2e0: 616c 7365 2c20 7665 7262 6f73 653d 7365  alse, verbose=se
-0000c2f0: 6c66 2e76 6572 626f 7365 290a 2020 2020  lf.verbose).    
-0000c300: 2020 2020 2020 2020 656c 6966 2073 656c          elif sel
-0000c310: 662e 636c 6620 3d3d 2027 7667 6731 3627  f.clf == 'vgg16'
-0000c320: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000c330: 2020 6d6f 6465 6c2c 2068 6973 746f 7279    model, history
-0000c340: 203d 2063 6e6e 5f6d 6f64 656c 2e56 4747   = cnn_model.VGG
-0000c350: 3136 2863 6c61 7373 5f31 2c20 636c 6173  16(class_1, clas
-0000c360: 735f 322c 2069 6d67 5f6e 756d 5f63 6861  s_2, img_num_cha
-0000c370: 6e6e 656c 733d 7365 6c66 2e69 6d67 5f6e  nnels=self.img_n
-0000c380: 756d 5f63 6861 6e6e 656c 732c 200a 2020  um_channels, .  
-0000c390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c3a0: 2020 6e6f 726d 616c 697a 653d 7365 6c66    normalize=self
-0000c3b0: 2e6e 6f72 6d61 6c69 7a65 2c20 6d69 6e5f  .normalize, min_
-0000c3c0: 7069 7865 6c3d 6d69 6e5f 7069 782c 206d  pixel=min_pix, m
-0000c3d0: 6178 5f70 6978 656c 3d6d 6178 5f70 6978  ax_pixel=max_pix
-0000c3e0: 2c20 7661 6c5f 706f 7369 7469 7665 3d76  , val_positive=v
-0000c3f0: 616c 5f63 6c61 7373 5f31 2c20 7661 6c5f  al_class_1, val_
-0000c400: 6e65 6761 7469 7665 3d76 616c 5f63 6c61  negative=val_cla
-0000c410: 7373 5f32 2c20 0a20 2020 2020 2020 2020  ss_2, .         
-0000c420: 2020 2020 2020 2020 2020 2065 706f 6368             epoch
-0000c430: 733d 7365 6c66 2e74 7261 696e 5f65 706f  s=self.train_epo
-0000c440: 6368 732c 2062 6174 6368 5f73 697a 653d  chs, batch_size=
-0000c450: 6261 7463 685f 7369 7a65 2c20 6f70 7469  batch_size, opti
-0000c460: 6d69 7a65 723d 6f70 7469 6d69 7a65 722c  mizer=optimizer,
-0000c470: 206c 723d 6c72 2c20 6465 6361 793d 6465   lr=lr, decay=de
-0000c480: 6361 792c 206d 6f6d 656e 7475 6d3d 6d6f  cay, momentum=mo
-0000c490: 6d65 6e74 756d 2c20 6e65 7374 6572 6f76  mentum, nesterov
-0000c4a0: 3d6e 6573 7465 726f 762c 200a 2020 2020  =nesterov, .    
-0000c4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c4c0: 6265 7461 5f31 3d62 6574 615f 312c 2062  beta_1=beta_1, b
-0000c4d0: 6574 615f 323d 6265 7461 5f32 2c20 616d  eta_2=beta_2, am
-0000c4e0: 7367 7261 643d 616d 7367 7261 642c 2073  sgrad=amsgrad, s
-0000c4f0: 6d6f 7465 5f73 616d 706c 696e 673d 7365  mote_sampling=se
-0000c500: 6c66 2e73 6d6f 7465 5f73 616d 706c 696e  lf.smote_samplin
-0000c510: 672c 2065 6172 6c79 5f73 746f 705f 6361  g, early_stop_ca
-0000c520: 6c6c 6261 636b 3d63 616c 6c62 6163 6b73  llback=callbacks
-0000c530: 2c20 6368 6563 6b70 6f69 6e74 3d46 616c  , checkpoint=Fal
-0000c540: 7365 2c20 7665 7262 6f73 653d 7365 6c66  se, verbose=self
-0000c550: 2e76 6572 626f 7365 290a 2020 2020 2020  .verbose).      
-0000c560: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
-0000c570: 636c 6620 3d3d 2027 7265 736e 6574 3138  clf == 'resnet18
-0000c580: 273a 0a20 2020 2020 2020 2020 2020 2020  ':.             
-0000c590: 2020 206d 6f64 656c 2c20 6869 7374 6f72     model, histor
-0000c5a0: 7920 3d20 636e 6e5f 6d6f 6465 6c2e 5265  y = cnn_model.Re
-0000c5b0: 736e 6574 3138 2863 6c61 7373 5f31 2c20  snet18(class_1, 
-0000c5c0: 636c 6173 735f 322c 2069 6d67 5f6e 756d  class_2, img_num
-0000c5d0: 5f63 6861 6e6e 656c 733d 7365 6c66 2e69  _channels=self.i
-0000c5e0: 6d67 5f6e 756d 5f63 6861 6e6e 656c 732c  mg_num_channels,
-0000c5f0: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-0000c600: 2020 2020 2020 6e6f 726d 616c 697a 653d        normalize=
-0000c610: 7365 6c66 2e6e 6f72 6d61 6c69 7a65 2c20  self.normalize, 
-0000c620: 6d69 6e5f 7069 7865 6c3d 6d69 6e5f 7069  min_pixel=min_pi
-0000c630: 782c 206d 6178 5f70 6978 656c 3d6d 6178  x, max_pixel=max
-0000c640: 5f70 6978 2c20 7661 6c5f 706f 7369 7469  _pix, val_positi
-0000c650: 7665 3d76 616c 5f63 6c61 7373 5f31 2c20  ve=val_class_1, 
-0000c660: 7661 6c5f 6e65 6761 7469 7665 3d76 616c  val_negative=val
-0000c670: 5f63 6c61 7373 5f32 2c20 0a20 2020 2020  _class_2, .     
-0000c680: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0000c690: 706f 6368 733d 7365 6c66 2e74 7261 696e  pochs=self.train
-0000c6a0: 5f65 706f 6368 732c 2062 6174 6368 5f73  _epochs, batch_s
-0000c6b0: 697a 653d 6261 7463 685f 7369 7a65 2c20  ize=batch_size, 
-0000c6c0: 6f70 7469 6d69 7a65 723d 6f70 7469 6d69  optimizer=optimi
-0000c6d0: 7a65 722c 206c 723d 6c72 2c20 6465 6361  zer, lr=lr, deca
-0000c6e0: 793d 6465 6361 792c 206d 6f6d 656e 7475  y=decay, momentu
-0000c6f0: 6d3d 6d6f 6d65 6e74 756d 2c20 6e65 7374  m=momentum, nest
-0000c700: 6572 6f76 3d6e 6573 7465 726f 762c 200a  erov=nesterov, .
-0000c710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c720: 2020 2020 6265 7461 5f31 3d62 6574 615f      beta_1=beta_
-0000c730: 312c 2062 6574 615f 323d 6265 7461 5f32  1, beta_2=beta_2
-0000c740: 2c20 616d 7367 7261 643d 616d 7367 7261  , amsgrad=amsgra
-0000c750: 642c 2073 6d6f 7465 5f73 616d 706c 696e  d, smote_samplin
-0000c760: 673d 7365 6c66 2e73 6d6f 7465 5f73 616d  g=self.smote_sam
-0000c770: 706c 696e 672c 2065 6172 6c79 5f73 746f  pling, early_sto
-0000c780: 705f 6361 6c6c 6261 636b 3d63 616c 6c62  p_callback=callb
-0000c790: 6163 6b73 2c20 6368 6563 6b70 6f69 6e74  acks, checkpoint
-0000c7a0: 3d46 616c 7365 2c20 7665 7262 6f73 653d  =False, verbose=
-0000c7b0: 7365 6c66 2e76 6572 626f 7365 290a 0a20  self.verbose).. 
-0000c7c0: 2020 2020 2020 2023 4966 2074 6865 2070         #If the p
-0000c7d0: 6174 6965 6e63 6520 6973 2072 6561 6368  atience is reach
-0000c7e0: 6564 202d 2d20 7265 7475 726e 2073 686f  ed -- return sho
-0000c7f0: 756c 6420 6265 2061 2076 616c 7565 2074  uld be a value t
-0000c800: 6861 7420 636f 6e74 6169 6e73 2069 6e66  hat contains inf
-0000c810: 6f72 6d61 7469 6f6e 2072 6567 6172 6469  ormation regardi
-0000c820: 6e67 2074 6865 206e 756d 206f 6620 636f  ng the num of co
-0000c830: 6d70 6c65 7465 6420 6570 6f63 6873 2c20  mpleted epochs, 
-0000c840: 6f74 6865 7277 6973 6520 6966 2072 6574  otherwise if ret
-0000c850: 7572 6e20 3020 6576 6572 7920 7469 6d65  urn 0 every time
-0000c860: 2074 6865 6e20 7468 6520 6f70 7469 6d69   then the optimi
-0000c870: 7a65 7220 6d61 7920 6765 7420 7374 7563  zer may get stuc
-0000c880: 6b23 0a20 2020 2020 2020 2069 6620 6c65  k#.        if le
-0000c890: 6e28 6869 7374 6f72 792e 6869 7374 6f72  n(history.histor
-0000c8a0: 795b 276c 6f73 7327 5d29 2021 3d20 7365  y['loss']) != se
-0000c8b0: 6c66 2e74 7261 696e 5f65 706f 6368 733a  lf.train_epochs:
-0000c8c0: 0a20 2020 2020 2020 2020 2020 2070 7269  .            pri
-0000c8d0: 6e74 2829 3b20 7072 696e 7428 2754 7261  nt(); print('Tra
-0000c8e0: 696e 696e 6720 7061 7469 656e 6365 2077  ining patience w
-0000c8f0: 6173 2072 6561 6368 6564 2e2e 2e27 293b  as reached...');
-0000c900: 2070 7269 6e74 2829 0a20 2020 2020 2020   print().       
-0000c910: 2020 2020 2072 6574 7572 6e20 286c 656e       return (len
-0000c920: 2868 6973 746f 7279 2e68 6973 746f 7279  (history.history
-0000c930: 5b27 6c6f 7373 275d 2920 2a20 302e 3030  ['loss']) * 0.00
-0000c940: 3129 202d 2039 3939 2e30 0a0a 2020 2020  1) - 999.0..    
-0000c950: 2020 2020 2349 6620 7468 6520 6f75 7470      #If the outp
-0000c960: 7574 2069 7320 6e61 6e0a 2020 2020 2020  ut is nan.      
-0000c970: 2020 6966 206e 702e 6973 6669 6e69 7465    if np.isfinite
-0000c980: 2868 6973 746f 7279 2e68 6973 746f 7279  (history.history
-0000c990: 5b27 6c6f 7373 275d 5b2d 315d 293a 0a20  ['loss'][-1]):. 
-0000c9a0: 2020 2020 2020 2020 2020 206d 6f64 656c             model
-0000c9b0: 732c 2068 6973 746f 7269 6573 203d 205b  s, histories = [
-0000c9c0: 5d2c 205b 5d0a 2020 2020 2020 2020 2020  ], [].          
-0000c9d0: 2020 6d6f 6465 6c73 2e61 7070 656e 6428    models.append(
-0000c9e0: 6d6f 6465 6c29 2c20 6869 7374 6f72 6965  model), historie
-0000c9f0: 732e 6170 7065 6e64 2868 6973 746f 7279  s.append(history
-0000ca00: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-0000ca10: 2020 2020 2020 2020 2020 2020 7072 696e              prin
-0000ca20: 7428 293b 2070 7269 6e74 2827 5472 6169  t(); print('Trai
-0000ca30: 6e69 6e67 2066 6169 6c65 6420 6475 6520  ning failed due 
-0000ca40: 746f 206e 756d 6572 6963 616c 2069 6e73  to numerical ins
-0000ca50: 7461 6269 6c69 7479 2c20 7265 7475 726e  tability, return
-0000ca60: 696e 6720 6e61 6e2e 2e2e 2729 0a20 2020  ing nan...').   
-0000ca70: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-0000ca80: 6e70 2e6e 616e 200a 0a20 2020 2020 2020  np.nan ..       
-0000ca90: 2023 2323 2323 2043 726f 7373 2d56 616c   ##### Cross-Val
-0000caa0: 6964 6174 696f 6e20 526f 7574 696e 6520  idation Routine 
-0000cab0: 2d20 696d 706c 656d 656e 7461 7469 6f6e  - implementation
-0000cac0: 2069 6e20 7768 6963 6820 7468 6520 7661   in which the va
-0000cad0: 6c69 6461 7469 6f6e 2064 6174 6120 6973  lidation data is
-0000cae0: 2069 6e73 6572 7465 6420 696e 746f 2074   inserted into t
-0000caf0: 6865 2074 7261 696e 696e 6720 6461 7461  he training data
-0000cb00: 2077 6974 6820 7468 6520 7265 706c 6163   with the replac
-0000cb10: 656d 656e 7420 7365 7276 696e 6720 6173  ement serving as
-0000cb20: 2074 6865 206e 6577 2076 616c 6964 6174   the new validat
-0000cb30: 696f 6e23 2323 2323 0a20 2020 2020 2020  ion#####.       
-0000cb40: 2069 6620 7365 6c66 2e6f 7074 5f63 7620   if self.opt_cv 
-0000cb50: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-0000cb60: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-0000cb70: 2e76 616c 5f70 6f73 6974 6976 6520 6973  .val_positive is
-0000cb80: 204e 6f6e 6520 616e 6420 7365 6c66 2e76   None and self.v
-0000cb90: 616c 5f6e 6567 6174 6976 6520 6973 206e  al_negative is n
-0000cba0: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
-0000cbb0: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-0000cbc0: 616c 7565 4572 726f 7228 2743 4e4e 2063  alueError('CNN c
-0000cbd0: 726f 7373 2d76 616c 6964 6174 696f 6e20  ross-validation 
-0000cbe0: 6973 2063 7572 7265 6e74 6c79 2073 7570  is currently sup
-0000cbf0: 706f 7274 6564 206f 6e6c 7920 6966 2076  ported only if v
-0000cc00: 616c 6964 6174 696f 6e20 6461 7461 2069  alidation data i
-0000cc10: 7320 696e 7075 742e 2729 0a20 2020 2020  s input.').     
-0000cc20: 2020 2020 2020 2069 6620 7365 6c66 2e76         if self.v
-0000cc30: 616c 5f70 6f73 6974 6976 6520 6973 206e  al_positive is n
-0000cc40: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
-0000cc50: 2020 2020 2020 2020 2069 6620 6c65 6e28           if len(
-0000cc60: 7365 6c66 2e70 6f73 6974 6976 655f 636c  self.positive_cl
-0000cc70: 6173 7329 202f 206c 656e 2873 656c 662e  ass) / len(self.
-0000cc80: 7661 6c5f 706f 7369 7469 7665 2920 3c20  val_positive) < 
-0000cc90: 7365 6c66 2e6f 7074 5f63 762d 313a 0a20  self.opt_cv-1:. 
-0000cca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ccb0: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-0000ccc0: 726f 7228 2743 616e 6e6f 7420 6576 656e  ror('Cannot even
-0000ccd0: 6c79 2070 6172 7469 7469 6f6e 2074 6865  ly partition the
-0000cce0: 2074 7261 696e 696e 672f 7661 6c69 6461   training/valida
-0000ccf0: 7469 6f6e 2064 6174 612c 2072 6566 6572  tion data, refer
-0000cd00: 2074 6f20 7468 6520 4d69 6372 6f4c 4941   to the MicroLIA
-0000cd10: 2041 5049 2064 6f63 756d 656e 7461 7469   API documentati
-0000cd20: 6f6e 2066 6f72 2069 6e73 7472 7563 7469  on for instructi
-0000cd30: 6f6e 7320 6f6e 2068 6f77 2074 6f20 7573  ons on how to us
-0000cd40: 6520 7468 6520 6f70 745f 6376 2070 6172  e the opt_cv par
-0000cd50: 616d 6574 6572 2e27 290a 2020 2020 2020  ameter.').      
-0000cd60: 2020 2020 2020 6966 2073 656c 662e 7661        if self.va
-0000cd70: 6c5f 6e65 6761 7469 7665 2069 7320 6e6f  l_negative is no
-0000cd80: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
-0000cd90: 2020 2020 2020 2020 6966 206c 656e 2873          if len(s
-0000cda0: 656c 662e 6e65 6761 7469 7665 5f63 6c61  elf.negative_cla
-0000cdb0: 7373 2920 2f20 6c65 6e28 7365 6c66 2e76  ss) / len(self.v
-0000cdc0: 616c 5f6e 6567 6174 6976 6529 203c 2073  al_negative) < s
-0000cdd0: 656c 662e 6f70 745f 6376 2d31 3a0a 2020  elf.opt_cv-1:.  
-0000cde0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cdf0: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-0000ce00: 6f72 2827 4361 6e6e 6f74 2065 7665 6e6c  or('Cannot evenl
-0000ce10: 7920 7061 7274 6974 696f 6e20 7468 6520  y partition the 
-0000ce20: 7472 6169 6e69 6e67 2f76 616c 6964 6174  training/validat
-0000ce30: 696f 6e20 6461 7461 2c20 7265 6665 7220  ion data, refer 
-0000ce40: 746f 2074 6865 204d 6963 726f 4c49 4120  to the MicroLIA 
-0000ce50: 4150 4920 646f 6375 6d65 6e74 6174 696f  API documentatio
-0000ce60: 6e20 666f 7220 696e 7374 7275 6374 696f  n for instructio
-0000ce70: 6e73 206f 6e20 686f 7720 746f 2075 7365  ns on how to use
-0000ce80: 2074 6865 206f 7074 5f63 7620 7061 7261   the opt_cv para
-0000ce90: 6d65 7465 722e 2729 0a20 2020 2020 2020  meter.').       
-0000cea0: 2020 2020 200a 2020 2020 2020 2020 2020       .          
-0000ceb0: 2020 2354 6865 2066 6972 7374 206d 6f64    #The first mod
-0000cec0: 656c 2061 6c72 6561 6479 2072 616e 2074  el already ran t
-0000ced0: 6865 7265 666f 7265 2073 7574 6272 6163  herefore sutbrac
-0000cee0: 7420 3120 2020 2020 200a 2020 2020 2020  t 1      .      
-0000cef0: 2020 2020 2020 666f 7220 6b20 696e 2072        for k in r
-0000cf00: 616e 6765 2873 656c 662e 6f70 745f 6376  ange(self.opt_cv
-0000cf10: 2d31 293a 2020 2020 2020 2020 2020 0a20  -1):          . 
-0000cf20: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-0000cf30: 4d61 6b65 2064 6565 7020 636f 7069 6573  Make deep copies
-0000cf40: 2074 6f20 6176 6f69 6420 6f76 6572 7772   to avoid overwr
-0000cf50: 6974 696e 6720 6172 7261 7973 0a20 2020  iting arrays.   
-0000cf60: 2020 2020 2020 2020 2020 2020 2063 6c61               cla
-0000cf70: 7373 5f31 2c20 636c 6173 735f 3220 3d20  ss_1, class_2 = 
-0000cf80: 636f 7079 2e64 6565 7063 6f70 7928 7365  copy.deepcopy(se
-0000cf90: 6c66 2e70 6f73 6974 6976 655f 636c 6173  lf.positive_clas
-0000cfa0: 7329 2c20 636f 7079 2e64 6565 7063 6f70  s), copy.deepcop
-0000cfb0: 7928 7365 6c66 2e6e 6567 6174 6976 655f  y(self.negative_
-0000cfc0: 636c 6173 7329 0a20 2020 2020 2020 2020  class).         
-0000cfd0: 2020 2020 2020 2076 616c 5f63 6c61 7373         val_class
-0000cfe0: 5f31 2c20 7661 6c5f 636c 6173 735f 3220  _1, val_class_2 
-0000cff0: 3d20 636f 7079 2e64 6565 7063 6f70 7928  = copy.deepcopy(
-0000d000: 7365 6c66 2e76 616c 5f70 6f73 6974 6976  self.val_positiv
-0000d010: 6529 2c20 636f 7079 2e64 6565 7063 6f70  e), copy.deepcop
-0000d020: 7928 7365 6c66 2e76 616c 5f6e 6567 6174  y(self.val_negat
-0000d030: 6976 6529 0a0a 2020 2020 2020 2020 2020  ive)..          
-0000d040: 2020 2020 2020 2353 6f72 7420 7468 6520        #Sort the 
-0000d050: 6e65 7720 6461 7461 2073 616d 706c 6573  new data samples
-0000d060: 2c20 6e6f 2072 616e 646f 6d20 7368 7566  , no random shuf
-0000d070: 666c 696e 672c 206a 7573 7420 6120 6c69  fling, just a li
-0000d080: 6e65 6172 2073 6571 7565 6e63 650a 2020  near sequence.  
-0000d090: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0000d0a0: 2076 616c 5f63 6c61 7373 5f31 2069 7320   val_class_1 is 
-0000d0b0: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
-0000d0c0: 2020 2020 2020 2020 2020 2020 2020 7661                va
-0000d0d0: 6c5f 686f 6c64 5f31 203d 2063 6f70 792e  l_hold_1 = copy.
-0000d0e0: 6465 6570 636f 7079 2863 6c61 7373 5f31  deepcopy(class_1
-0000d0f0: 5b6b 2a6c 656e 2876 616c 5f63 6c61 7373  [k*len(val_class
-0000d100: 5f31 293a 6c65 6e28 7661 6c5f 636c 6173  _1):len(val_clas
-0000d110: 735f 3129 2a28 6b2b 3129 5d29 2023 5468  s_1)*(k+1)]) #Th
-0000d120: 6520 6e65 7720 7661 6c69 6461 7469 6f6e  e new validation
-0000d130: 2064 6174 610a 2020 2020 2020 2020 2020   data.          
-0000d140: 2020 2020 2020 2020 2020 636c 6173 735f            class_
-0000d150: 315b 6b2a 6c65 6e28 7661 6c5f 636c 6173  1[k*len(val_clas
-0000d160: 735f 3129 3a6c 656e 2876 616c 5f63 6c61  s_1):len(val_cla
-0000d170: 7373 5f31 292a 286b 2b31 295d 203d 2063  ss_1)*(k+1)] = c
-0000d180: 6f70 792e 6465 6570 636f 7079 2876 616c  opy.deepcopy(val
-0000d190: 5f63 6c61 7373 5f31 290a 2020 2020 2020  _class_1).      
-0000d1a0: 2020 2020 2020 2020 2020 2020 2020 7661                va
-0000d1b0: 6c5f 636c 6173 735f 3120 3d20 7661 6c5f  l_class_1 = val_
-0000d1c0: 686f 6c64 5f31 2023 5468 6520 6e65 7720  hold_1 #The new 
-0000d1d0: 7661 6c69 6461 7469 6f6e 2064 6174 610a  validation data.
-0000d1e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d1f0: 6966 2076 616c 5f63 6c61 7373 5f32 2069  if val_class_2 i
-0000d200: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
-0000d210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d220: 7661 6c5f 686f 6c64 5f32 203d 2063 6f70  val_hold_2 = cop
-0000d230: 792e 6465 6570 636f 7079 2863 6c61 7373  y.deepcopy(class
-0000d240: 5f32 5b6b 2a6c 656e 2876 616c 5f63 6c61  _2[k*len(val_cla
-0000d250: 7373 5f32 293a 6c65 6e28 7661 6c5f 636c  ss_2):len(val_cl
-0000d260: 6173 735f 3229 2a28 6b2b 3129 5d29 2023  ass_2)*(k+1)]) #
-0000d270: 5468 6520 6e65 7720 7661 6c69 6461 7469  The new validati
-0000d280: 6f6e 2064 6174 610a 2020 2020 2020 2020  on data.        
-0000d290: 2020 2020 2020 2020 2020 2020 636c 6173              clas
-0000d2a0: 735f 325b 6b2a 6c65 6e28 7661 6c5f 636c  s_2[k*len(val_cl
-0000d2b0: 6173 735f 3229 3a6c 656e 2876 616c 5f63  ass_2):len(val_c
-0000d2c0: 6c61 7373 5f32 292a 286b 2b31 295d 203d  lass_2)*(k+1)] =
-0000d2d0: 2063 6f70 792e 6465 6570 636f 7079 2876   copy.deepcopy(v
-0000d2e0: 616c 5f63 6c61 7373 5f32 290a 2020 2020  al_class_2).    
-0000d2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d300: 7661 6c5f 636c 6173 735f 3220 3d20 7661  val_class_2 = va
-0000d310: 6c5f 686f 6c64 5f32 2023 5468 6520 6e65  l_hold_2 #The ne
-0000d320: 7720 7661 6c69 6461 7469 6f6e 2064 6174  w validation dat
-0000d330: 610a 0a20 2020 2020 2020 2020 2020 2020  a..             
-0000d340: 2020 2069 6620 7365 6c66 2e6f 7074 5f61     if self.opt_a
-0000d350: 7567 3a0a 2020 2020 2020 2020 2020 2020  ug:.            
-0000d360: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-0000d370: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
-0000d380: 203d 3d20 313a 0a20 2020 2020 2020 2020   == 1:.         
-0000d390: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-0000d3a0: 6861 6e6e 656c 312c 2063 6861 6e6e 656c  hannel1, channel
-0000d3b0: 322c 2063 6861 6e6e 656c 3320 3d20 636f  2, channel3 = co
-0000d3c0: 7079 2e64 6565 7063 6f70 7928 636c 6173  py.deepcopy(clas
-0000d3d0: 735f 3129 2c20 4e6f 6e65 2c20 4e6f 6e65  s_1), None, None
-0000d3e0: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-0000d3f0: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
-0000d400: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
-0000d410: 203d 3d20 323a 0a20 2020 2020 2020 2020   == 2:.         
-0000d420: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-0000d430: 6861 6e6e 656c 312c 2063 6861 6e6e 656c  hannel1, channel
-0000d440: 322c 2063 6861 6e6e 656c 3320 3d20 636f  2, channel3 = co
-0000d450: 7079 2e64 6565 7063 6f70 7928 636c 6173  py.deepcopy(clas
-0000d460: 735f 315b 3a2c 3a2c 3a2c 305d 292c 2063  s_1[:,:,:,0]), c
-0000d470: 6f70 792e 6465 6570 636f 7079 2863 6c61  opy.deepcopy(cla
-0000d480: 7373 5f31 5b3a 2c3a 2c3a 2c31 5d29 2c20  ss_1[:,:,:,1]), 
-0000d490: 4e6f 6e65 200a 2020 2020 2020 2020 2020  None .          
-0000d4a0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-0000d4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d4c0: 2020 2020 2020 2020 6368 616e 6e65 6c31          channel1
-0000d4d0: 2c20 6368 616e 6e65 6c32 2c20 6368 616e  , channel2, chan
-0000d4e0: 6e65 6c33 203d 2063 6f70 792e 6465 6570  nel3 = copy.deep
-0000d4f0: 636f 7079 2863 6c61 7373 5f31 5b3a 2c3a  copy(class_1[:,:
-0000d500: 2c3a 2c30 5d29 2c20 636f 7079 2e64 6565  ,:,0]), copy.dee
-0000d510: 7063 6f70 7928 636c 6173 735f 315b 3a2c  pcopy(class_1[:,
-0000d520: 3a2c 3a2c 315d 292c 2063 6f70 792e 6465  :,:,1]), copy.de
-0000d530: 6570 636f 7079 2863 6c61 7373 5f31 5b3a  epcopy(class_1[:
-0000d540: 2c3a 2c3a 2c32 5d29 0a0a 2020 2020 2020  ,:,:,2])..      
-0000d550: 2020 2020 2020 2020 2020 2020 2020 6175                au
-0000d560: 676d 656e 7465 645f 696d 6167 6573 203d  gmented_images =
-0000d570: 2061 7567 6d65 6e74 6174 696f 6e28 6368   augmentation(ch
-0000d580: 616e 6e65 6c31 3d63 6861 6e6e 656c 312c  annel1=channel1,
-0000d590: 2063 6861 6e6e 656c 323d 6368 616e 6e65   channel2=channe
-0000d5a0: 6c32 2c20 6368 616e 6e65 6c33 3d63 6861  l2, channel3=cha
-0000d5b0: 6e6e 656c 332c 2062 6174 6368 3d6e 756d  nnel3, batch=num
-0000d5c0: 5f61 7567 2c20 0a20 2020 2020 2020 2020  _aug, .         
-0000d5d0: 2020 2020 2020 2020 2020 2020 2020 2077                 w
-0000d5e0: 6964 7468 5f73 6869 6674 3d73 656c 662e  idth_shift=self.
-0000d5f0: 7368 6966 742c 2068 6569 6768 745f 7368  shift, height_sh
-0000d600: 6966 743d 7365 6c66 2e73 6869 6674 2c20  ift=self.shift, 
-0000d610: 686f 7269 7a6f 6e74 616c 3d68 6f72 697a  horizontal=horiz
-0000d620: 6f6e 7461 6c2c 2076 6572 7469 6361 6c3d  ontal, vertical=
-0000d630: 7665 7274 6963 616c 2c20 726f 7461 7469  vertical, rotati
-0000d640: 6f6e 3d72 6f74 6174 696f 6e2c 200a 2020  on=rotation, .  
-0000d650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d660: 2020 2020 2020 696d 6167 655f 7369 7a65        image_size
-0000d670: 3d69 6d61 6765 5f73 697a 652c 206d 6173  =image_size, mas
-0000d680: 6b5f 7369 7a65 3d73 656c 662e 6d61 736b  k_size=self.mask
-0000d690: 5f73 697a 652c 206e 756d 5f6d 6173 6b73  _size, num_masks
-0000d6a0: 3d73 656c 662e 6e75 6d5f 6d61 736b 732c  =self.num_masks,
-0000d6b0: 2062 6c65 6e64 5f6d 756c 7469 706c 6965   blend_multiplie
-0000d6c0: 723d 626c 656e 645f 6d75 6c74 6970 6c69  r=blend_multipli
-0000d6d0: 6572 2c20 0a20 2020 2020 2020 2020 2020  er, .           
-0000d6e0: 2020 2020 2020 2020 2020 2020 2062 6c65               ble
-0000d6f0: 6e64 696e 675f 6675 6e63 3d73 656c 662e  nding_func=self.
-0000d700: 626c 656e 6469 6e67 5f66 756e 632c 206e  blending_func, n
-0000d710: 756d 5f69 6d61 6765 735f 746f 5f62 6c65  um_images_to_ble
-0000d720: 6e64 3d73 656c 662e 6e75 6d5f 696d 6167  nd=self.num_imag
-0000d730: 6573 5f74 6f5f 626c 656e 642c 207a 6f6f  es_to_blend, zoo
-0000d740: 6d5f 7261 6e67 653d 7365 6c66 2e7a 6f6f  m_range=self.zoo
-0000d750: 6d5f 7261 6e67 652c 2073 6b65 775f 616e  m_range, skew_an
-0000d760: 676c 653d 736b 6577 5f61 6e67 6c65 290a  gle=skew_angle).
-0000d770: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d780: 2020 2020 2069 6620 7365 6c66 2e69 6d67       if self.img
-0000d790: 5f6e 756d 5f63 6861 6e6e 656c 7320 3e20  _num_channels > 
-0000d7a0: 313a 0a20 2020 2020 2020 2020 2020 2020  1:.             
-0000d7b0: 2020 2020 2020 2020 2020 2063 6c61 7373             class
-0000d7c0: 5f31 3d5b 5d0a 2020 2020 2020 2020 2020  _1=[].          
-0000d7d0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0000d7e0: 2073 656c 662e 696d 675f 6e75 6d5f 6368   self.img_num_ch
-0000d7f0: 616e 6e65 6c73 203d 3d20 323a 0a20 2020  annels == 2:.   
-0000d800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d810: 2020 2020 2020 2020 2066 6f72 2069 2069           for i i
-0000d820: 6e20 7261 6e67 6528 6c65 6e28 6175 676d  n range(len(augm
-0000d830: 656e 7465 645f 696d 6167 6573 5b30 5d29  ented_images[0])
-0000d840: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-0000d850: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d860: 2020 2063 6c61 7373 5f31 2e61 7070 656e     class_1.appen
-0000d870: 6428 6461 7461 5f70 726f 6365 7373 696e  d(data_processin
-0000d880: 672e 636f 6e63 6174 5f63 6861 6e6e 656c  g.concat_channel
-0000d890: 7328 6175 676d 656e 7465 645f 696d 6167  s(augmented_imag
-0000d8a0: 6573 5b30 5d5b 695d 2c20 6175 676d 656e  es[0][i], augmen
-0000d8b0: 7465 645f 696d 6167 6573 5b31 5d5b 695d  ted_images[1][i]
-0000d8c0: 2929 0a20 2020 2020 2020 2020 2020 2020  )).             
-0000d8d0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-0000d8e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d8f0: 2020 2020 2020 2020 2020 2020 2066 6f72               for
-0000d900: 2069 2069 6e20 7261 6e67 6528 6c65 6e28   i in range(len(
-0000d910: 6175 676d 656e 7465 645f 696d 6167 6573  augmented_images
-0000d920: 5b30 5d29 293a 0a20 2020 2020 2020 2020  [0])):.         
-0000d930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d940: 2020 2020 2020 2063 6c61 7373 5f31 2e61         class_1.a
-0000d950: 7070 656e 6428 6461 7461 5f70 726f 6365  ppend(data_proce
-0000d960: 7373 696e 672e 636f 6e63 6174 5f63 6861  ssing.concat_cha
-0000d970: 6e6e 656c 7328 6175 676d 656e 7465 645f  nnels(augmented_
-0000d980: 696d 6167 6573 5b30 5d5b 695d 2c20 6175  images[0][i], au
-0000d990: 676d 656e 7465 645f 696d 6167 6573 5b31  gmented_images[1
-0000d9a0: 5d5b 695d 2c20 6175 676d 656e 7465 645f  ][i], augmented_
-0000d9b0: 696d 6167 6573 5b32 5d5b 695d 2929 0a20  images[2][i])). 
-0000d9c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d9d0: 2020 2020 2020 2063 6c61 7373 5f31 203d         class_1 =
-0000d9e0: 206e 702e 6172 7261 7928 636c 6173 735f   np.array(class_
-0000d9f0: 3129 0a20 2020 2020 2020 2020 2020 2020  1).             
-0000da00: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0000da10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000da20: 2020 2020 2063 6c61 7373 5f31 203d 2061       class_1 = a
-0000da30: 7567 6d65 6e74 6564 5f69 6d61 6765 730a  ugmented_images.
-0000da40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000da50: 2020 2020 2023 5065 7266 6f72 6d20 7361       #Perform sa
-0000da60: 6d65 2061 7567 6d65 6e74 6174 696f 6e20  me augmentation 
-0000da70: 7465 6368 6e69 7175 6573 206f 6e20 6e65  techniques on ne
-0000da80: 6761 7469 7665 2063 6c61 7373 2064 6174  gative class dat
-0000da90: 612c 2062 6174 6368 5f6f 7468 6572 3d31  a, batch_other=1
-0000daa0: 2062 7920 6465 6661 756c 740a 2020 2020   by default.    
-0000dab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dac0: 6966 2073 656c 662e 696d 675f 6e75 6d5f  if self.img_num_
-0000dad0: 6368 616e 6e65 6c73 203d 3d20 313a 0a20  channels == 1:. 
-0000dae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000daf0: 2020 2020 2020 2063 6861 6e6e 656c 312c         channel1,
-0000db00: 2063 6861 6e6e 656c 322c 2063 6861 6e6e   channel2, chann
-0000db10: 656c 3320 3d20 636f 7079 2e64 6565 7063  el3 = copy.deepc
-0000db20: 6f70 7928 636c 6173 735f 3229 2c20 4e6f  opy(class_2), No
-0000db30: 6e65 2c20 4e6f 6e65 200a 2020 2020 2020  ne, None .      
-0000db40: 2020 2020 2020 2020 2020 2020 2020 656c                el
-0000db50: 6966 2073 656c 662e 696d 675f 6e75 6d5f  if self.img_num_
-0000db60: 6368 616e 6e65 6c73 203d 3d20 323a 0a20  channels == 2:. 
-0000db70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000db80: 2020 2020 2020 2063 6861 6e6e 656c 312c         channel1,
-0000db90: 2063 6861 6e6e 656c 322c 2063 6861 6e6e   channel2, chann
-0000dba0: 656c 3320 3d20 636f 7079 2e64 6565 7063  el3 = copy.deepc
-0000dbb0: 6f70 7928 636c 6173 735f 325b 3a2c 3a2c  opy(class_2[:,:,
-0000dbc0: 3a2c 305d 292c 2063 6f70 792e 6465 6570  :,0]), copy.deep
-0000dbd0: 636f 7079 2863 6c61 7373 5f32 5b3a 2c3a  copy(class_2[:,:
-0000dbe0: 2c3a 2c31 5d29 2c20 4e6f 6e65 200a 2020  ,:,1]), None .  
-0000dbf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dc00: 2020 656c 6966 2073 656c 662e 696d 675f    elif self.img_
-0000dc10: 6e75 6d5f 6368 616e 6e65 6c73 203d 3d20  num_channels == 
-0000dc20: 333a 0a20 2020 2020 2020 2020 2020 2020  3:.             
-0000dc30: 2020 2020 2020 2020 2020 2063 6861 6e6e             chann
-0000dc40: 656c 312c 2063 6861 6e6e 656c 322c 2063  el1, channel2, c
-0000dc50: 6861 6e6e 656c 3320 3d20 636f 7079 2e64  hannel3 = copy.d
-0000dc60: 6565 7063 6f70 7928 636c 6173 735f 325b  eepcopy(class_2[
-0000dc70: 3a2c 3a2c 3a2c 305d 292c 2063 6f70 792e  :,:,:,0]), copy.
-0000dc80: 6465 6570 636f 7079 2863 6c61 7373 5f32  deepcopy(class_2
-0000dc90: 5b3a 2c3a 2c3a 2c31 5d29 2c20 636f 7079  [:,:,:,1]), copy
-0000dca0: 2e64 6565 7063 6f70 7928 636c 6173 735f  .deepcopy(class_
-0000dcb0: 325b 3a2c 3a2c 3a2c 325d 290a 2020 2020  2[:,:,:,2]).    
-0000dcc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dcd0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000dce0: 2020 2020 2061 7567 6d65 6e74 6564 5f69       augmented_i
-0000dcf0: 6d61 6765 735f 6e65 6761 7469 7665 203d  mages_negative =
-0000dd00: 2061 7567 6d65 6e74 6174 696f 6e28 6368   augmentation(ch
-0000dd10: 616e 6e65 6c31 3d63 6861 6e6e 656c 312c  annel1=channel1,
-0000dd20: 2063 6861 6e6e 656c 323d 6368 616e 6e65   channel2=channe
-0000dd30: 6c32 2c20 6368 616e 6e65 6c33 3d63 6861  l2, channel3=cha
-0000dd40: 6e6e 656c 332c 2062 6174 6368 3d73 656c  nnel3, batch=sel
-0000dd50: 662e 6261 7463 685f 6f74 6865 722c 200a  f.batch_other, .
-0000dd60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dd70: 2020 2020 2020 2020 7769 6474 685f 7368          width_sh
-0000dd80: 6966 743d 7365 6c66 2e73 6869 6674 2c20  ift=self.shift, 
-0000dd90: 6865 6967 6874 5f73 6869 6674 3d73 656c  height_shift=sel
-0000dda0: 662e 7368 6966 742c 2068 6f72 697a 6f6e  f.shift, horizon
-0000ddb0: 7461 6c3d 686f 7269 7a6f 6e74 616c 2c20  tal=horizontal, 
-0000ddc0: 7665 7274 6963 616c 3d76 6572 7469 6361  vertical=vertica
-0000ddd0: 6c2c 2072 6f74 6174 696f 6e3d 726f 7461  l, rotation=rota
-0000dde0: 7469 6f6e 2c20 0a20 2020 2020 2020 2020  tion, .         
-0000ddf0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0000de00: 6d61 6765 5f73 697a 653d 696d 6167 655f  mage_size=image_
-0000de10: 7369 7a65 2c20 6d61 736b 5f73 697a 653d  size, mask_size=
-0000de20: 7365 6c66 2e6d 6173 6b5f 7369 7a65 2c20  self.mask_size, 
-0000de30: 6e75 6d5f 6d61 736b 733d 7365 6c66 2e6e  num_masks=self.n
-0000de40: 756d 5f6d 6173 6b73 2c20 626c 656e 645f  um_masks, blend_
-0000de50: 6d75 6c74 6970 6c69 6572 3d73 656c 662e  multiplier=self.
-0000de60: 626c 656e 645f 6f74 6865 722c 200a 2020  blend_other, .  
-0000de70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000de80: 2020 2020 2020 626c 656e 6469 6e67 5f66        blending_f
-0000de90: 756e 633d 7365 6c66 2e62 6c65 6e64 696e  unc=self.blendin
-0000dea0: 675f 6675 6e63 2c20 6e75 6d5f 696d 6167  g_func, num_imag
-0000deb0: 6573 5f74 6f5f 626c 656e 643d 7365 6c66  es_to_blend=self
-0000dec0: 2e6e 756d 5f69 6d61 6765 735f 746f 5f62  .num_images_to_b
-0000ded0: 6c65 6e64 2c20 7a6f 6f6d 5f72 616e 6765  lend, zoom_range
-0000dee0: 3d73 656c 662e 7a6f 6f6d 5f72 616e 6765  =self.zoom_range
-0000def0: 2c20 736b 6577 5f61 6e67 6c65 3d73 6b65  , skew_angle=ske
-0000df00: 775f 616e 676c 6529 0a0a 2020 2020 2020  w_angle)..      
-0000df10: 2020 2020 2020 2020 2020 2020 2020 2354                #T
-0000df20: 6865 2061 7567 6d65 6e74 6174 696f 6e20  he augmentation 
-0000df30: 726f 7574 696e 6520 7265 7475 726e 7320  routine returns 
-0000df40: 616e 206f 7574 7075 7420 666f 7220 6561  an output for ea
-0000df50: 6368 2066 696c 7465 722c 2065 2e67 2e20  ch filter, e.g. 
-0000df60: 3320 6f75 7470 7574 7320 666f 7220 5247  3 outputs for RG
-0000df70: 420a 2020 2020 2020 2020 2020 2020 2020  B.              
-0000df80: 2020 2020 2020 6966 2073 656c 662e 696d        if self.im
-0000df90: 675f 6e75 6d5f 6368 616e 6e65 6c73 203e  g_num_channels >
-0000dfa0: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
-0000dfb0: 2020 2020 2020 2020 2020 2020 636c 6173              clas
-0000dfc0: 735f 323d 5b5d 0a20 2020 2020 2020 2020  s_2=[].         
-0000dfd0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0000dfe0: 6620 7365 6c66 2e69 6d67 5f6e 756d 5f63  f self.img_num_c
-0000dff0: 6861 6e6e 656c 7320 3d3d 2032 3a0a 2020  hannels == 2:.  
-0000e000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e010: 2020 2020 2020 2020 2020 666f 7220 6920            for i 
-0000e020: 696e 2072 616e 6765 286c 656e 2861 7567  in range(len(aug
-0000e030: 6d65 6e74 6564 5f69 6d61 6765 735f 6e65  mented_images_ne
-0000e040: 6761 7469 7665 5b30 5d29 293a 0a20 2020  gative[0])):.   
-0000e050: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e060: 2020 2020 2020 2020 2020 2020 2063 6c61               cla
-0000e070: 7373 5f32 2e61 7070 656e 6428 6461 7461  ss_2.append(data
-0000e080: 5f70 726f 6365 7373 696e 672e 636f 6e63  _processing.conc
-0000e090: 6174 5f63 6861 6e6e 656c 7328 6175 676d  at_channels(augm
-0000e0a0: 656e 7465 645f 696d 6167 6573 5f6e 6567  ented_images_neg
-0000e0b0: 6174 6976 655b 305d 5b69 5d2c 2061 7567  ative[0][i], aug
-0000e0c0: 6d65 6e74 6564 5f69 6d61 6765 735f 6e65  mented_images_ne
-0000e0d0: 6761 7469 7665 5b31 5d5b 695d 2929 0a20  gative[1][i])). 
-0000e0e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e0f0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0000e100: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e110: 2020 2020 2020 2020 2066 6f72 2069 2069           for i i
-0000e120: 6e20 7261 6e67 6528 6c65 6e28 6175 676d  n range(len(augm
-0000e130: 656e 7465 645f 696d 6167 6573 5f6e 6567  ented_images_neg
-0000e140: 6174 6976 655b 305d 2929 3a0a 2020 2020  ative[0])):.    
-0000e150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e160: 2020 2020 2020 2020 2020 2020 636c 6173              clas
-0000e170: 735f 322e 6170 7065 6e64 2864 6174 615f  s_2.append(data_
-0000e180: 7072 6f63 6573 7369 6e67 2e63 6f6e 6361  processing.conca
-0000e190: 745f 6368 616e 6e65 6c73 2861 7567 6d65  t_channels(augme
-0000e1a0: 6e74 6564 5f69 6d61 6765 735f 6e65 6761  nted_images_nega
-0000e1b0: 7469 7665 5b30 5d5b 695d 2c20 6175 676d  tive[0][i], augm
-0000e1c0: 656e 7465 645f 696d 6167 6573 5f6e 6567  ented_images_neg
-0000e1d0: 6174 6976 655b 315d 5b69 5d2c 2061 7567  ative[1][i], aug
-0000e1e0: 6d65 6e74 6564 5f69 6d61 6765 735f 6e65  mented_images_ne
-0000e1f0: 6761 7469 7665 5b32 5d5b 695d 2929 0a20  gative[2][i])). 
-0000e200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e210: 2020 2020 2020 2063 6c61 7373 5f32 203d         class_2 =
-0000e220: 206e 702e 6172 7261 7928 636c 6173 735f   np.array(class_
-0000e230: 3229 0a20 2020 2020 2020 2020 2020 2020  2).             
-0000e240: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0000e250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e260: 2020 2020 2063 6c61 7373 5f32 203d 2061       class_2 = a
-0000e270: 7567 6d65 6e74 6564 5f69 6d61 6765 735f  ugmented_images_
-0000e280: 6e65 6761 7469 7665 0a0a 2020 2020 2020  negative..      
-0000e290: 2020 2020 2020 2020 2020 2020 2020 2342                #B
-0000e2a0: 616c 616e 6365 2074 6865 2063 6c61 7373  alance the class
-0000e2b0: 2073 697a 6573 2069 6620 6e65 6365 7373   sizes if necess
-0000e2c0: 6172 790a 2020 2020 2020 2020 2020 2020  ary.            
-0000e2d0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-0000e2e0: 6261 6c61 6e63 653a 0a20 2020 2020 2020  balance:.       
-0000e2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e300: 2069 6620 7365 6c66 2e62 6174 6368 5f6f   if self.batch_o
-0000e310: 7468 6572 203e 2031 3a20 234d 7573 7420  ther > 1: #Must 
-0000e320: 7368 7566 666c 6521 2121 0a20 2020 2020  shuffle!!!.     
-0000e330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e340: 2020 2020 2020 2069 7820 3d20 6e70 2e72         ix = np.r
-0000e350: 616e 646f 6d2e 7065 726d 7574 6174 696f  andom.permutatio
-0000e360: 6e28 6c65 6e28 636c 6173 735f 3229 290a  n(len(class_2)).
-0000e370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e380: 2020 2020 2020 2020 2020 2020 636c 6173              clas
-0000e390: 735f 3220 3d20 636c 6173 735f 325b 6978  s_2 = class_2[ix
-0000e3a0: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
-0000e3b0: 2020 2020 2020 2020 2020 636c 6173 735f            class_
-0000e3c0: 3220 3d20 636c 6173 735f 325b 3a6c 656e  2 = class_2[:len
-0000e3d0: 2863 6c61 7373 5f31 295d 2020 200a 0a20  (class_1)]   .. 
-0000e3e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e3f0: 2020 2069 6620 7365 6c66 2e69 6d67 5f6e     if self.img_n
-0000e400: 756d 5f63 6861 6e6e 656c 7320 3d3d 2031  um_channels == 1
-0000e410: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000e420: 2020 2020 2020 2020 2020 636c 6173 735f            class_
-0000e430: 3220 3d20 7265 7369 7a65 2863 6c61 7373  2 = resize(class
-0000e440: 5f32 2c20 7369 7a65 3d69 6d61 6765 5f73  _2, size=image_s
-0000e450: 697a 6529 0a20 2020 2020 2020 2020 2020  ize).           
-0000e460: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-0000e470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e480: 2020 2020 2020 2063 6861 6e6e 656c 3120         channel1 
-0000e490: 3d20 7265 7369 7a65 2863 6c61 7373 5f32  = resize(class_2
-0000e4a0: 5b3a 2c3a 2c3a 2c30 5d2c 2073 697a 653d  [:,:,:,0], size=
-0000e4b0: 696d 6167 655f 7369 7a65 290a 2020 2020  image_size).    
-0000e4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e4d0: 2020 2020 6368 616e 6e65 6c32 203d 2072      channel2 = r
-0000e4e0: 6573 697a 6528 636c 6173 735f 325b 3a2c  esize(class_2[:,
-0000e4f0: 3a2c 3a2c 315d 2c20 7369 7a65 3d69 6d61  :,:,1], size=ima
-0000e500: 6765 5f73 697a 6529 0a20 2020 2020 2020  ge_size).       
-0000e510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e520: 2069 6620 7365 6c66 2e69 6d67 5f6e 756d   if self.img_num
-0000e530: 5f63 6861 6e6e 656c 7320 3d3d 2032 3a0a  _channels == 2:.
-0000e540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e550: 2020 2020 2020 2020 2020 2020 636c 6173              clas
-0000e560: 735f 3220 3d20 6461 7461 5f70 726f 6365  s_2 = data_proce
-0000e570: 7373 696e 672e 636f 6e63 6174 5f63 6861  ssing.concat_cha
-0000e580: 6e6e 656c 7328 6368 616e 6e65 6c31 2c20  nnels(channel1, 
-0000e590: 6368 616e 6e65 6c32 290a 2020 2020 2020  channel2).      
-0000e5a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e5b0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-0000e5c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e5d0: 2020 2020 6368 616e 6e65 6c33 203d 2072      channel3 = r
-0000e5e0: 6573 697a 6528 636c 6173 735f 325b 3a2c  esize(class_2[:,
-0000e5f0: 3a2c 3a2c 325d 2c20 7369 7a65 3d69 6d61  :,:,2], size=ima
-0000e600: 6765 5f73 697a 6529 0a20 2020 2020 2020  ge_size).       
-0000e610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e620: 2020 2020 2063 6c61 7373 5f32 203d 2064       class_2 = d
-0000e630: 6174 615f 7072 6f63 6573 7369 6e67 2e63  ata_processing.c
-0000e640: 6f6e 6361 745f 6368 616e 6e65 6c73 2863  oncat_channels(c
-0000e650: 6861 6e6e 656c 312c 2063 6861 6e6e 656c  hannel1, channel
-0000e660: 322c 2063 6861 6e6e 656c 3329 0a0a 2020  2, channel3)..  
-0000e670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e680: 2020 6966 2076 616c 5f63 6c61 7373 5f31    if val_class_1
-0000e690: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
-0000e6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e6b0: 2020 2020 2020 6966 2073 656c 662e 696d        if self.im
-0000e6c0: 675f 6e75 6d5f 6368 616e 6e65 6c73 203d  g_num_channels =
-0000e6d0: 3d20 313a 0a20 2020 2020 2020 2020 2020  = 1:.           
-0000e6e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e6f0: 2076 616c 5f63 6c61 7373 5f31 203d 2072   val_class_1 = r
-0000e700: 6573 697a 6528 7661 6c5f 636c 6173 735f  esize(val_class_
-0000e710: 312c 2073 697a 653d 696d 6167 655f 7369  1, size=image_si
-0000e720: 7a65 290a 2020 2020 2020 2020 2020 2020  ze).            
-0000e730: 2020 2020 2020 2020 2020 2020 656c 7365              else
-0000e740: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000e750: 2020 2020 2020 2020 2020 2020 2020 7661                va
-0000e760: 6c5f 6368 616e 6e65 6c31 203d 2072 6573  l_channel1 = res
-0000e770: 697a 6528 7661 6c5f 636c 6173 735f 315b  ize(val_class_1[
-0000e780: 3a2c 3a2c 3a2c 305d 2c20 7369 7a65 3d69  :,:,:,0], size=i
-0000e790: 6d61 6765 5f73 697a 6529 0a20 2020 2020  mage_size).     
-0000e7a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e7b0: 2020 2020 2020 2076 616c 5f63 6861 6e6e         val_chann
-0000e7c0: 656c 3220 3d20 7265 7369 7a65 2876 616c  el2 = resize(val
-0000e7d0: 5f63 6c61 7373 5f31 5b3a 2c3a 2c3a 2c31  _class_1[:,:,:,1
-0000e7e0: 5d2c 2073 697a 653d 696d 6167 655f 7369  ], size=image_si
-0000e7f0: 7a65 290a 2020 2020 2020 2020 2020 2020  ze).            
-0000e800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e810: 6966 2073 656c 662e 696d 675f 6e75 6d5f  if self.img_num_
-0000e820: 6368 616e 6e65 6c73 203d 3d20 323a 0a20  channels == 2:. 
-0000e830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e840: 2020 2020 2020 2020 2020 2020 2020 2076                 v
-0000e850: 616c 5f63 6c61 7373 5f31 203d 2064 6174  al_class_1 = dat
-0000e860: 615f 7072 6f63 6573 7369 6e67 2e63 6f6e  a_processing.con
-0000e870: 6361 745f 6368 616e 6e65 6c73 2876 616c  cat_channels(val
-0000e880: 5f63 6861 6e6e 656c 312c 2076 616c 5f63  _channel1, val_c
-0000e890: 6861 6e6e 656c 3229 0a20 2020 2020 2020  hannel2).       
-0000e8a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e8b0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-0000e8c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e8d0: 2020 2020 2020 2020 2020 2076 616c 5f63             val_c
-0000e8e0: 6861 6e6e 656c 3320 3d20 7265 7369 7a65  hannel3 = resize
-0000e8f0: 2876 616c 5f63 6c61 7373 5f31 5b3a 2c3a  (val_class_1[:,:
-0000e900: 2c3a 2c32 5d2c 2073 697a 653d 696d 6167  ,:,2], size=imag
-0000e910: 655f 7369 7a65 290a 2020 2020 2020 2020  e_size).        
-0000e920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e930: 2020 2020 2020 2020 7661 6c5f 636c 6173          val_clas
-0000e940: 735f 3120 3d20 6461 7461 5f70 726f 6365  s_1 = data_proce
-0000e950: 7373 696e 672e 636f 6e63 6174 5f63 6861  ssing.concat_cha
-0000e960: 6e6e 656c 7328 7661 6c5f 6368 616e 6e65  nnels(val_channe
-0000e970: 6c31 2c20 7661 6c5f 6368 616e 6e65 6c32  l1, val_channel2
-0000e980: 2c20 7661 6c5f 6368 616e 6e65 6c33 290a  , val_channel3).
-0000e990: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e9a0: 2020 2020 2069 6620 7661 6c5f 636c 6173       if val_clas
-0000e9b0: 735f 3220 6973 206e 6f74 204e 6f6e 653a  s_2 is not None:
-0000e9c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e9d0: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-0000e9e0: 2e69 6d67 5f6e 756d 5f63 6861 6e6e 656c  .img_num_channel
-0000e9f0: 7320 3d3d 2031 3a0a 2020 2020 2020 2020  s == 1:.        
+0000ad30: 2020 706f 6f6c 696e 675f 3320 3d20 7472    pooling_3 = tr
+0000ad40: 6961 6c2e 7375 6767 6573 745f 6361 7465  ial.suggest_cate
+0000ad50: 676f 7269 6361 6c28 2770 6f6f 6c69 6e67  gorical('pooling
+0000ad60: 5f33 272c 205b 276d 696e 272c 2027 6d61  _3', ['min', 'ma
+0000ad70: 7827 2c20 2761 7665 7261 6765 275d 290a  x', 'average']).
+0000ad80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ad90: 2020 2020 706f 6f6c 5f73 697a 655f 3320      pool_size_3 
+0000ada0: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+0000adb0: 696e 7428 2770 6f6f 6c5f 7369 7a65 5f33  int('pool_size_3
+0000adc0: 272c 2031 2c20 372c 2073 7465 703d 3129  ', 1, 7, step=1)
+0000add0: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000ade0: 2020 2323 2320 4465 6e73 6520 4c61 7965    ### Dense Laye
+0000adf0: 7273 2023 2323 0a0a 2020 2020 2020 2020  rs ###..        
+0000ae00: 2020 2020 2020 2020 6465 6e73 655f 6e65          dense_ne
+0000ae10: 7572 6f6e 735f 3120 3d20 7472 6961 6c2e  urons_1 = trial.
+0000ae20: 7375 6767 6573 745f 696e 7428 2764 656e  suggest_int('den
+0000ae30: 7365 5f6e 6575 726f 6e73 5f31 272c 2031  se_neurons_1', 1
+0000ae40: 3238 2c20 3634 3030 2c20 7374 6570 3d31  28, 6400, step=1
+0000ae50: 3238 290a 2020 2020 2020 2020 2020 2020  28).            
+0000ae60: 2020 2020 6472 6f70 6f75 745f 3120 3d20      dropout_1 = 
+0000ae70: 7472 6961 6c2e 7375 6767 6573 745f 666c  trial.suggest_fl
+0000ae80: 6f61 7428 2764 726f 706f 7574 5f31 272c  oat('dropout_1',
+0000ae90: 2030 2e30 2c20 302e 352c 2073 7465 703d   0.0, 0.5, step=
+0000aea0: 302e 3031 290a 2020 2020 2020 2020 2020  0.01).          
+0000aeb0: 2020 2020 2020 6e75 6d5f 6465 6e73 655f        num_dense_
+0000aec0: 6c61 7965 7273 203d 2074 7269 616c 2e73  layers = trial.s
+0000aed0: 7567 6765 7374 5f69 6e74 2827 6e75 6d5f  uggest_int('num_
+0000aee0: 6465 6e73 655f 6c61 7965 7273 272c 2031  dense_layers', 1
+0000aef0: 2c20 332c 2073 7465 703d 3129 0a0a 2020  , 3, step=1)..  
+0000af00: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000af10: 206e 756d 5f64 656e 7365 5f6c 6179 6572   num_dense_layer
+0000af20: 7320 3d3d 2031 3a0a 2020 2020 2020 2020  s == 1:.        
+0000af30: 2020 2020 2020 2020 2020 2020 6465 6e73              dens
+0000af40: 655f 6e65 7572 6f6e 735f 3220 3d20 6472  e_neurons_2 = dr
+0000af50: 6f70 6f75 745f 3220 3d20 6465 6e73 655f  opout_2 = dense_
+0000af60: 6e65 7572 6f6e 735f 3320 3d20 6472 6f70  neurons_3 = drop
+0000af70: 6f75 745f 3320 3d20 300a 2020 2020 2020  out_3 = 0.      
+0000af80: 2020 2020 2020 2020 2020 6966 206e 756d            if num
+0000af90: 5f64 656e 7365 5f6c 6179 6572 7320 3e3d  _dense_layers >=
+0000afa0: 2032 3a0a 2020 2020 2020 2020 2020 2020   2:.            
+0000afb0: 2020 2020 2020 2020 6465 6e73 655f 6e65          dense_ne
+0000afc0: 7572 6f6e 735f 3220 3d20 7472 6961 6c2e  urons_2 = trial.
+0000afd0: 7375 6767 6573 745f 696e 7428 2764 656e  suggest_int('den
+0000afe0: 7365 5f6e 6575 726f 6e73 5f32 272c 2031  se_neurons_2', 1
+0000aff0: 3238 2c20 3634 3030 2c20 7374 6570 3d31  28, 6400, step=1
+0000b000: 3238 290a 2020 2020 2020 2020 2020 2020  28).            
+0000b010: 2020 2020 2020 2020 6472 6f70 6f75 745f          dropout_
+0000b020: 3220 3d20 7472 6961 6c2e 7375 6767 6573  2 = trial.sugges
+0000b030: 745f 666c 6f61 7428 2764 726f 706f 7574  t_float('dropout
+0000b040: 5f32 272c 2030 2e30 2c20 302e 352c 2073  _2', 0.0, 0.5, s
+0000b050: 7465 703d 302e 3031 290a 2020 2020 2020  tep=0.01).      
+0000b060: 2020 2020 2020 2020 2020 2020 2020 6465                de
+0000b070: 6e73 655f 6e65 7572 6f6e 735f 3320 3d20  nse_neurons_3 = 
+0000b080: 6472 6f70 6f75 745f 3320 3d20 300a 2020  dropout_3 = 0.  
+0000b090: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000b0a0: 206e 756d 5f64 656e 7365 5f6c 6179 6572   num_dense_layer
+0000b0b0: 7320 3d3d 2033 3a0a 2020 2020 2020 2020  s == 3:.        
+0000b0c0: 2020 2020 2020 2020 2020 2020 6465 6e73              dens
+0000b0d0: 655f 6e65 7572 6f6e 735f 3320 3d20 7472  e_neurons_3 = tr
+0000b0e0: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
+0000b0f0: 2764 656e 7365 5f6e 6575 726f 6e73 5f33  'dense_neurons_3
+0000b100: 272c 2031 3238 2c20 3634 3030 2c20 7374  ', 128, 6400, st
+0000b110: 6570 3d31 3238 290a 2020 2020 2020 2020  ep=128).        
+0000b120: 2020 2020 2020 2020 2020 2020 6472 6f70              drop
+0000b130: 6f75 745f 3320 3d20 7472 6961 6c2e 7375  out_3 = trial.su
+0000b140: 6767 6573 745f 666c 6f61 7428 2764 726f  ggest_float('dro
+0000b150: 706f 7574 5f33 272c 2030 2e30 2c20 302e  pout_3', 0.0, 0.
+0000b160: 352c 2073 7465 703d 302e 3031 290a 0a20  5, step=0.01).. 
+0000b170: 2020 2020 2020 2020 2020 2020 2020 206d                 m
+0000b180: 6f64 656c 2c20 6869 7374 6f72 7920 3d20  odel, history = 
+0000b190: 636e 6e5f 6d6f 6465 6c2e 6375 7374 6f6d  cnn_model.custom
+0000b1a0: 5f6d 6f64 656c 2863 6c61 7373 5f31 2c20  _model(class_1, 
+0000b1b0: 636c 6173 735f 322c 2069 6d67 5f6e 756d  class_2, img_num
+0000b1c0: 5f63 6861 6e6e 656c 733d 7365 6c66 2e69  _channels=self.i
+0000b1d0: 6d67 5f6e 756d 5f63 6861 6e6e 656c 732c  mg_num_channels,
+0000b1e0: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+0000b1f0: 2020 2020 2020 6e6f 726d 616c 697a 653d        normalize=
+0000b200: 7365 6c66 2e6e 6f72 6d61 6c69 7a65 2c20  self.normalize, 
+0000b210: 6d69 6e5f 7069 7865 6c3d 6d69 6e5f 7069  min_pixel=min_pi
+0000b220: 782c 206d 6178 5f70 6978 656c 3d6d 6178  x, max_pixel=max
+0000b230: 5f70 6978 2c20 7661 6c5f 706f 7369 7469  _pix, val_positi
+0000b240: 7665 3d76 616c 5f63 6c61 7373 5f31 2c20  ve=val_class_1, 
+0000b250: 7661 6c5f 6e65 6761 7469 7665 3d76 616c  val_negative=val
+0000b260: 5f63 6c61 7373 5f32 2c20 0a20 2020 2020  _class_2, .     
+0000b270: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+0000b280: 706f 6368 733d 7365 6c66 2e74 7261 696e  pochs=self.train
+0000b290: 5f65 706f 6368 732c 2062 6174 6368 5f73  _epochs, batch_s
+0000b2a0: 697a 653d 6261 7463 685f 7369 7a65 2c20  ize=batch_size, 
+0000b2b0: 6f70 7469 6d69 7a65 723d 6f70 7469 6d69  optimizer=optimi
+0000b2c0: 7a65 722c 206c 723d 6c72 2c20 6465 6361  zer, lr=lr, deca
+0000b2d0: 793d 6465 6361 792c 206d 6f6d 656e 7475  y=decay, momentu
+0000b2e0: 6d3d 6d6f 6d65 6e74 756d 2c20 6e65 7374  m=momentum, nest
+0000b2f0: 6572 6f76 3d6e 6573 7465 726f 762c 200a  erov=nesterov, .
+0000b300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b310: 2020 2020 6265 7461 5f31 3d62 6574 615f      beta_1=beta_
+0000b320: 312c 2062 6574 615f 323d 6265 7461 5f32  1, beta_2=beta_2
+0000b330: 2c20 616d 7367 7261 643d 616d 7367 7261  , amsgrad=amsgra
+0000b340: 642c 206c 6f73 733d 6c6f 7373 2c20 6163  d, loss=loss, ac
+0000b350: 7469 7661 7469 6f6e 5f63 6f6e 763d 6163  tivation_conv=ac
+0000b360: 7469 7661 7469 6f6e 5f63 6f6e 762c 2061  tivation_conv, a
+0000b370: 6374 6976 6174 696f 6e5f 6465 6e73 653d  ctivation_dense=
+0000b380: 6163 7469 7661 7469 6f6e 5f64 656e 7365  activation_dense
+0000b390: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+0000b3a0: 2020 2020 2020 2063 6f6e 765f 696e 6974         conv_init
+0000b3b0: 3d63 6f6e 765f 696e 6974 2c20 6465 6e73  =conv_init, dens
+0000b3c0: 655f 696e 6974 3d64 656e 7365 5f69 6e69  e_init=dense_ini
+0000b3d0: 742c 206d 6f64 656c 5f72 6567 3d6d 6f64  t, model_reg=mod
+0000b3e0: 656c 5f72 6567 2c20 0a20 2020 2020 2020  el_reg, .       
+0000b3f0: 2020 2020 2020 2020 2020 2020 2066 696c               fil
+0000b400: 7465 725f 313d 6669 6c74 6572 5f31 2c20  ter_1=filter_1, 
+0000b410: 6669 6c74 6572 5f73 697a 655f 313d 6669  filter_size_1=fi
+0000b420: 6c74 6572 5f73 697a 655f 312c 2073 7472  lter_size_1, str
+0000b430: 6964 6573 5f31 3d73 7472 6964 6573 5f31  ides_1=strides_1
+0000b440: 2c20 706f 6f6c 696e 675f 313d 706f 6f6c  , pooling_1=pool
+0000b450: 696e 675f 312c 2070 6f6f 6c5f 7369 7a65  ing_1, pool_size
+0000b460: 5f31 3d70 6f6f 6c5f 7369 7a65 5f31 2c20  _1=pool_size_1, 
+0000b470: 706f 6f6c 5f73 7472 6964 655f 313d 706f  pool_stride_1=po
+0000b480: 6f6c 5f73 7472 6964 655f 312c 200a 2020  ol_stride_1, .  
+0000b490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b4a0: 2020 6669 6c74 6572 5f32 3d66 696c 7465    filter_2=filte
+0000b4b0: 725f 322c 2066 696c 7465 725f 7369 7a65  r_2, filter_size
+0000b4c0: 5f32 3d66 696c 7465 725f 7369 7a65 5f32  _2=filter_size_2
+0000b4d0: 2c20 7374 7269 6465 735f 323d 7374 7269  , strides_2=stri
+0000b4e0: 6465 735f 322c 2070 6f6f 6c69 6e67 5f32  des_2, pooling_2
+0000b4f0: 3d70 6f6f 6c69 6e67 5f32 2c20 706f 6f6c  =pooling_2, pool
+0000b500: 5f73 697a 655f 323d 706f 6f6c 5f73 697a  _size_2=pool_siz
+0000b510: 655f 322c 2070 6f6f 6c5f 7374 7269 6465  e_2, pool_stride
+0000b520: 5f32 3d70 6f6f 6c5f 7374 7269 6465 5f32  _2=pool_stride_2
+0000b530: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+0000b540: 2020 2020 2020 2066 696c 7465 725f 333d         filter_3=
+0000b550: 6669 6c74 6572 5f33 2c20 6669 6c74 6572  filter_3, filter
+0000b560: 5f73 697a 655f 333d 6669 6c74 6572 5f73  _size_3=filter_s
+0000b570: 697a 655f 332c 2073 7472 6964 6573 5f33  ize_3, strides_3
+0000b580: 3d73 7472 6964 6573 5f33 2c20 706f 6f6c  =strides_3, pool
+0000b590: 696e 675f 333d 706f 6f6c 696e 675f 332c  ing_3=pooling_3,
+0000b5a0: 2070 6f6f 6c5f 7369 7a65 5f33 3d70 6f6f   pool_size_3=poo
+0000b5b0: 6c5f 7369 7a65 5f33 2c20 706f 6f6c 5f73  l_size_3, pool_s
+0000b5c0: 7472 6964 655f 333d 706f 6f6c 5f73 7472  tride_3=pool_str
+0000b5d0: 6964 655f 332c 200a 2020 2020 2020 2020  ide_3, .        
+0000b5e0: 2020 2020 2020 2020 2020 2020 6465 6e73              dens
+0000b5f0: 655f 6e65 7572 6f6e 735f 313d 6465 6e73  e_neurons_1=dens
+0000b600: 655f 6e65 7572 6f6e 735f 312c 2064 656e  e_neurons_1, den
+0000b610: 7365 5f6e 6575 726f 6e73 5f32 3d64 656e  se_neurons_2=den
+0000b620: 7365 5f6e 6575 726f 6e73 5f32 2c20 6465  se_neurons_2, de
+0000b630: 6e73 655f 6e65 7572 6f6e 735f 333d 6465  nse_neurons_3=de
+0000b640: 6e73 655f 6e65 7572 6f6e 735f 332c 200a  nse_neurons_3, .
+0000b650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b660: 2020 2020 6472 6f70 6f75 745f 313d 6472      dropout_1=dr
+0000b670: 6f70 6f75 745f 312c 2064 726f 706f 7574  opout_1, dropout
+0000b680: 5f32 3d64 726f 706f 7574 5f32 2c20 6472  _2=dropout_2, dr
+0000b690: 6f70 6f75 745f 333d 6472 6f70 6f75 745f  opout_3=dropout_
+0000b6a0: 332c 2073 6d6f 7465 5f73 616d 706c 696e  3, smote_samplin
+0000b6b0: 673d 7365 6c66 2e73 6d6f 7465 5f73 616d  g=self.smote_sam
+0000b6c0: 706c 696e 672c 2020 0a20 2020 2020 2020  pling,  .       
+0000b6d0: 2020 2020 2020 2020 2020 2020 2065 6172               ear
+0000b6e0: 6c79 5f73 746f 705f 6361 6c6c 6261 636b  ly_stop_callback
+0000b6f0: 3d63 616c 6c62 6163 6b73 2c20 6368 6563  =callbacks, chec
+0000b700: 6b70 6f69 6e74 3d46 616c 7365 2c20 7665  kpoint=False, ve
+0000b710: 7262 6f73 653d 7365 6c66 2e76 6572 626f  rbose=self.verbo
+0000b720: 7365 290a 0a20 2020 2020 2020 2020 2020  se)..           
+0000b730: 2065 6c69 6620 7365 6c66 2e63 6c66 203d   elif self.clf =
+0000b740: 3d20 2776 6767 3136 273a 0a20 2020 2020  = 'vgg16':.     
+0000b750: 2020 2020 2020 2020 2020 2023 2323 2052             ### R
+0000b760: 6567 756c 6172 697a 6174 696f 6e20 5465  egularization Te
+0000b770: 6368 6e69 7175 6520 2842 4e20 6973 206e  chnique (BN is n
+0000b780: 6577 6572 2c20 5647 4731 3620 7573 6564  ewer, VGG16 used
+0000b790: 204e 6f6e 6529 2023 2323 0a20 2020 2020   None) ###.     
+0000b7a0: 2020 2020 2020 2020 2020 206d 6f64 656c             model
+0000b7b0: 5f72 6567 203d 2074 7269 616c 2e73 7567  _reg = trial.sug
+0000b7c0: 6765 7374 5f63 6174 6567 6f72 6963 616c  gest_categorical
+0000b7d0: 2827 6d6f 6465 6c5f 7265 6727 2c20 5b4e  ('model_reg', [N
+0000b7e0: 6f6e 652c 2027 6261 7463 685f 6e6f 726d  one, 'batch_norm
+0000b7f0: 272c 2027 6c6f 6361 6c5f 7265 7370 6f6e  ', 'local_respon
+0000b800: 7365 275d 290a 0a20 2020 2020 2020 2020  se'])..         
+0000b810: 2020 2020 2020 2023 2323 204f 6e6c 7920         ### Only 
+0000b820: 7468 6520 706f 6f6c 696e 6720 7479 7065  the pooling type
+0000b830: 7320 6172 6520 6f70 7469 6d69 7a65 6420  s are optimized 
+0000b840: 6966 206c 696d 6974 5f73 6561 7263 683d  if limit_search=
+0000b850: 5472 7565 2023 2323 0a20 2020 2020 2020  True ###.       
+0000b860: 2020 2020 2020 2020 2070 6f6f 6c69 6e67           pooling
+0000b870: 5f31 203d 2074 7269 616c 2e73 7567 6765  _1 = trial.sugge
+0000b880: 7374 5f63 6174 6567 6f72 6963 616c 2827  st_categorical('
+0000b890: 706f 6f6c 696e 675f 3127 2c20 5b27 6d69  pooling_1', ['mi
+0000b8a0: 6e27 2c20 276d 6178 272c 2027 6176 6572  n', 'max', 'aver
+0000b8b0: 6167 6527 5d29 0a20 2020 2020 2020 2020  age']).         
+0000b8c0: 2020 2020 2020 2070 6f6f 6c69 6e67 5f32         pooling_2
+0000b8d0: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
+0000b8e0: 5f63 6174 6567 6f72 6963 616c 2827 706f  _categorical('po
+0000b8f0: 6f6c 696e 675f 3227 2c20 5b27 6d69 6e27  oling_2', ['min'
+0000b900: 2c20 276d 6178 272c 2027 6176 6572 6167  , 'max', 'averag
+0000b910: 6527 5d29 0a20 2020 2020 2020 2020 2020  e']).           
+0000b920: 2020 2020 2070 6f6f 6c69 6e67 5f33 203d       pooling_3 =
+0000b930: 2074 7269 616c 2e73 7567 6765 7374 5f63   trial.suggest_c
+0000b940: 6174 6567 6f72 6963 616c 2827 706f 6f6c  ategorical('pool
+0000b950: 696e 675f 3327 2c20 5b27 6d69 6e27 2c20  ing_3', ['min', 
+0000b960: 276d 6178 272c 2027 6176 6572 6167 6527  'max', 'average'
+0000b970: 5d29 0a20 2020 2020 2020 2020 2020 2020  ]).             
+0000b980: 2020 2070 6f6f 6c69 6e67 5f34 203d 2074     pooling_4 = t
+0000b990: 7269 616c 2e73 7567 6765 7374 5f63 6174  rial.suggest_cat
+0000b9a0: 6567 6f72 6963 616c 2827 706f 6f6c 696e  egorical('poolin
+0000b9b0: 675f 3427 2c20 5b27 6d69 6e27 2c20 276d  g_4', ['min', 'm
+0000b9c0: 6178 272c 2027 6176 6572 6167 6527 5d29  ax', 'average'])
+0000b9d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000b9e0: 2070 6f6f 6c69 6e67 5f35 203d 2074 7269   pooling_5 = tri
+0000b9f0: 616c 2e73 7567 6765 7374 5f63 6174 6567  al.suggest_categ
+0000ba00: 6f72 6963 616c 2827 706f 6f6c 696e 675f  orical('pooling_
+0000ba10: 3527 2c20 5b27 6d69 6e27 2c20 276d 6178  5', ['min', 'max
+0000ba20: 272c 2027 6176 6572 6167 6527 5d29 0a0a  ', 'average'])..
+0000ba30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ba40: 6966 2073 656c 662e 6c69 6d69 745f 7365  if self.limit_se
+0000ba50: 6172 6368 3a0a 2020 2020 2020 2020 2020  arch:.          
+0000ba60: 2020 2020 2020 2020 2020 6d6f 6465 6c2c            model,
+0000ba70: 2068 6973 746f 7279 203d 2063 6e6e 5f6d   history = cnn_m
+0000ba80: 6f64 656c 2e56 4747 3136 2863 6c61 7373  odel.VGG16(class
+0000ba90: 5f31 2c20 636c 6173 735f 322c 2069 6d67  _1, class_2, img
+0000baa0: 5f6e 756d 5f63 6861 6e6e 656c 733d 7365  _num_channels=se
+0000bab0: 6c66 2e69 6d67 5f6e 756d 5f63 6861 6e6e  lf.img_num_chann
+0000bac0: 656c 732c 200a 2020 2020 2020 2020 2020  els, .          
+0000bad0: 2020 2020 2020 2020 2020 2020 2020 6e6f                no
+0000bae0: 726d 616c 697a 653d 7365 6c66 2e6e 6f72  rmalize=self.nor
+0000baf0: 6d61 6c69 7a65 2c20 6d69 6e5f 7069 7865  malize, min_pixe
+0000bb00: 6c3d 6d69 6e5f 7069 782c 206d 6178 5f70  l=min_pix, max_p
+0000bb10: 6978 656c 3d6d 6178 5f70 6978 2c20 7661  ixel=max_pix, va
+0000bb20: 6c5f 706f 7369 7469 7665 3d76 616c 5f63  l_positive=val_c
+0000bb30: 6c61 7373 5f31 2c20 7661 6c5f 6e65 6761  lass_1, val_nega
+0000bb40: 7469 7665 3d76 616c 5f63 6c61 7373 5f32  tive=val_class_2
+0000bb50: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+0000bb60: 2020 2020 2020 2020 2020 2065 706f 6368             epoch
+0000bb70: 733d 7365 6c66 2e74 7261 696e 5f65 706f  s=self.train_epo
+0000bb80: 6368 732c 2062 6174 6368 5f73 697a 653d  chs, batch_size=
+0000bb90: 6261 7463 685f 7369 7a65 2c20 6f70 7469  batch_size, opti
+0000bba0: 6d69 7a65 723d 6f70 7469 6d69 7a65 722c  mizer=optimizer,
+0000bbb0: 206c 723d 6c72 2c20 6465 6361 793d 6465   lr=lr, decay=de
+0000bbc0: 6361 792c 206d 6f6d 656e 7475 6d3d 6d6f  cay, momentum=mo
+0000bbd0: 6d65 6e74 756d 2c20 6e65 7374 6572 6f76  mentum, nesterov
+0000bbe0: 3d6e 6573 7465 726f 762c 200a 2020 2020  =nesterov, .    
+0000bbf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bc00: 2020 2020 6265 7461 5f31 3d62 6574 615f      beta_1=beta_
+0000bc10: 312c 2062 6574 615f 323d 6265 7461 5f32  1, beta_2=beta_2
+0000bc20: 2c20 616d 7367 7261 643d 616d 7367 7261  , amsgrad=amsgra
+0000bc30: 642c 206c 6f73 733d 6c6f 7373 2c20 6163  d, loss=loss, ac
+0000bc40: 7469 7661 7469 6f6e 5f63 6f6e 763d 6163  tivation_conv=ac
+0000bc50: 7469 7661 7469 6f6e 5f63 6f6e 762c 2061  tivation_conv, a
+0000bc60: 6374 6976 6174 696f 6e5f 6465 6e73 653d  ctivation_dense=
+0000bc70: 6163 7469 7661 7469 6f6e 5f64 656e 7365  activation_dense
+0000bc80: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+0000bc90: 2020 2020 2020 2020 2020 2063 6f6e 765f             conv_
+0000bca0: 696e 6974 3d63 6f6e 765f 696e 6974 2c20  init=conv_init, 
+0000bcb0: 6465 6e73 655f 696e 6974 3d64 656e 7365  dense_init=dense
+0000bcc0: 5f69 6e69 742c 206d 6f64 656c 5f72 6567  _init, model_reg
+0000bcd0: 3d6d 6f64 656c 5f72 6567 2c0a 2020 2020  =model_reg,.    
+0000bce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bcf0: 2020 2020 706f 6f6c 696e 675f 313d 706f      pooling_1=po
+0000bd00: 6f6c 696e 675f 312c 2070 6f6f 6c69 6e67  oling_1, pooling
+0000bd10: 5f32 3d70 6f6f 6c69 6e67 5f32 2c20 706f  _2=pooling_2, po
+0000bd20: 6f6c 696e 675f 333d 706f 6f6c 696e 675f  oling_3=pooling_
+0000bd30: 332c 2070 6f6f 6c69 6e67 5f34 3d70 6f6f  3, pooling_4=poo
+0000bd40: 6c69 6e67 5f34 2c20 706f 6f6c 696e 675f  ling_4, pooling_
+0000bd50: 353d 706f 6f6c 696e 675f 352c 0a20 2020  5=pooling_5,.   
+0000bd60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bd70: 2020 2020 2073 6d6f 7465 5f73 616d 706c       smote_sampl
+0000bd80: 696e 673d 7365 6c66 2e73 6d6f 7465 5f73  ing=self.smote_s
+0000bd90: 616d 706c 696e 672c 2065 6172 6c79 5f73  ampling, early_s
+0000bda0: 746f 705f 6361 6c6c 6261 636b 3d63 616c  top_callback=cal
+0000bdb0: 6c62 6163 6b73 2c20 6368 6563 6b70 6f69  lbacks, checkpoi
+0000bdc0: 6e74 3d46 616c 7365 2c20 7665 7262 6f73  nt=False, verbos
+0000bdd0: 653d 7365 6c66 2e76 6572 626f 7365 290a  e=self.verbose).
+0000bde0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bdf0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+0000be00: 2020 2020 2020 2020 2020 2323 2320 4669            ### Fi
+0000be10: 6c74 6572 2061 6e64 204c 6179 6572 2043  lter and Layer C
+0000be20: 6861 7261 6374 6572 7374 6963 7320 2323  haracterstics ##
+0000be30: 230a 2020 2020 2020 2020 2020 2020 2020  #.              
+0000be40: 2020 2020 2020 6669 6c74 6572 5f31 203d        filter_1 =
+0000be50: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+0000be60: 6e74 2827 6669 6c74 6572 5f31 272c 2031  nt('filter_1', 1
+0000be70: 322c 2035 3136 2c20 7374 6570 3d31 3229  2, 516, step=12)
+0000be80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000be90: 2020 2020 2066 696c 7465 725f 7369 7a65       filter_size
+0000bea0: 5f31 203d 2074 7269 616c 2e73 7567 6765  _1 = trial.sugge
+0000beb0: 7374 5f69 6e74 2827 6669 6c74 6572 5f73  st_int('filter_s
+0000bec0: 697a 655f 3127 2c20 312c 2031 312c 2073  ize_1', 1, 11, s
+0000bed0: 7465 703d 3229 0a20 2020 2020 2020 2020  tep=2).         
+0000bee0: 2020 2020 2020 2020 2020 2073 7472 6964             strid
+0000bef0: 6573 5f31 203d 2074 7269 616c 2e73 7567  es_1 = trial.sug
+0000bf00: 6765 7374 5f69 6e74 2827 7374 7269 6465  gest_int('stride
+0000bf10: 735f 3127 2c20 312c 2033 2c20 7374 6570  s_1', 1, 3, step
+0000bf20: 3d31 290a 2020 2020 2020 2020 2020 2020  =1).            
+0000bf30: 2020 2020 2020 2020 706f 6f6c 5f73 697a          pool_siz
+0000bf40: 655f 3120 3d20 7472 6961 6c2e 7375 6767  e_1 = trial.sugg
+0000bf50: 6573 745f 696e 7428 2770 6f6f 6c5f 7369  est_int('pool_si
+0000bf60: 7a65 5f31 272c 2031 2c20 372c 2073 7465  ze_1', 1, 7, ste
+0000bf70: 703d 3129 0a20 2020 2020 2020 2020 2020  p=1).           
+0000bf80: 2020 2020 2020 2020 2070 6f6f 6c5f 7374           pool_st
+0000bf90: 7269 6465 5f31 203d 2074 7269 616c 2e73  ride_1 = trial.s
+0000bfa0: 7567 6765 7374 5f69 6e74 2827 706f 6f6c  uggest_int('pool
+0000bfb0: 5f73 7472 6964 655f 3127 2c20 312c 2033  _stride_1', 1, 3
+0000bfc0: 2c20 7374 6570 3d31 290a 0a20 2020 2020  , step=1)..     
+0000bfd0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0000bfe0: 696c 7465 725f 3220 3d20 7472 6961 6c2e  ilter_2 = trial.
+0000bff0: 7375 6767 6573 745f 696e 7428 2766 696c  suggest_int('fil
+0000c000: 7465 725f 3227 2c20 3132 2c20 3531 362c  ter_2', 12, 516,
+0000c010: 2073 7465 703d 3132 290a 2020 2020 2020   step=12).      
+0000c020: 2020 2020 2020 2020 2020 2020 2020 6669                fi
+0000c030: 6c74 6572 5f73 697a 655f 3220 3d20 7472  lter_size_2 = tr
+0000c040: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
+0000c050: 2766 696c 7465 725f 7369 7a65 5f32 272c  'filter_size_2',
+0000c060: 2031 2c20 372c 2073 7465 703d 3229 0a20   1, 7, step=2). 
+0000c070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c080: 2020 2073 7472 6964 6573 5f32 203d 2074     strides_2 = t
+0000c090: 7269 616c 2e73 7567 6765 7374 5f69 6e74  rial.suggest_int
+0000c0a0: 2827 7374 7269 6465 735f 3227 2c20 312c  ('strides_2', 1,
+0000c0b0: 2033 2c20 7374 6570 3d31 290a 2020 2020   3, step=1).    
+0000c0c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c0d0: 706f 6f6c 5f73 697a 655f 3220 3d20 7472  pool_size_2 = tr
+0000c0e0: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
+0000c0f0: 2770 6f6f 6c5f 7369 7a65 5f32 272c 2031  'pool_size_2', 1
+0000c100: 2c20 372c 2073 7465 703d 3129 0a20 2020  , 7, step=1).   
+0000c110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c120: 2070 6f6f 6c5f 7374 7269 6465 5f32 203d   pool_stride_2 =
+0000c130: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+0000c140: 6e74 2827 706f 6f6c 5f73 7472 6964 655f  nt('pool_stride_
+0000c150: 3227 2c20 312c 2033 2c20 7374 6570 3d31  2', 1, 3, step=1
+0000c160: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
+0000c170: 2020 2020 2020 2066 696c 7465 725f 3320         filter_3 
+0000c180: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+0000c190: 696e 7428 2766 696c 7465 725f 3327 2c20  int('filter_3', 
+0000c1a0: 3132 2c20 3531 362c 2073 7465 703d 3132  12, 516, step=12
+0000c1b0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0000c1c0: 2020 2020 2020 6669 6c74 6572 5f73 697a        filter_siz
+0000c1d0: 655f 3320 3d20 7472 6961 6c2e 7375 6767  e_3 = trial.sugg
+0000c1e0: 6573 745f 696e 7428 2766 696c 7465 725f  est_int('filter_
+0000c1f0: 7369 7a65 5f33 272c 2031 2c20 372c 2073  size_3', 1, 7, s
+0000c200: 7465 703d 3229 0a20 2020 2020 2020 2020  tep=2).         
+0000c210: 2020 2020 2020 2020 2020 2073 7472 6964             strid
+0000c220: 6573 5f33 203d 2074 7269 616c 2e73 7567  es_3 = trial.sug
+0000c230: 6765 7374 5f69 6e74 2827 7374 7269 6465  gest_int('stride
+0000c240: 735f 3327 2c20 312c 2033 2c20 7374 6570  s_3', 1, 3, step
+0000c250: 3d31 290a 2020 2020 2020 2020 2020 2020  =1).            
+0000c260: 2020 2020 2020 2020 706f 6f6c 5f73 697a          pool_siz
+0000c270: 655f 3320 3d20 7472 6961 6c2e 7375 6767  e_3 = trial.sugg
+0000c280: 6573 745f 696e 7428 2770 6f6f 6c5f 7369  est_int('pool_si
+0000c290: 7a65 5f33 272c 2031 2c20 372c 2073 7465  ze_3', 1, 7, ste
+0000c2a0: 703d 3129 0a20 2020 2020 2020 2020 2020  p=1).           
+0000c2b0: 2020 2020 2020 2020 2070 6f6f 6c5f 7374           pool_st
+0000c2c0: 7269 6465 5f33 203d 2074 7269 616c 2e73  ride_3 = trial.s
+0000c2d0: 7567 6765 7374 5f69 6e74 2827 706f 6f6c  uggest_int('pool
+0000c2e0: 5f73 7472 6964 655f 3327 2c20 312c 2033  _stride_3', 1, 3
+0000c2f0: 2c20 7374 6570 3d31 290a 0a20 2020 2020  , step=1)..     
+0000c300: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0000c310: 696c 7465 725f 3420 3d20 7472 6961 6c2e  ilter_4 = trial.
+0000c320: 7375 6767 6573 745f 696e 7428 2766 696c  suggest_int('fil
+0000c330: 7465 725f 3427 2c20 3132 2c20 3531 362c  ter_4', 12, 516,
+0000c340: 2073 7465 703d 3132 290a 2020 2020 2020   step=12).      
+0000c350: 2020 2020 2020 2020 2020 2020 2020 6669                fi
+0000c360: 6c74 6572 5f73 697a 655f 3420 3d20 7472  lter_size_4 = tr
+0000c370: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
+0000c380: 2766 696c 7465 725f 7369 7a65 5f34 272c  'filter_size_4',
+0000c390: 2031 2c20 372c 2073 7465 703d 3229 0a20   1, 7, step=2). 
+0000c3a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c3b0: 2020 2073 7472 6964 6573 5f34 203d 2074     strides_4 = t
+0000c3c0: 7269 616c 2e73 7567 6765 7374 5f69 6e74  rial.suggest_int
+0000c3d0: 2827 7374 7269 6465 735f 3427 2c20 312c  ('strides_4', 1,
+0000c3e0: 2033 2c20 7374 6570 3d31 290a 2020 2020   3, step=1).    
+0000c3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c400: 706f 6f6c 5f73 697a 655f 3420 3d20 7472  pool_size_4 = tr
+0000c410: 6961 6c2e 7375 6767 6573 745f 696e 7428  ial.suggest_int(
+0000c420: 2770 6f6f 6c5f 7369 7a65 5f34 272c 2031  'pool_size_4', 1
+0000c430: 2c20 372c 2073 7465 703d 3129 0a20 2020  , 7, step=1).   
+0000c440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c450: 2070 6f6f 6c5f 7374 7269 6465 5f34 203d   pool_stride_4 =
+0000c460: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+0000c470: 6e74 2827 706f 6f6c 5f73 7472 6964 655f  nt('pool_stride_
+0000c480: 3427 2c20 312c 2033 2c20 7374 6570 3d31  4', 1, 3, step=1
+0000c490: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
+0000c4a0: 2020 2020 2020 2066 696c 7465 725f 3520         filter_5 
+0000c4b0: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+0000c4c0: 696e 7428 2766 696c 7465 725f 3527 2c20  int('filter_5', 
+0000c4d0: 3132 2c20 3531 362c 2073 7465 703d 3132  12, 516, step=12
+0000c4e0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0000c4f0: 2020 2020 2020 6669 6c74 6572 5f73 697a        filter_siz
+0000c500: 655f 3520 3d20 7472 6961 6c2e 7375 6767  e_5 = trial.sugg
+0000c510: 6573 745f 696e 7428 2766 696c 7465 725f  est_int('filter_
+0000c520: 7369 7a65 5f35 272c 2031 2c20 372c 2073  size_5', 1, 7, s
+0000c530: 7465 703d 3229 0a20 2020 2020 2020 2020  tep=2).         
+0000c540: 2020 2020 2020 2020 2020 2073 7472 6964             strid
+0000c550: 6573 5f35 203d 2074 7269 616c 2e73 7567  es_5 = trial.sug
+0000c560: 6765 7374 5f69 6e74 2827 7374 7269 6465  gest_int('stride
+0000c570: 735f 3527 2c20 312c 2033 2c20 7374 6570  s_5', 1, 3, step
+0000c580: 3d31 2920 0a20 2020 2020 2020 2020 2020  =1) .           
+0000c590: 2020 2020 2020 2020 2070 6f6f 6c5f 7369           pool_si
+0000c5a0: 7a65 5f35 203d 2074 7269 616c 2e73 7567  ze_5 = trial.sug
+0000c5b0: 6765 7374 5f69 6e74 2827 706f 6f6c 5f73  gest_int('pool_s
+0000c5c0: 697a 655f 3527 2c20 312c 2037 2c20 7374  ize_5', 1, 7, st
+0000c5d0: 6570 3d31 290a 2020 2020 2020 2020 2020  ep=1).          
+0000c5e0: 2020 2020 2020 2020 2020 706f 6f6c 5f73            pool_s
+0000c5f0: 7472 6964 655f 3520 3d20 7472 6961 6c2e  tride_5 = trial.
+0000c600: 7375 6767 6573 745f 696e 7428 2770 6f6f  suggest_int('poo
+0000c610: 6c5f 7374 7269 6465 5f35 272c 2031 2c20  l_stride_5', 1, 
+0000c620: 332c 2073 7465 703d 3129 0a0a 2020 2020  3, step=1)..    
+0000c630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c640: 2323 2320 4465 6e73 6520 4c61 7965 7273  ### Dense Layers
+0000c650: 2023 2323 0a20 2020 2020 2020 2020 2020   ###.           
+0000c660: 2020 2020 2020 2020 2064 656e 7365 5f6e           dense_n
+0000c670: 6575 726f 6e73 5f31 203d 2074 7269 616c  eurons_1 = trial
+0000c680: 2e73 7567 6765 7374 5f69 6e74 2827 6465  .suggest_int('de
+0000c690: 6e73 655f 6e65 7572 6f6e 735f 3127 2c20  nse_neurons_1', 
+0000c6a0: 3132 382c 2036 3430 302c 2073 7465 703d  128, 6400, step=
+0000c6b0: 3132 3829 0a20 2020 2020 2020 2020 2020  128).           
+0000c6c0: 2020 2020 2020 2020 2064 656e 7365 5f6e           dense_n
+0000c6d0: 6575 726f 6e73 5f32 203d 2074 7269 616c  eurons_2 = trial
+0000c6e0: 2e73 7567 6765 7374 5f69 6e74 2827 6465  .suggest_int('de
+0000c6f0: 6e73 655f 6e65 7572 6f6e 735f 3227 2c20  nse_neurons_2', 
+0000c700: 3132 382c 2036 3430 302c 2073 7465 703d  128, 6400, step=
+0000c710: 3132 3829 0a20 2020 2020 2020 2020 2020  128).           
+0000c720: 2020 2020 2020 2020 2064 726f 706f 7574           dropout
+0000c730: 5f31 203d 2074 7269 616c 2e73 7567 6765  _1 = trial.sugge
+0000c740: 7374 5f66 6c6f 6174 2827 6472 6f70 6f75  st_float('dropou
+0000c750: 745f 3127 2c20 302e 302c 2030 2e35 2c20  t_1', 0.0, 0.5, 
+0000c760: 7374 6570 3d30 2e30 3129 0a20 2020 2020  step=0.01).     
+0000c770: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+0000c780: 726f 706f 7574 5f32 203d 2074 7269 616c  ropout_2 = trial
+0000c790: 2e73 7567 6765 7374 5f66 6c6f 6174 2827  .suggest_float('
+0000c7a0: 6472 6f70 6f75 745f 3227 2c20 302e 302c  dropout_2', 0.0,
+0000c7b0: 2030 2e35 2c20 7374 6570 3d30 2e30 3129   0.5, step=0.01)
+0000c7c0: 200a 0a20 2020 2020 2020 2020 2020 2020   ..             
+0000c7d0: 2020 2020 2020 206d 6f64 656c 2c20 6869         model, hi
+0000c7e0: 7374 6f72 7920 3d20 636e 6e5f 6d6f 6465  story = cnn_mode
+0000c7f0: 6c2e 5647 4731 3628 636c 6173 735f 312c  l.VGG16(class_1,
+0000c800: 2063 6c61 7373 5f32 2c20 696d 675f 6e75   class_2, img_nu
+0000c810: 6d5f 6368 616e 6e65 6c73 3d73 656c 662e  m_channels=self.
+0000c820: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+0000c830: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+0000c840: 2020 2020 2020 2020 2020 206e 6f72 6d61             norma
+0000c850: 6c69 7a65 3d73 656c 662e 6e6f 726d 616c  lize=self.normal
+0000c860: 697a 652c 206d 696e 5f70 6978 656c 3d6d  ize, min_pixel=m
+0000c870: 696e 5f70 6978 2c20 6d61 785f 7069 7865  in_pix, max_pixe
+0000c880: 6c3d 6d61 785f 7069 782c 2076 616c 5f70  l=max_pix, val_p
+0000c890: 6f73 6974 6976 653d 7661 6c5f 636c 6173  ositive=val_clas
+0000c8a0: 735f 312c 2076 616c 5f6e 6567 6174 6976  s_1, val_negativ
+0000c8b0: 653d 7661 6c5f 636c 6173 735f 322c 200a  e=val_class_2, .
+0000c8c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c8d0: 2020 2020 2020 2020 6570 6f63 6873 3d73          epochs=s
+0000c8e0: 656c 662e 7472 6169 6e5f 6570 6f63 6873  elf.train_epochs
+0000c8f0: 2c20 6261 7463 685f 7369 7a65 3d62 6174  , batch_size=bat
+0000c900: 6368 5f73 697a 652c 206f 7074 696d 697a  ch_size, optimiz
+0000c910: 6572 3d6f 7074 696d 697a 6572 2c20 6c72  er=optimizer, lr
+0000c920: 3d6c 722c 2064 6563 6179 3d64 6563 6179  =lr, decay=decay
+0000c930: 2c20 6d6f 6d65 6e74 756d 3d6d 6f6d 656e  , momentum=momen
+0000c940: 7475 6d2c 206e 6573 7465 726f 763d 6e65  tum, nesterov=ne
+0000c950: 7374 6572 6f76 2c20 0a20 2020 2020 2020  sterov, .       
+0000c960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c970: 2062 6574 615f 313d 6265 7461 5f31 2c20   beta_1=beta_1, 
+0000c980: 6265 7461 5f32 3d62 6574 615f 322c 2061  beta_2=beta_2, a
+0000c990: 6d73 6772 6164 3d61 6d73 6772 6164 2c20  msgrad=amsgrad, 
+0000c9a0: 6c6f 7373 3d6c 6f73 732c 2061 6374 6976  loss=loss, activ
+0000c9b0: 6174 696f 6e5f 636f 6e76 3d61 6374 6976  ation_conv=activ
+0000c9c0: 6174 696f 6e5f 636f 6e76 2c20 6163 7469  ation_conv, acti
+0000c9d0: 7661 7469 6f6e 5f64 656e 7365 3d61 6374  vation_dense=act
+0000c9e0: 6976 6174 696f 6e5f 6465 6e73 652c 200a  ivation_dense, .
+0000c9f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ca00: 2020 2020 2020 2020 636f 6e76 5f69 6e69          conv_ini
+0000ca10: 743d 636f 6e76 5f69 6e69 742c 2064 656e  t=conv_init, den
+0000ca20: 7365 5f69 6e69 743d 6465 6e73 655f 696e  se_init=dense_in
+0000ca30: 6974 2c20 6d6f 6465 6c5f 7265 673d 6d6f  it, model_reg=mo
+0000ca40: 6465 6c5f 7265 672c 2020 2020 2020 2020  del_reg,        
+0000ca50: 2020 2020 2020 2020 2020 2020 2020 0a20                . 
+0000ca60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ca70: 2020 2020 2020 2066 696c 7465 725f 313d         filter_1=
+0000ca80: 6669 6c74 6572 5f31 2c20 6669 6c74 6572  filter_1, filter
+0000ca90: 5f73 697a 655f 313d 6669 6c74 6572 5f73  _size_1=filter_s
+0000caa0: 697a 655f 312c 2073 7472 6964 6573 5f31  ize_1, strides_1
+0000cab0: 3d73 7472 6964 6573 5f31 2c20 706f 6f6c  =strides_1, pool
+0000cac0: 696e 675f 313d 706f 6f6c 696e 675f 312c  ing_1=pooling_1,
+0000cad0: 2070 6f6f 6c5f 7369 7a65 5f31 3d70 6f6f   pool_size_1=poo
+0000cae0: 6c5f 7369 7a65 5f31 2c20 706f 6f6c 5f73  l_size_1, pool_s
+0000caf0: 7472 6964 655f 313d 706f 6f6c 5f73 7472  tride_1=pool_str
+0000cb00: 6964 655f 312c 0a20 2020 2020 2020 2020  ide_1,.         
+0000cb10: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0000cb20: 696c 7465 725f 323d 6669 6c74 6572 5f32  ilter_2=filter_2
+0000cb30: 2c20 6669 6c74 6572 5f73 697a 655f 323d  , filter_size_2=
+0000cb40: 6669 6c74 6572 5f73 697a 655f 322c 2073  filter_size_2, s
+0000cb50: 7472 6964 6573 5f32 3d73 7472 6964 6573  trides_2=strides
+0000cb60: 5f32 2c20 706f 6f6c 696e 675f 323d 706f  _2, pooling_2=po
+0000cb70: 6f6c 696e 675f 322c 2070 6f6f 6c5f 7369  oling_2, pool_si
+0000cb80: 7a65 5f32 3d70 6f6f 6c5f 7369 7a65 5f32  ze_2=pool_size_2
+0000cb90: 2c20 706f 6f6c 5f73 7472 6964 655f 323d  , pool_stride_2=
+0000cba0: 706f 6f6c 5f73 7472 6964 655f 322c 0a20  pool_stride_2,. 
+0000cbb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cbc0: 2020 2020 2020 2066 696c 7465 725f 333d         filter_3=
+0000cbd0: 6669 6c74 6572 5f33 2c20 6669 6c74 6572  filter_3, filter
+0000cbe0: 5f73 697a 655f 333d 6669 6c74 6572 5f73  _size_3=filter_s
+0000cbf0: 697a 655f 332c 2073 7472 6964 6573 5f33  ize_3, strides_3
+0000cc00: 3d73 7472 6964 6573 5f33 2c20 706f 6f6c  =strides_3, pool
+0000cc10: 696e 675f 333d 706f 6f6c 696e 675f 332c  ing_3=pooling_3,
+0000cc20: 2070 6f6f 6c5f 7369 7a65 5f33 3d70 6f6f   pool_size_3=poo
+0000cc30: 6c5f 7369 7a65 5f33 2c20 706f 6f6c 5f73  l_size_3, pool_s
+0000cc40: 7472 6964 655f 333d 706f 6f6c 5f73 7472  tride_3=pool_str
+0000cc50: 6964 655f 332c 0a20 2020 2020 2020 2020  ide_3,.         
+0000cc60: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0000cc70: 696c 7465 725f 343d 6669 6c74 6572 5f34  ilter_4=filter_4
+0000cc80: 2c20 6669 6c74 6572 5f73 697a 655f 343d  , filter_size_4=
+0000cc90: 6669 6c74 6572 5f73 697a 655f 342c 2073  filter_size_4, s
+0000cca0: 7472 6964 6573 5f34 3d73 7472 6964 6573  trides_4=strides
+0000ccb0: 5f34 2c20 706f 6f6c 696e 675f 343d 706f  _4, pooling_4=po
+0000ccc0: 6f6c 696e 675f 342c 2070 6f6f 6c5f 7369  oling_4, pool_si
+0000ccd0: 7a65 5f34 3d70 6f6f 6c5f 7369 7a65 5f34  ze_4=pool_size_4
+0000cce0: 2c20 706f 6f6c 5f73 7472 6964 655f 343d  , pool_stride_4=
+0000ccf0: 706f 6f6c 5f73 7472 6964 655f 342c 0a20  pool_stride_4,. 
+0000cd00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cd10: 2020 2020 2020 2066 696c 7465 725f 353d         filter_5=
+0000cd20: 6669 6c74 6572 5f35 2c20 6669 6c74 6572  filter_5, filter
+0000cd30: 5f73 697a 655f 353d 6669 6c74 6572 5f73  _size_5=filter_s
+0000cd40: 697a 655f 352c 2073 7472 6964 6573 5f35  ize_5, strides_5
+0000cd50: 3d73 7472 6964 6573 5f35 2c20 706f 6f6c  =strides_5, pool
+0000cd60: 696e 675f 353d 706f 6f6c 696e 675f 352c  ing_5=pooling_5,
+0000cd70: 2070 6f6f 6c5f 7369 7a65 5f35 3d70 6f6f   pool_size_5=poo
+0000cd80: 6c5f 7369 7a65 5f35 2c20 706f 6f6c 5f73  l_size_5, pool_s
+0000cd90: 7472 6964 655f 353d 706f 6f6c 5f73 7472  tride_5=pool_str
+0000cda0: 6964 655f 352c 0a20 2020 2020 2020 2020  ide_5,.         
+0000cdb0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+0000cdc0: 656e 7365 5f6e 6575 726f 6e73 5f31 3d64  ense_neurons_1=d
+0000cdd0: 656e 7365 5f6e 6575 726f 6e73 5f31 2c20  ense_neurons_1, 
+0000cde0: 6465 6e73 655f 6e65 7572 6f6e 735f 323d  dense_neurons_2=
+0000cdf0: 6465 6e73 655f 6e65 7572 6f6e 735f 322c  dense_neurons_2,
+0000ce00: 2064 726f 706f 7574 5f31 3d64 726f 706f   dropout_1=dropo
+0000ce10: 7574 5f31 2c20 6472 6f70 6f75 745f 323d  ut_1, dropout_2=
+0000ce20: 6472 6f70 6f75 745f 322c 200a 2020 2020  dropout_2, .    
+0000ce30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ce40: 2020 2020 736d 6f74 655f 7361 6d70 6c69      smote_sampli
+0000ce50: 6e67 3d73 656c 662e 736d 6f74 655f 7361  ng=self.smote_sa
+0000ce60: 6d70 6c69 6e67 2c20 6561 726c 795f 7374  mpling, early_st
+0000ce70: 6f70 5f63 616c 6c62 6163 6b3d 6361 6c6c  op_callback=call
+0000ce80: 6261 636b 732c 2063 6865 636b 706f 696e  backs, checkpoin
+0000ce90: 743d 4661 6c73 652c 2076 6572 626f 7365  t=False, verbose
+0000cea0: 3d73 656c 662e 7665 7262 6f73 6529 0a0a  =self.verbose)..
+0000ceb0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+0000cec0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+0000ced0: 662e 6f70 745f 6376 2069 7320 6e6f 7420  f.opt_cv is not 
+0000cee0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+0000cef0: 2020 2020 2020 7072 696e 7428 293b 2070        print(); p
+0000cf00: 7269 6e74 2827 2a2a 2a2a 2a2a 2a2a 2a2a  rint('**********
+0000cf10: 2a20 2043 5620 2d20 3120 2a2a 2a2a 2a2a  *  CV - 1 ******
+0000cf20: 2a2a 2a2a 2a27 293b 2070 7269 6e74 2829  *****'); print()
+0000cf30: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+0000cf40: 7365 6c66 2e6f 7074 5f61 7567 3a0a 2020  self.opt_aug:.  
+0000cf50: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+0000cf60: 696e 7428 293b 2070 7269 6e74 2827 3d3d  int(); print('==
+0000cf70: 3d3d 3d3d 3d20 496d 6167 6520 5061 7261  ===== Image Para
+0000cf80: 6d65 7465 7273 203d 3d3d 3d3d 3d27 293b  meters ======');
+0000cf90: 2070 7269 6e74 2829 3b20 7072 696e 7428   print(); print(
+0000cfa0: 274e 756d 2041 7567 6d65 6e74 6174 696f  'Num Augmentatio
+0000cfb0: 6e73 203a 272c 206e 756d 5f61 7567 293b  ns :', num_aug);
+0000cfc0: 2070 7269 6e74 2827 496d 6167 6520 5369   print('Image Si
+0000cfd0: 7a65 203a 2027 2c20 696d 6167 655f 7369  ze : ', image_si
+0000cfe0: 7a65 293b 2070 7269 6e74 2827 4d61 7820  ze); print('Max 
+0000cff0: 5069 7865 6c28 7329 203a 272c 206d 6178  Pixel(s) :', max
+0000d000: 5f70 6978 293b 2070 7269 6e74 2827 4e75  _pix); print('Nu
+0000d010: 6d20 4d61 736b 7320 3a27 2c20 6e75 6d5f  m Masks :', num_
+0000d020: 6d61 736b 7329 3b20 7072 696e 7428 274d  masks); print('M
+0000d030: 6173 6b20 5369 7a65 203a 272c 206d 6173  ask Size :', mas
+0000d040: 6b5f 7369 7a65 293b 2070 7269 6e74 2827  k_size); print('
+0000d050: 426c 656e 6420 4d75 6c74 6970 6c69 6572  Blend Multiplier
+0000d060: 203a 272c 2062 6c65 6e64 5f6d 756c 7469   :', blend_multi
+0000d070: 706c 6965 7229 3b20 7072 696e 7428 2753  plier); print('S
+0000d080: 6b65 7720 416e 676c 6520 3a27 2c20 736b  kew Angle :', sk
+0000d090: 6577 5f61 6e67 6c65 290a 2020 2020 200a  ew_angle).     .
+0000d0a0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+0000d0b0: 656c 662e 636c 6620 3d3d 2027 616c 6578  elf.clf == 'alex
+0000d0c0: 6e65 7427 3a0a 2020 2020 2020 2020 2020  net':.          
+0000d0d0: 2020 2020 2020 6d6f 6465 6c2c 2068 6973        model, his
+0000d0e0: 746f 7279 203d 2063 6e6e 5f6d 6f64 656c  tory = cnn_model
+0000d0f0: 2e41 6c65 784e 6574 2863 6c61 7373 5f31  .AlexNet(class_1
+0000d100: 2c20 636c 6173 735f 322c 2069 6d67 5f6e  , class_2, img_n
+0000d110: 756d 5f63 6861 6e6e 656c 733d 7365 6c66  um_channels=self
+0000d120: 2e69 6d67 5f6e 756d 5f63 6861 6e6e 656c  .img_num_channel
+0000d130: 732c 200a 2020 2020 2020 2020 2020 2020  s, .            
+0000d140: 2020 2020 2020 2020 6e6f 726d 616c 697a          normaliz
+0000d150: 653d 7365 6c66 2e6e 6f72 6d61 6c69 7a65  e=self.normalize
+0000d160: 2c20 6d69 6e5f 7069 7865 6c3d 6d69 6e5f  , min_pixel=min_
+0000d170: 7069 782c 206d 6178 5f70 6978 656c 3d6d  pix, max_pixel=m
+0000d180: 6178 5f70 6978 2c20 7661 6c5f 706f 7369  ax_pix, val_posi
+0000d190: 7469 7665 3d76 616c 5f63 6c61 7373 5f31  tive=val_class_1
+0000d1a0: 2c20 7661 6c5f 6e65 6761 7469 7665 3d76  , val_negative=v
+0000d1b0: 616c 5f63 6c61 7373 5f32 2c20 0a20 2020  al_class_2, .   
+0000d1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d1d0: 2065 706f 6368 733d 7365 6c66 2e74 7261   epochs=self.tra
+0000d1e0: 696e 5f65 706f 6368 732c 2062 6174 6368  in_epochs, batch
+0000d1f0: 5f73 697a 653d 6261 7463 685f 7369 7a65  _size=batch_size
+0000d200: 2c20 6f70 7469 6d69 7a65 723d 6f70 7469  , optimizer=opti
+0000d210: 6d69 7a65 722c 206c 723d 6c72 2c20 6465  mizer, lr=lr, de
+0000d220: 6361 793d 6465 6361 792c 206d 6f6d 656e  cay=decay, momen
+0000d230: 7475 6d3d 6d6f 6d65 6e74 756d 2c20 6e65  tum=momentum, ne
+0000d240: 7374 6572 6f76 3d6e 6573 7465 726f 762c  sterov=nesterov,
+0000d250: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+0000d260: 2020 2020 2020 6265 7461 5f31 3d62 6574        beta_1=bet
+0000d270: 615f 312c 2062 6574 615f 323d 6265 7461  a_1, beta_2=beta
+0000d280: 5f32 2c20 616d 7367 7261 643d 616d 7367  _2, amsgrad=amsg
+0000d290: 7261 642c 2073 6d6f 7465 5f73 616d 706c  rad, smote_sampl
+0000d2a0: 696e 673d 7365 6c66 2e73 6d6f 7465 5f73  ing=self.smote_s
+0000d2b0: 616d 706c 696e 672c 2065 6172 6c79 5f73  ampling, early_s
+0000d2c0: 746f 705f 6361 6c6c 6261 636b 3d63 616c  top_callback=cal
+0000d2d0: 6c62 6163 6b73 2c20 6368 6563 6b70 6f69  lbacks, checkpoi
+0000d2e0: 6e74 3d46 616c 7365 2c20 7665 7262 6f73  nt=False, verbos
+0000d2f0: 653d 7365 6c66 2e76 6572 626f 7365 290a  e=self.verbose).
+0000d300: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+0000d310: 2073 656c 662e 636c 6620 3d3d 2027 6375   self.clf == 'cu
+0000d320: 7374 6f6d 5f63 6e6e 273a 0a20 2020 2020  stom_cnn':.     
+0000d330: 2020 2020 2020 2020 2020 206d 6f64 656c             model
+0000d340: 2c20 6869 7374 6f72 7920 3d20 636e 6e5f  , history = cnn_
+0000d350: 6d6f 6465 6c2e 6375 7374 6f6d 5f6d 6f64  model.custom_mod
+0000d360: 656c 2863 6c61 7373 5f31 2c20 636c 6173  el(class_1, clas
+0000d370: 735f 322c 2069 6d67 5f6e 756d 5f63 6861  s_2, img_num_cha
+0000d380: 6e6e 656c 733d 7365 6c66 2e69 6d67 5f6e  nnels=self.img_n
+0000d390: 756d 5f63 6861 6e6e 656c 732c 200a 2020  um_channels, .  
+0000d3a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d3b0: 2020 6e6f 726d 616c 697a 653d 7365 6c66    normalize=self
+0000d3c0: 2e6e 6f72 6d61 6c69 7a65 2c20 6d69 6e5f  .normalize, min_
+0000d3d0: 7069 7865 6c3d 6d69 6e5f 7069 782c 206d  pixel=min_pix, m
+0000d3e0: 6178 5f70 6978 656c 3d6d 6178 5f70 6978  ax_pixel=max_pix
+0000d3f0: 2c20 7661 6c5f 706f 7369 7469 7665 3d76  , val_positive=v
+0000d400: 616c 5f63 6c61 7373 5f31 2c20 7661 6c5f  al_class_1, val_
+0000d410: 6e65 6761 7469 7665 3d76 616c 5f63 6c61  negative=val_cla
+0000d420: 7373 5f32 2c20 0a20 2020 2020 2020 2020  ss_2, .         
+0000d430: 2020 2020 2020 2020 2020 2065 706f 6368             epoch
+0000d440: 733d 7365 6c66 2e74 7261 696e 5f65 706f  s=self.train_epo
+0000d450: 6368 732c 2062 6174 6368 5f73 697a 653d  chs, batch_size=
+0000d460: 6261 7463 685f 7369 7a65 2c20 6f70 7469  batch_size, opti
+0000d470: 6d69 7a65 723d 6f70 7469 6d69 7a65 722c  mizer=optimizer,
+0000d480: 206c 723d 6c72 2c20 6465 6361 793d 6465   lr=lr, decay=de
+0000d490: 6361 792c 206d 6f6d 656e 7475 6d3d 6d6f  cay, momentum=mo
+0000d4a0: 6d65 6e74 756d 2c20 6e65 7374 6572 6f76  mentum, nesterov
+0000d4b0: 3d6e 6573 7465 726f 762c 200a 2020 2020  =nesterov, .    
+0000d4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d4d0: 6265 7461 5f31 3d62 6574 615f 312c 2062  beta_1=beta_1, b
+0000d4e0: 6574 615f 323d 6265 7461 5f32 2c20 616d  eta_2=beta_2, am
+0000d4f0: 7367 7261 643d 616d 7367 7261 642c 2073  sgrad=amsgrad, s
+0000d500: 6d6f 7465 5f73 616d 706c 696e 673d 7365  mote_sampling=se
+0000d510: 6c66 2e73 6d6f 7465 5f73 616d 706c 696e  lf.smote_samplin
+0000d520: 672c 2065 6172 6c79 5f73 746f 705f 6361  g, early_stop_ca
+0000d530: 6c6c 6261 636b 3d63 616c 6c62 6163 6b73  llback=callbacks
+0000d540: 2c20 6368 6563 6b70 6f69 6e74 3d46 616c  , checkpoint=Fal
+0000d550: 7365 2c20 7665 7262 6f73 653d 7365 6c66  se, verbose=self
+0000d560: 2e76 6572 626f 7365 290a 2020 2020 2020  .verbose).      
+0000d570: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
+0000d580: 636c 6620 3d3d 2027 7667 6731 3627 3a0a  clf == 'vgg16':.
+0000d590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d5a0: 6d6f 6465 6c2c 2068 6973 746f 7279 203d  model, history =
+0000d5b0: 2063 6e6e 5f6d 6f64 656c 2e56 4747 3136   cnn_model.VGG16
+0000d5c0: 2863 6c61 7373 5f31 2c20 636c 6173 735f  (class_1, class_
+0000d5d0: 322c 2069 6d67 5f6e 756d 5f63 6861 6e6e  2, img_num_chann
+0000d5e0: 656c 733d 7365 6c66 2e69 6d67 5f6e 756d  els=self.img_num
+0000d5f0: 5f63 6861 6e6e 656c 732c 200a 2020 2020  _channels, .    
+0000d600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d610: 6e6f 726d 616c 697a 653d 7365 6c66 2e6e  normalize=self.n
+0000d620: 6f72 6d61 6c69 7a65 2c20 6d69 6e5f 7069  ormalize, min_pi
+0000d630: 7865 6c3d 6d69 6e5f 7069 782c 206d 6178  xel=min_pix, max
+0000d640: 5f70 6978 656c 3d6d 6178 5f70 6978 2c20  _pixel=max_pix, 
+0000d650: 7661 6c5f 706f 7369 7469 7665 3d76 616c  val_positive=val
+0000d660: 5f63 6c61 7373 5f31 2c20 7661 6c5f 6e65  _class_1, val_ne
+0000d670: 6761 7469 7665 3d76 616c 5f63 6c61 7373  gative=val_class
+0000d680: 5f32 2c20 0a20 2020 2020 2020 2020 2020  _2, .           
+0000d690: 2020 2020 2020 2020 2065 706f 6368 733d           epochs=
+0000d6a0: 7365 6c66 2e74 7261 696e 5f65 706f 6368  self.train_epoch
+0000d6b0: 732c 2062 6174 6368 5f73 697a 653d 6261  s, batch_size=ba
+0000d6c0: 7463 685f 7369 7a65 2c20 6f70 7469 6d69  tch_size, optimi
+0000d6d0: 7a65 723d 6f70 7469 6d69 7a65 722c 206c  zer=optimizer, l
+0000d6e0: 723d 6c72 2c20 6465 6361 793d 6465 6361  r=lr, decay=deca
+0000d6f0: 792c 206d 6f6d 656e 7475 6d3d 6d6f 6d65  y, momentum=mome
+0000d700: 6e74 756d 2c20 6e65 7374 6572 6f76 3d6e  ntum, nesterov=n
+0000d710: 6573 7465 726f 762c 200a 2020 2020 2020  esterov, .      
+0000d720: 2020 2020 2020 2020 2020 2020 2020 6265                be
+0000d730: 7461 5f31 3d62 6574 615f 312c 2062 6574  ta_1=beta_1, bet
+0000d740: 615f 323d 6265 7461 5f32 2c20 616d 7367  a_2=beta_2, amsg
+0000d750: 7261 643d 616d 7367 7261 642c 2073 6d6f  rad=amsgrad, smo
+0000d760: 7465 5f73 616d 706c 696e 673d 7365 6c66  te_sampling=self
+0000d770: 2e73 6d6f 7465 5f73 616d 706c 696e 672c  .smote_sampling,
+0000d780: 2065 6172 6c79 5f73 746f 705f 6361 6c6c   early_stop_call
+0000d790: 6261 636b 3d63 616c 6c62 6163 6b73 2c20  back=callbacks, 
+0000d7a0: 6368 6563 6b70 6f69 6e74 3d46 616c 7365  checkpoint=False
+0000d7b0: 2c20 7665 7262 6f73 653d 7365 6c66 2e76  , verbose=self.v
+0000d7c0: 6572 626f 7365 290a 2020 2020 2020 2020  erbose).        
+0000d7d0: 2020 2020 656c 6966 2073 656c 662e 636c      elif self.cl
+0000d7e0: 6620 3d3d 2027 7265 736e 6574 3138 273a  f == 'resnet18':
+0000d7f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d800: 206d 6f64 656c 2c20 6869 7374 6f72 7920   model, history 
+0000d810: 3d20 636e 6e5f 6d6f 6465 6c2e 5265 736e  = cnn_model.Resn
+0000d820: 6574 3138 2863 6c61 7373 5f31 2c20 636c  et18(class_1, cl
+0000d830: 6173 735f 322c 2069 6d67 5f6e 756d 5f63  ass_2, img_num_c
+0000d840: 6861 6e6e 656c 733d 7365 6c66 2e69 6d67  hannels=self.img
+0000d850: 5f6e 756d 5f63 6861 6e6e 656c 732c 200a  _num_channels, .
+0000d860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d870: 2020 2020 6e6f 726d 616c 697a 653d 7365      normalize=se
+0000d880: 6c66 2e6e 6f72 6d61 6c69 7a65 2c20 6d69  lf.normalize, mi
+0000d890: 6e5f 7069 7865 6c3d 6d69 6e5f 7069 782c  n_pixel=min_pix,
+0000d8a0: 206d 6178 5f70 6978 656c 3d6d 6178 5f70   max_pixel=max_p
+0000d8b0: 6978 2c20 7661 6c5f 706f 7369 7469 7665  ix, val_positive
+0000d8c0: 3d76 616c 5f63 6c61 7373 5f31 2c20 7661  =val_class_1, va
+0000d8d0: 6c5f 6e65 6761 7469 7665 3d76 616c 5f63  l_negative=val_c
+0000d8e0: 6c61 7373 5f32 2c20 0a20 2020 2020 2020  lass_2, .       
+0000d8f0: 2020 2020 2020 2020 2020 2020 2065 706f               epo
+0000d900: 6368 733d 7365 6c66 2e74 7261 696e 5f65  chs=self.train_e
+0000d910: 706f 6368 732c 2062 6174 6368 5f73 697a  pochs, batch_siz
+0000d920: 653d 6261 7463 685f 7369 7a65 2c20 6f70  e=batch_size, op
+0000d930: 7469 6d69 7a65 723d 6f70 7469 6d69 7a65  timizer=optimize
+0000d940: 722c 206c 723d 6c72 2c20 6465 6361 793d  r, lr=lr, decay=
+0000d950: 6465 6361 792c 206d 6f6d 656e 7475 6d3d  decay, momentum=
+0000d960: 6d6f 6d65 6e74 756d 2c20 6e65 7374 6572  momentum, nester
+0000d970: 6f76 3d6e 6573 7465 726f 762c 200a 2020  ov=nesterov, .  
+0000d980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d990: 2020 6265 7461 5f31 3d62 6574 615f 312c    beta_1=beta_1,
+0000d9a0: 2062 6574 615f 323d 6265 7461 5f32 2c20   beta_2=beta_2, 
+0000d9b0: 616d 7367 7261 643d 616d 7367 7261 642c  amsgrad=amsgrad,
+0000d9c0: 2073 6d6f 7465 5f73 616d 706c 696e 673d   smote_sampling=
+0000d9d0: 7365 6c66 2e73 6d6f 7465 5f73 616d 706c  self.smote_sampl
+0000d9e0: 696e 672c 2065 6172 6c79 5f73 746f 705f  ing, early_stop_
+0000d9f0: 6361 6c6c 6261 636b 3d63 616c 6c62 6163  callback=callbac
+0000da00: 6b73 2c20 6368 6563 6b70 6f69 6e74 3d46  ks, checkpoint=F
+0000da10: 616c 7365 2c20 7665 7262 6f73 653d 7365  alse, verbose=se
+0000da20: 6c66 2e76 6572 626f 7365 290a 0a20 2020  lf.verbose)..   
+0000da30: 2020 2020 2023 4966 2074 6865 2070 6174       #If the pat
+0000da40: 6965 6e63 6520 6973 2072 6561 6368 6564  ience is reached
+0000da50: 202d 2d20 7265 7475 726e 2073 686f 756c   -- return shoul
+0000da60: 6420 6265 2061 2076 616c 7565 2074 6861  d be a value tha
+0000da70: 7420 636f 6e74 6169 6e73 2069 6e66 6f72  t contains infor
+0000da80: 6d61 7469 6f6e 2072 6567 6172 6469 6e67  mation regarding
+0000da90: 2074 6865 206e 756d 206f 6620 636f 6d70   the num of comp
+0000daa0: 6c65 7465 6420 6570 6f63 6873 2c20 6f74  leted epochs, ot
+0000dab0: 6865 7277 6973 6520 6966 2072 6574 7572  herwise if retur
+0000dac0: 6e20 3020 6576 6572 7920 7469 6d65 2074  n 0 every time t
+0000dad0: 6865 6e20 7468 6520 6f70 7469 6d69 7a65  hen the optimize
+0000dae0: 7220 7769 6c6c 2067 6574 2073 7475 636b  r will get stuck
+0000daf0: 230a 2020 2020 2020 2020 6966 206c 656e  #.        if len
+0000db00: 2868 6973 746f 7279 2e68 6973 746f 7279  (history.history
+0000db10: 5b27 6c6f 7373 275d 2920 213d 2073 656c  ['loss']) != sel
+0000db20: 662e 7472 6169 6e5f 6570 6f63 6873 3a0a  f.train_epochs:.
+0000db30: 2020 2020 2020 2020 2020 2020 7072 696e              prin
+0000db40: 7428 293b 2070 7269 6e74 2827 5472 6169  t(); print('Trai
+0000db50: 6e69 6e67 2070 6174 6965 6e63 6520 7761  ning patience wa
+0000db60: 7320 7265 6163 6865 642e 2e2e 2729 3b20  s reached...'); 
+0000db70: 7072 696e 7428 290a 2020 2020 2020 2020  print().        
+0000db80: 2020 2020 7265 7475 726e 2028 6c65 6e28      return (len(
+0000db90: 6869 7374 6f72 792e 6869 7374 6f72 795b  history.history[
+0000dba0: 276c 6f73 7327 5d29 202a 2030 2e30 3031  'loss']) * 0.001
+0000dbb0: 2920 2d20 3939 392e 300a 0a20 2020 2020  ) - 999.0..     
+0000dbc0: 2020 2023 4966 2074 6865 206f 7574 7075     #If the outpu
+0000dbd0: 7420 6973 206e 616e 0a20 2020 2020 2020  t is nan.       
+0000dbe0: 2069 6620 6e70 2e69 7366 696e 6974 6528   if np.isfinite(
+0000dbf0: 6869 7374 6f72 792e 6869 7374 6f72 795b  history.history[
+0000dc00: 276c 6f73 7327 5d5b 2d31 5d29 3a0a 2020  'loss'][-1]):.  
+0000dc10: 2020 2020 2020 2020 2020 6d6f 6465 6c73            models
+0000dc20: 2c20 6869 7374 6f72 6965 7320 3d20 5b5d  , histories = []
+0000dc30: 2c20 5b5d 2023 5769 6c6c 2062 6520 7573  , [] #Will be us
+0000dc40: 6564 2074 6f20 6170 7065 6e64 2061 6464  ed to append add
+0000dc50: 6974 696f 6e61 6c20 6d6f 6465 6c73 2c20  itional models, 
+0000dc60: 6974 206f 7074 5f63 7620 6973 2065 6e61  it opt_cv is ena
+0000dc70: 626c 6564 0a20 2020 2020 2020 2020 2020  bled.           
+0000dc80: 206d 6f64 656c 732e 6170 7065 6e64 286d   models.append(m
+0000dc90: 6f64 656c 292c 2068 6973 746f 7269 6573  odel), histories
+0000dca0: 2e61 7070 656e 6428 6869 7374 6f72 7929  .append(history)
+0000dcb0: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+0000dcc0: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+0000dcd0: 2829 3b20 7072 696e 7428 2754 7261 696e  (); print('Train
+0000dce0: 696e 6720 6661 696c 6564 2064 7565 2074  ing failed due t
+0000dcf0: 6f20 6e75 6d65 7269 6361 6c20 696e 7374  o numerical inst
+0000dd00: 6162 696c 6974 792c 2072 6574 7572 6e69  ability, returni
+0000dd10: 6e67 206e 616e 2e2e 2e27 290a 2020 2020  ng nan...').    
+0000dd20: 2020 2020 2020 2020 7265 7475 726e 206e          return n
+0000dd30: 702e 6e61 6e20 0a0a 2020 2020 2020 2020  p.nan ..        
+0000dd40: 2323 2323 2320 4372 6f73 732d 5661 6c69  ##### Cross-Vali
+0000dd50: 6461 7469 6f6e 2052 6f75 7469 6e65 202d  dation Routine -
+0000dd60: 2069 6d70 6c65 6d65 6e74 6174 696f 6e20   implementation 
+0000dd70: 696e 2077 6869 6368 2074 6865 2076 616c  in which the val
+0000dd80: 6964 6174 696f 6e20 6461 7461 2069 7320  idation data is 
+0000dd90: 696e 7365 7274 6564 2069 6e74 6f20 7468  inserted into th
+0000dda0: 6520 7472 6169 6e69 6e67 2064 6174 6120  e training data 
+0000ddb0: 7769 7468 2074 6865 2072 6570 6c61 6365  with the replace
+0000ddc0: 6d65 6e74 2073 6572 7669 6e67 2061 7320  ment serving as 
+0000ddd0: 7468 6520 6e65 7720 7661 6c69 6461 7469  the new validati
+0000dde0: 6f6e 2323 2323 230a 2020 2020 2020 2020  on#####.        
+0000ddf0: 6966 2073 656c 662e 6f70 745f 6376 2069  if self.opt_cv i
+0000de00: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
+0000de10: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+0000de20: 7661 6c5f 706f 7369 7469 7665 2069 7320  val_positive is 
+0000de30: 4e6f 6e65 2061 6e64 2073 656c 662e 7661  None and self.va
+0000de40: 6c5f 6e65 6761 7469 7665 2069 7320 4e6f  l_negative is No
+0000de50: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+0000de60: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+0000de70: 7272 6f72 2827 434e 4e20 6372 6f73 732d  rror('CNN cross-
+0000de80: 7661 6c69 6461 7469 6f6e 2069 7320 6f6e  validation is on
+0000de90: 6c79 2073 7570 706f 7274 6564 2069 6620  ly supported if 
+0000dea0: 7661 6c69 6461 7469 6f6e 2064 6174 6120  validation data 
+0000deb0: 6973 2069 6e70 7574 2e27 290a 2020 2020  is input.').    
+0000dec0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+0000ded0: 7661 6c5f 706f 7369 7469 7665 2069 7320  val_positive is 
+0000dee0: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+0000def0: 2020 2020 2020 2020 2020 6966 206c 656e            if len
+0000df00: 2873 656c 662e 706f 7369 7469 7665 5f63  (self.positive_c
+0000df10: 6c61 7373 2920 2f20 6c65 6e28 7365 6c66  lass) / len(self
+0000df20: 2e76 616c 5f70 6f73 6974 6976 6529 203c  .val_positive) <
+0000df30: 2073 656c 662e 6f70 745f 6376 2d31 3a0a   self.opt_cv-1:.
+0000df40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000df50: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+0000df60: 7272 6f72 2827 4361 6e6e 6f74 2065 7665  rror('Cannot eve
+0000df70: 6e6c 7920 7061 7274 6974 696f 6e20 7468  nly partition th
+0000df80: 6520 706f 7369 7469 7665 2074 7261 696e  e positive train
+0000df90: 696e 672f 7661 6c69 6461 7469 6f6e 2064  ing/validation d
+0000dfa0: 6174 612c 2072 6566 6572 2074 6f20 7468  ata, refer to th
+0000dfb0: 6520 4d69 6372 6f4c 4941 2041 5049 2064  e MicroLIA API d
+0000dfc0: 6f63 756d 656e 7461 7469 6f6e 2066 6f72  ocumentation for
+0000dfd0: 2069 6e73 7472 7563 7469 6f6e 7320 6f6e   instructions on
+0000dfe0: 2068 6f77 2074 6f20 7573 6520 7468 6520   how to use the 
+0000dff0: 6f70 745f 6376 2070 6172 616d 6574 6572  opt_cv parameter
+0000e000: 2e27 290a 2020 2020 2020 2020 2020 2020  .').            
+0000e010: 6966 2073 656c 662e 7661 6c5f 6e65 6761  if self.val_nega
+0000e020: 7469 7665 2069 7320 6e6f 7420 4e6f 6e65  tive is not None
+0000e030: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000e040: 2020 6966 206c 656e 2873 656c 662e 6e65    if len(self.ne
+0000e050: 6761 7469 7665 5f63 6c61 7373 2920 2f20  gative_class) / 
+0000e060: 6c65 6e28 7365 6c66 2e76 616c 5f6e 6567  len(self.val_neg
+0000e070: 6174 6976 6529 203c 2073 656c 662e 6f70  ative) < self.op
+0000e080: 745f 6376 2d31 3a0a 2020 2020 2020 2020  t_cv-1:.        
+0000e090: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+0000e0a0: 6520 5661 6c75 6545 7272 6f72 2827 4361  e ValueError('Ca
+0000e0b0: 6e6e 6f74 2065 7665 6e6c 7920 7061 7274  nnot evenly part
+0000e0c0: 6974 696f 6e20 7468 6520 6e65 6761 7469  ition the negati
+0000e0d0: 7665 2074 7261 696e 696e 672f 7661 6c69  ve training/vali
+0000e0e0: 6461 7469 6f6e 2064 6174 612c 2072 6566  dation data, ref
+0000e0f0: 6572 2074 6f20 7468 6520 4d69 6372 6f4c  er to the MicroL
+0000e100: 4941 2041 5049 2064 6f63 756d 656e 7461  IA API documenta
+0000e110: 7469 6f6e 2066 6f72 2069 6e73 7472 7563  tion for instruc
+0000e120: 7469 6f6e 7320 6f6e 2068 6f77 2074 6f20  tions on how to 
+0000e130: 7573 6520 7468 6520 6f70 745f 6376 2070  use the opt_cv p
+0000e140: 6172 616d 6574 6572 2e27 290a 2020 2020  arameter.').    
+0000e150: 2020 2020 2020 2020 0a20 2020 2020 2020          .       
+0000e160: 2020 2020 2023 5468 6520 6669 7273 7420       #The first 
+0000e170: 6d6f 6465 6c20 2874 6865 7265 666f 7265  model (therefore
+0000e180: 2074 6865 2066 6972 7374 2022 666f 6c64   the first "fold
+0000e190: 2229 2061 6c72 6561 6479 2072 616e 2c20  ") already ran, 
+0000e1a0: 7468 6572 6566 6f72 6520 7375 7462 7261  therefore sutbra
+0000e1b0: 6374 2031 2020 2020 2020 0a20 2020 2020  ct 1      .     
+0000e1c0: 2020 2020 2020 2066 6f72 206b 2069 6e20         for k in 
+0000e1d0: 7261 6e67 6528 7365 6c66 2e6f 7074 5f63  range(self.opt_c
+0000e1e0: 762d 3129 3a20 2020 2020 2020 2020 200a  v-1):          .
+0000e1f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e200: 234d 616b 6520 6465 6570 2063 6f70 6965  #Make deep copie
+0000e210: 7320 746f 2061 766f 6964 206f 7665 7277  s to avoid overw
+0000e220: 7269 7469 6e67 2061 7272 6179 730a 2020  riting arrays.  
+0000e230: 2020 2020 2020 2020 2020 2020 2020 636c                cl
+0000e240: 6173 735f 312c 2063 6c61 7373 5f32 203d  ass_1, class_2 =
+0000e250: 2063 6f70 792e 6465 6570 636f 7079 2873   copy.deepcopy(s
+0000e260: 656c 662e 706f 7369 7469 7665 5f63 6c61  elf.positive_cla
+0000e270: 7373 292c 2063 6f70 792e 6465 6570 636f  ss), copy.deepco
+0000e280: 7079 2873 656c 662e 6e65 6761 7469 7665  py(self.negative
+0000e290: 5f63 6c61 7373 290a 2020 2020 2020 2020  _class).        
+0000e2a0: 2020 2020 2020 2020 7661 6c5f 636c 6173          val_clas
+0000e2b0: 735f 312c 2076 616c 5f63 6c61 7373 5f32  s_1, val_class_2
+0000e2c0: 203d 2063 6f70 792e 6465 6570 636f 7079   = copy.deepcopy
+0000e2d0: 2873 656c 662e 7661 6c5f 706f 7369 7469  (self.val_positi
+0000e2e0: 7665 292c 2063 6f70 792e 6465 6570 636f  ve), copy.deepco
+0000e2f0: 7079 2873 656c 662e 7661 6c5f 6e65 6761  py(self.val_nega
+0000e300: 7469 7665 290a 0a20 2020 2020 2020 2020  tive)..         
+0000e310: 2020 2020 2020 2023 536f 7274 2074 6865         #Sort the
+0000e320: 206e 6577 2064 6174 6120 7361 6d70 6c65   new data sample
+0000e330: 732c 206e 6f20 7261 6e64 6f6d 2073 6875  s, no random shu
+0000e340: 6666 6c69 6e67 2c20 6a75 7374 2061 206c  ffling, just a l
+0000e350: 696e 6561 7220 7365 7175 656e 6365 0a20  inear sequence. 
+0000e360: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0000e370: 6620 7661 6c5f 636c 6173 735f 3120 6973  f val_class_1 is
+0000e380: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+0000e390: 2020 2020 2020 2020 2020 2020 2020 2076                 v
+0000e3a0: 616c 5f68 6f6c 645f 3120 3d20 636f 7079  al_hold_1 = copy
+0000e3b0: 2e64 6565 7063 6f70 7928 636c 6173 735f  .deepcopy(class_
+0000e3c0: 315b 6b2a 6c65 6e28 7661 6c5f 636c 6173  1[k*len(val_clas
+0000e3d0: 735f 3129 3a6c 656e 2876 616c 5f63 6c61  s_1):len(val_cla
+0000e3e0: 7373 5f31 292a 286b 2b31 295d 2920 2354  ss_1)*(k+1)]) #T
+0000e3f0: 6865 206e 6577 2070 6f73 6974 6976 6520  he new positive 
+0000e400: 7661 6c69 6461 7469 6f6e 2064 6174 610a  validation data.
+0000e410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e420: 2020 2020 636c 6173 735f 315b 6b2a 6c65      class_1[k*le
+0000e430: 6e28 7661 6c5f 636c 6173 735f 3129 3a6c  n(val_class_1):l
+0000e440: 656e 2876 616c 5f63 6c61 7373 5f31 292a  en(val_class_1)*
+0000e450: 286b 2b31 295d 203d 2063 6f70 792e 6465  (k+1)] = copy.de
+0000e460: 6570 636f 7079 2876 616c 5f63 6c61 7373  epcopy(val_class
+0000e470: 5f31 2920 2354 6865 206e 6577 2063 6c61  _1) #The new cla
+0000e480: 7373 5f31 2c20 636f 7079 696e 6720 746f  ss_1, copying to
+0000e490: 2061 766f 6964 206c 696e 6b61 6765 2062   avoid linkage b
+0000e4a0: 6574 7765 656e 2061 7272 6179 730a 2020  etween arrays.  
+0000e4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e4c0: 2020 7661 6c5f 636c 6173 735f 3120 3d20    val_class_1 = 
+0000e4d0: 7661 6c5f 686f 6c64 5f31 200a 2020 2020  val_hold_1 .    
+0000e4e0: 2020 2020 2020 2020 2020 2020 6966 2076              if v
+0000e4f0: 616c 5f63 6c61 7373 5f32 2069 7320 6e6f  al_class_2 is no
+0000e500: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
+0000e510: 2020 2020 2020 2020 2020 2020 7661 6c5f              val_
+0000e520: 686f 6c64 5f32 203d 2063 6f70 792e 6465  hold_2 = copy.de
+0000e530: 6570 636f 7079 2863 6c61 7373 5f32 5b6b  epcopy(class_2[k
+0000e540: 2a6c 656e 2876 616c 5f63 6c61 7373 5f32  *len(val_class_2
+0000e550: 293a 6c65 6e28 7661 6c5f 636c 6173 735f  ):len(val_class_
+0000e560: 3229 2a28 6b2b 3129 5d29 2023 5468 6520  2)*(k+1)]) #The 
+0000e570: 6e65 7720 7661 6c69 6461 7469 6f6e 2064  new validation d
+0000e580: 6174 610a 2020 2020 2020 2020 2020 2020  ata.            
+0000e590: 2020 2020 2020 2020 636c 6173 735f 325b          class_2[
+0000e5a0: 6b2a 6c65 6e28 7661 6c5f 636c 6173 735f  k*len(val_class_
+0000e5b0: 3229 3a6c 656e 2876 616c 5f63 6c61 7373  2):len(val_class
+0000e5c0: 5f32 292a 286b 2b31 295d 203d 2063 6f70  _2)*(k+1)] = cop
+0000e5d0: 792e 6465 6570 636f 7079 2876 616c 5f63  y.deepcopy(val_c
+0000e5e0: 6c61 7373 5f32 2920 2354 6865 206e 6577  lass_2) #The new
+0000e5f0: 2063 6c61 7373 5f32 2c20 636f 7079 696e   class_2, copyin
+0000e600: 6720 746f 2061 766f 6964 206c 696e 6b61  g to avoid linka
+0000e610: 6765 2062 6574 7765 656e 2061 7272 6179  ge between array
+0000e620: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
+0000e630: 2020 2020 2020 7661 6c5f 636c 6173 735f        val_class_
+0000e640: 3220 3d20 7661 6c5f 686f 6c64 5f32 200a  2 = val_hold_2 .
+0000e650: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000e660: 2069 6620 7365 6c66 2e6f 7074 5f61 7567   if self.opt_aug
+0000e670: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000e680: 2020 2020 2020 6966 2073 656c 662e 696d        if self.im
+0000e690: 675f 6e75 6d5f 6368 616e 6e65 6c73 203d  g_num_channels =
+0000e6a0: 3d20 313a 0a20 2020 2020 2020 2020 2020  = 1:.           
+0000e6b0: 2020 2020 2020 2020 2020 2020 2063 6861               cha
+0000e6c0: 6e6e 656c 312c 2063 6861 6e6e 656c 322c  nnel1, channel2,
+0000e6d0: 2063 6861 6e6e 656c 3320 3d20 636f 7079   channel3 = copy
+0000e6e0: 2e64 6565 7063 6f70 7928 636c 6173 735f  .deepcopy(class_
+0000e6f0: 3129 2c20 4e6f 6e65 2c20 4e6f 6e65 200a  1), None, None .
+0000e700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e710: 2020 2020 656c 6966 2073 656c 662e 696d      elif self.im
+0000e720: 675f 6e75 6d5f 6368 616e 6e65 6c73 203d  g_num_channels =
+0000e730: 3d20 323a 0a20 2020 2020 2020 2020 2020  = 2:.           
+0000e740: 2020 2020 2020 2020 2020 2020 2063 6861               cha
+0000e750: 6e6e 656c 312c 2063 6861 6e6e 656c 322c  nnel1, channel2,
+0000e760: 2063 6861 6e6e 656c 3320 3d20 636f 7079   channel3 = copy
+0000e770: 2e64 6565 7063 6f70 7928 636c 6173 735f  .deepcopy(class_
+0000e780: 315b 3a2c 3a2c 3a2c 305d 292c 2063 6f70  1[:,:,:,0]), cop
+0000e790: 792e 6465 6570 636f 7079 2863 6c61 7373  y.deepcopy(class
+0000e7a0: 5f31 5b3a 2c3a 2c3a 2c31 5d29 2c20 4e6f  _1[:,:,:,1]), No
+0000e7b0: 6e65 200a 2020 2020 2020 2020 2020 2020  ne .            
+0000e7c0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+0000e7d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e7e0: 2020 2020 2020 6368 616e 6e65 6c31 2c20        channel1, 
+0000e7f0: 6368 616e 6e65 6c32 2c20 6368 616e 6e65  channel2, channe
+0000e800: 6c33 203d 2063 6f70 792e 6465 6570 636f  l3 = copy.deepco
+0000e810: 7079 2863 6c61 7373 5f31 5b3a 2c3a 2c3a  py(class_1[:,:,:
+0000e820: 2c30 5d29 2c20 636f 7079 2e64 6565 7063  ,0]), copy.deepc
+0000e830: 6f70 7928 636c 6173 735f 315b 3a2c 3a2c  opy(class_1[:,:,
+0000e840: 3a2c 315d 292c 2063 6f70 792e 6465 6570  :,1]), copy.deep
+0000e850: 636f 7079 2863 6c61 7373 5f31 5b3a 2c3a  copy(class_1[:,:
+0000e860: 2c3a 2c32 5d29 0a0a 2020 2020 2020 2020  ,:,2])..        
+0000e870: 2020 2020 2020 2020 2020 2020 6175 676d              augm
+0000e880: 656e 7465 645f 696d 6167 6573 203d 2061  ented_images = a
+0000e890: 7567 6d65 6e74 6174 696f 6e28 6368 616e  ugmentation(chan
+0000e8a0: 6e65 6c31 3d63 6861 6e6e 656c 312c 2063  nel1=channel1, c
+0000e8b0: 6861 6e6e 656c 323d 6368 616e 6e65 6c32  hannel2=channel2
+0000e8c0: 2c20 6368 616e 6e65 6c33 3d63 6861 6e6e  , channel3=chann
+0000e8d0: 656c 332c 2062 6174 6368 3d6e 756d 5f61  el3, batch=num_a
+0000e8e0: 7567 2c20 0a20 2020 2020 2020 2020 2020  ug, .           
+0000e8f0: 2020 2020 2020 2020 2020 2020 2077 6964               wid
+0000e900: 7468 5f73 6869 6674 3d73 656c 662e 7368  th_shift=self.sh
+0000e910: 6966 742c 2068 6569 6768 745f 7368 6966  ift, height_shif
+0000e920: 743d 7365 6c66 2e73 6869 6674 2c20 686f  t=self.shift, ho
+0000e930: 7269 7a6f 6e74 616c 3d73 656c 662e 686f  rizontal=self.ho
+0000e940: 7269 7a6f 6e74 616c 2c20 7665 7274 6963  rizontal, vertic
+0000e950: 616c 3d73 656c 662e 7665 7274 6963 616c  al=self.vertical
+0000e960: 2c20 726f 7461 7469 6f6e 3d73 656c 662e  , rotation=self.
+0000e970: 726f 7461 7469 6f6e 2c20 0a20 2020 2020  rotation, .     
+0000e980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e990: 2020 2069 6d61 6765 5f73 697a 653d 696d     image_size=im
+0000e9a0: 6167 655f 7369 7a65 2c20 6d61 736b 5f73  age_size, mask_s
+0000e9b0: 697a 653d 6d61 736b 5f73 697a 652c 206e  ize=mask_size, n
+0000e9c0: 756d 5f6d 6173 6b73 3d6e 756d 5f6d 6173  um_masks=num_mas
+0000e9d0: 6b73 2c20 626c 656e 645f 6d75 6c74 6970  ks, blend_multip
+0000e9e0: 6c69 6572 3d62 6c65 6e64 5f6d 756c 7469  lier=blend_multi
+0000e9f0: 706c 6965 722c 200a 2020 2020 2020 2020  plier, .        
 0000ea00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ea10: 2020 2020 7661 6c5f 636c 6173 735f 3220      val_class_2 
-0000ea20: 3d20 7265 7369 7a65 2876 616c 5f63 6c61  = resize(val_cla
-0000ea30: 7373 5f32 2c20 7369 7a65 3d69 6d61 6765  ss_2, size=image
-0000ea40: 5f73 697a 6529 0a20 2020 2020 2020 2020  _size).         
-0000ea50: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0000ea60: 6c69 6620 7365 6c66 2e69 6d67 5f6e 756d  lif self.img_num
-0000ea70: 5f63 6861 6e6e 656c 7320 3e20 313a 0a20  _channels > 1:. 
-0000ea80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ea90: 2020 2020 2020 2020 2020 2076 616c 5f63             val_c
-0000eaa0: 6861 6e6e 656c 3120 3d20 7265 7369 7a65  hannel1 = resize
-0000eab0: 2876 616c 5f63 6c61 7373 5f32 5b3a 2c3a  (val_class_2[:,:
-0000eac0: 2c3a 2c30 5d2c 2073 697a 653d 696d 6167  ,:,0], size=imag
-0000ead0: 655f 7369 7a65 290a 2020 2020 2020 2020  e_size).        
-0000eae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eaf0: 2020 2020 7661 6c5f 6368 616e 6e65 6c32      val_channel2
-0000eb00: 203d 2072 6573 697a 6528 7661 6c5f 636c   = resize(val_cl
-0000eb10: 6173 735f 325b 3a2c 3a2c 3a2c 315d 2c20  ass_2[:,:,:,1], 
-0000eb20: 7369 7a65 3d69 6d61 6765 5f73 697a 6529  size=image_size)
-0000eb30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000eb40: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-0000eb50: 7365 6c66 2e69 6d67 5f6e 756d 5f63 6861  self.img_num_cha
-0000eb60: 6e6e 656c 7320 3d3d 2032 3a0a 2020 2020  nnels == 2:.    
+0000ea10: 626c 656e 6469 6e67 5f66 756e 633d 7365  blending_func=se
+0000ea20: 6c66 2e62 6c65 6e64 696e 675f 6675 6e63  lf.blending_func
+0000ea30: 2c20 6e75 6d5f 696d 6167 6573 5f74 6f5f  , num_images_to_
+0000ea40: 626c 656e 643d 7365 6c66 2e6e 756d 5f69  blend=self.num_i
+0000ea50: 6d61 6765 735f 746f 5f62 6c65 6e64 2c20  mages_to_blend, 
+0000ea60: 7a6f 6f6d 5f72 616e 6765 3d73 656c 662e  zoom_range=self.
+0000ea70: 7a6f 6f6d 5f72 616e 6765 2c20 736b 6577  zoom_range, skew
+0000ea80: 5f61 6e67 6c65 3d73 6b65 775f 616e 676c  _angle=skew_angl
+0000ea90: 6529 0a0a 2020 2020 2020 2020 2020 2020  e)..            
+0000eaa0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+0000eab0: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+0000eac0: 203e 2031 3a0a 2020 2020 2020 2020 2020   > 1:.          
+0000ead0: 2020 2020 2020 2020 2020 2020 2020 636c                cl
+0000eae0: 6173 735f 313d 5b5d 0a20 2020 2020 2020  ass_1=[].       
+0000eaf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eb00: 2069 6620 7365 6c66 2e69 6d67 5f6e 756d   if self.img_num
+0000eb10: 5f63 6861 6e6e 656c 7320 3d3d 2032 3a0a  _channels == 2:.
+0000eb20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eb30: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+0000eb40: 6920 696e 2072 616e 6765 286c 656e 2861  i in range(len(a
+0000eb50: 7567 6d65 6e74 6564 5f69 6d61 6765 735b  ugmented_images[
+0000eb60: 305d 2929 3a0a 2020 2020 2020 2020 2020  0])):.          
 0000eb70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eb80: 2020 2020 2020 2020 2020 2020 7661 6c5f              val_
-0000eb90: 636c 6173 735f 3220 3d20 6461 7461 5f70  class_2 = data_p
-0000eba0: 726f 6365 7373 696e 672e 636f 6e63 6174  rocessing.concat
-0000ebb0: 5f63 6861 6e6e 656c 7328 7661 6c5f 6368  _channels(val_ch
-0000ebc0: 616e 6e65 6c31 2c20 7661 6c5f 6368 616e  annel1, val_chan
-0000ebd0: 6e65 6c32 290a 2020 2020 2020 2020 2020  nel2).          
-0000ebe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ebf0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-0000ec00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ec10: 2020 2020 2020 2020 7661 6c5f 6368 616e          val_chan
-0000ec20: 6e65 6c33 203d 2072 6573 697a 6528 7661  nel3 = resize(va
-0000ec30: 6c5f 636c 6173 735f 325b 3a2c 3a2c 3a2c  l_class_2[:,:,:,
-0000ec40: 325d 2c20 7369 7a65 3d69 6d61 6765 5f73  2], size=image_s
-0000ec50: 697a 6529 0a20 2020 2020 2020 2020 2020  ize).           
-0000ec60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ec70: 2020 2020 2076 616c 5f63 6c61 7373 5f32       val_class_2
-0000ec80: 203d 2064 6174 615f 7072 6f63 6573 7369   = data_processi
-0000ec90: 6e67 2e63 6f6e 6361 745f 6368 616e 6e65  ng.concat_channe
-0000eca0: 6c73 2876 616c 5f63 6861 6e6e 656c 312c  ls(val_channel1,
-0000ecb0: 2076 616c 5f63 6861 6e6e 656c 322c 2076   val_channel2, v
-0000ecc0: 616c 5f63 6861 6e6e 656c 3329 0a0a 2020  al_channel3)..  
-0000ecd0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0000ece0: 2073 656c 662e 7665 7262 6f73 6520 3d3d   self.verbose ==
-0000ecf0: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
-0000ed00: 2020 2020 2020 2020 7072 696e 7428 293b          print();
-0000ed10: 2070 7269 6e74 2827 2a2a 2a2a 2a2a 2a2a   print('********
-0000ed20: 2a2a 2a20 2043 5620 2d20 7b7d 202a 2a2a  ***  CV - {} ***
-0000ed30: 2a2a 2a2a 2a2a 2a2a 272e 666f 726d 6174  ********'.format
-0000ed40: 286b 2b32 2929 3b20 7072 696e 7428 290a  (k+2)); print().
-0000ed50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ed60: 2063 6c65 6172 5f73 6573 7369 6f6e 2829   clear_session()
-0000ed70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ed80: 2069 6620 7365 6c66 2e6f 7074 5f6d 6f64   if self.opt_mod
-0000ed90: 656c 2069 7320 4661 6c73 653a 0a20 2020  el is False:.   
-0000eda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000edb0: 2069 6620 7365 6c66 2e63 6c66 203d 3d20   if self.clf == 
-0000edc0: 2761 6c65 786e 6574 273a 0a20 2020 2020  'alexnet':.     
+0000eb80: 2020 2020 2020 636c 6173 735f 312e 6170        class_1.ap
+0000eb90: 7065 6e64 2864 6174 615f 7072 6f63 6573  pend(data_proces
+0000eba0: 7369 6e67 2e63 6f6e 6361 745f 6368 616e  sing.concat_chan
+0000ebb0: 6e65 6c73 2861 7567 6d65 6e74 6564 5f69  nels(augmented_i
+0000ebc0: 6d61 6765 735b 305d 5b69 5d2c 2061 7567  mages[0][i], aug
+0000ebd0: 6d65 6e74 6564 5f69 6d61 6765 735b 315d  mented_images[1]
+0000ebe0: 5b69 5d29 290a 2020 2020 2020 2020 2020  [i])).          
+0000ebf0: 2020 2020 2020 2020 2020 2020 2020 656c                el
+0000ec00: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+0000ec10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ec20: 666f 7220 6920 696e 2072 616e 6765 286c  for i in range(l
+0000ec30: 656e 2861 7567 6d65 6e74 6564 5f69 6d61  en(augmented_ima
+0000ec40: 6765 735b 305d 2929 3a0a 2020 2020 2020  ges[0])):.      
+0000ec50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ec60: 2020 2020 2020 2020 2020 636c 6173 735f            class_
+0000ec70: 312e 6170 7065 6e64 2864 6174 615f 7072  1.append(data_pr
+0000ec80: 6f63 6573 7369 6e67 2e63 6f6e 6361 745f  ocessing.concat_
+0000ec90: 6368 616e 6e65 6c73 2861 7567 6d65 6e74  channels(augment
+0000eca0: 6564 5f69 6d61 6765 735b 305d 5b69 5d2c  ed_images[0][i],
+0000ecb0: 2061 7567 6d65 6e74 6564 5f69 6d61 6765   augmented_image
+0000ecc0: 735b 315d 5b69 5d2c 2061 7567 6d65 6e74  s[1][i], augment
+0000ecd0: 6564 5f69 6d61 6765 735b 325d 5b69 5d29  ed_images[2][i])
+0000ece0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0000ecf0: 2020 2020 2020 2020 2020 636c 6173 735f            class_
+0000ed00: 3120 3d20 6e70 2e61 7272 6179 2863 6c61  1 = np.array(cla
+0000ed10: 7373 5f31 290a 2020 2020 2020 2020 2020  ss_1).          
+0000ed20: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+0000ed30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ed40: 2020 2020 2020 2020 636c 6173 735f 3120          class_1 
+0000ed50: 3d20 6175 676d 656e 7465 645f 696d 6167  = augmented_imag
+0000ed60: 6573 0a0a 2020 2020 2020 2020 2020 2020  es..            
+0000ed70: 2020 2020 2020 2020 2350 6572 666f 726d          #Perform
+0000ed80: 2073 616d 6520 6175 676d 656e 7461 7469   same augmentati
+0000ed90: 6f6e 2074 6563 686e 6971 7565 7320 6f6e  on techniques on
+0000eda0: 206e 6567 6174 6976 6520 636c 6173 7320   negative class 
+0000edb0: 6461 7461 2c20 6261 7463 685f 6f74 6865  data, batch_othe
+0000edc0: 723d 3120 6279 2064 6566 6175 6c74 0a20  r=1 by default. 
 0000edd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ede0: 2020 206d 6f64 656c 2c20 6869 7374 6f72     model, histor
-0000edf0: 7920 3d20 636e 6e5f 6d6f 6465 6c2e 416c  y = cnn_model.Al
-0000ee00: 6578 4e65 7428 636c 6173 735f 312c 2063  exNet(class_1, c
-0000ee10: 6c61 7373 5f32 2c20 696d 675f 6e75 6d5f  lass_2, img_num_
-0000ee20: 6368 616e 6e65 6c73 3d73 656c 662e 696d  channels=self.im
-0000ee30: 675f 6e75 6d5f 6368 616e 6e65 6c73 2c20  g_num_channels, 
-0000ee40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ee50: 2020 2020 2020 2020 2020 2020 206e 6f72               nor
-0000ee60: 6d61 6c69 7a65 3d73 656c 662e 6e6f 726d  malize=self.norm
-0000ee70: 616c 697a 652c 206d 696e 5f70 6978 656c  alize, min_pixel
-0000ee80: 3d6d 696e 5f70 6978 2c20 6d61 785f 7069  =min_pix, max_pi
-0000ee90: 7865 6c3d 6d61 785f 7069 782c 2076 616c  xel=max_pix, val
-0000eea0: 5f70 6f73 6974 6976 653d 7661 6c5f 636c  _positive=val_cl
-0000eeb0: 6173 735f 312c 2076 616c 5f6e 6567 6174  ass_1, val_negat
-0000eec0: 6976 653d 7661 6c5f 636c 6173 735f 322c  ive=val_class_2,
-0000eed0: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-0000eee0: 2020 2020 2020 2020 2020 2020 2020 6570                ep
-0000eef0: 6f63 6873 3d73 656c 662e 7472 6169 6e5f  ochs=self.train_
-0000ef00: 6570 6f63 6873 2c20 6261 7463 685f 7369  epochs, batch_si
-0000ef10: 7a65 3d62 6174 6368 5f73 697a 652c 206f  ze=batch_size, o
-0000ef20: 7074 696d 697a 6572 3d6f 7074 696d 697a  ptimizer=optimiz
-0000ef30: 6572 2c20 6c72 3d6c 722c 2064 6563 6179  er, lr=lr, decay
-0000ef40: 3d64 6563 6179 2c20 6d6f 6d65 6e74 756d  =decay, momentum
-0000ef50: 3d6d 6f6d 656e 7475 6d2c 206e 6573 7465  =momentum, neste
-0000ef60: 726f 763d 6e65 7374 6572 6f76 2c20 0a20  rov=nesterov, . 
-0000ef70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ef80: 2020 2020 2020 2020 2020 2062 6574 615f             beta_
-0000ef90: 313d 6265 7461 5f31 2c20 6265 7461 5f32  1=beta_1, beta_2
-0000efa0: 3d62 6574 615f 322c 2061 6d73 6772 6164  =beta_2, amsgrad
-0000efb0: 3d61 6d73 6772 6164 2c20 736d 6f74 655f  =amsgrad, smote_
-0000efc0: 7361 6d70 6c69 6e67 3d73 656c 662e 736d  sampling=self.sm
-0000efd0: 6f74 655f 7361 6d70 6c69 6e67 2c20 6561  ote_sampling, ea
-0000efe0: 726c 795f 7374 6f70 5f63 616c 6c62 6163  rly_stop_callbac
-0000eff0: 6b3d 6361 6c6c 6261 636b 732c 2063 6865  k=callbacks, che
-0000f000: 636b 706f 696e 743d 4661 6c73 652c 2076  ckpoint=False, v
-0000f010: 6572 626f 7365 3d73 656c 662e 7665 7262  erbose=self.verb
-0000f020: 6f73 6529 0a20 2020 2020 2020 2020 2020  ose).           
-0000f030: 2020 2020 2020 2020 2065 6c69 6620 7365           elif se
-0000f040: 6c66 2e63 6c66 203d 3d20 2763 7573 746f  lf.clf == 'custo
-0000f050: 6d5f 636e 6e27 3a0a 2020 2020 2020 2020  m_cnn':.        
-0000f060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f070: 6d6f 6465 6c2c 2068 6973 746f 7279 203d  model, history =
-0000f080: 2063 6e6e 5f6d 6f64 656c 2e63 7573 746f   cnn_model.custo
-0000f090: 6d5f 6d6f 6465 6c28 636c 6173 735f 312c  m_model(class_1,
-0000f0a0: 2063 6c61 7373 5f32 2c20 696d 675f 6e75   class_2, img_nu
-0000f0b0: 6d5f 6368 616e 6e65 6c73 3d73 656c 662e  m_channels=self.
-0000f0c0: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
-0000f0d0: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
-0000f0e0: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-0000f0f0: 6f72 6d61 6c69 7a65 3d73 656c 662e 6e6f  ormalize=self.no
-0000f100: 726d 616c 697a 652c 206d 696e 5f70 6978  rmalize, min_pix
-0000f110: 656c 3d6d 696e 5f70 6978 2c20 6d61 785f  el=min_pix, max_
-0000f120: 7069 7865 6c3d 6d61 785f 7069 782c 2076  pixel=max_pix, v
-0000f130: 616c 5f70 6f73 6974 6976 653d 7661 6c5f  al_positive=val_
-0000f140: 636c 6173 735f 312c 2076 616c 5f6e 6567  class_1, val_neg
-0000f150: 6174 6976 653d 7661 6c5f 636c 6173 735f  ative=val_class_
-0000f160: 322c 200a 2020 2020 2020 2020 2020 2020  2, .            
-0000f170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f180: 6570 6f63 6873 3d73 656c 662e 7472 6169  epochs=self.trai
-0000f190: 6e5f 6570 6f63 6873 2c20 6261 7463 685f  n_epochs, batch_
-0000f1a0: 7369 7a65 3d62 6174 6368 5f73 697a 652c  size=batch_size,
-0000f1b0: 206f 7074 696d 697a 6572 3d6f 7074 696d   optimizer=optim
-0000f1c0: 697a 6572 2c20 6c72 3d6c 722c 2064 6563  izer, lr=lr, dec
-0000f1d0: 6179 3d64 6563 6179 2c20 6d6f 6d65 6e74  ay=decay, moment
-0000f1e0: 756d 3d6d 6f6d 656e 7475 6d2c 206e 6573  um=momentum, nes
-0000f1f0: 7465 726f 763d 6e65 7374 6572 6f76 2c20  terov=nesterov, 
-0000f200: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f210: 2020 2020 2020 2020 2020 2020 2062 6574               bet
-0000f220: 615f 313d 6265 7461 5f31 2c20 6265 7461  a_1=beta_1, beta
-0000f230: 5f32 3d62 6574 615f 322c 2061 6d73 6772  _2=beta_2, amsgr
-0000f240: 6164 3d61 6d73 6772 6164 2c20 736d 6f74  ad=amsgrad, smot
-0000f250: 655f 7361 6d70 6c69 6e67 3d73 656c 662e  e_sampling=self.
-0000f260: 736d 6f74 655f 7361 6d70 6c69 6e67 2c20  smote_sampling, 
-0000f270: 6561 726c 795f 7374 6f70 5f63 616c 6c62  early_stop_callb
-0000f280: 6163 6b3d 6361 6c6c 6261 636b 732c 2063  ack=callbacks, c
-0000f290: 6865 636b 706f 696e 743d 4661 6c73 652c  heckpoint=False,
-0000f2a0: 2076 6572 626f 7365 3d73 656c 662e 7665   verbose=self.ve
-0000f2b0: 7262 6f73 6529 0a20 2020 2020 2020 2020  rbose).         
-0000f2c0: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
-0000f2d0: 7365 6c66 2e63 6c66 203d 3d20 2776 6767  self.clf == 'vgg
-0000f2e0: 3136 273a 0a20 2020 2020 2020 2020 2020  16':.           
-0000f2f0: 2020 2020 2020 2020 2020 2020 206d 6f64               mod
-0000f300: 656c 2c20 6869 7374 6f72 7920 3d20 636e  el, history = cn
-0000f310: 6e5f 6d6f 6465 6c2e 5647 4731 3628 636c  n_model.VGG16(cl
-0000f320: 6173 735f 312c 2063 6c61 7373 5f32 2c20  ass_1, class_2, 
-0000f330: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
-0000f340: 3d73 656c 662e 696d 675f 6e75 6d5f 6368  =self.img_num_ch
-0000f350: 616e 6e65 6c73 2c20 0a20 2020 2020 2020  annels, .       
-0000f360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f370: 2020 2020 206e 6f72 6d61 6c69 7a65 3d73       normalize=s
-0000f380: 656c 662e 6e6f 726d 616c 697a 652c 206d  elf.normalize, m
-0000f390: 696e 5f70 6978 656c 3d6d 696e 5f70 6978  in_pixel=min_pix
-0000f3a0: 2c20 6d61 785f 7069 7865 6c3d 6d61 785f  , max_pixel=max_
-0000f3b0: 7069 782c 2076 616c 5f70 6f73 6974 6976  pix, val_positiv
-0000f3c0: 653d 7661 6c5f 636c 6173 735f 312c 2076  e=val_class_1, v
-0000f3d0: 616c 5f6e 6567 6174 6976 653d 7661 6c5f  al_negative=val_
-0000f3e0: 636c 6173 735f 322c 200a 2020 2020 2020  class_2, .      
-0000f3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f400: 2020 2020 2020 6570 6f63 6873 3d73 656c        epochs=sel
-0000f410: 662e 7472 6169 6e5f 6570 6f63 6873 2c20  f.train_epochs, 
-0000f420: 6261 7463 685f 7369 7a65 3d62 6174 6368  batch_size=batch
-0000f430: 5f73 697a 652c 206f 7074 696d 697a 6572  _size, optimizer
-0000f440: 3d6f 7074 696d 697a 6572 2c20 6c72 3d6c  =optimizer, lr=l
-0000f450: 722c 2064 6563 6179 3d64 6563 6179 2c20  r, decay=decay, 
-0000f460: 6d6f 6d65 6e74 756d 3d6d 6f6d 656e 7475  momentum=momentu
-0000f470: 6d2c 206e 6573 7465 726f 763d 6e65 7374  m, nesterov=nest
-0000f480: 6572 6f76 2c20 0a20 2020 2020 2020 2020  erov, .         
-0000f490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f4a0: 2020 2062 6574 615f 313d 6265 7461 5f31     beta_1=beta_1
-0000f4b0: 2c20 6265 7461 5f32 3d62 6574 615f 322c  , beta_2=beta_2,
-0000f4c0: 2061 6d73 6772 6164 3d61 6d73 6772 6164   amsgrad=amsgrad
-0000f4d0: 2c20 736d 6f74 655f 7361 6d70 6c69 6e67  , smote_sampling
-0000f4e0: 3d73 656c 662e 736d 6f74 655f 7361 6d70  =self.smote_samp
-0000f4f0: 6c69 6e67 2c20 6561 726c 795f 7374 6f70  ling, early_stop
-0000f500: 5f63 616c 6c62 6163 6b3d 6361 6c6c 6261  _callback=callba
-0000f510: 636b 732c 2063 6865 636b 706f 696e 743d  cks, checkpoint=
-0000f520: 4661 6c73 652c 2076 6572 626f 7365 3d73  False, verbose=s
-0000f530: 656c 662e 7665 7262 6f73 6529 0a20 2020  elf.verbose).   
-0000f540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f550: 2065 6c69 6620 7365 6c66 2e63 6c66 203d   elif self.clf =
-0000f560: 3d20 2772 6573 6e65 7431 3827 3a0a 2020  = 'resnet18':.  
-0000f570: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f580: 2020 2020 2020 6d6f 6465 6c2c 2068 6973        model, his
-0000f590: 746f 7279 203d 2063 6e6e 5f6d 6f64 656c  tory = cnn_model
-0000f5a0: 2e52 6573 6e65 7431 3828 636c 6173 735f  .Resnet18(class_
-0000f5b0: 312c 2063 6c61 7373 5f32 2c20 696d 675f  1, class_2, img_
-0000f5c0: 6e75 6d5f 6368 616e 6e65 6c73 3d73 656c  num_channels=sel
-0000f5d0: 662e 696d 675f 6e75 6d5f 6368 616e 6e65  f.img_num_channe
-0000f5e0: 6c73 2c20 0a20 2020 2020 2020 2020 2020  ls, .           
+0000ede0: 2020 2069 6620 7365 6c66 2e69 6d67 5f6e     if self.img_n
+0000edf0: 756d 5f63 6861 6e6e 656c 7320 3d3d 2031  um_channels == 1
+0000ee00: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000ee10: 2020 2020 2020 2020 2020 6368 616e 6e65            channe
+0000ee20: 6c31 2c20 6368 616e 6e65 6c32 2c20 6368  l1, channel2, ch
+0000ee30: 616e 6e65 6c33 203d 2063 6f70 792e 6465  annel3 = copy.de
+0000ee40: 6570 636f 7079 2863 6c61 7373 5f32 292c  epcopy(class_2),
+0000ee50: 204e 6f6e 652c 204e 6f6e 6520 0a20 2020   None, None .   
+0000ee60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ee70: 2065 6c69 6620 7365 6c66 2e69 6d67 5f6e   elif self.img_n
+0000ee80: 756d 5f63 6861 6e6e 656c 7320 3d3d 2032  um_channels == 2
+0000ee90: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0000eea0: 2020 2020 2020 2020 2020 6368 616e 6e65            channe
+0000eeb0: 6c31 2c20 6368 616e 6e65 6c32 2c20 6368  l1, channel2, ch
+0000eec0: 616e 6e65 6c33 203d 2063 6f70 792e 6465  annel3 = copy.de
+0000eed0: 6570 636f 7079 2863 6c61 7373 5f32 5b3a  epcopy(class_2[:
+0000eee0: 2c3a 2c3a 2c30 5d29 2c20 636f 7079 2e64  ,:,:,0]), copy.d
+0000eef0: 6565 7063 6f70 7928 636c 6173 735f 325b  eepcopy(class_2[
+0000ef00: 3a2c 3a2c 3a2c 315d 292c 204e 6f6e 6520  :,:,:,1]), None 
+0000ef10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ef20: 2020 2020 2065 6c69 6620 7365 6c66 2e69       elif self.i
+0000ef30: 6d67 5f6e 756d 5f63 6861 6e6e 656c 7320  mg_num_channels 
+0000ef40: 3d3d 2033 3a0a 2020 2020 2020 2020 2020  == 3:.          
+0000ef50: 2020 2020 2020 2020 2020 2020 2020 6368                ch
+0000ef60: 616e 6e65 6c31 2c20 6368 616e 6e65 6c32  annel1, channel2
+0000ef70: 2c20 6368 616e 6e65 6c33 203d 2063 6f70  , channel3 = cop
+0000ef80: 792e 6465 6570 636f 7079 2863 6c61 7373  y.deepcopy(class
+0000ef90: 5f32 5b3a 2c3a 2c3a 2c30 5d29 2c20 636f  _2[:,:,:,0]), co
+0000efa0: 7079 2e64 6565 7063 6f70 7928 636c 6173  py.deepcopy(clas
+0000efb0: 735f 325b 3a2c 3a2c 3a2c 315d 292c 2063  s_2[:,:,:,1]), c
+0000efc0: 6f70 792e 6465 6570 636f 7079 2863 6c61  opy.deepcopy(cla
+0000efd0: 7373 5f32 5b3a 2c3a 2c3a 2c32 5d29 0a20  ss_2[:,:,:,2]). 
+0000efe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eff0: 2020 200a 2020 2020 2020 2020 2020 2020     .            
+0000f000: 2020 2020 2020 2020 6175 676d 656e 7465          augmente
+0000f010: 645f 696d 6167 6573 5f6e 6567 6174 6976  d_images_negativ
+0000f020: 6520 3d20 6175 676d 656e 7461 7469 6f6e  e = augmentation
+0000f030: 2863 6861 6e6e 656c 313d 6368 616e 6e65  (channel1=channe
+0000f040: 6c31 2c20 6368 616e 6e65 6c32 3d63 6861  l1, channel2=cha
+0000f050: 6e6e 656c 322c 2063 6861 6e6e 656c 333d  nnel2, channel3=
+0000f060: 6368 616e 6e65 6c33 2c20 6261 7463 683d  channel3, batch=
+0000f070: 7365 6c66 2e62 6174 6368 5f6f 7468 6572  self.batch_other
+0000f080: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+0000f090: 2020 2020 2020 2020 2020 2077 6964 7468             width
+0000f0a0: 5f73 6869 6674 3d73 656c 662e 7368 6966  _shift=self.shif
+0000f0b0: 742c 2068 6569 6768 745f 7368 6966 743d  t, height_shift=
+0000f0c0: 7365 6c66 2e73 6869 6674 2c20 686f 7269  self.shift, hori
+0000f0d0: 7a6f 6e74 616c 3d73 656c 662e 686f 7269  zontal=self.hori
+0000f0e0: 7a6f 6e74 616c 2c20 7665 7274 6963 616c  zontal, vertical
+0000f0f0: 3d73 656c 662e 7665 7274 6963 616c 2c20  =self.vertical, 
+0000f100: 726f 7461 7469 6f6e 3d73 656c 662e 726f  rotation=self.ro
+0000f110: 7461 7469 6f6e 2c20 0a20 2020 2020 2020  tation, .       
+0000f120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f130: 2069 6d61 6765 5f73 697a 653d 696d 6167   image_size=imag
+0000f140: 655f 7369 7a65 2c20 6d61 736b 5f73 697a  e_size, mask_siz
+0000f150: 653d 6d61 736b 5f73 697a 652c 206e 756d  e=mask_size, num
+0000f160: 5f6d 6173 6b73 3d6e 756d 5f6d 6173 6b73  _masks=num_masks
+0000f170: 2c20 626c 656e 645f 6d75 6c74 6970 6c69  , blend_multipli
+0000f180: 6572 3d73 656c 662e 626c 656e 645f 6f74  er=self.blend_ot
+0000f190: 6865 722c 200a 2020 2020 2020 2020 2020  her, .          
+0000f1a0: 2020 2020 2020 2020 2020 2020 2020 626c                bl
+0000f1b0: 656e 6469 6e67 5f66 756e 633d 7365 6c66  ending_func=self
+0000f1c0: 2e62 6c65 6e64 696e 675f 6675 6e63 2c20  .blending_func, 
+0000f1d0: 6e75 6d5f 696d 6167 6573 5f74 6f5f 626c  num_images_to_bl
+0000f1e0: 656e 643d 7365 6c66 2e6e 756d 5f69 6d61  end=self.num_ima
+0000f1f0: 6765 735f 746f 5f62 6c65 6e64 2c20 7a6f  ges_to_blend, zo
+0000f200: 6f6d 5f72 616e 6765 3d73 656c 662e 7a6f  om_range=self.zo
+0000f210: 6f6d 5f72 616e 6765 2c20 736b 6577 5f61  om_range, skew_a
+0000f220: 6e67 6c65 3d73 6b65 775f 616e 676c 6529  ngle=skew_angle)
+0000f230: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000f240: 2020 2020 2020 2354 6865 2061 7567 6d65        #The augme
+0000f250: 6e74 6174 696f 6e20 726f 7574 696e 6520  ntation routine 
+0000f260: 7265 7475 726e 7320 616e 206f 7574 7075  returns an outpu
+0000f270: 7420 666f 7220 6561 6368 2066 696c 7465  t for each filte
+0000f280: 722c 2065 2e67 2e20 3320 6f75 7470 7574  r, e.g. 3 output
+0000f290: 7320 666f 7220 5247 420a 2020 2020 2020  s for RGB.      
+0000f2a0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000f2b0: 2073 656c 662e 696d 675f 6e75 6d5f 6368   self.img_num_ch
+0000f2c0: 616e 6e65 6c73 203e 2031 3a0a 2020 2020  annels > 1:.    
+0000f2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f2e0: 2020 2020 636c 6173 735f 323d 5b5d 0a20      class_2=[]. 
+0000f2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f300: 2020 2020 2020 2069 6620 7365 6c66 2e69         if self.i
+0000f310: 6d67 5f6e 756d 5f63 6861 6e6e 656c 7320  mg_num_channels 
+0000f320: 3d3d 2032 3a0a 2020 2020 2020 2020 2020  == 2:.          
+0000f330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f340: 2020 666f 7220 6920 696e 2072 616e 6765    for i in range
+0000f350: 286c 656e 2861 7567 6d65 6e74 6564 5f69  (len(augmented_i
+0000f360: 6d61 6765 735f 6e65 6761 7469 7665 5b30  mages_negative[0
+0000f370: 5d29 293a 0a20 2020 2020 2020 2020 2020  ])):.           
+0000f380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f390: 2020 2020 2063 6c61 7373 5f32 2e61 7070       class_2.app
+0000f3a0: 656e 6428 6461 7461 5f70 726f 6365 7373  end(data_process
+0000f3b0: 696e 672e 636f 6e63 6174 5f63 6861 6e6e  ing.concat_chann
+0000f3c0: 656c 7328 6175 676d 656e 7465 645f 696d  els(augmented_im
+0000f3d0: 6167 6573 5f6e 6567 6174 6976 655b 305d  ages_negative[0]
+0000f3e0: 5b69 5d2c 2061 7567 6d65 6e74 6564 5f69  [i], augmented_i
+0000f3f0: 6d61 6765 735f 6e65 6761 7469 7665 5b31  mages_negative[1
+0000f400: 5d5b 695d 2929 0a20 2020 2020 2020 2020  ][i])).         
+0000f410: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+0000f420: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+0000f430: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f440: 2066 6f72 2069 2069 6e20 7261 6e67 6528   for i in range(
+0000f450: 6c65 6e28 6175 676d 656e 7465 645f 696d  len(augmented_im
+0000f460: 6167 6573 5f6e 6567 6174 6976 655b 305d  ages_negative[0]
+0000f470: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
+0000f480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f490: 2020 2020 636c 6173 735f 322e 6170 7065      class_2.appe
+0000f4a0: 6e64 2864 6174 615f 7072 6f63 6573 7369  nd(data_processi
+0000f4b0: 6e67 2e63 6f6e 6361 745f 6368 616e 6e65  ng.concat_channe
+0000f4c0: 6c73 2861 7567 6d65 6e74 6564 5f69 6d61  ls(augmented_ima
+0000f4d0: 6765 735f 6e65 6761 7469 7665 5b30 5d5b  ges_negative[0][
+0000f4e0: 695d 2c20 6175 676d 656e 7465 645f 696d  i], augmented_im
+0000f4f0: 6167 6573 5f6e 6567 6174 6976 655b 315d  ages_negative[1]
+0000f500: 5b69 5d2c 2061 7567 6d65 6e74 6564 5f69  [i], augmented_i
+0000f510: 6d61 6765 735f 6e65 6761 7469 7665 5b32  mages_negative[2
+0000f520: 5d5b 695d 2929 0a20 2020 2020 2020 2020  ][i])).         
+0000f530: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+0000f540: 6c61 7373 5f32 203d 206e 702e 6172 7261  lass_2 = np.arra
+0000f550: 7928 636c 6173 735f 3229 0a20 2020 2020  y(class_2).     
+0000f560: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+0000f570: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+0000f580: 2020 2020 2020 2020 2020 2020 2063 6c61               cla
+0000f590: 7373 5f32 203d 2061 7567 6d65 6e74 6564  ss_2 = augmented
+0000f5a0: 5f69 6d61 6765 735f 6e65 6761 7469 7665  _images_negative
+0000f5b0: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000f5c0: 2020 2020 2020 2342 616c 616e 6365 2074        #Balance t
+0000f5d0: 6865 2063 6c61 7373 2073 697a 6573 2069  he class sizes i
+0000f5e0: 6620 6e65 6365 7373 6172 790a 2020 2020  f necessary.    
 0000f5f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f600: 206e 6f72 6d61 6c69 7a65 3d73 656c 662e   normalize=self.
-0000f610: 6e6f 726d 616c 697a 652c 206d 696e 5f70  normalize, min_p
-0000f620: 6978 656c 3d6d 696e 5f70 6978 2c20 6d61  ixel=min_pix, ma
-0000f630: 785f 7069 7865 6c3d 6d61 785f 7069 782c  x_pixel=max_pix,
-0000f640: 2076 616c 5f70 6f73 6974 6976 653d 7661   val_positive=va
-0000f650: 6c5f 636c 6173 735f 312c 2076 616c 5f6e  l_class_1, val_n
-0000f660: 6567 6174 6976 653d 7661 6c5f 636c 6173  egative=val_clas
-0000f670: 735f 322c 200a 2020 2020 2020 2020 2020  s_2, .          
-0000f680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f690: 2020 6570 6f63 6873 3d73 656c 662e 7472    epochs=self.tr
-0000f6a0: 6169 6e5f 6570 6f63 6873 2c20 6261 7463  ain_epochs, batc
-0000f6b0: 685f 7369 7a65 3d62 6174 6368 5f73 697a  h_size=batch_siz
-0000f6c0: 652c 206f 7074 696d 697a 6572 3d6f 7074  e, optimizer=opt
-0000f6d0: 696d 697a 6572 2c20 6c72 3d6c 722c 2064  imizer, lr=lr, d
-0000f6e0: 6563 6179 3d64 6563 6179 2c20 6d6f 6d65  ecay=decay, mome
-0000f6f0: 6e74 756d 3d6d 6f6d 656e 7475 6d2c 206e  ntum=momentum, n
-0000f700: 6573 7465 726f 763d 6e65 7374 6572 6f76  esterov=nesterov
-0000f710: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
-0000f720: 2020 2020 2020 2020 2020 2020 2020 2062                 b
-0000f730: 6574 615f 313d 6265 7461 5f31 2c20 6265  eta_1=beta_1, be
-0000f740: 7461 5f32 3d62 6574 615f 322c 2061 6d73  ta_2=beta_2, ams
-0000f750: 6772 6164 3d61 6d73 6772 6164 2c20 736d  grad=amsgrad, sm
-0000f760: 6f74 655f 7361 6d70 6c69 6e67 3d73 656c  ote_sampling=sel
-0000f770: 662e 736d 6f74 655f 7361 6d70 6c69 6e67  f.smote_sampling
-0000f780: 2c20 6561 726c 795f 7374 6f70 5f63 616c  , early_stop_cal
-0000f790: 6c62 6163 6b3d 6361 6c6c 6261 636b 732c  lback=callbacks,
-0000f7a0: 2063 6865 636b 706f 696e 743d 4661 6c73   checkpoint=Fals
-0000f7b0: 652c 2076 6572 626f 7365 3d73 656c 662e  e, verbose=self.
-0000f7c0: 7665 7262 6f73 6529 0a20 2020 2020 2020  verbose).       
-0000f7d0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-0000f7e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f7f0: 2020 2069 6620 7365 6c66 2e63 6c66 203d     if self.clf =
-0000f800: 3d20 2761 6c65 786e 6574 273a 0a20 2020  = 'alexnet':.   
-0000f810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f820: 2020 2020 2069 6620 7365 6c66 2e6c 696d       if self.lim
-0000f830: 6974 5f73 6561 7263 683a 0a20 2020 2020  it_search:.     
-0000f840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f850: 2020 2020 2020 206d 6f64 656c 2c20 6869         model, hi
-0000f860: 7374 6f72 7920 3d20 636e 6e5f 6d6f 6465  story = cnn_mode
-0000f870: 6c2e 416c 6578 4e65 7428 636c 6173 735f  l.AlexNet(class_
-0000f880: 312c 2063 6c61 7373 5f32 2c20 696d 675f  1, class_2, img_
-0000f890: 6e75 6d5f 6368 616e 6e65 6c73 3d73 656c  num_channels=sel
-0000f8a0: 662e 696d 675f 6e75 6d5f 6368 616e 6e65  f.img_num_channe
-0000f8b0: 6c73 2c20 0a20 2020 2020 2020 2020 2020  ls, .           
-0000f8c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f8d0: 2020 2020 206e 6f72 6d61 6c69 7a65 3d73       normalize=s
-0000f8e0: 656c 662e 6e6f 726d 616c 697a 652c 206d  elf.normalize, m
-0000f8f0: 696e 5f70 6978 656c 3d6d 696e 5f70 6978  in_pixel=min_pix
-0000f900: 2c20 6d61 785f 7069 7865 6c3d 6d61 785f  , max_pixel=max_
-0000f910: 7069 782c 2076 616c 5f70 6f73 6974 6976  pix, val_positiv
-0000f920: 653d 7661 6c5f 636c 6173 735f 312c 2076  e=val_class_1, v
-0000f930: 616c 5f6e 6567 6174 6976 653d 7661 6c5f  al_negative=val_
-0000f940: 636c 6173 735f 322c 200a 2020 2020 2020  class_2, .      
-0000f950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f960: 2020 2020 2020 2020 2020 6570 6f63 6873            epochs
-0000f970: 3d73 656c 662e 7472 6169 6e5f 6570 6f63  =self.train_epoc
-0000f980: 6873 2c20 6261 7463 685f 7369 7a65 3d62  hs, batch_size=b
-0000f990: 6174 6368 5f73 697a 652c 206f 7074 696d  atch_size, optim
-0000f9a0: 697a 6572 3d6f 7074 696d 697a 6572 2c20  izer=optimizer, 
-0000f9b0: 6c72 3d6c 722c 2064 6563 6179 3d64 6563  lr=lr, decay=dec
-0000f9c0: 6179 2c20 6d6f 6d65 6e74 756d 3d6d 6f6d  ay, momentum=mom
-0000f9d0: 656e 7475 6d2c 206e 6573 7465 726f 763d  entum, nesterov=
-0000f9e0: 6e65 7374 6572 6f76 2c20 0a20 2020 2020  nesterov, .     
-0000f9f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fa00: 2020 2020 2020 2020 2020 2062 6574 615f             beta_
-0000fa10: 313d 6265 7461 5f31 2c20 6265 7461 5f32  1=beta_1, beta_2
-0000fa20: 3d62 6574 615f 322c 2061 6d73 6772 6164  =beta_2, amsgrad
-0000fa30: 3d61 6d73 6772 6164 2c20 6c6f 7373 3d6c  =amsgrad, loss=l
-0000fa40: 6f73 732c 2061 6374 6976 6174 696f 6e5f  oss, activation_
-0000fa50: 636f 6e76 3d61 6374 6976 6174 696f 6e5f  conv=activation_
-0000fa60: 636f 6e76 2c20 6163 7469 7661 7469 6f6e  conv, activation
-0000fa70: 5f64 656e 7365 3d61 6374 6976 6174 696f  _dense=activatio
-0000fa80: 6e5f 6465 6e73 652c 200a 2020 2020 2020  n_dense, .      
-0000fa90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000faa0: 2020 2020 2020 2020 2020 636f 6e76 5f69            conv_i
-0000fab0: 6e69 743d 636f 6e76 5f69 6e69 742c 2064  nit=conv_init, d
-0000fac0: 656e 7365 5f69 6e69 743d 6465 6e73 655f  ense_init=dense_
-0000fad0: 696e 6974 2c20 6d6f 6465 6c5f 7265 673d  init, model_reg=
-0000fae0: 6d6f 6465 6c5f 7265 672c 2070 6f6f 6c69  model_reg, pooli
-0000faf0: 6e67 5f31 3d70 6f6f 6c69 6e67 5f31 2c20  ng_1=pooling_1, 
-0000fb00: 706f 6f6c 696e 675f 323d 706f 6f6c 696e  pooling_2=poolin
-0000fb10: 675f 322c 2070 6f6f 6c69 6e67 5f33 3d70  g_2, pooling_3=p
-0000fb20: 6f6f 6c69 6e67 5f33 2c20 0a20 2020 2020  ooling_3, .     
-0000fb30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fb40: 2020 2020 2020 2020 2020 2073 6d6f 7465             smote
-0000fb50: 5f73 616d 706c 696e 673d 7365 6c66 2e73  _sampling=self.s
-0000fb60: 6d6f 7465 5f73 616d 706c 696e 672c 2065  mote_sampling, e
-0000fb70: 6172 6c79 5f73 746f 705f 6361 6c6c 6261  arly_stop_callba
-0000fb80: 636b 3d63 616c 6c62 6163 6b73 2c20 6368  ck=callbacks, ch
-0000fb90: 6563 6b70 6f69 6e74 3d46 616c 7365 2c20  eckpoint=False, 
-0000fba0: 7665 7262 6f73 653d 7365 6c66 2e76 6572  verbose=self.ver
-0000fbb0: 626f 7365 290a 2020 2020 2020 2020 2020  bose).          
-0000fbc0: 2020 2020 2020 2020 2020 2020 2020 656c                el
-0000fbd0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-0000fbe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fbf0: 6d6f 6465 6c2c 2068 6973 746f 7279 203d  model, history =
-0000fc00: 2063 6e6e 5f6d 6f64 656c 2e41 6c65 784e   cnn_model.AlexN
-0000fc10: 6574 2863 6c61 7373 5f31 2c20 636c 6173  et(class_1, clas
-0000fc20: 735f 322c 2069 6d67 5f6e 756d 5f63 6861  s_2, img_num_cha
-0000fc30: 6e6e 656c 733d 7365 6c66 2e69 6d67 5f6e  nnels=self.img_n
-0000fc40: 756d 5f63 6861 6e6e 656c 732c 200a 2020  um_channels, .  
+0000f600: 6966 2073 656c 662e 6261 6c61 6e63 653a  if self.balance:
+0000f610: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f620: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+0000f630: 2e62 6174 6368 5f6f 7468 6572 203e 2031  .batch_other > 1
+0000f640: 3a20 234d 7573 7420 7368 7566 666c 6521  : #Must shuffle!
+0000f650: 2121 0a20 2020 2020 2020 2020 2020 2020  !!.             
+0000f660: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0000f670: 7820 3d20 6e70 2e72 616e 646f 6d2e 7065  x = np.random.pe
+0000f680: 726d 7574 6174 696f 6e28 6c65 6e28 636c  rmutation(len(cl
+0000f690: 6173 735f 3229 290a 2020 2020 2020 2020  ass_2)).        
+0000f6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f6b0: 2020 2020 636c 6173 735f 3220 3d20 636c      class_2 = cl
+0000f6c0: 6173 735f 325b 6978 5d0a 2020 2020 2020  ass_2[ix].      
+0000f6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f6e0: 2020 636c 6173 735f 3220 3d20 636c 6173    class_2 = clas
+0000f6f0: 735f 325b 3a6c 656e 2863 6c61 7373 5f31  s_2[:len(class_1
+0000f700: 295d 2020 200a 0a20 2020 2020 2020 2020  )]   ..         
+0000f710: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+0000f720: 6c66 2e69 6d67 5f6e 756d 5f63 6861 6e6e  lf.img_num_chann
+0000f730: 656c 7320 3d3d 2031 3a0a 2020 2020 2020  els == 1:.      
+0000f740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f750: 2020 636c 6173 735f 3220 3d20 7265 7369    class_2 = resi
+0000f760: 7a65 2863 6c61 7373 5f32 2c20 7369 7a65  ze(class_2, size
+0000f770: 3d69 6d61 6765 5f73 697a 6529 0a20 2020  =image_size).   
+0000f780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f790: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+0000f7a0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+0000f7b0: 6861 6e6e 656c 3120 3d20 7265 7369 7a65  hannel1 = resize
+0000f7c0: 2863 6c61 7373 5f32 5b3a 2c3a 2c3a 2c30  (class_2[:,:,:,0
+0000f7d0: 5d2c 2073 697a 653d 696d 6167 655f 7369  ], size=image_si
+0000f7e0: 7a65 290a 2020 2020 2020 2020 2020 2020  ze).            
+0000f7f0: 2020 2020 2020 2020 2020 2020 6368 616e              chan
+0000f800: 6e65 6c32 203d 2072 6573 697a 6528 636c  nel2 = resize(cl
+0000f810: 6173 735f 325b 3a2c 3a2c 3a2c 315d 2c20  ass_2[:,:,:,1], 
+0000f820: 7369 7a65 3d69 6d61 6765 5f73 697a 6529  size=image_size)
+0000f830: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f840: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+0000f850: 2e69 6d67 5f6e 756d 5f63 6861 6e6e 656c  .img_num_channel
+0000f860: 7320 3d3d 2032 3a0a 2020 2020 2020 2020  s == 2:.        
+0000f870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f880: 2020 2020 636c 6173 735f 3220 3d20 6461      class_2 = da
+0000f890: 7461 5f70 726f 6365 7373 696e 672e 636f  ta_processing.co
+0000f8a0: 6e63 6174 5f63 6861 6e6e 656c 7328 6368  ncat_channels(ch
+0000f8b0: 616e 6e65 6c31 2c20 6368 616e 6e65 6c32  annel1, channel2
+0000f8c0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0000f8d0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+0000f8e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f8f0: 2020 2020 2020 2020 2020 2020 6368 616e              chan
+0000f900: 6e65 6c33 203d 2072 6573 697a 6528 636c  nel3 = resize(cl
+0000f910: 6173 735f 325b 3a2c 3a2c 3a2c 325d 2c20  ass_2[:,:,:,2], 
+0000f920: 7369 7a65 3d69 6d61 6765 5f73 697a 6529  size=image_size)
+0000f930: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f940: 2020 2020 2020 2020 2020 2020 2063 6c61               cla
+0000f950: 7373 5f32 203d 2064 6174 615f 7072 6f63  ss_2 = data_proc
+0000f960: 6573 7369 6e67 2e63 6f6e 6361 745f 6368  essing.concat_ch
+0000f970: 616e 6e65 6c73 2863 6861 6e6e 656c 312c  annels(channel1,
+0000f980: 2063 6861 6e6e 656c 322c 2063 6861 6e6e   channel2, chann
+0000f990: 656c 3329 0a0a 2020 2020 2020 2020 2020  el3)..          
+0000f9a0: 2020 2020 2020 2020 2020 6966 2076 616c            if val
+0000f9b0: 5f63 6c61 7373 5f31 2069 7320 6e6f 7420  _class_1 is not 
+0000f9c0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+0000f9d0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000f9e0: 2073 656c 662e 696d 675f 6e75 6d5f 6368   self.img_num_ch
+0000f9f0: 616e 6e65 6c73 203d 3d20 313a 0a20 2020  annels == 1:.   
+0000fa00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fa10: 2020 2020 2020 2020 2076 616c 5f63 6c61           val_cla
+0000fa20: 7373 5f31 203d 2072 6573 697a 6528 7661  ss_1 = resize(va
+0000fa30: 6c5f 636c 6173 735f 312c 2073 697a 653d  l_class_1, size=
+0000fa40: 696d 6167 655f 7369 7a65 290a 2020 2020  image_size).    
+0000fa50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fa60: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+0000fa70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fa80: 2020 2020 2020 7661 6c5f 6368 616e 6e65        val_channe
+0000fa90: 6c31 203d 2072 6573 697a 6528 7661 6c5f  l1 = resize(val_
+0000faa0: 636c 6173 735f 315b 3a2c 3a2c 3a2c 305d  class_1[:,:,:,0]
+0000fab0: 2c20 7369 7a65 3d69 6d61 6765 5f73 697a  , size=image_siz
+0000fac0: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+0000fad0: 2020 2020 2020 2020 2020 2020 2020 2076                 v
+0000fae0: 616c 5f63 6861 6e6e 656c 3220 3d20 7265  al_channel2 = re
+0000faf0: 7369 7a65 2876 616c 5f63 6c61 7373 5f31  size(val_class_1
+0000fb00: 5b3a 2c3a 2c3a 2c31 5d2c 2073 697a 653d  [:,:,:,1], size=
+0000fb10: 696d 6167 655f 7369 7a65 290a 2020 2020  image_size).    
+0000fb20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fb30: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+0000fb40: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+0000fb50: 203d 3d20 323a 0a20 2020 2020 2020 2020   == 2:.         
+0000fb60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fb70: 2020 2020 2020 2076 616c 5f63 6c61 7373         val_class
+0000fb80: 5f31 203d 2064 6174 615f 7072 6f63 6573  _1 = data_proces
+0000fb90: 7369 6e67 2e63 6f6e 6361 745f 6368 616e  sing.concat_chan
+0000fba0: 6e65 6c73 2876 616c 5f63 6861 6e6e 656c  nels(val_channel
+0000fbb0: 312c 2076 616c 5f63 6861 6e6e 656c 3229  1, val_channel2)
+0000fbc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000fbd0: 2020 2020 2020 2020 2020 2020 2065 6c73               els
+0000fbe0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+0000fbf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fc00: 2020 2076 616c 5f63 6861 6e6e 656c 3320     val_channel3 
+0000fc10: 3d20 7265 7369 7a65 2876 616c 5f63 6c61  = resize(val_cla
+0000fc20: 7373 5f31 5b3a 2c3a 2c3a 2c32 5d2c 2073  ss_1[:,:,:,2], s
+0000fc30: 697a 653d 696d 6167 655f 7369 7a65 290a  ize=image_size).
+0000fc40: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0000fc50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fc60: 2020 2020 2020 2020 2020 2020 2020 6e6f                no
-0000fc70: 726d 616c 697a 653d 7365 6c66 2e6e 6f72  rmalize=self.nor
-0000fc80: 6d61 6c69 7a65 2c20 6d69 6e5f 7069 7865  malize, min_pixe
-0000fc90: 6c3d 6d69 6e5f 7069 782c 206d 6178 5f70  l=min_pix, max_p
-0000fca0: 6978 656c 3d6d 6178 5f70 6978 2c20 7661  ixel=max_pix, va
-0000fcb0: 6c5f 706f 7369 7469 7665 3d76 616c 5f63  l_positive=val_c
-0000fcc0: 6c61 7373 5f31 2c20 7661 6c5f 6e65 6761  lass_1, val_nega
-0000fcd0: 7469 7665 3d76 616c 5f63 6c61 7373 5f32  tive=val_class_2
-0000fce0: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+0000fc60: 7661 6c5f 636c 6173 735f 3120 3d20 6461  val_class_1 = da
+0000fc70: 7461 5f70 726f 6365 7373 696e 672e 636f  ta_processing.co
+0000fc80: 6e63 6174 5f63 6861 6e6e 656c 7328 7661  ncat_channels(va
+0000fc90: 6c5f 6368 616e 6e65 6c31 2c20 7661 6c5f  l_channel1, val_
+0000fca0: 6368 616e 6e65 6c32 2c20 7661 6c5f 6368  channel2, val_ch
+0000fcb0: 616e 6e65 6c33 290a 0a20 2020 2020 2020  annel3)..       
+0000fcc0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0000fcd0: 7661 6c5f 636c 6173 735f 3220 6973 206e  val_class_2 is n
+0000fce0: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
 0000fcf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fd00: 2020 2065 706f 6368 733d 7365 6c66 2e74     epochs=self.t
-0000fd10: 7261 696e 5f65 706f 6368 732c 2062 6174  rain_epochs, bat
-0000fd20: 6368 5f73 697a 653d 6261 7463 685f 7369  ch_size=batch_si
-0000fd30: 7a65 2c20 6f70 7469 6d69 7a65 723d 6f70  ze, optimizer=op
-0000fd40: 7469 6d69 7a65 722c 206c 723d 6c72 2c20  timizer, lr=lr, 
-0000fd50: 6465 6361 793d 6465 6361 792c 206d 6f6d  decay=decay, mom
-0000fd60: 656e 7475 6d3d 6d6f 6d65 6e74 756d 2c20  entum=momentum, 
-0000fd70: 6e65 7374 6572 6f76 3d6e 6573 7465 726f  nesterov=nestero
-0000fd80: 762c 200a 2020 2020 2020 2020 2020 2020  v, .            
-0000fd90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fda0: 2020 2020 6265 7461 5f31 3d62 6574 615f      beta_1=beta_
-0000fdb0: 312c 2062 6574 615f 323d 6265 7461 5f32  1, beta_2=beta_2
-0000fdc0: 2c20 616d 7367 7261 643d 616d 7367 7261  , amsgrad=amsgra
-0000fdd0: 642c 206c 6f73 733d 6c6f 7373 2c20 6163  d, loss=loss, ac
-0000fde0: 7469 7661 7469 6f6e 5f63 6f6e 763d 6163  tivation_conv=ac
-0000fdf0: 7469 7661 7469 6f6e 5f63 6f6e 762c 2061  tivation_conv, a
-0000fe00: 6374 6976 6174 696f 6e5f 6465 6e73 653d  ctivation_dense=
-0000fe10: 6163 7469 7661 7469 6f6e 5f64 656e 7365  activation_dense
-0000fe20: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
-0000fe30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fe40: 2020 2063 6f6e 765f 696e 6974 3d63 6f6e     conv_init=con
-0000fe50: 765f 696e 6974 2c20 6465 6e73 655f 696e  v_init, dense_in
-0000fe60: 6974 3d64 656e 7365 5f69 6e69 742c 206d  it=dense_init, m
-0000fe70: 6f64 656c 5f72 6567 3d6d 6f64 656c 5f72  odel_reg=model_r
-0000fe80: 6567 2c20 0a20 2020 2020 2020 2020 2020  eg, .           
-0000fe90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fea0: 2020 2020 2066 696c 7465 725f 313d 6669       filter_1=fi
-0000feb0: 6c74 6572 5f31 2c20 6669 6c74 6572 5f73  lter_1, filter_s
-0000fec0: 697a 655f 313d 6669 6c74 6572 5f73 697a  ize_1=filter_siz
-0000fed0: 655f 312c 2073 7472 6964 6573 5f31 3d73  e_1, strides_1=s
-0000fee0: 7472 6964 6573 5f31 2c20 706f 6f6c 696e  trides_1, poolin
-0000fef0: 675f 313d 706f 6f6c 696e 675f 312c 2070  g_1=pooling_1, p
-0000ff00: 6f6f 6c5f 7369 7a65 5f31 3d70 6f6f 6c5f  ool_size_1=pool_
-0000ff10: 7369 7a65 5f31 2c20 706f 6f6c 5f73 7472  size_1, pool_str
-0000ff20: 6964 655f 313d 706f 6f6c 5f73 7472 6964  ide_1=pool_strid
-0000ff30: 655f 312c 0a20 2020 2020 2020 2020 2020  e_1,.           
-0000ff40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ff50: 2020 2020 2066 696c 7465 725f 323d 6669       filter_2=fi
-0000ff60: 6c74 6572 5f32 2c20 6669 6c74 6572 5f73  lter_2, filter_s
-0000ff70: 697a 655f 323d 6669 6c74 6572 5f73 697a  ize_2=filter_siz
-0000ff80: 655f 322c 2073 7472 6964 6573 5f32 3d73  e_2, strides_2=s
-0000ff90: 7472 6964 6573 5f32 2c20 706f 6f6c 696e  trides_2, poolin
-0000ffa0: 675f 323d 706f 6f6c 696e 675f 322c 2070  g_2=pooling_2, p
-0000ffb0: 6f6f 6c5f 7369 7a65 5f32 3d70 6f6f 6c5f  ool_size_2=pool_
-0000ffc0: 7369 7a65 5f32 2c20 706f 6f6c 5f73 7472  size_2, pool_str
-0000ffd0: 6964 655f 323d 706f 6f6c 5f73 7472 6964  ide_2=pool_strid
-0000ffe0: 655f 322c 0a20 2020 2020 2020 2020 2020  e_2,.           
-0000fff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010000: 2020 2020 2066 696c 7465 725f 333d 6669       filter_3=fi
-00010010: 6c74 6572 5f33 2c20 6669 6c74 6572 5f73  lter_3, filter_s
-00010020: 697a 655f 333d 6669 6c74 6572 5f73 697a  ize_3=filter_siz
-00010030: 655f 332c 2073 7472 6964 6573 5f33 3d73  e_3, strides_3=s
-00010040: 7472 6964 6573 5f33 2c20 706f 6f6c 696e  trides_3, poolin
-00010050: 675f 333d 706f 6f6c 696e 675f 332c 2070  g_3=pooling_3, p
-00010060: 6f6f 6c5f 7369 7a65 5f33 3d70 6f6f 6c5f  ool_size_3=pool_
-00010070: 7369 7a65 5f33 2c20 706f 6f6c 5f73 7472  size_3, pool_str
-00010080: 6964 655f 333d 706f 6f6c 5f73 7472 6964  ide_3=pool_strid
-00010090: 655f 332c 0a20 2020 2020 2020 2020 2020  e_3,.           
-000100a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000100b0: 2020 2020 2066 696c 7465 725f 343d 6669       filter_4=fi
-000100c0: 6c74 6572 5f34 2c20 6669 6c74 6572 5f73  lter_4, filter_s
-000100d0: 697a 655f 343d 6669 6c74 6572 5f73 697a  ize_4=filter_siz
-000100e0: 655f 342c 2073 7472 6964 6573 5f34 3d73  e_4, strides_4=s
-000100f0: 7472 6964 6573 5f34 2c20 0a20 2020 2020  trides_4, .     
-00010100: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010110: 2020 2020 2020 2020 2020 2066 696c 7465             filte
-00010120: 725f 353d 6669 6c74 6572 5f35 2c20 6669  r_5=filter_5, fi
-00010130: 6c74 6572 5f73 697a 655f 353d 6669 6c74  lter_size_5=filt
-00010140: 6572 5f73 697a 655f 352c 2073 7472 6964  er_size_5, strid
-00010150: 6573 5f35 3d73 7472 6964 6573 5f35 2c0a  es_5=strides_5,.
-00010160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fd00: 2069 6620 7365 6c66 2e69 6d67 5f6e 756d   if self.img_num
+0000fd10: 5f63 6861 6e6e 656c 7320 3d3d 2031 3a0a  _channels == 1:.
+0000fd20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fd30: 2020 2020 2020 2020 2020 2020 7661 6c5f              val_
+0000fd40: 636c 6173 735f 3220 3d20 7265 7369 7a65  class_2 = resize
+0000fd50: 2876 616c 5f63 6c61 7373 5f32 2c20 7369  (val_class_2, si
+0000fd60: 7a65 3d69 6d61 6765 5f73 697a 6529 0a20  ze=image_size). 
+0000fd70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fd80: 2020 2020 2020 2065 6c69 6620 7365 6c66         elif self
+0000fd90: 2e69 6d67 5f6e 756d 5f63 6861 6e6e 656c  .img_num_channel
+0000fda0: 7320 3e20 313a 0a20 2020 2020 2020 2020  s > 1:.         
+0000fdb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fdc0: 2020 2076 616c 5f63 6861 6e6e 656c 3120     val_channel1 
+0000fdd0: 3d20 7265 7369 7a65 2876 616c 5f63 6c61  = resize(val_cla
+0000fde0: 7373 5f32 5b3a 2c3a 2c3a 2c30 5d2c 2073  ss_2[:,:,:,0], s
+0000fdf0: 697a 653d 696d 6167 655f 7369 7a65 290a  ize=image_size).
+0000fe00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fe10: 2020 2020 2020 2020 2020 2020 7661 6c5f              val_
+0000fe20: 6368 616e 6e65 6c32 203d 2072 6573 697a  channel2 = resiz
+0000fe30: 6528 7661 6c5f 636c 6173 735f 325b 3a2c  e(val_class_2[:,
+0000fe40: 3a2c 3a2c 315d 2c20 7369 7a65 3d69 6d61  :,:,1], size=ima
+0000fe50: 6765 5f73 697a 6529 0a20 2020 2020 2020  ge_size).       
+0000fe60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fe70: 2020 2020 2069 6620 7365 6c66 2e69 6d67       if self.img
+0000fe80: 5f6e 756d 5f63 6861 6e6e 656c 7320 3d3d  _num_channels ==
+0000fe90: 2032 3a0a 2020 2020 2020 2020 2020 2020   2:.            
+0000fea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000feb0: 2020 2020 7661 6c5f 636c 6173 735f 3220      val_class_2 
+0000fec0: 3d20 6461 7461 5f70 726f 6365 7373 696e  = data_processin
+0000fed0: 672e 636f 6e63 6174 5f63 6861 6e6e 656c  g.concat_channel
+0000fee0: 7328 7661 6c5f 6368 616e 6e65 6c31 2c20  s(val_channel1, 
+0000fef0: 7661 6c5f 6368 616e 6e65 6c32 290a 2020  val_channel2).  
+0000ff00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ff10: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+0000ff20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ff30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ff40: 7661 6c5f 6368 616e 6e65 6c33 203d 2072  val_channel3 = r
+0000ff50: 6573 697a 6528 7661 6c5f 636c 6173 735f  esize(val_class_
+0000ff60: 325b 3a2c 3a2c 3a2c 325d 2c20 7369 7a65  2[:,:,:,2], size
+0000ff70: 3d69 6d61 6765 5f73 697a 6529 0a20 2020  =image_size).   
+0000ff80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ff90: 2020 2020 2020 2020 2020 2020 2076 616c               val
+0000ffa0: 5f63 6c61 7373 5f32 203d 2064 6174 615f  _class_2 = data_
+0000ffb0: 7072 6f63 6573 7369 6e67 2e63 6f6e 6361  processing.conca
+0000ffc0: 745f 6368 616e 6e65 6c73 2876 616c 5f63  t_channels(val_c
+0000ffd0: 6861 6e6e 656c 312c 2076 616c 5f63 6861  hannel1, val_cha
+0000ffe0: 6e6e 656c 322c 2076 616c 5f63 6861 6e6e  nnel2, val_chann
+0000fff0: 656c 3329 0a0a 2020 2020 2020 2020 2020  el3)..          
+00010000: 2020 2020 2020 6966 2073 656c 662e 7665        if self.ve
+00010010: 7262 6f73 6520 3d3d 2031 3a0a 2020 2020  rbose == 1:.    
+00010020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010030: 7072 696e 7428 293b 2070 7269 6e74 2827  print(); print('
+00010040: 2a2a 2a2a 2a2a 2a2a 2a2a 2a20 2043 5620  ***********  CV 
+00010050: 2d20 7b7d 202a 2a2a 2a2a 2a2a 2a2a 2a2a  - {} ***********
+00010060: 272e 666f 726d 6174 286b 2b32 2929 3b20  '.format(k+2)); 
+00010070: 7072 696e 7428 290a 0a20 2020 2020 2020  print()..       
+00010080: 2020 2020 2020 2020 2063 6c65 6172 5f73           clear_s
+00010090: 6573 7369 6f6e 2829 0a20 2020 2020 2020  ession().       
+000100a0: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+000100b0: 2e6f 7074 5f6d 6f64 656c 2069 7320 4661  .opt_model is Fa
+000100c0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+000100d0: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+000100e0: 2e63 6c66 203d 3d20 2761 6c65 786e 6574  .clf == 'alexnet
+000100f0: 273a 0a20 2020 2020 2020 2020 2020 2020  ':.             
+00010100: 2020 2020 2020 2020 2020 206d 6f64 656c             model
+00010110: 2c20 6869 7374 6f72 7920 3d20 636e 6e5f  , history = cnn_
+00010120: 6d6f 6465 6c2e 416c 6578 4e65 7428 636c  model.AlexNet(cl
+00010130: 6173 735f 312c 2063 6c61 7373 5f32 2c20  ass_1, class_2, 
+00010140: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+00010150: 3d73 656c 662e 696d 675f 6e75 6d5f 6368  =self.img_num_ch
+00010160: 616e 6e65 6c73 2c20 0a20 2020 2020 2020  annels, .       
 00010170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010180: 6465 6e73 655f 6e65 7572 6f6e 735f 313d  dense_neurons_1=
-00010190: 6465 6e73 655f 6e65 7572 6f6e 735f 312c  dense_neurons_1,
-000101a0: 2064 656e 7365 5f6e 6575 726f 6e73 5f32   dense_neurons_2
-000101b0: 3d64 656e 7365 5f6e 6575 726f 6e73 5f32  =dense_neurons_2
-000101c0: 2c20 6472 6f70 6f75 745f 313d 6472 6f70  , dropout_1=drop
-000101d0: 6f75 745f 312c 2064 726f 706f 7574 5f32  out_1, dropout_2
-000101e0: 3d64 726f 706f 7574 5f32 2c20 0a20 2020  =dropout_2, .   
-000101f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010200: 2020 2020 2020 2020 2020 2020 2073 6d6f               smo
-00010210: 7465 5f73 616d 706c 696e 673d 7365 6c66  te_sampling=self
-00010220: 2e73 6d6f 7465 5f73 616d 706c 696e 672c  .smote_sampling,
-00010230: 2065 6172 6c79 5f73 746f 705f 6361 6c6c   early_stop_call
-00010240: 6261 636b 3d63 616c 6c62 6163 6b73 2c20  back=callbacks, 
-00010250: 6368 6563 6b70 6f69 6e74 3d46 616c 7365  checkpoint=False
-00010260: 2c20 7665 7262 6f73 653d 7365 6c66 2e76  , verbose=self.v
-00010270: 6572 626f 7365 290a 2020 2020 2020 2020  erbose).        
-00010280: 2020 2020 2020 2020 2020 2020 656c 6966              elif
-00010290: 2073 656c 662e 636c 6620 3d3d 2027 6375   self.clf == 'cu
-000102a0: 7374 6f6d 5f63 6e6e 273a 0a20 2020 2020  stom_cnn':.     
-000102b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000102c0: 2020 206d 6f64 656c 2c20 6869 7374 6f72     model, histor
-000102d0: 7920 3d20 636e 6e5f 6d6f 6465 6c2e 6375  y = cnn_model.cu
-000102e0: 7374 6f6d 5f6d 6f64 656c 2863 6c61 7373  stom_model(class
-000102f0: 5f31 2c20 636c 6173 735f 322c 2069 6d67  _1, class_2, img
-00010300: 5f6e 756d 5f63 6861 6e6e 656c 733d 7365  _num_channels=se
-00010310: 6c66 2e69 6d67 5f6e 756d 5f63 6861 6e6e  lf.img_num_chann
-00010320: 656c 732c 200a 2020 2020 2020 2020 2020  els, .          
-00010330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010340: 2020 6e6f 726d 616c 697a 653d 7365 6c66    normalize=self
-00010350: 2e6e 6f72 6d61 6c69 7a65 2c20 6d69 6e5f  .normalize, min_
-00010360: 7069 7865 6c3d 6d69 6e5f 7069 782c 206d  pixel=min_pix, m
-00010370: 6178 5f70 6978 656c 3d6d 6178 5f70 6978  ax_pixel=max_pix
-00010380: 2c20 7661 6c5f 706f 7369 7469 7665 3d76  , val_positive=v
-00010390: 616c 5f63 6c61 7373 5f31 2c20 7661 6c5f  al_class_1, val_
-000103a0: 6e65 6761 7469 7665 3d76 616c 5f63 6c61  negative=val_cla
-000103b0: 7373 5f32 2c20 0a20 2020 2020 2020 2020  ss_2, .         
-000103c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000103d0: 2020 2065 706f 6368 733d 7365 6c66 2e74     epochs=self.t
-000103e0: 7261 696e 5f65 706f 6368 732c 2062 6174  rain_epochs, bat
-000103f0: 6368 5f73 697a 653d 6261 7463 685f 7369  ch_size=batch_si
-00010400: 7a65 2c20 6f70 7469 6d69 7a65 723d 6f70  ze, optimizer=op
-00010410: 7469 6d69 7a65 722c 206c 723d 6c72 2c20  timizer, lr=lr, 
-00010420: 6465 6361 793d 6465 6361 792c 206d 6f6d  decay=decay, mom
-00010430: 656e 7475 6d3d 6d6f 6d65 6e74 756d 2c20  entum=momentum, 
-00010440: 6e65 7374 6572 6f76 3d6e 6573 7465 726f  nesterov=nestero
-00010450: 762c 200a 2020 2020 2020 2020 2020 2020  v, .            
-00010460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010470: 6265 7461 5f31 3d62 6574 615f 312c 2062  beta_1=beta_1, b
-00010480: 6574 615f 323d 6265 7461 5f32 2c20 616d  eta_2=beta_2, am
-00010490: 7367 7261 643d 616d 7367 7261 642c 206c  sgrad=amsgrad, l
-000104a0: 6f73 733d 6c6f 7373 2c20 6163 7469 7661  oss=loss, activa
-000104b0: 7469 6f6e 5f63 6f6e 763d 6163 7469 7661  tion_conv=activa
-000104c0: 7469 6f6e 5f63 6f6e 762c 2061 6374 6976  tion_conv, activ
-000104d0: 6174 696f 6e5f 6465 6e73 653d 6163 7469  ation_dense=acti
-000104e0: 7661 7469 6f6e 5f64 656e 7365 2c20 0a20  vation_dense, . 
-000104f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010500: 2020 2020 2020 2020 2020 2063 6f6e 765f             conv_
-00010510: 696e 6974 3d63 6f6e 765f 696e 6974 2c20  init=conv_init, 
-00010520: 6465 6e73 655f 696e 6974 3d64 656e 7365  dense_init=dense
-00010530: 5f69 6e69 742c 206d 6f64 656c 5f72 6567  _init, model_reg
-00010540: 3d6d 6f64 656c 5f72 6567 2c20 0a20 2020  =model_reg, .   
-00010550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010560: 2020 2020 2020 2020 2066 696c 7465 725f           filter_
-00010570: 313d 6669 6c74 6572 5f31 2c20 6669 6c74  1=filter_1, filt
-00010580: 6572 5f73 697a 655f 313d 6669 6c74 6572  er_size_1=filter
-00010590: 5f73 697a 655f 312c 2073 7472 6964 6573  _size_1, strides
-000105a0: 5f31 3d73 7472 6964 6573 5f31 2c20 706f  _1=strides_1, po
-000105b0: 6f6c 696e 675f 313d 706f 6f6c 696e 675f  oling_1=pooling_
-000105c0: 312c 2070 6f6f 6c5f 7369 7a65 5f31 3d70  1, pool_size_1=p
-000105d0: 6f6f 6c5f 7369 7a65 5f31 2c20 706f 6f6c  ool_size_1, pool
-000105e0: 5f73 7472 6964 655f 313d 706f 6f6c 5f73  _stride_1=pool_s
-000105f0: 7472 6964 655f 312c 200a 2020 2020 2020  tride_1, .      
-00010600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010610: 2020 2020 2020 6669 6c74 6572 5f32 3d66        filter_2=f
-00010620: 696c 7465 725f 322c 2066 696c 7465 725f  ilter_2, filter_
-00010630: 7369 7a65 5f32 3d66 696c 7465 725f 7369  size_2=filter_si
-00010640: 7a65 5f32 2c20 7374 7269 6465 735f 323d  ze_2, strides_2=
-00010650: 7374 7269 6465 735f 322c 2070 6f6f 6c69  strides_2, pooli
-00010660: 6e67 5f32 3d70 6f6f 6c69 6e67 5f32 2c20  ng_2=pooling_2, 
-00010670: 706f 6f6c 5f73 697a 655f 323d 706f 6f6c  pool_size_2=pool
-00010680: 5f73 697a 655f 322c 2070 6f6f 6c5f 7374  _size_2, pool_st
-00010690: 7269 6465 5f32 3d70 6f6f 6c5f 7374 7269  ride_2=pool_stri
-000106a0: 6465 5f32 2c20 0a20 2020 2020 2020 2020  de_2, .         
-000106b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000106c0: 2020 2066 696c 7465 725f 333d 6669 6c74     filter_3=filt
-000106d0: 6572 5f33 2c20 6669 6c74 6572 5f73 697a  er_3, filter_siz
-000106e0: 655f 333d 6669 6c74 6572 5f73 697a 655f  e_3=filter_size_
-000106f0: 332c 2073 7472 6964 6573 5f33 3d73 7472  3, strides_3=str
-00010700: 6964 6573 5f33 2c20 706f 6f6c 696e 675f  ides_3, pooling_
-00010710: 333d 706f 6f6c 696e 675f 332c 2070 6f6f  3=pooling_3, poo
-00010720: 6c5f 7369 7a65 5f33 3d70 6f6f 6c5f 7369  l_size_3=pool_si
-00010730: 7a65 5f33 2c20 706f 6f6c 5f73 7472 6964  ze_3, pool_strid
-00010740: 655f 333d 706f 6f6c 5f73 7472 6964 655f  e_3=pool_stride_
-00010750: 332c 200a 2020 2020 2020 2020 2020 2020  3, .            
-00010760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010770: 6465 6e73 655f 6e65 7572 6f6e 735f 313d  dense_neurons_1=
-00010780: 6465 6e73 655f 6e65 7572 6f6e 735f 312c  dense_neurons_1,
-00010790: 2064 656e 7365 5f6e 6575 726f 6e73 5f32   dense_neurons_2
-000107a0: 3d64 656e 7365 5f6e 6575 726f 6e73 5f32  =dense_neurons_2
-000107b0: 2c20 6465 6e73 655f 6e65 7572 6f6e 735f  , dense_neurons_
-000107c0: 333d 6465 6e73 655f 6e65 7572 6f6e 735f  3=dense_neurons_
-000107d0: 332c 200a 2020 2020 2020 2020 2020 2020  3, .            
-000107e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000107f0: 6472 6f70 6f75 745f 313d 6472 6f70 6f75  dropout_1=dropou
-00010800: 745f 312c 2064 726f 706f 7574 5f32 3d64  t_1, dropout_2=d
-00010810: 726f 706f 7574 5f32 2c20 6472 6f70 6f75  ropout_2, dropou
-00010820: 745f 333d 6472 6f70 6f75 745f 332c 2073  t_3=dropout_3, s
-00010830: 6d6f 7465 5f73 616d 706c 696e 673d 7365  mote_sampling=se
-00010840: 6c66 2e73 6d6f 7465 5f73 616d 706c 696e  lf.smote_samplin
-00010850: 672c 200a 2020 2020 2020 2020 2020 2020  g, .            
-00010860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010870: 6561 726c 795f 7374 6f70 5f63 616c 6c62  early_stop_callb
-00010880: 6163 6b3d 6361 6c6c 6261 636b 732c 2063  ack=callbacks, c
-00010890: 6865 636b 706f 696e 743d 4661 6c73 652c  heckpoint=False,
-000108a0: 2076 6572 626f 7365 3d73 656c 662e 7665   verbose=self.ve
-000108b0: 7262 6f73 6529 2020 0a20 2020 2020 2020  rbose)  .       
-000108c0: 2020 2020 2020 2020 2020 2020 2065 6c69               eli
-000108d0: 6620 7365 6c66 2e63 6c66 203d 3d20 2776  f self.clf == 'v
-000108e0: 6767 3136 273a 0a20 2020 2020 2020 2020  gg16':.         
-000108f0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00010900: 6620 7365 6c66 2e6c 696d 6974 5f73 6561  f self.limit_sea
-00010910: 7263 683a 0a20 2020 2020 2020 2020 2020  rch:.           
-00010920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010930: 206d 6f64 656c 2c20 6869 7374 6f72 7920   model, history 
-00010940: 3d20 636e 6e5f 6d6f 6465 6c2e 5647 4731  = cnn_model.VGG1
-00010950: 3628 636c 6173 735f 312c 2063 6c61 7373  6(class_1, class
-00010960: 5f32 2c20 696d 675f 6e75 6d5f 6368 616e  _2, img_num_chan
-00010970: 6e65 6c73 3d73 656c 662e 696d 675f 6e75  nels=self.img_nu
-00010980: 6d5f 6368 616e 6e65 6c73 2c20 0a20 2020  m_channels, .   
-00010990: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000109a0: 2020 2020 2020 2020 2020 2020 206e 6f72               nor
-000109b0: 6d61 6c69 7a65 3d73 656c 662e 6e6f 726d  malize=self.norm
-000109c0: 616c 697a 652c 206d 696e 5f70 6978 656c  alize, min_pixel
-000109d0: 3d6d 696e 5f70 6978 2c20 6d61 785f 7069  =min_pix, max_pi
-000109e0: 7865 6c3d 6d61 785f 7069 782c 2076 616c  xel=max_pix, val
-000109f0: 5f70 6f73 6974 6976 653d 7661 6c5f 636c  _positive=val_cl
-00010a00: 6173 735f 312c 2076 616c 5f6e 6567 6174  ass_1, val_negat
-00010a10: 6976 653d 7661 6c5f 636c 6173 735f 322c  ive=val_class_2,
-00010a20: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-00010a30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010a40: 2020 6570 6f63 6873 3d73 656c 662e 7472    epochs=self.tr
-00010a50: 6169 6e5f 6570 6f63 6873 2c20 6261 7463  ain_epochs, batc
-00010a60: 685f 7369 7a65 3d62 6174 6368 5f73 697a  h_size=batch_siz
-00010a70: 652c 206f 7074 696d 697a 6572 3d6f 7074  e, optimizer=opt
-00010a80: 696d 697a 6572 2c20 6c72 3d6c 722c 2064  imizer, lr=lr, d
-00010a90: 6563 6179 3d64 6563 6179 2c20 6d6f 6d65  ecay=decay, mome
-00010aa0: 6e74 756d 3d6d 6f6d 656e 7475 6d2c 206e  ntum=momentum, n
-00010ab0: 6573 7465 726f 763d 6e65 7374 6572 6f76  esterov=nesterov
-00010ac0: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
-00010ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010ae0: 2020 2062 6574 615f 313d 6265 7461 5f31     beta_1=beta_1
-00010af0: 2c20 6265 7461 5f32 3d62 6574 615f 322c  , beta_2=beta_2,
-00010b00: 2061 6d73 6772 6164 3d61 6d73 6772 6164   amsgrad=amsgrad
-00010b10: 2c20 6c6f 7373 3d6c 6f73 732c 2061 6374  , loss=loss, act
-00010b20: 6976 6174 696f 6e5f 636f 6e76 3d61 6374  ivation_conv=act
-00010b30: 6976 6174 696f 6e5f 636f 6e76 2c20 6163  ivation_conv, ac
-00010b40: 7469 7661 7469 6f6e 5f64 656e 7365 3d61  tivation_dense=a
-00010b50: 6374 6976 6174 696f 6e5f 6465 6e73 652c  ctivation_dense,
-00010b60: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-00010b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010b80: 2020 636f 6e76 5f69 6e69 743d 636f 6e76    conv_init=conv
-00010b90: 5f69 6e69 742c 2064 656e 7365 5f69 6e69  _init, dense_ini
-00010ba0: 743d 6465 6e73 655f 696e 6974 2c20 6d6f  t=dense_init, mo
-00010bb0: 6465 6c5f 7265 673d 6d6f 6465 6c5f 7265  del_reg=model_re
-00010bc0: 672c 0a20 2020 2020 2020 2020 2020 2020  g,.             
-00010bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010be0: 2020 2070 6f6f 6c69 6e67 5f31 3d70 6f6f     pooling_1=poo
-00010bf0: 6c69 6e67 5f31 2c20 706f 6f6c 696e 675f  ling_1, pooling_
-00010c00: 323d 706f 6f6c 696e 675f 322c 2070 6f6f  2=pooling_2, poo
-00010c10: 6c69 6e67 5f33 3d70 6f6f 6c69 6e67 5f33  ling_3=pooling_3
-00010c20: 2c20 706f 6f6c 696e 675f 343d 706f 6f6c  , pooling_4=pool
-00010c30: 696e 675f 342c 2070 6f6f 6c69 6e67 5f35  ing_4, pooling_5
-00010c40: 3d70 6f6f 6c69 6e67 5f35 2c0a 2020 2020  =pooling_5,.    
-00010c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010c60: 2020 2020 2020 2020 2020 2020 736d 6f74              smot
-00010c70: 655f 7361 6d70 6c69 6e67 3d73 656c 662e  e_sampling=self.
-00010c80: 736d 6f74 655f 7361 6d70 6c69 6e67 2c20  smote_sampling, 
-00010c90: 6561 726c 795f 7374 6f70 5f63 616c 6c62  early_stop_callb
-00010ca0: 6163 6b3d 6361 6c6c 6261 636b 732c 2063  ack=callbacks, c
-00010cb0: 6865 636b 706f 696e 743d 4661 6c73 652c  heckpoint=False,
-00010cc0: 2076 6572 626f 7365 3d73 656c 662e 7665   verbose=self.ve
-00010cd0: 7262 6f73 6529 0a20 2020 2020 2020 2020  rbose).         
-00010ce0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00010cf0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00010d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010d10: 206d 6f64 656c 2c20 6869 7374 6f72 7920   model, history 
-00010d20: 3d20 636e 6e5f 6d6f 6465 6c2e 5647 4731  = cnn_model.VGG1
-00010d30: 3628 636c 6173 735f 312c 2063 6c61 7373  6(class_1, class
-00010d40: 5f32 2c20 696d 675f 6e75 6d5f 6368 616e  _2, img_num_chan
-00010d50: 6e65 6c73 3d73 656c 662e 696d 675f 6e75  nels=self.img_nu
-00010d60: 6d5f 6368 616e 6e65 6c73 2c20 0a20 2020  m_channels, .   
-00010d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010d80: 2020 2020 2020 2020 2020 2020 206e 6f72               nor
-00010d90: 6d61 6c69 7a65 3d73 656c 662e 6e6f 726d  malize=self.norm
-00010da0: 616c 697a 652c 206d 696e 5f70 6978 656c  alize, min_pixel
-00010db0: 3d6d 696e 5f70 6978 2c20 6d61 785f 7069  =min_pix, max_pi
-00010dc0: 7865 6c3d 6d61 785f 7069 782c 2076 616c  xel=max_pix, val
-00010dd0: 5f70 6f73 6974 6976 653d 7661 6c5f 636c  _positive=val_cl
-00010de0: 6173 735f 312c 2076 616c 5f6e 6567 6174  ass_1, val_negat
-00010df0: 6976 653d 7661 6c5f 636c 6173 735f 322c  ive=val_class_2,
-00010e00: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-00010e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010e20: 2020 6570 6f63 6873 3d73 656c 662e 7472    epochs=self.tr
-00010e30: 6169 6e5f 6570 6f63 6873 2c20 6261 7463  ain_epochs, batc
-00010e40: 685f 7369 7a65 3d62 6174 6368 5f73 697a  h_size=batch_siz
-00010e50: 652c 206f 7074 696d 697a 6572 3d6f 7074  e, optimizer=opt
-00010e60: 696d 697a 6572 2c20 6c72 3d6c 722c 2064  imizer, lr=lr, d
-00010e70: 6563 6179 3d64 6563 6179 2c20 6d6f 6d65  ecay=decay, mome
-00010e80: 6e74 756d 3d6d 6f6d 656e 7475 6d2c 206e  ntum=momentum, n
-00010e90: 6573 7465 726f 763d 6e65 7374 6572 6f76  esterov=nesterov
-00010ea0: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
-00010eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010ec0: 2020 2062 6574 615f 313d 6265 7461 5f31     beta_1=beta_1
-00010ed0: 2c20 6265 7461 5f32 3d62 6574 615f 322c  , beta_2=beta_2,
-00010ee0: 2061 6d73 6772 6164 3d61 6d73 6772 6164   amsgrad=amsgrad
-00010ef0: 2c20 6c6f 7373 3d6c 6f73 732c 2061 6374  , loss=loss, act
-00010f00: 6976 6174 696f 6e5f 636f 6e76 3d61 6374  ivation_conv=act
-00010f10: 6976 6174 696f 6e5f 636f 6e76 2c20 6163  ivation_conv, ac
-00010f20: 7469 7661 7469 6f6e 5f64 656e 7365 3d61  tivation_dense=a
-00010f30: 6374 6976 6174 696f 6e5f 6465 6e73 652c  ctivation_dense,
-00010f40: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-00010f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010f60: 2020 636f 6e76 5f69 6e69 743d 636f 6e76    conv_init=conv
-00010f70: 5f69 6e69 742c 2064 656e 7365 5f69 6e69  _init, dense_ini
-00010f80: 743d 6465 6e73 655f 696e 6974 2c20 6d6f  t=dense_init, mo
-00010f90: 6465 6c5f 7265 673d 6d6f 6465 6c5f 7265  del_reg=model_re
-00010fa0: 672c 2020 2020 2020 2020 2020 2020 2020  g,              
-00010fb0: 2020 2020 2020 2020 0a20 2020 2020 2020          .       
-00010fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010fd0: 2020 2020 2020 2020 2066 696c 7465 725f           filter_
-00010fe0: 313d 6669 6c74 6572 5f31 2c20 6669 6c74  1=filter_1, filt
-00010ff0: 6572 5f73 697a 655f 313d 6669 6c74 6572  er_size_1=filter
-00011000: 5f73 697a 655f 312c 2073 7472 6964 6573  _size_1, strides
-00011010: 5f31 3d73 7472 6964 6573 5f31 2c20 706f  _1=strides_1, po
-00011020: 6f6c 696e 675f 313d 706f 6f6c 696e 675f  oling_1=pooling_
-00011030: 312c 2070 6f6f 6c5f 7369 7a65 5f31 3d70  1, pool_size_1=p
-00011040: 6f6f 6c5f 7369 7a65 5f31 2c20 706f 6f6c  ool_size_1, pool
-00011050: 5f73 7472 6964 655f 313d 706f 6f6c 5f73  _stride_1=pool_s
-00011060: 7472 6964 655f 312c 0a20 2020 2020 2020  tride_1,.       
-00011070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011080: 2020 2020 2020 2020 2066 696c 7465 725f           filter_
-00011090: 323d 6669 6c74 6572 5f32 2c20 6669 6c74  2=filter_2, filt
-000110a0: 6572 5f73 697a 655f 323d 6669 6c74 6572  er_size_2=filter
-000110b0: 5f73 697a 655f 322c 2073 7472 6964 6573  _size_2, strides
-000110c0: 5f32 3d73 7472 6964 6573 5f32 2c20 706f  _2=strides_2, po
-000110d0: 6f6c 696e 675f 323d 706f 6f6c 696e 675f  oling_2=pooling_
-000110e0: 322c 2070 6f6f 6c5f 7369 7a65 5f32 3d70  2, pool_size_2=p
-000110f0: 6f6f 6c5f 7369 7a65 5f32 2c20 706f 6f6c  ool_size_2, pool
-00011100: 5f73 7472 6964 655f 323d 706f 6f6c 5f73  _stride_2=pool_s
-00011110: 7472 6964 655f 322c 0a20 2020 2020 2020  tride_2,.       
-00011120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011130: 2020 2020 2020 2020 2066 696c 7465 725f           filter_
-00011140: 333d 6669 6c74 6572 5f33 2c20 6669 6c74  3=filter_3, filt
-00011150: 6572 5f73 697a 655f 333d 6669 6c74 6572  er_size_3=filter
-00011160: 5f73 697a 655f 332c 2073 7472 6964 6573  _size_3, strides
-00011170: 5f33 3d73 7472 6964 6573 5f33 2c20 706f  _3=strides_3, po
-00011180: 6f6c 696e 675f 333d 706f 6f6c 696e 675f  oling_3=pooling_
-00011190: 332c 2070 6f6f 6c5f 7369 7a65 5f33 3d70  3, pool_size_3=p
-000111a0: 6f6f 6c5f 7369 7a65 5f33 2c20 706f 6f6c  ool_size_3, pool
-000111b0: 5f73 7472 6964 655f 333d 706f 6f6c 5f73  _stride_3=pool_s
-000111c0: 7472 6964 655f 332c 0a20 2020 2020 2020  tride_3,.       
-000111d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000111e0: 2020 2020 2020 2020 2066 696c 7465 725f           filter_
-000111f0: 343d 6669 6c74 6572 5f34 2c20 6669 6c74  4=filter_4, filt
-00011200: 6572 5f73 697a 655f 343d 6669 6c74 6572  er_size_4=filter
-00011210: 5f73 697a 655f 342c 2073 7472 6964 6573  _size_4, strides
-00011220: 5f34 3d73 7472 6964 6573 5f34 2c20 706f  _4=strides_4, po
-00011230: 6f6c 696e 675f 343d 706f 6f6c 696e 675f  oling_4=pooling_
-00011240: 342c 2070 6f6f 6c5f 7369 7a65 5f34 3d70  4, pool_size_4=p
-00011250: 6f6f 6c5f 7369 7a65 5f34 2c20 706f 6f6c  ool_size_4, pool
-00011260: 5f73 7472 6964 655f 343d 706f 6f6c 5f73  _stride_4=pool_s
-00011270: 7472 6964 655f 342c 0a20 2020 2020 2020  tride_4,.       
-00011280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011290: 2020 2020 2020 2020 2066 696c 7465 725f           filter_
-000112a0: 353d 6669 6c74 6572 5f35 2c20 6669 6c74  5=filter_5, filt
-000112b0: 6572 5f73 697a 655f 353d 6669 6c74 6572  er_size_5=filter
-000112c0: 5f73 697a 655f 352c 2073 7472 6964 6573  _size_5, strides
-000112d0: 5f35 3d73 7472 6964 6573 5f35 2c20 706f  _5=strides_5, po
-000112e0: 6f6c 696e 675f 353d 706f 6f6c 696e 675f  oling_5=pooling_
-000112f0: 352c 2070 6f6f 6c5f 7369 7a65 5f35 3d70  5, pool_size_5=p
-00011300: 6f6f 6c5f 7369 7a65 5f35 2c20 706f 6f6c  ool_size_5, pool
-00011310: 5f73 7472 6964 655f 353d 706f 6f6c 5f73  _stride_5=pool_s
-00011320: 7472 6964 655f 352c 0a20 2020 2020 2020  tride_5,.       
-00011330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011340: 2020 2020 2020 2020 2064 656e 7365 5f6e           dense_n
-00011350: 6575 726f 6e73 5f31 3d64 656e 7365 5f6e  eurons_1=dense_n
-00011360: 6575 726f 6e73 5f31 2c20 6465 6e73 655f  eurons_1, dense_
-00011370: 6e65 7572 6f6e 735f 323d 6465 6e73 655f  neurons_2=dense_
-00011380: 6e65 7572 6f6e 735f 322c 2064 726f 706f  neurons_2, dropo
-00011390: 7574 5f31 3d64 726f 706f 7574 5f31 2c20  ut_1=dropout_1, 
-000113a0: 6472 6f70 6f75 745f 323d 6472 6f70 6f75  dropout_2=dropou
-000113b0: 745f 322c 200a 2020 2020 2020 2020 2020  t_2, .          
+00010180: 2020 2020 206e 6f72 6d61 6c69 7a65 3d73       normalize=s
+00010190: 656c 662e 6e6f 726d 616c 697a 652c 206d  elf.normalize, m
+000101a0: 696e 5f70 6978 656c 3d6d 696e 5f70 6978  in_pixel=min_pix
+000101b0: 2c20 6d61 785f 7069 7865 6c3d 6d61 785f  , max_pixel=max_
+000101c0: 7069 782c 2076 616c 5f70 6f73 6974 6976  pix, val_positiv
+000101d0: 653d 7661 6c5f 636c 6173 735f 312c 2076  e=val_class_1, v
+000101e0: 616c 5f6e 6567 6174 6976 653d 7661 6c5f  al_negative=val_
+000101f0: 636c 6173 735f 322c 200a 2020 2020 2020  class_2, .      
+00010200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010210: 2020 2020 2020 6570 6f63 6873 3d73 656c        epochs=sel
+00010220: 662e 7472 6169 6e5f 6570 6f63 6873 2c20  f.train_epochs, 
+00010230: 6261 7463 685f 7369 7a65 3d62 6174 6368  batch_size=batch
+00010240: 5f73 697a 652c 206f 7074 696d 697a 6572  _size, optimizer
+00010250: 3d6f 7074 696d 697a 6572 2c20 6c72 3d6c  =optimizer, lr=l
+00010260: 722c 2064 6563 6179 3d64 6563 6179 2c20  r, decay=decay, 
+00010270: 6d6f 6d65 6e74 756d 3d6d 6f6d 656e 7475  momentum=momentu
+00010280: 6d2c 206e 6573 7465 726f 763d 6e65 7374  m, nesterov=nest
+00010290: 6572 6f76 2c20 0a20 2020 2020 2020 2020  erov, .         
+000102a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000102b0: 2020 2062 6574 615f 313d 6265 7461 5f31     beta_1=beta_1
+000102c0: 2c20 6265 7461 5f32 3d62 6574 615f 322c  , beta_2=beta_2,
+000102d0: 2061 6d73 6772 6164 3d61 6d73 6772 6164   amsgrad=amsgrad
+000102e0: 2c20 736d 6f74 655f 7361 6d70 6c69 6e67  , smote_sampling
+000102f0: 3d73 656c 662e 736d 6f74 655f 7361 6d70  =self.smote_samp
+00010300: 6c69 6e67 2c20 6561 726c 795f 7374 6f70  ling, early_stop
+00010310: 5f63 616c 6c62 6163 6b3d 6361 6c6c 6261  _callback=callba
+00010320: 636b 732c 2063 6865 636b 706f 696e 743d  cks, checkpoint=
+00010330: 4661 6c73 652c 2076 6572 626f 7365 3d73  False, verbose=s
+00010340: 656c 662e 7665 7262 6f73 6529 0a20 2020  elf.verbose).   
+00010350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010360: 2065 6c69 6620 7365 6c66 2e63 6c66 203d   elif self.clf =
+00010370: 3d20 2763 7573 746f 6d5f 636e 6e27 3a0a  = 'custom_cnn':.
+00010380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010390: 2020 2020 2020 2020 6d6f 6465 6c2c 2068          model, h
+000103a0: 6973 746f 7279 203d 2063 6e6e 5f6d 6f64  istory = cnn_mod
+000103b0: 656c 2e63 7573 746f 6d5f 6d6f 6465 6c28  el.custom_model(
+000103c0: 636c 6173 735f 312c 2063 6c61 7373 5f32  class_1, class_2
+000103d0: 2c20 696d 675f 6e75 6d5f 6368 616e 6e65  , img_num_channe
+000103e0: 6c73 3d73 656c 662e 696d 675f 6e75 6d5f  ls=self.img_num_
+000103f0: 6368 616e 6e65 6c73 2c20 0a20 2020 2020  channels, .     
+00010400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010410: 2020 2020 2020 206e 6f72 6d61 6c69 7a65         normalize
+00010420: 3d73 656c 662e 6e6f 726d 616c 697a 652c  =self.normalize,
+00010430: 206d 696e 5f70 6978 656c 3d6d 696e 5f70   min_pixel=min_p
+00010440: 6978 2c20 6d61 785f 7069 7865 6c3d 6d61  ix, max_pixel=ma
+00010450: 785f 7069 782c 2076 616c 5f70 6f73 6974  x_pix, val_posit
+00010460: 6976 653d 7661 6c5f 636c 6173 735f 312c  ive=val_class_1,
+00010470: 2076 616c 5f6e 6567 6174 6976 653d 7661   val_negative=va
+00010480: 6c5f 636c 6173 735f 322c 200a 2020 2020  l_class_2, .    
+00010490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000104a0: 2020 2020 2020 2020 6570 6f63 6873 3d73          epochs=s
+000104b0: 656c 662e 7472 6169 6e5f 6570 6f63 6873  elf.train_epochs
+000104c0: 2c20 6261 7463 685f 7369 7a65 3d62 6174  , batch_size=bat
+000104d0: 6368 5f73 697a 652c 206f 7074 696d 697a  ch_size, optimiz
+000104e0: 6572 3d6f 7074 696d 697a 6572 2c20 6c72  er=optimizer, lr
+000104f0: 3d6c 722c 2064 6563 6179 3d64 6563 6179  =lr, decay=decay
+00010500: 2c20 6d6f 6d65 6e74 756d 3d6d 6f6d 656e  , momentum=momen
+00010510: 7475 6d2c 206e 6573 7465 726f 763d 6e65  tum, nesterov=ne
+00010520: 7374 6572 6f76 2c20 0a20 2020 2020 2020  sterov, .       
+00010530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010540: 2020 2020 2062 6574 615f 313d 6265 7461       beta_1=beta
+00010550: 5f31 2c20 6265 7461 5f32 3d62 6574 615f  _1, beta_2=beta_
+00010560: 322c 2061 6d73 6772 6164 3d61 6d73 6772  2, amsgrad=amsgr
+00010570: 6164 2c20 736d 6f74 655f 7361 6d70 6c69  ad, smote_sampli
+00010580: 6e67 3d73 656c 662e 736d 6f74 655f 7361  ng=self.smote_sa
+00010590: 6d70 6c69 6e67 2c20 6561 726c 795f 7374  mpling, early_st
+000105a0: 6f70 5f63 616c 6c62 6163 6b3d 6361 6c6c  op_callback=call
+000105b0: 6261 636b 732c 2063 6865 636b 706f 696e  backs, checkpoin
+000105c0: 743d 4661 6c73 652c 2076 6572 626f 7365  t=False, verbose
+000105d0: 3d73 656c 662e 7665 7262 6f73 6529 0a20  =self.verbose). 
+000105e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000105f0: 2020 2065 6c69 6620 7365 6c66 2e63 6c66     elif self.clf
+00010600: 203d 3d20 2776 6767 3136 273a 0a20 2020   == 'vgg16':.   
+00010610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010620: 2020 2020 206d 6f64 656c 2c20 6869 7374       model, hist
+00010630: 6f72 7920 3d20 636e 6e5f 6d6f 6465 6c2e  ory = cnn_model.
+00010640: 5647 4731 3628 636c 6173 735f 312c 2063  VGG16(class_1, c
+00010650: 6c61 7373 5f32 2c20 696d 675f 6e75 6d5f  lass_2, img_num_
+00010660: 6368 616e 6e65 6c73 3d73 656c 662e 696d  channels=self.im
+00010670: 675f 6e75 6d5f 6368 616e 6e65 6c73 2c20  g_num_channels, 
+00010680: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00010690: 2020 2020 2020 2020 2020 2020 206e 6f72               nor
+000106a0: 6d61 6c69 7a65 3d73 656c 662e 6e6f 726d  malize=self.norm
+000106b0: 616c 697a 652c 206d 696e 5f70 6978 656c  alize, min_pixel
+000106c0: 3d6d 696e 5f70 6978 2c20 6d61 785f 7069  =min_pix, max_pi
+000106d0: 7865 6c3d 6d61 785f 7069 782c 2076 616c  xel=max_pix, val
+000106e0: 5f70 6f73 6974 6976 653d 7661 6c5f 636c  _positive=val_cl
+000106f0: 6173 735f 312c 2076 616c 5f6e 6567 6174  ass_1, val_negat
+00010700: 6976 653d 7661 6c5f 636c 6173 735f 322c  ive=val_class_2,
+00010710: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+00010720: 2020 2020 2020 2020 2020 2020 2020 6570                ep
+00010730: 6f63 6873 3d73 656c 662e 7472 6169 6e5f  ochs=self.train_
+00010740: 6570 6f63 6873 2c20 6261 7463 685f 7369  epochs, batch_si
+00010750: 7a65 3d62 6174 6368 5f73 697a 652c 206f  ze=batch_size, o
+00010760: 7074 696d 697a 6572 3d6f 7074 696d 697a  ptimizer=optimiz
+00010770: 6572 2c20 6c72 3d6c 722c 2064 6563 6179  er, lr=lr, decay
+00010780: 3d64 6563 6179 2c20 6d6f 6d65 6e74 756d  =decay, momentum
+00010790: 3d6d 6f6d 656e 7475 6d2c 206e 6573 7465  =momentum, neste
+000107a0: 726f 763d 6e65 7374 6572 6f76 2c20 0a20  rov=nesterov, . 
+000107b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000107c0: 2020 2020 2020 2020 2020 2062 6574 615f             beta_
+000107d0: 313d 6265 7461 5f31 2c20 6265 7461 5f32  1=beta_1, beta_2
+000107e0: 3d62 6574 615f 322c 2061 6d73 6772 6164  =beta_2, amsgrad
+000107f0: 3d61 6d73 6772 6164 2c20 736d 6f74 655f  =amsgrad, smote_
+00010800: 7361 6d70 6c69 6e67 3d73 656c 662e 736d  sampling=self.sm
+00010810: 6f74 655f 7361 6d70 6c69 6e67 2c20 6561  ote_sampling, ea
+00010820: 726c 795f 7374 6f70 5f63 616c 6c62 6163  rly_stop_callbac
+00010830: 6b3d 6361 6c6c 6261 636b 732c 2063 6865  k=callbacks, che
+00010840: 636b 706f 696e 743d 4661 6c73 652c 2076  ckpoint=False, v
+00010850: 6572 626f 7365 3d73 656c 662e 7665 7262  erbose=self.verb
+00010860: 6f73 6529 0a20 2020 2020 2020 2020 2020  ose).           
+00010870: 2020 2020 2020 2020 2065 6c69 6620 7365           elif se
+00010880: 6c66 2e63 6c66 203d 3d20 2772 6573 6e65  lf.clf == 'resne
+00010890: 7431 3827 3a0a 2020 2020 2020 2020 2020  t18':.          
+000108a0: 2020 2020 2020 2020 2020 2020 2020 6d6f                mo
+000108b0: 6465 6c2c 2068 6973 746f 7279 203d 2063  del, history = c
+000108c0: 6e6e 5f6d 6f64 656c 2e52 6573 6e65 7431  nn_model.Resnet1
+000108d0: 3828 636c 6173 735f 312c 2063 6c61 7373  8(class_1, class
+000108e0: 5f32 2c20 696d 675f 6e75 6d5f 6368 616e  _2, img_num_chan
+000108f0: 6e65 6c73 3d73 656c 662e 696d 675f 6e75  nels=self.img_nu
+00010900: 6d5f 6368 616e 6e65 6c73 2c20 0a20 2020  m_channels, .   
+00010910: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010920: 2020 2020 2020 2020 206e 6f72 6d61 6c69           normali
+00010930: 7a65 3d73 656c 662e 6e6f 726d 616c 697a  ze=self.normaliz
+00010940: 652c 206d 696e 5f70 6978 656c 3d6d 696e  e, min_pixel=min
+00010950: 5f70 6978 2c20 6d61 785f 7069 7865 6c3d  _pix, max_pixel=
+00010960: 6d61 785f 7069 782c 2076 616c 5f70 6f73  max_pix, val_pos
+00010970: 6974 6976 653d 7661 6c5f 636c 6173 735f  itive=val_class_
+00010980: 312c 2076 616c 5f6e 6567 6174 6976 653d  1, val_negative=
+00010990: 7661 6c5f 636c 6173 735f 322c 200a 2020  val_class_2, .  
+000109a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000109b0: 2020 2020 2020 2020 2020 6570 6f63 6873            epochs
+000109c0: 3d73 656c 662e 7472 6169 6e5f 6570 6f63  =self.train_epoc
+000109d0: 6873 2c20 6261 7463 685f 7369 7a65 3d62  hs, batch_size=b
+000109e0: 6174 6368 5f73 697a 652c 206f 7074 696d  atch_size, optim
+000109f0: 697a 6572 3d6f 7074 696d 697a 6572 2c20  izer=optimizer, 
+00010a00: 6c72 3d6c 722c 2064 6563 6179 3d64 6563  lr=lr, decay=dec
+00010a10: 6179 2c20 6d6f 6d65 6e74 756d 3d6d 6f6d  ay, momentum=mom
+00010a20: 656e 7475 6d2c 206e 6573 7465 726f 763d  entum, nesterov=
+00010a30: 6e65 7374 6572 6f76 2c20 0a20 2020 2020  nesterov, .     
+00010a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010a50: 2020 2020 2020 2062 6574 615f 313d 6265         beta_1=be
+00010a60: 7461 5f31 2c20 6265 7461 5f32 3d62 6574  ta_1, beta_2=bet
+00010a70: 615f 322c 2061 6d73 6772 6164 3d61 6d73  a_2, amsgrad=ams
+00010a80: 6772 6164 2c20 736d 6f74 655f 7361 6d70  grad, smote_samp
+00010a90: 6c69 6e67 3d73 656c 662e 736d 6f74 655f  ling=self.smote_
+00010aa0: 7361 6d70 6c69 6e67 2c20 6561 726c 795f  sampling, early_
+00010ab0: 7374 6f70 5f63 616c 6c62 6163 6b3d 6361  stop_callback=ca
+00010ac0: 6c6c 6261 636b 732c 2063 6865 636b 706f  llbacks, checkpo
+00010ad0: 696e 743d 4661 6c73 652c 2076 6572 626f  int=False, verbo
+00010ae0: 7365 3d73 656c 662e 7665 7262 6f73 6529  se=self.verbose)
+00010af0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00010b00: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00010b10: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+00010b20: 6c66 2e63 6c66 203d 3d20 2761 6c65 786e  lf.clf == 'alexn
+00010b30: 6574 273a 0a20 2020 2020 2020 2020 2020  et':.           
+00010b40: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00010b50: 7365 6c66 2e6c 696d 6974 5f73 6561 7263  self.limit_searc
+00010b60: 683a 0a20 2020 2020 2020 2020 2020 2020  h:.             
+00010b70: 2020 2020 2020 2020 2020 2020 2020 206d                 m
+00010b80: 6f64 656c 2c20 6869 7374 6f72 7920 3d20  odel, history = 
+00010b90: 636e 6e5f 6d6f 6465 6c2e 416c 6578 4e65  cnn_model.AlexNe
+00010ba0: 7428 636c 6173 735f 312c 2063 6c61 7373  t(class_1, class
+00010bb0: 5f32 2c20 696d 675f 6e75 6d5f 6368 616e  _2, img_num_chan
+00010bc0: 6e65 6c73 3d73 656c 662e 696d 675f 6e75  nels=self.img_nu
+00010bd0: 6d5f 6368 616e 6e65 6c73 2c20 0a20 2020  m_channels, .   
+00010be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010bf0: 2020 2020 2020 2020 2020 2020 206e 6f72               nor
+00010c00: 6d61 6c69 7a65 3d73 656c 662e 6e6f 726d  malize=self.norm
+00010c10: 616c 697a 652c 206d 696e 5f70 6978 656c  alize, min_pixel
+00010c20: 3d6d 696e 5f70 6978 2c20 6d61 785f 7069  =min_pix, max_pi
+00010c30: 7865 6c3d 6d61 785f 7069 782c 2076 616c  xel=max_pix, val
+00010c40: 5f70 6f73 6974 6976 653d 7661 6c5f 636c  _positive=val_cl
+00010c50: 6173 735f 312c 2076 616c 5f6e 6567 6174  ass_1, val_negat
+00010c60: 6976 653d 7661 6c5f 636c 6173 735f 322c  ive=val_class_2,
+00010c70: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+00010c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010c90: 2020 6570 6f63 6873 3d73 656c 662e 7472    epochs=self.tr
+00010ca0: 6169 6e5f 6570 6f63 6873 2c20 6261 7463  ain_epochs, batc
+00010cb0: 685f 7369 7a65 3d62 6174 6368 5f73 697a  h_size=batch_siz
+00010cc0: 652c 206f 7074 696d 697a 6572 3d6f 7074  e, optimizer=opt
+00010cd0: 696d 697a 6572 2c20 6c72 3d6c 722c 2064  imizer, lr=lr, d
+00010ce0: 6563 6179 3d64 6563 6179 2c20 6d6f 6d65  ecay=decay, mome
+00010cf0: 6e74 756d 3d6d 6f6d 656e 7475 6d2c 206e  ntum=momentum, n
+00010d00: 6573 7465 726f 763d 6e65 7374 6572 6f76  esterov=nesterov
+00010d10: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+00010d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010d30: 2020 2062 6574 615f 313d 6265 7461 5f31     beta_1=beta_1
+00010d40: 2c20 6265 7461 5f32 3d62 6574 615f 322c  , beta_2=beta_2,
+00010d50: 2061 6d73 6772 6164 3d61 6d73 6772 6164   amsgrad=amsgrad
+00010d60: 2c20 6c6f 7373 3d6c 6f73 732c 2061 6374  , loss=loss, act
+00010d70: 6976 6174 696f 6e5f 636f 6e76 3d61 6374  ivation_conv=act
+00010d80: 6976 6174 696f 6e5f 636f 6e76 2c20 6163  ivation_conv, ac
+00010d90: 7469 7661 7469 6f6e 5f64 656e 7365 3d61  tivation_dense=a
+00010da0: 6374 6976 6174 696f 6e5f 6465 6e73 652c  ctivation_dense,
+00010db0: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+00010dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010dd0: 2020 636f 6e76 5f69 6e69 743d 636f 6e76    conv_init=conv
+00010de0: 5f69 6e69 742c 2064 656e 7365 5f69 6e69  _init, dense_ini
+00010df0: 743d 6465 6e73 655f 696e 6974 2c20 6d6f  t=dense_init, mo
+00010e00: 6465 6c5f 7265 673d 6d6f 6465 6c5f 7265  del_reg=model_re
+00010e10: 672c 2070 6f6f 6c69 6e67 5f31 3d70 6f6f  g, pooling_1=poo
+00010e20: 6c69 6e67 5f31 2c20 706f 6f6c 696e 675f  ling_1, pooling_
+00010e30: 323d 706f 6f6c 696e 675f 322c 2070 6f6f  2=pooling_2, poo
+00010e40: 6c69 6e67 5f33 3d70 6f6f 6c69 6e67 5f33  ling_3=pooling_3
+00010e50: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+00010e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010e70: 2020 2073 6d6f 7465 5f73 616d 706c 696e     smote_samplin
+00010e80: 673d 7365 6c66 2e73 6d6f 7465 5f73 616d  g=self.smote_sam
+00010e90: 706c 696e 672c 2065 6172 6c79 5f73 746f  pling, early_sto
+00010ea0: 705f 6361 6c6c 6261 636b 3d63 616c 6c62  p_callback=callb
+00010eb0: 6163 6b73 2c20 6368 6563 6b70 6f69 6e74  acks, checkpoint
+00010ec0: 3d46 616c 7365 2c20 7665 7262 6f73 653d  =False, verbose=
+00010ed0: 7365 6c66 2e76 6572 626f 7365 290a 2020  self.verbose).  
+00010ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010ef0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00010f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010f10: 2020 2020 2020 2020 6d6f 6465 6c2c 2068          model, h
+00010f20: 6973 746f 7279 203d 2063 6e6e 5f6d 6f64  istory = cnn_mod
+00010f30: 656c 2e41 6c65 784e 6574 2863 6c61 7373  el.AlexNet(class
+00010f40: 5f31 2c20 636c 6173 735f 322c 2069 6d67  _1, class_2, img
+00010f50: 5f6e 756d 5f63 6861 6e6e 656c 733d 7365  _num_channels=se
+00010f60: 6c66 2e69 6d67 5f6e 756d 5f63 6861 6e6e  lf.img_num_chann
+00010f70: 656c 732c 200a 2020 2020 2020 2020 2020  els, .          
+00010f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010f90: 2020 2020 2020 6e6f 726d 616c 697a 653d        normalize=
+00010fa0: 7365 6c66 2e6e 6f72 6d61 6c69 7a65 2c20  self.normalize, 
+00010fb0: 6d69 6e5f 7069 7865 6c3d 6d69 6e5f 7069  min_pixel=min_pi
+00010fc0: 782c 206d 6178 5f70 6978 656c 3d6d 6178  x, max_pixel=max
+00010fd0: 5f70 6978 2c20 7661 6c5f 706f 7369 7469  _pix, val_positi
+00010fe0: 7665 3d76 616c 5f63 6c61 7373 5f31 2c20  ve=val_class_1, 
+00010ff0: 7661 6c5f 6e65 6761 7469 7665 3d76 616c  val_negative=val
+00011000: 5f63 6c61 7373 5f32 2c20 0a20 2020 2020  _class_2, .     
+00011010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011020: 2020 2020 2020 2020 2020 2065 706f 6368             epoch
+00011030: 733d 7365 6c66 2e74 7261 696e 5f65 706f  s=self.train_epo
+00011040: 6368 732c 2062 6174 6368 5f73 697a 653d  chs, batch_size=
+00011050: 6261 7463 685f 7369 7a65 2c20 6f70 7469  batch_size, opti
+00011060: 6d69 7a65 723d 6f70 7469 6d69 7a65 722c  mizer=optimizer,
+00011070: 206c 723d 6c72 2c20 6465 6361 793d 6465   lr=lr, decay=de
+00011080: 6361 792c 206d 6f6d 656e 7475 6d3d 6d6f  cay, momentum=mo
+00011090: 6d65 6e74 756d 2c20 6e65 7374 6572 6f76  mentum, nesterov
+000110a0: 3d6e 6573 7465 726f 762c 200a 2020 2020  =nesterov, .    
+000110b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000110c0: 2020 2020 2020 2020 2020 2020 6265 7461              beta
+000110d0: 5f31 3d62 6574 615f 312c 2062 6574 615f  _1=beta_1, beta_
+000110e0: 323d 6265 7461 5f32 2c20 616d 7367 7261  2=beta_2, amsgra
+000110f0: 643d 616d 7367 7261 642c 206c 6f73 733d  d=amsgrad, loss=
+00011100: 6c6f 7373 2c20 6163 7469 7661 7469 6f6e  loss, activation
+00011110: 5f63 6f6e 763d 6163 7469 7661 7469 6f6e  _conv=activation
+00011120: 5f63 6f6e 762c 2061 6374 6976 6174 696f  _conv, activatio
+00011130: 6e5f 6465 6e73 653d 6163 7469 7661 7469  n_dense=activati
+00011140: 6f6e 5f64 656e 7365 2c20 0a20 2020 2020  on_dense, .     
+00011150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011160: 2020 2020 2020 2020 2020 2063 6f6e 765f             conv_
+00011170: 696e 6974 3d63 6f6e 765f 696e 6974 2c20  init=conv_init, 
+00011180: 6465 6e73 655f 696e 6974 3d64 656e 7365  dense_init=dense
+00011190: 5f69 6e69 742c 206d 6f64 656c 5f72 6567  _init, model_reg
+000111a0: 3d6d 6f64 656c 5f72 6567 2c20 0a20 2020  =model_reg, .   
+000111b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000111c0: 2020 2020 2020 2020 2020 2020 2066 696c               fil
+000111d0: 7465 725f 313d 6669 6c74 6572 5f31 2c20  ter_1=filter_1, 
+000111e0: 6669 6c74 6572 5f73 697a 655f 313d 6669  filter_size_1=fi
+000111f0: 6c74 6572 5f73 697a 655f 312c 2073 7472  lter_size_1, str
+00011200: 6964 6573 5f31 3d73 7472 6964 6573 5f31  ides_1=strides_1
+00011210: 2c20 706f 6f6c 696e 675f 313d 706f 6f6c  , pooling_1=pool
+00011220: 696e 675f 312c 2070 6f6f 6c5f 7369 7a65  ing_1, pool_size
+00011230: 5f31 3d70 6f6f 6c5f 7369 7a65 5f31 2c20  _1=pool_size_1, 
+00011240: 706f 6f6c 5f73 7472 6964 655f 313d 706f  pool_stride_1=po
+00011250: 6f6c 5f73 7472 6964 655f 312c 0a20 2020  ol_stride_1,.   
+00011260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011270: 2020 2020 2020 2020 2020 2020 2066 696c               fil
+00011280: 7465 725f 323d 6669 6c74 6572 5f32 2c20  ter_2=filter_2, 
+00011290: 6669 6c74 6572 5f73 697a 655f 323d 6669  filter_size_2=fi
+000112a0: 6c74 6572 5f73 697a 655f 322c 2073 7472  lter_size_2, str
+000112b0: 6964 6573 5f32 3d73 7472 6964 6573 5f32  ides_2=strides_2
+000112c0: 2c20 706f 6f6c 696e 675f 323d 706f 6f6c  , pooling_2=pool
+000112d0: 696e 675f 322c 2070 6f6f 6c5f 7369 7a65  ing_2, pool_size
+000112e0: 5f32 3d70 6f6f 6c5f 7369 7a65 5f32 2c20  _2=pool_size_2, 
+000112f0: 706f 6f6c 5f73 7472 6964 655f 323d 706f  pool_stride_2=po
+00011300: 6f6c 5f73 7472 6964 655f 322c 0a20 2020  ol_stride_2,.   
+00011310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011320: 2020 2020 2020 2020 2020 2020 2066 696c               fil
+00011330: 7465 725f 333d 6669 6c74 6572 5f33 2c20  ter_3=filter_3, 
+00011340: 6669 6c74 6572 5f73 697a 655f 333d 6669  filter_size_3=fi
+00011350: 6c74 6572 5f73 697a 655f 332c 2073 7472  lter_size_3, str
+00011360: 6964 6573 5f33 3d73 7472 6964 6573 5f33  ides_3=strides_3
+00011370: 2c20 706f 6f6c 696e 675f 333d 706f 6f6c  , pooling_3=pool
+00011380: 696e 675f 332c 2070 6f6f 6c5f 7369 7a65  ing_3, pool_size
+00011390: 5f33 3d70 6f6f 6c5f 7369 7a65 5f33 2c20  _3=pool_size_3, 
+000113a0: 706f 6f6c 5f73 7472 6964 655f 333d 706f  pool_stride_3=po
+000113b0: 6f6c 5f73 7472 6964 655f 332c 0a20 2020  ol_stride_3,.   
 000113c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000113d0: 2020 2020 2020 736d 6f74 655f 7361 6d70        smote_samp
-000113e0: 6c69 6e67 3d73 656c 662e 736d 6f74 655f  ling=self.smote_
-000113f0: 7361 6d70 6c69 6e67 2c20 6561 726c 795f  sampling, early_
-00011400: 7374 6f70 5f63 616c 6c62 6163 6b3d 6361  stop_callback=ca
-00011410: 6c6c 6261 636b 732c 2063 6865 636b 706f  llbacks, checkpo
-00011420: 696e 743d 4661 6c73 652c 2076 6572 626f  int=False, verbo
-00011430: 7365 3d73 656c 662e 7665 7262 6f73 6529  se=self.verbose)
-00011440: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011450: 2020 2020 2065 6c69 6620 7365 6c66 2e63       elif self.c
-00011460: 6c66 203d 3d20 2772 6573 6e65 7431 3827  lf == 'resnet18'
-00011470: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00011480: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-00011490: 662e 6c69 6d69 745f 7365 6172 6368 3a0a  f.limit_search:.
-000114a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000114b0: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
-000114c0: 6c2c 2068 6973 746f 7279 203d 2063 6e6e  l, history = cnn
-000114d0: 5f6d 6f64 656c 2e52 6573 6e65 7431 3828  _model.Resnet18(
-000114e0: 636c 6173 735f 312c 2063 6c61 7373 5f32  class_1, class_2
-000114f0: 2c20 696d 675f 6e75 6d5f 6368 616e 6e65  , img_num_channe
-00011500: 6c73 3d73 656c 662e 696d 675f 6e75 6d5f  ls=self.img_num_
-00011510: 6368 616e 6e65 6c73 2c20 0a20 2020 2020  channels, .     
+000113d0: 2020 2020 2020 2020 2020 2020 2066 696c               fil
+000113e0: 7465 725f 343d 6669 6c74 6572 5f34 2c20  ter_4=filter_4, 
+000113f0: 6669 6c74 6572 5f73 697a 655f 343d 6669  filter_size_4=fi
+00011400: 6c74 6572 5f73 697a 655f 342c 2073 7472  lter_size_4, str
+00011410: 6964 6573 5f34 3d73 7472 6964 6573 5f34  ides_4=strides_4
+00011420: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+00011430: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011440: 2020 2066 696c 7465 725f 353d 6669 6c74     filter_5=filt
+00011450: 6572 5f35 2c20 6669 6c74 6572 5f73 697a  er_5, filter_siz
+00011460: 655f 353d 6669 6c74 6572 5f73 697a 655f  e_5=filter_size_
+00011470: 352c 2073 7472 6964 6573 5f35 3d73 7472  5, strides_5=str
+00011480: 6964 6573 5f35 2c0a 2020 2020 2020 2020  ides_5,.        
+00011490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000114a0: 2020 2020 2020 2020 6465 6e73 655f 6e65          dense_ne
+000114b0: 7572 6f6e 735f 313d 6465 6e73 655f 6e65  urons_1=dense_ne
+000114c0: 7572 6f6e 735f 312c 2064 656e 7365 5f6e  urons_1, dense_n
+000114d0: 6575 726f 6e73 5f32 3d64 656e 7365 5f6e  eurons_2=dense_n
+000114e0: 6575 726f 6e73 5f32 2c20 6472 6f70 6f75  eurons_2, dropou
+000114f0: 745f 313d 6472 6f70 6f75 745f 312c 2064  t_1=dropout_1, d
+00011500: 726f 706f 7574 5f32 3d64 726f 706f 7574  ropout_2=dropout
+00011510: 5f32 2c20 0a20 2020 2020 2020 2020 2020  _2, .           
 00011520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011530: 2020 2020 2020 2020 2020 206e 6f72 6d61             norma
-00011540: 6c69 7a65 3d73 656c 662e 6e6f 726d 616c  lize=self.normal
-00011550: 697a 652c 206d 696e 5f70 6978 656c 3d6d  ize, min_pixel=m
-00011560: 696e 5f70 6978 2c20 6d61 785f 7069 7865  in_pix, max_pixe
-00011570: 6c3d 6d61 785f 7069 782c 2076 616c 5f70  l=max_pix, val_p
-00011580: 6f73 6974 6976 653d 7661 6c5f 636c 6173  ositive=val_clas
-00011590: 735f 312c 2076 616c 5f6e 6567 6174 6976  s_1, val_negativ
-000115a0: 653d 7661 6c5f 636c 6173 735f 322c 200a  e=val_class_2, .
-000115b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000115c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000115d0: 6570 6f63 6873 3d73 656c 662e 7472 6169  epochs=self.trai
-000115e0: 6e5f 6570 6f63 6873 2c20 6261 7463 685f  n_epochs, batch_
-000115f0: 7369 7a65 3d62 6174 6368 5f73 697a 652c  size=batch_size,
-00011600: 206f 7074 696d 697a 6572 3d6f 7074 696d   optimizer=optim
-00011610: 697a 6572 2c20 6c72 3d6c 722c 2064 6563  izer, lr=lr, dec
-00011620: 6179 3d64 6563 6179 2c20 6d6f 6d65 6e74  ay=decay, moment
-00011630: 756d 3d6d 6f6d 656e 7475 6d2c 206e 6573  um=momentum, nes
-00011640: 7465 726f 763d 6e65 7374 6572 6f76 2c20  terov=nesterov, 
-00011650: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011670: 2062 6574 615f 313d 6265 7461 5f31 2c20   beta_1=beta_1, 
-00011680: 6265 7461 5f32 3d62 6574 615f 322c 2061  beta_2=beta_2, a
-00011690: 6d73 6772 6164 3d61 6d73 6772 6164 2c20  msgrad=amsgrad, 
-000116a0: 6c6f 7373 3d6c 6f73 732c 2061 6374 6976  loss=loss, activ
-000116b0: 6174 696f 6e5f 636f 6e76 3d61 6374 6976  ation_conv=activ
-000116c0: 6174 696f 6e5f 636f 6e76 2c20 6163 7469  ation_conv, acti
-000116d0: 7661 7469 6f6e 5f64 656e 7365 3d61 6374  vation_dense=act
-000116e0: 6976 6174 696f 6e5f 6465 6e73 652c 200a  ivation_dense, .
-000116f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011710: 636f 6e76 5f69 6e69 743d 636f 6e76 5f69  conv_init=conv_i
-00011720: 6e69 742c 2064 656e 7365 5f69 6e69 743d  nit, dense_init=
-00011730: 6465 6e73 655f 696e 6974 2c20 6d6f 6465  dense_init, mode
-00011740: 6c5f 7265 673d 6d6f 6465 6c5f 7265 672c  l_reg=model_reg,
-00011750: 2070 6f6f 6c69 6e67 3d70 6f6f 6c69 6e67   pooling=pooling
-00011760: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00011770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011780: 2020 736d 6f74 655f 7361 6d70 6c69 6e67    smote_sampling
-00011790: 3d73 656c 662e 736d 6f74 655f 7361 6d70  =self.smote_samp
-000117a0: 6c69 6e67 2c20 6561 726c 795f 7374 6f70  ling, early_stop
-000117b0: 5f63 616c 6c62 6163 6b3d 6361 6c6c 6261  _callback=callba
-000117c0: 636b 732c 2063 6865 636b 706f 696e 743d  cks, checkpoint=
-000117d0: 4661 6c73 652c 2076 6572 626f 7365 3d73  False, verbose=s
-000117e0: 656c 662e 7665 7262 6f73 6529 0a20 2020  elf.verbose).   
-000117f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011800: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00011810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011820: 2020 2020 2020 206d 6f64 656c 2c20 6869         model, hi
-00011830: 7374 6f72 7920 3d20 636e 6e5f 6d6f 6465  story = cnn_mode
-00011840: 6c2e 5265 736e 6574 3138 2863 6c61 7373  l.Resnet18(class
-00011850: 5f31 2c20 636c 6173 735f 322c 2069 6d67  _1, class_2, img
-00011860: 5f6e 756d 5f63 6861 6e6e 656c 733d 7365  _num_channels=se
-00011870: 6c66 2e69 6d67 5f6e 756d 5f63 6861 6e6e  lf.img_num_chann
-00011880: 656c 732c 200a 2020 2020 2020 2020 2020  els, .          
-00011890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000118a0: 2020 2020 2020 6e6f 726d 616c 697a 653d        normalize=
-000118b0: 7365 6c66 2e6e 6f72 6d61 6c69 7a65 2c20  self.normalize, 
-000118c0: 6d69 6e5f 7069 7865 6c3d 6d69 6e5f 7069  min_pixel=min_pi
-000118d0: 782c 206d 6178 5f70 6978 656c 3d6d 6178  x, max_pixel=max
-000118e0: 5f70 6978 2c20 7661 6c5f 706f 7369 7469  _pix, val_positi
-000118f0: 7665 3d76 616c 5f63 6c61 7373 5f31 2c20  ve=val_class_1, 
-00011900: 7661 6c5f 6e65 6761 7469 7665 3d76 616c  val_negative=val
-00011910: 5f63 6c61 7373 5f32 2c20 0a20 2020 2020  _class_2, .     
-00011920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011930: 2020 2020 2020 2020 2020 2065 706f 6368             epoch
-00011940: 733d 7365 6c66 2e74 7261 696e 5f65 706f  s=self.train_epo
-00011950: 6368 732c 2062 6174 6368 5f73 697a 653d  chs, batch_size=
-00011960: 6261 7463 685f 7369 7a65 2c20 6f70 7469  batch_size, opti
-00011970: 6d69 7a65 723d 6f70 7469 6d69 7a65 722c  mizer=optimizer,
-00011980: 206c 723d 6c72 2c20 6465 6361 793d 6465   lr=lr, decay=de
-00011990: 6361 792c 206d 6f6d 656e 7475 6d3d 6d6f  cay, momentum=mo
-000119a0: 6d65 6e74 756d 2c20 6e65 7374 6572 6f76  mentum, nesterov
-000119b0: 3d6e 6573 7465 726f 762c 200a 2020 2020  =nesterov, .    
-000119c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000119d0: 2020 2020 2020 2020 2020 2020 6265 7461              beta
-000119e0: 5f31 3d62 6574 615f 312c 2062 6574 615f  _1=beta_1, beta_
-000119f0: 323d 6265 7461 5f32 2c20 616d 7367 7261  2=beta_2, amsgra
-00011a00: 643d 616d 7367 7261 642c 206c 6f73 733d  d=amsgrad, loss=
-00011a10: 6c6f 7373 2c20 6163 7469 7661 7469 6f6e  loss, activation
-00011a20: 5f63 6f6e 763d 6163 7469 7661 7469 6f6e  _conv=activation
-00011a30: 5f63 6f6e 762c 2061 6374 6976 6174 696f  _conv, activatio
-00011a40: 6e5f 6465 6e73 653d 6163 7469 7661 7469  n_dense=activati
-00011a50: 6f6e 5f64 656e 7365 2c20 0a20 2020 2020  on_dense, .     
-00011a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011a70: 2020 2020 2020 2020 2020 2063 6f6e 765f             conv_
-00011a80: 696e 6974 3d63 6f6e 765f 696e 6974 2c20  init=conv_init, 
-00011a90: 6465 6e73 655f 696e 6974 3d64 656e 7365  dense_init=dense
-00011aa0: 5f69 6e69 742c 206d 6f64 656c 5f72 6567  _init, model_reg
-00011ab0: 3d6d 6f64 656c 5f72 6567 2c20 6669 6c74  =model_reg, filt
-00011ac0: 6572 733d 6669 6c74 6572 732c 2066 696c  ers=filters, fil
-00011ad0: 7465 725f 7369 7a65 3d66 696c 7465 725f  ter_size=filter_
-00011ae0: 7369 7a65 2c20 7374 7269 6465 733d 7374  size, strides=st
-00011af0: 7269 6465 732c 2020 0a20 2020 2020 2020  rides,  .       
+00011530: 2020 2020 2073 6d6f 7465 5f73 616d 706c       smote_sampl
+00011540: 696e 673d 7365 6c66 2e73 6d6f 7465 5f73  ing=self.smote_s
+00011550: 616d 706c 696e 672c 2065 6172 6c79 5f73  ampling, early_s
+00011560: 746f 705f 6361 6c6c 6261 636b 3d63 616c  top_callback=cal
+00011570: 6c62 6163 6b73 2c20 6368 6563 6b70 6f69  lbacks, checkpoi
+00011580: 6e74 3d46 616c 7365 2c20 7665 7262 6f73  nt=False, verbos
+00011590: 653d 7365 6c66 2e76 6572 626f 7365 290a  e=self.verbose).
+000115a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000115b0: 2020 2020 656c 6966 2073 656c 662e 636c      elif self.cl
+000115c0: 6620 3d3d 2027 6375 7374 6f6d 5f63 6e6e  f == 'custom_cnn
+000115d0: 273a 0a20 2020 2020 2020 2020 2020 2020  ':.             
+000115e0: 2020 2020 2020 2020 2020 206d 6f64 656c             model
+000115f0: 2c20 6869 7374 6f72 7920 3d20 636e 6e5f  , history = cnn_
+00011600: 6d6f 6465 6c2e 6375 7374 6f6d 5f6d 6f64  model.custom_mod
+00011610: 656c 2863 6c61 7373 5f31 2c20 636c 6173  el(class_1, clas
+00011620: 735f 322c 2069 6d67 5f6e 756d 5f63 6861  s_2, img_num_cha
+00011630: 6e6e 656c 733d 7365 6c66 2e69 6d67 5f6e  nnels=self.img_n
+00011640: 756d 5f63 6861 6e6e 656c 732c 200a 2020  um_channels, .  
+00011650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011660: 2020 2020 2020 2020 2020 6e6f 726d 616c            normal
+00011670: 697a 653d 7365 6c66 2e6e 6f72 6d61 6c69  ize=self.normali
+00011680: 7a65 2c20 6d69 6e5f 7069 7865 6c3d 6d69  ze, min_pixel=mi
+00011690: 6e5f 7069 782c 206d 6178 5f70 6978 656c  n_pix, max_pixel
+000116a0: 3d6d 6178 5f70 6978 2c20 7661 6c5f 706f  =max_pix, val_po
+000116b0: 7369 7469 7665 3d76 616c 5f63 6c61 7373  sitive=val_class
+000116c0: 5f31 2c20 7661 6c5f 6e65 6761 7469 7665  _1, val_negative
+000116d0: 3d76 616c 5f63 6c61 7373 5f32 2c20 0a20  =val_class_2, . 
+000116e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000116f0: 2020 2020 2020 2020 2020 2065 706f 6368             epoch
+00011700: 733d 7365 6c66 2e74 7261 696e 5f65 706f  s=self.train_epo
+00011710: 6368 732c 2062 6174 6368 5f73 697a 653d  chs, batch_size=
+00011720: 6261 7463 685f 7369 7a65 2c20 6f70 7469  batch_size, opti
+00011730: 6d69 7a65 723d 6f70 7469 6d69 7a65 722c  mizer=optimizer,
+00011740: 206c 723d 6c72 2c20 6465 6361 793d 6465   lr=lr, decay=de
+00011750: 6361 792c 206d 6f6d 656e 7475 6d3d 6d6f  cay, momentum=mo
+00011760: 6d65 6e74 756d 2c20 6e65 7374 6572 6f76  mentum, nesterov
+00011770: 3d6e 6573 7465 726f 762c 200a 2020 2020  =nesterov, .    
+00011780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011790: 2020 2020 2020 2020 6265 7461 5f31 3d62          beta_1=b
+000117a0: 6574 615f 312c 2062 6574 615f 323d 6265  eta_1, beta_2=be
+000117b0: 7461 5f32 2c20 616d 7367 7261 643d 616d  ta_2, amsgrad=am
+000117c0: 7367 7261 642c 206c 6f73 733d 6c6f 7373  sgrad, loss=loss
+000117d0: 2c20 6163 7469 7661 7469 6f6e 5f63 6f6e  , activation_con
+000117e0: 763d 6163 7469 7661 7469 6f6e 5f63 6f6e  v=activation_con
+000117f0: 762c 2061 6374 6976 6174 696f 6e5f 6465  v, activation_de
+00011800: 6e73 653d 6163 7469 7661 7469 6f6e 5f64  nse=activation_d
+00011810: 656e 7365 2c20 0a20 2020 2020 2020 2020  ense, .         
+00011820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011830: 2020 2063 6f6e 765f 696e 6974 3d63 6f6e     conv_init=con
+00011840: 765f 696e 6974 2c20 6465 6e73 655f 696e  v_init, dense_in
+00011850: 6974 3d64 656e 7365 5f69 6e69 742c 206d  it=dense_init, m
+00011860: 6f64 656c 5f72 6567 3d6d 6f64 656c 5f72  odel_reg=model_r
+00011870: 6567 2c20 0a20 2020 2020 2020 2020 2020  eg, .           
+00011880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011890: 2066 696c 7465 725f 313d 6669 6c74 6572   filter_1=filter
+000118a0: 5f31 2c20 6669 6c74 6572 5f73 697a 655f  _1, filter_size_
+000118b0: 313d 6669 6c74 6572 5f73 697a 655f 312c  1=filter_size_1,
+000118c0: 2073 7472 6964 6573 5f31 3d73 7472 6964   strides_1=strid
+000118d0: 6573 5f31 2c20 706f 6f6c 696e 675f 313d  es_1, pooling_1=
+000118e0: 706f 6f6c 696e 675f 312c 2070 6f6f 6c5f  pooling_1, pool_
+000118f0: 7369 7a65 5f31 3d70 6f6f 6c5f 7369 7a65  size_1=pool_size
+00011900: 5f31 2c20 706f 6f6c 5f73 7472 6964 655f  _1, pool_stride_
+00011910: 313d 706f 6f6c 5f73 7472 6964 655f 312c  1=pool_stride_1,
+00011920: 200a 2020 2020 2020 2020 2020 2020 2020   .              
+00011930: 2020 2020 2020 2020 2020 2020 2020 6669                fi
+00011940: 6c74 6572 5f32 3d66 696c 7465 725f 322c  lter_2=filter_2,
+00011950: 2066 696c 7465 725f 7369 7a65 5f32 3d66   filter_size_2=f
+00011960: 696c 7465 725f 7369 7a65 5f32 2c20 7374  ilter_size_2, st
+00011970: 7269 6465 735f 323d 7374 7269 6465 735f  rides_2=strides_
+00011980: 322c 2070 6f6f 6c69 6e67 5f32 3d70 6f6f  2, pooling_2=poo
+00011990: 6c69 6e67 5f32 2c20 706f 6f6c 5f73 697a  ling_2, pool_siz
+000119a0: 655f 323d 706f 6f6c 5f73 697a 655f 322c  e_2=pool_size_2,
+000119b0: 2070 6f6f 6c5f 7374 7269 6465 5f32 3d70   pool_stride_2=p
+000119c0: 6f6f 6c5f 7374 7269 6465 5f32 2c20 0a20  ool_stride_2, . 
+000119d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000119e0: 2020 2020 2020 2020 2020 2066 696c 7465             filte
+000119f0: 725f 333d 6669 6c74 6572 5f33 2c20 6669  r_3=filter_3, fi
+00011a00: 6c74 6572 5f73 697a 655f 333d 6669 6c74  lter_size_3=filt
+00011a10: 6572 5f73 697a 655f 332c 2073 7472 6964  er_size_3, strid
+00011a20: 6573 5f33 3d73 7472 6964 6573 5f33 2c20  es_3=strides_3, 
+00011a30: 706f 6f6c 696e 675f 333d 706f 6f6c 696e  pooling_3=poolin
+00011a40: 675f 332c 2070 6f6f 6c5f 7369 7a65 5f33  g_3, pool_size_3
+00011a50: 3d70 6f6f 6c5f 7369 7a65 5f33 2c20 706f  =pool_size_3, po
+00011a60: 6f6c 5f73 7472 6964 655f 333d 706f 6f6c  ol_stride_3=pool
+00011a70: 5f73 7472 6964 655f 332c 200a 2020 2020  _stride_3, .    
+00011a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011a90: 2020 2020 2020 2020 6465 6e73 655f 6e65          dense_ne
+00011aa0: 7572 6f6e 735f 313d 6465 6e73 655f 6e65  urons_1=dense_ne
+00011ab0: 7572 6f6e 735f 312c 2064 656e 7365 5f6e  urons_1, dense_n
+00011ac0: 6575 726f 6e73 5f32 3d64 656e 7365 5f6e  eurons_2=dense_n
+00011ad0: 6575 726f 6e73 5f32 2c20 6465 6e73 655f  eurons_2, dense_
+00011ae0: 6e65 7572 6f6e 735f 333d 6465 6e73 655f  neurons_3=dense_
+00011af0: 6e65 7572 6f6e 735f 332c 200a 2020 2020  neurons_3, .    
 00011b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011b10: 2020 2020 2020 2020 2070 6f6f 6c69 6e67           pooling
-00011b20: 3d70 6f6f 6c69 6e67 2c20 706f 6f6c 5f73  =pooling, pool_s
-00011b30: 697a 653d 706f 6f6c 5f73 697a 652c 2070  ize=pool_size, p
-00011b40: 6f6f 6c5f 7374 7269 6465 3d70 6f6f 6c5f  ool_stride=pool_
-00011b50: 7374 7269 6465 2c20 626c 6f63 6b5f 6669  stride, block_fi
-00011b60: 6c74 6572 735f 313d 626c 6f63 6b5f 6669  lters_1=block_fi
-00011b70: 6c74 6572 735f 312c 2062 6c6f 636b 5f66  lters_1, block_f
-00011b80: 696c 7465 7273 5f32 3d62 6c6f 636b 5f66  ilters_2=block_f
-00011b90: 696c 7465 7273 5f32 2c20 0a20 2020 2020  ilters_2, .     
-00011ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011bb0: 2020 2020 2020 2020 2020 2062 6c6f 636b             block
-00011bc0: 5f66 696c 7465 7273 5f33 3d62 6c6f 636b  _filters_3=block
-00011bd0: 5f66 696c 7465 7273 5f33 2c20 626c 6f63  _filters_3, bloc
-00011be0: 6b5f 6669 6c74 6572 735f 343d 626c 6f63  k_filters_4=bloc
-00011bf0: 6b5f 6669 6c74 6572 735f 342c 2062 6c6f  k_filters_4, blo
-00011c00: 636b 5f66 696c 7465 7273 5f73 697a 653d  ck_filters_size=
-00011c10: 626c 6f63 6b5f 6669 6c74 6572 735f 7369  block_filters_si
-00011c20: 7a65 2c20 0a20 2020 2020 2020 2020 2020  ze, .           
-00011c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c40: 2020 2020 2073 6d6f 7465 5f73 616d 706c       smote_sampl
-00011c50: 696e 673d 7365 6c66 2e73 6d6f 7465 5f73  ing=self.smote_s
-00011c60: 616d 706c 696e 672c 2065 6172 6c79 5f73  ampling, early_s
-00011c70: 746f 705f 6361 6c6c 6261 636b 3d63 616c  top_callback=cal
-00011c80: 6c62 6163 6b73 2c20 6368 6563 6b70 6f69  lbacks, checkpoi
-00011c90: 6e74 3d46 616c 7365 2c20 7665 7262 6f73  nt=False, verbos
-00011ca0: 653d 7365 6c66 2e76 6572 626f 7365 290a  e=self.verbose).
-00011cb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011cc0: 2023 4966 2074 6865 2070 6174 6965 6e63   #If the patienc
-00011cd0: 6520 6973 2072 6561 6368 6564 202d 2d20  e is reached -- 
-00011ce0: 7265 7475 726e 2073 686f 756c 6420 6265  return should be
-00011cf0: 2061 2076 616c 7565 2074 6861 7420 636f   a value that co
-00011d00: 6e74 6169 6e73 2069 6e66 6f72 6d61 7469  ntains informati
-00011d10: 6f6e 2072 6567 6172 6469 6e67 2074 6865  on regarding the
-00011d20: 206e 756d 206f 6620 636f 6d70 6c65 7465   num of complete
-00011d30: 6420 6570 6f63 6873 2c20 6f74 6865 7277  d epochs, otherw
-00011d40: 6973 6520 6966 2072 6574 7572 6e20 3020  ise if return 0 
-00011d50: 6576 6572 7920 7469 6d65 2074 6865 6e20  every time then 
-00011d60: 7468 6520 6f70 7469 6d69 7a65 7220 6d61  the optimizer ma
-00011d70: 7920 6765 7420 7374 7563 6b23 0a20 2020  y get stuck#.   
-00011d80: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00011d90: 6c65 6e28 6869 7374 6f72 792e 6869 7374  len(history.hist
-00011da0: 6f72 795b 276c 6f73 7327 5d29 2021 3d20  ory['loss']) != 
-00011db0: 7365 6c66 2e74 7261 696e 5f65 706f 6368  self.train_epoch
-00011dc0: 733a 0a20 2020 2020 2020 2020 2020 2020  s:.             
-00011dd0: 2020 2020 2020 2070 7269 6e74 2829 3b20         print(); 
-00011de0: 7072 696e 7428 2754 6865 2074 7261 696e  print('The train
-00011df0: 696e 6720 7061 7469 656e 6365 2077 6173  ing patience was
-00011e00: 2072 6561 6368 6564 2e2e 2e27 293b 2070   reached...'); p
-00011e10: 7269 6e74 2829 0a20 2020 2020 2020 2020  rint().         
-00011e20: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00011e30: 6e20 286c 656e 2868 6973 746f 7279 2e68  n (len(history.h
-00011e40: 6973 746f 7279 5b27 6c6f 7373 275d 2920  istory['loss']) 
-00011e50: 2a20 302e 3030 3129 202d 2039 3939 2e30  * 0.001) - 999.0
-00011e60: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00011e70: 2020 2349 6620 7468 6520 7472 6169 6e69    #If the traini
-00011e80: 6e67 2066 6169 6c73 2072 6574 7572 6e20  ng fails return 
-00011e90: 4e61 4e20 7269 6768 7420 6177 6179 230a  NaN right away#.
-00011ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011eb0: 6966 206e 702e 6973 6669 6e69 7465 2868  if np.isfinite(h
-00011ec0: 6973 746f 7279 2e68 6973 746f 7279 5b27  istory.history['
-00011ed0: 6c6f 7373 275d 5b2d 315d 293a 0a20 2020  loss'][-1]):.   
-00011ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011ef0: 206d 6f64 656c 732e 6170 7065 6e64 286d   models.append(m
-00011f00: 6f64 656c 292c 2068 6973 746f 7269 6573  odel), histories
-00011f10: 2e61 7070 656e 6428 6869 7374 6f72 7929  .append(history)
-00011f20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011f30: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-00011f40: 2020 2020 2020 2020 2020 2070 7269 6e74             print
-00011f50: 2829 3b20 7072 696e 7428 2754 7261 696e  (); print('Train
-00011f60: 696e 6720 6661 696c 6564 2064 7565 2074  ing failed due t
-00011f70: 6f20 6e75 6d65 7269 6361 6c20 696e 7374  o numerical inst
-00011f80: 6162 696c 6974 792c 2072 6574 7572 6e69  ability, returni
-00011f90: 6e67 206e 616e 2e2e 2e27 290a 2020 2020  ng nan...').    
-00011fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011fb0: 7265 7475 726e 206e 702e 6e61 6e20 0a0a  return np.nan ..
-00011fc0: 2020 2020 2020 2020 2323 2323 2323 2041          ###### A
-00011fd0: 6464 6974 696f 6e61 6c20 7465 7374 2064  dditional test d
-00011fe0: 6174 6120 6d65 7472 6963 2c20 6f70 7469  ata metric, opti
-00011ff0: 6f6e 616c 2069 6e70 7574 2023 2323 2323  onal input #####
-00012000: 230a 2020 2020 2020 2020 6966 2073 656c  #.        if sel
-00012010: 662e 7465 7374 5f70 6f73 6974 6976 6520  f.test_positive 
-00012020: 6973 206e 6f74 204e 6f6e 6520 6f72 2073  is not None or s
-00012030: 656c 662e 7465 7374 5f6e 6567 6174 6976  elf.test_negativ
-00012040: 6520 6973 206e 6f74 204e 6f6e 653a 0a20  e is not None:. 
-00012050: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-00012060: 6c66 2e74 6573 745f 706f 7369 7469 7665  lf.test_positive
-00012070: 2069 7320 6e6f 7420 4e6f 6e65 2061 6e64   is not None and
-00012080: 2073 656c 662e 7465 7374 5f6e 6567 6174   self.test_negat
-00012090: 6976 6520 6973 206e 6f74 204e 6f6e 653a  ive is not None:
-000120a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000120b0: 2070 6f73 6974 6976 655f 7465 7374 5f63   positive_test_c
-000120c0: 726f 702c 206e 6567 6174 6976 655f 7465  rop, negative_te
-000120d0: 7374 5f63 726f 7020 3d20 7265 7369 7a65  st_crop = resize
-000120e0: 2873 656c 662e 7465 7374 5f70 6f73 6974  (self.test_posit
-000120f0: 6976 652c 2073 697a 653d 696d 6167 655f  ive, size=image_
-00012100: 7369 7a65 292c 2072 6573 697a 6528 7365  size), resize(se
-00012110: 6c66 2e74 6573 745f 6e65 6761 7469 7665  lf.test_negative
-00012120: 2c20 7369 7a65 3d69 6d61 6765 5f73 697a  , size=image_siz
-00012130: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
-00012140: 2020 2058 5f74 6573 742c 2059 5f74 6573     X_test, Y_tes
-00012150: 7420 3d20 6372 6561 7465 5f74 7261 696e  t = create_train
-00012160: 696e 675f 7365 7428 706f 7369 7469 7665  ing_set(positive
-00012170: 5f74 6573 745f 6372 6f70 2c20 6e65 6761  _test_crop, nega
-00012180: 7469 7665 5f74 6573 745f 6372 6f70 2c20  tive_test_crop, 
-00012190: 6e6f 726d 616c 697a 653d 7365 6c66 2e6e  normalize=self.n
-000121a0: 6f72 6d61 6c69 7a65 2c20 6d69 6e5f 7069  ormalize, min_pi
-000121b0: 7865 6c3d 6d69 6e5f 7069 782c 206d 6178  xel=min_pix, max
-000121c0: 5f70 6978 656c 3d6d 6178 5f70 6978 2c20  _pixel=max_pix, 
-000121d0: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
-000121e0: 3d73 656c 662e 696d 675f 6e75 6d5f 6368  =self.img_num_ch
-000121f0: 616e 6e65 6c73 290a 2020 2020 2020 2020  annels).        
-00012200: 2020 2020 656c 6966 2073 656c 662e 7465      elif self.te
-00012210: 7374 5f70 6f73 6974 6976 6520 6973 206e  st_positive is n
-00012220: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
-00012230: 2020 2020 2020 2020 2070 6f73 6974 6976           positiv
-00012240: 655f 7465 7374 5f63 726f 7020 3d20 7265  e_test_crop = re
-00012250: 7369 7a65 2873 656c 662e 7465 7374 5f70  size(self.test_p
-00012260: 6f73 6974 6976 652c 2073 697a 653d 696d  ositive, size=im
-00012270: 6167 655f 7369 7a65 290a 2020 2020 2020  age_size).      
-00012280: 2020 2020 2020 2020 2020 706f 7369 7469            positi
-00012290: 7665 5f63 6c61 7373 5f64 6174 612c 2070  ve_class_data, p
-000122a0: 6f73 6974 6976 655f 636c 6173 735f 6c61  ositive_class_la
-000122b0: 6265 6c20 3d20 6461 7461 5f70 726f 6365  bel = data_proce
-000122c0: 7373 696e 672e 7072 6f63 6573 735f 636c  ssing.process_cl
-000122d0: 6173 7328 706f 7369 7469 7665 5f74 6573  ass(positive_tes
-000122e0: 745f 6372 6f70 2c20 6c61 6265 6c3d 312c  t_crop, label=1,
-000122f0: 206e 6f72 6d61 6c69 7a65 3d73 656c 662e   normalize=self.
-00012300: 6e6f 726d 616c 697a 652c 206d 696e 5f70  normalize, min_p
-00012310: 6978 656c 3d6d 696e 5f70 6978 2c20 6d61  ixel=min_pix, ma
-00012320: 785f 7069 7865 6c3d 6d61 785f 7069 782c  x_pixel=max_pix,
-00012330: 2069 6d67 5f6e 756d 5f63 6861 6e6e 656c   img_num_channel
-00012340: 733d 7365 6c66 2e69 6d67 5f6e 756d 5f63  s=self.img_num_c
-00012350: 6861 6e6e 656c 7329 0a20 2020 2020 2020  hannels).       
-00012360: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-00012370: 2e74 6573 745f 6e65 6761 7469 7665 2069  .test_negative i
-00012380: 7320 6e6f 7420 4e6f 6e65 3a0a 2020 2020  s not None:.    
-00012390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000123a0: 6e65 6761 7469 7665 5f74 6573 745f 6372  negative_test_cr
-000123b0: 6f70 203d 2072 6573 697a 6528 7365 6c66  op = resize(self
-000123c0: 2e74 6573 745f 6e65 6761 7469 7665 2c20  .test_negative, 
-000123d0: 7369 7a65 3d69 6d61 6765 5f73 697a 6529  size=image_size)
-000123e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000123f0: 2020 2020 206e 6567 6174 6976 655f 636c       negative_cl
-00012400: 6173 735f 6461 7461 2c20 6e65 6761 7469  ass_data, negati
-00012410: 7665 5f63 6c61 7373 5f6c 6162 656c 203d  ve_class_label =
-00012420: 2064 6174 615f 7072 6f63 6573 7369 6e67   data_processing
-00012430: 2e70 726f 6365 7373 5f63 6c61 7373 286e  .process_class(n
-00012440: 6567 6174 6976 655f 7465 7374 5f63 726f  egative_test_cro
-00012450: 702c 206c 6162 656c 3d30 2c20 6e6f 726d  p, label=0, norm
-00012460: 616c 697a 653d 7365 6c66 2e6e 6f72 6d61  alize=self.norma
-00012470: 6c69 7a65 2c20 6d69 6e5f 7069 7865 6c3d  lize, min_pixel=
-00012480: 6d69 6e5f 7069 782c 206d 6178 5f70 6978  min_pix, max_pix
-00012490: 656c 3d6d 6178 5f70 6978 2c20 696d 675f  el=max_pix, img_
-000124a0: 6e75 6d5f 6368 616e 6e65 6c73 3d73 656c  num_channels=sel
-000124b0: 662e 696d 675f 6e75 6d5f 6368 616e 6e65  f.img_num_channe
-000124c0: 6c73 290a 2020 2020 2020 2020 2020 2020  ls).            
-000124d0: 2020 2020 2020 2020 585f 7465 7374 2c20          X_test, 
-000124e0: 595f 7465 7374 203d 206e 702e 725f 5b70  Y_test = np.r_[p
-000124f0: 6f73 6974 6976 655f 636c 6173 735f 6461  ositive_class_da
-00012500: 7461 2c20 6e65 6761 7469 7665 5f63 6c61  ta, negative_cla
-00012510: 7373 5f64 6174 615d 2c20 6e70 2e72 5f5b  ss_data], np.r_[
-00012520: 706f 7369 7469 7665 5f63 6c61 7373 5f6c  positive_class_l
-00012530: 6162 656c 2c20 6e65 6761 7469 7665 5f63  abel, negative_c
-00012540: 6c61 7373 5f6c 6162 656c 5d0a 2020 2020  lass_label].    
-00012550: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00012560: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00012570: 2020 2020 2020 585f 7465 7374 2c20 595f        X_test, Y_
-00012580: 7465 7374 203d 2070 6f73 6974 6976 655f  test = positive_
-00012590: 636c 6173 735f 6461 7461 2c20 706f 7369  class_data, posi
-000125a0: 7469 7665 5f63 6c61 7373 5f6c 6162 656c  tive_class_label
-000125b0: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
-000125c0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-000125d0: 2020 2069 6620 7365 6c66 2e74 6573 745f     if self.test_
-000125e0: 6e65 6761 7469 7665 2069 7320 6e6f 7420  negative is not 
-000125f0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-00012600: 2020 2020 2020 2020 2020 585f 7465 7374            X_test
-00012610: 2c20 595f 7465 7374 203d 2064 6174 615f  , Y_test = data_
-00012620: 7072 6f63 6573 7369 6e67 2e70 726f 6365  processing.proce
-00012630: 7373 5f63 6c61 7373 286e 6567 6174 6976  ss_class(negativ
-00012640: 655f 7465 7374 5f63 726f 702c 206c 6162  e_test_crop, lab
-00012650: 656c 3d30 2c20 6e6f 726d 616c 697a 653d  el=0, normalize=
-00012660: 7365 6c66 2e6e 6f72 6d61 6c69 7a65 2c20  self.normalize, 
-00012670: 6d69 6e5f 7069 7865 6c3d 6d69 6e5f 7069  min_pixel=min_pi
-00012680: 782c 206d 6178 5f70 6978 656c 3d6d 6178  x, max_pixel=max
-00012690: 5f70 6978 2c20 696d 675f 6e75 6d5f 6368  _pix, img_num_ch
-000126a0: 616e 6e65 6c73 3d73 656c 662e 696d 675f  annels=self.img_
-000126b0: 6e75 6d5f 6368 616e 6e65 6c73 290a 2020  num_channels).  
-000126c0: 2020 2020 2020 2020 2020 200a 2020 2020             .    
-000126d0: 2020 2020 2020 2020 2323 234c 6f6f 7020          ###Loop 
-000126e0: 7468 726f 7567 6820 616c 6c20 7468 6520  through all the 
-000126f0: 6d6f 6465 6c73 2074 6f20 6361 6c63 756c  models to calcul
-00012700: 6174 6520 7468 6520 7065 7266 6f72 6d61  ate the performa
-00012710: 6e63 6520 6f66 2065 6163 6823 2323 0a20  nce of each###. 
-00012720: 2020 2020 2020 2020 2020 2074 6573 7420             test 
-00012730: 3d20 5b5d 0a20 2020 2020 2020 2020 2020  = [].           
-00012740: 2066 6f72 205f 6d6f 6465 6c5f 2069 6e20   for _model_ in 
-00012750: 6d6f 6465 6c73 3a0a 2020 2020 2020 2020  models:.        
-00012760: 2020 2020 2020 2020 7465 7374 5f6c 6f73          test_los
-00012770: 732c 2074 6573 745f 6163 632c 2074 6573  s, test_acc, tes
-00012780: 745f 6631 5f73 636f 7265 203d 205f 6d6f  t_f1_score = _mo
-00012790: 6465 6c5f 2e65 7661 6c75 6174 6528 585f  del_.evaluate(X_
-000127a0: 7465 7374 2c20 595f 7465 7374 2c20 6261  test, Y_test, ba
-000127b0: 7463 685f 7369 7a65 3d6c 656e 2858 5f74  tch_size=len(X_t
-000127c0: 6573 7429 290a 2020 2020 2020 2020 2020  est)).          
-000127d0: 2020 2020 2020 6966 2027 6c6f 7373 2720        if 'loss' 
-000127e0: 696e 2073 656c 662e 6d65 7472 6963 3a0a  in self.metric:.
-000127f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012800: 2020 2020 7465 7374 5f6d 6574 7269 6320      test_metric 
-00012810: 3d20 3120 2d20 7465 7374 5f6c 6f73 730a  = 1 - test_loss.
-00012820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012830: 656c 6966 2027 6163 6327 2069 6e20 7365  elif 'acc' in se
-00012840: 6c66 2e6d 6574 7269 633a 0a20 2020 2020  lf.metric:.     
-00012850: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00012860: 6573 745f 6d65 7472 6963 203d 2074 6573  est_metric = tes
-00012870: 745f 6163 6320 0a20 2020 2020 2020 2020  t_acc .         
-00012880: 2020 2020 2020 2065 6c69 6620 2766 3127         elif 'f1'
-00012890: 2069 6e20 7365 6c66 2e6d 6574 7269 633a   in self.metric:
-000128a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000128b0: 2020 2020 2074 6573 745f 6d65 7472 6963       test_metric
-000128c0: 203d 2074 6573 745f 6631 5f73 636f 7265   = test_f1_score
-000128d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000128e0: 2065 6c69 6620 2761 6c6c 2720 696e 2073   elif 'all' in s
-000128f0: 656c 662e 6d65 7472 6963 3a0a 2020 2020  elf.metric:.    
-00012900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012910: 7465 7374 5f6d 6574 7269 6320 3d20 6e70  test_metric = np
-00012920: 2e6d 6561 6e28 5b31 202d 2074 6573 745f  .mean([1 - test_
-00012930: 6c6f 7373 2c20 7465 7374 5f61 6363 2c20  loss, test_acc, 
-00012940: 7465 7374 5f66 315f 7363 6f72 655d 290a  test_f1_score]).
-00012950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012960: 7465 7374 2e61 7070 656e 6428 7465 7374  test.append(test
-00012970: 5f6d 6574 7269 6329 0a0a 2020 2020 2020  _metric)..      
-00012980: 2020 2020 2020 7465 7374 5f6d 6574 7269        test_metri
-00012990: 6320 3d20 6e70 2e6d 6561 6e28 7465 7374  c = np.mean(test
-000129a0: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
-000129b0: 2073 656c 662e 7665 7262 6f73 6520 3d3d   self.verbose ==
-000129c0: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
-000129d0: 2020 2020 7072 696e 7428 293b 2070 7269      print(); pri
-000129e0: 6e74 2827 506f 7374 2d54 7269 616c 204d  nt('Post-Trial M
-000129f0: 6574 7269 633a 2027 2b73 7472 2874 6573  etric: '+str(tes
-00012a00: 745f 6d65 7472 6963 2929 0a20 2020 2020  t_metric)).     
-00012a10: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00012a20: 2020 2020 2074 6573 745f 6d65 7472 6963       test_metric
-00012a30: 203d 204e 6f6e 650a 0a20 2020 2020 2020   = None..       
-00012a40: 2023 2323 2043 616c 6375 6c61 7465 2074   ### Calculate t
-00012a50: 6865 2066 696e 616c 206f 7074 696d 697a  he final optimiz
-00012a60: 6174 696f 6e20 6d65 7472 6963 2023 2323  ation metric ###
-00012a70: 0a20 2020 2020 2020 206d 6574 7269 6373  .        metrics
-00012a80: 203d 205b 276c 6f73 7327 2c20 2762 696e   = ['loss', 'bin
-00012a90: 6172 795f 6163 6375 7261 6379 272c 2027  ary_accuracy', '
-00012aa0: 6631 5f73 636f 7265 275d 0a20 2020 2020  f1_score'].     
-00012ab0: 2020 2069 6620 7365 6c66 2e6d 6574 7269     if self.metri
-00012ac0: 6320 3d3d 2027 616c 6c27 3a20 2341 7665  c == 'all': #Ave
-00012ad0: 7261 6765 2061 6c6c 2074 6865 2074 7261  rage all the tra
-00012ae0: 696e 696e 6720 6d65 7472 6963 730a 2020  ining metrics.  
-00012af0: 2020 2020 2020 2020 2020 7472 6169 6e69            traini
-00012b00: 6e67 5f6d 6574 7269 6373 5f6d 6561 6e2c  ng_metrics_mean,
-00012b10: 2074 7261 696e 696e 675f 6c6f 7373 5f6d   training_loss_m
-00012b20: 6561 6e20 3d20 5b5d 2c20 5b5d 0a20 2020  ean = [], [].   
-00012b30: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-00012b40: 2e61 7665 7261 6765 3a0a 2020 2020 2020  .average:.      
-00012b50: 2020 2020 2020 2020 2020 666f 7220 5f68            for _h
-00012b60: 6973 746f 7279 5f20 696e 2068 6973 746f  istory_ in histo
-00012b70: 7269 6573 3a0a 2020 2020 2020 2020 2020  ries:.          
-00012b80: 2020 2020 2020 2020 2020 7472 6169 6e69            traini
-00012b90: 6e67 5f6d 6574 7269 6373 5f6d 6561 6e2e  ng_metrics_mean.
-00012ba0: 6170 7065 6e64 286e 702e 6d65 616e 285b  append(np.mean([
-00012bb0: 6e70 2e6d 6561 6e28 5f68 6973 746f 7279  np.mean(_history
-00012bc0: 5f2e 6869 7374 6f72 795b 6d65 7472 6963  _.history[metric
-00012bd0: 5d29 2066 6f72 206d 6574 7269 6320 696e  ]) for metric in
-00012be0: 206d 6574 7269 6373 2069 6620 276c 6f73   metrics if 'los
-00012bf0: 7327 206e 6f74 2069 6e20 6d65 7472 6963  s' not in metric
-00012c00: 5d29 290a 2020 2020 2020 2020 2020 2020  ])).            
-00012c10: 2020 2020 2020 2020 7472 6169 6e69 6e67          training
-00012c20: 5f6c 6f73 735f 6d65 616e 2e61 7070 656e  _loss_mean.appen
-00012c30: 6428 3120 2d20 6e70 2e6d 6561 6e28 5f68  d(1 - np.mean(_h
-00012c40: 6973 746f 7279 5f2e 6869 7374 6f72 795b  istory_.history[
-00012c50: 276c 6f73 7327 5d29 290a 2020 2020 2020  'loss'])).      
-00012c60: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00012c70: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-00012c80: 5f68 6973 746f 7279 5f20 696e 2068 6973  _history_ in his
-00012c90: 746f 7269 6573 3a0a 2020 2020 2020 2020  tories:.        
-00012ca0: 2020 2020 2020 2020 2020 2020 7472 6169              trai
-00012cb0: 6e69 6e67 5f6d 6574 7269 6373 5f6d 6561  ning_metrics_mea
-00012cc0: 6e2e 6170 7065 6e64 286e 702e 6d65 616e  n.append(np.mean
-00012cd0: 285b 5f68 6973 746f 7279 5f2e 6869 7374  ([_history_.hist
-00012ce0: 6f72 795b 6d65 7472 6963 5d5b 2d31 5d20  ory[metric][-1] 
-00012cf0: 666f 7220 6d65 7472 6963 2069 6e20 6d65  for metric in me
-00012d00: 7472 6963 7320 6966 2027 6c6f 7373 2720  trics if 'loss' 
-00012d10: 6e6f 7420 696e 206d 6574 7269 635d 2929  not in metric]))
-00012d20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00012d30: 2020 2020 2074 7261 696e 696e 675f 6c6f       training_lo
-00012d40: 7373 5f6d 6561 6e2e 6170 7065 6e64 2831  ss_mean.append(1
-00012d50: 202d 205f 6869 7374 6f72 795f 2e68 6973   - _history_.his
-00012d60: 746f 7279 5b27 6c6f 7373 275d 5b2d 315d  tory['loss'][-1]
-00012d70: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
-00012d80: 2074 6573 745f 6d65 7472 6963 2069 7320   test_metric is 
-00012d90: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-00012da0: 2020 2020 2020 6669 6e61 6c5f 7363 6f72        final_scor
-00012db0: 6520 3d20 6e70 2e6d 6561 6e28 5b74 7261  e = np.mean([tra
-00012dc0: 696e 696e 675f 6d65 7472 6963 735f 6d65  ining_metrics_me
-00012dd0: 616e 2c20 7472 6169 6e69 6e67 5f6c 6f73  an, training_los
-00012de0: 735f 6d65 616e 5d29 0a20 2020 2020 2020  s_mean]).       
-00012df0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00012e00: 2020 2020 2020 2020 2020 2066 696e 616c             final
-00012e10: 5f73 636f 7265 203d 206e 702e 6d65 616e  _score = np.mean
-00012e20: 285b 7472 6169 6e69 6e67 5f6d 6574 7269  ([training_metri
-00012e30: 6373 5f6d 6561 6e2c 2074 7261 696e 696e  cs_mean, trainin
-00012e40: 675f 6c6f 7373 5f6d 6561 6e2c 2074 6573  g_loss_mean, tes
-00012e50: 745f 6d65 7472 6963 5d29 0a20 2020 2020  t_metric]).     
-00012e60: 2020 2065 6c69 6620 7365 6c66 2e6d 6574     elif self.met
-00012e70: 7269 6320 3d3d 2027 7661 6c5f 616c 6c27  ric == 'val_all'
-00012e80: 3a20 2341 7665 7261 6765 2061 6c6c 2074  : #Average all t
-00012e90: 6865 2076 616c 6964 6174 696f 6e20 6d65  he validation me
-00012ea0: 7472 6963 730a 2020 2020 2020 2020 2020  trics.          
-00012eb0: 2020 7661 6c5f 6d65 7472 6963 735f 6d65    val_metrics_me
-00012ec0: 616e 2c20 7661 6c5f 6c6f 7373 5f6d 6561  an, val_loss_mea
-00012ed0: 6e20 3d20 5b5d 2c20 5b5d 200a 2020 2020  n = [], [] .    
-00012ee0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00012ef0: 6176 6572 6167 653a 0a20 2020 2020 2020  average:.       
-00012f00: 2020 2020 2020 2020 2066 6f72 205f 6869           for _hi
-00012f10: 7374 6f72 795f 2069 6e20 6869 7374 6f72  story_ in histor
-00012f20: 6965 733a 0a20 2020 2020 2020 2020 2020  ies:.           
-00012f30: 2020 2020 2020 2020 2076 616c 5f6d 6574           val_met
-00012f40: 7269 6373 5f6d 6561 6e2e 6170 7065 6e64  rics_mean.append
-00012f50: 286e 702e 6d65 616e 285b 6e70 2e6d 6561  (np.mean([np.mea
-00012f60: 6e28 5f68 6973 746f 7279 5f2e 6869 7374  n(_history_.hist
-00012f70: 6f72 795b 2776 616c 5f27 2b6d 6574 7269  ory['val_'+metri
-00012f80: 635d 2920 666f 7220 6d65 7472 6963 2069  c]) for metric i
-00012f90: 6e20 6d65 7472 6963 7320 6966 2027 6c6f  n metrics if 'lo
-00012fa0: 7373 2720 6e6f 7420 696e 206d 6574 7269  ss' not in metri
-00012fb0: 635d 2929 0a20 2020 2020 2020 2020 2020  c])).           
-00012fc0: 2020 2020 2020 2020 2076 616c 5f6c 6f73           val_los
-00012fd0: 735f 6d65 616e 2e61 7070 656e 6428 3120  s_mean.append(1 
-00012fe0: 2d20 6e70 2e6d 6561 6e28 5f68 6973 746f  - np.mean(_histo
-00012ff0: 7279 5f2e 6869 7374 6f72 795b 2776 616c  ry_.history['val
-00013000: 5f6c 6f73 7327 5d29 290a 2020 2020 2020  _loss'])).      
-00013010: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00013020: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-00013030: 5f68 6973 746f 7279 5f20 696e 2068 6973  _history_ in his
-00013040: 746f 7269 6573 3a0a 2020 2020 2020 2020  tories:.        
-00013050: 2020 2020 2020 2020 2020 2020 7661 6c5f              val_
-00013060: 6d65 7472 6963 735f 6d65 616e 2e61 7070  metrics_mean.app
-00013070: 656e 6428 6e70 2e6d 6561 6e28 5b5f 6869  end(np.mean([_hi
-00013080: 7374 6f72 795f 2e68 6973 746f 7279 5b27  story_.history['
-00013090: 7661 6c5f 272b 6d65 7472 6963 5d5b 2d31  val_'+metric][-1
-000130a0: 5d20 666f 7220 6d65 7472 6963 2069 6e20  ] for metric in 
-000130b0: 6d65 7472 6963 7320 6966 2027 6c6f 7373  metrics if 'loss
-000130c0: 2720 6e6f 7420 696e 206d 6574 7269 635d  ' not in metric]
-000130d0: 2929 0a20 2020 2020 2020 2020 2020 2020  )).             
-000130e0: 2020 2020 2020 2076 616c 5f6c 6f73 735f         val_loss_
-000130f0: 6d65 616e 2e61 7070 656e 6428 3120 2d20  mean.append(1 - 
-00013100: 5f68 6973 746f 7279 5f2e 6869 7374 6f72  _history_.histor
-00013110: 795b 2776 616c 5f6c 6f73 7327 5d5b 2d31  y['val_loss'][-1
-00013120: 5d29 0a20 2020 2020 2020 2020 2020 2069  ]).            i
-00013130: 6620 7465 7374 5f6d 6574 7269 6320 6973  f test_metric is
-00013140: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-00013150: 2020 2020 2020 2066 696e 616c 5f73 636f         final_sco
-00013160: 7265 203d 206e 702e 6d65 616e 285b 7661  re = np.mean([va
-00013170: 6c5f 6d65 7472 6963 735f 6d65 616e 2c20  l_metrics_mean, 
-00013180: 7661 6c5f 6c6f 7373 5f6d 6561 6e5d 290a  val_loss_mean]).
-00013190: 2020 2020 2020 2020 2020 2020 656c 7365              else
-000131a0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000131b0: 2020 6669 6e61 6c5f 7363 6f72 6520 3d20    final_score = 
-000131c0: 6e70 2e6d 6561 6e28 5b76 616c 5f6d 6574  np.mean([val_met
-000131d0: 7269 6373 5f6d 6561 6e2c 2076 616c 5f6c  rics_mean, val_l
-000131e0: 6f73 735f 6d65 616e 2c20 7465 7374 5f6d  oss_mean, test_m
-000131f0: 6574 7269 635d 290a 2020 2020 2020 2020  etric]).        
-00013200: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00013210: 2020 7363 6f72 6573 203d 205b 5d0a 2020    scores = [].  
-00013220: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-00013230: 662e 6176 6572 6167 653a 0a20 2020 2020  f.average:.     
-00013240: 2020 2020 2020 2020 2020 2066 6f72 205f             for _
-00013250: 6869 7374 6f72 795f 2069 6e20 6869 7374  history_ in hist
-00013260: 6f72 6965 733a 0a20 2020 2020 2020 2020  ories:.         
-00013270: 2020 2020 2020 2020 2020 2073 636f 7265             score
-00013280: 732e 6170 7065 6e64 286e 702e 6d65 616e  s.append(np.mean
-00013290: 285f 6869 7374 6f72 795f 2e68 6973 746f  (_history_.histo
-000132a0: 7279 5b73 656c 662e 6d65 7472 6963 5d29  ry[self.metric])
-000132b0: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-000132c0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-000132d0: 2020 2020 666f 7220 5f68 6973 746f 7279      for _history
-000132e0: 5f20 696e 2068 6973 746f 7269 6573 3a0a  _ in histories:.
-000132f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013300: 2020 2020 7363 6f72 6573 2e61 7070 656e      scores.appen
-00013310: 6428 5f68 6973 746f 7279 5f2e 6869 7374  d(_history_.hist
-00013320: 6f72 795b 7365 6c66 2e6d 6574 7269 635d  ory[self.metric]
-00013330: 5b2d 315d 290a 0a20 2020 2020 2020 2020  [-1])..         
-00013340: 2020 2066 696e 616c 5f73 636f 7265 203d     final_score =
-00013350: 206e 702e 6d65 616e 2873 636f 7265 7329   np.mean(scores)
-00013360: 0a0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-00013370: 2027 6c6f 7373 2720 696e 2073 656c 662e   'loss' in self.
-00013380: 6d65 7472 6963 3a20 0a20 2020 2020 2020  metric: .       
-00013390: 2020 2020 2020 2020 2066 696e 616c 5f73           final_s
-000133a0: 636f 7265 203d 2031 202d 2066 696e 616c  core = 1 - final
-000133b0: 5f73 636f 7265 0a20 2020 2020 2020 2020  _score.         
-000133c0: 2020 2069 6620 7465 7374 5f6d 6574 7269     if test_metri
-000133d0: 6320 6973 206e 6f74 204e 6f6e 653a 0a20  c is not None:. 
-000133e0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-000133f0: 696e 616c 5f73 636f 7265 203d 2028 6669  inal_score = (fi
-00013400: 6e61 6c5f 7363 6f72 6520 2b20 7465 7374  nal_score + test
-00013410: 5f6d 6574 7269 6329 202f 2032 2e30 0a20  _metric) / 2.0. 
-00013420: 2020 2020 2020 200a 2020 2020 2020 2020         .        
-00013430: 7265 7475 726e 2066 696e 616c 5f73 636f  return final_sco
-00013440: 7265 0a0a 636c 6173 7320 6f62 6a65 6374  re..class object
-00013450: 6976 655f 7867 6228 6f62 6a65 6374 293a  ive_xgb(object):
-00013460: 0a20 2020 2022 2222 0a20 2020 204f 7074  .    """.    Opt
-00013470: 696d 697a 6174 696f 6e20 6f62 6a65 6374  imization object
-00013480: 6976 6520 6675 6e63 7469 6f6e 2066 6f72  ive function for
-00013490: 2074 6865 2074 7265 652d 6261 7365 6420   the tree-based 
-000134a0: 5847 426f 6f73 7420 636c 6173 7369 6669  XGBoost classifi
-000134b0: 6572 2e20 0a20 2020 2054 6865 204f 7074  er. .    The Opt
-000134c0: 756e 6120 736f 6674 7761 7265 2066 6f72  una software for
-000134d0: 2068 7970 6572 7061 7261 6d65 7465 7220   hyperparameter 
-000134e0: 6f70 7469 6d69 7a61 7469 6f6e 2077 6173  optimization was
-000134f0: 2070 7562 6c69 7368 6564 2069 6e20 0a20   published in . 
-00013500: 2020 2032 3031 3920 6279 2041 6b69 6261     2019 by Akiba
-00013510: 2065 7420 616c 2e20 5061 7065 723a 2068   et al. Paper: h
-00013520: 7474 7073 3a2f 2f61 7278 6976 2e6f 7267  ttps://arxiv.org
-00013530: 2f61 6273 2f31 3930 372e 3130 3930 320a  /abs/1907.10902.
-00013540: 2020 2020 0a20 2020 204e 6f74 653a 0a20      .    Note:. 
-00013550: 2020 2020 2020 2049 6620 6f70 745f 6376         If opt_cv
-00013560: 2069 7320 6265 7477 6565 6e20 3020 616e   is between 0 an
-00013570: 6420 312c 2061 2070 7275 6e69 6e67 2070  d 1, a pruning p
-00013580: 726f 6365 6475 7265 2077 696c 6c20 6265  rocedure will be
-00013590: 2069 6e69 7469 6c69 617a 6564 2028 6120   initiliazed (a 
-000135a0: 7072 6f63 6564 7572 6520 696e 636f 6d70  procedure incomp
-000135b0: 6174 6962 6c65 2077 6974 6820 6372 6f73  atible with cros
-000135c0: 732d 7661 6c69 6461 7469 6f6e 292c 0a20  s-validation),. 
-000135d0: 2020 2020 2020 2073 6f20 6173 2074 6f20         so as to 
-000135e0: 7370 6565 6420 7570 2074 6865 2058 4742  speed up the XGB
-000135f0: 206f 7074 696d 697a 6174 696f 6e2e 2049   optimization. I
-00013600: 6620 6f70 745f 6376 2069 7320 6265 7477  f opt_cv is betw
-00013610: 6565 6e20 3020 616e 6420 312c 2061 2072  een 0 and 1, a r
-00013620: 616e 646f 6d20 7661 6c69 6461 7469 6f6e  andom validation
-00013630: 2064 6174 6120 7769 6c6c 2062 6520 6765   data will be ge
-00013640: 6e65 7261 7465 6420 6163 636f 7264 696e  nerated accordin
-00013650: 6720 746f 2074 6869 7320 7261 7469 6f2c  g to this ratio,
-00013660: 0a20 2020 2020 2020 2077 6869 6368 2077  .        which w
-00013670: 696c 6c20 7265 706c 6163 6520 7468 6520  ill replace the 
-00013680: 6372 6f73 732d 7661 6c69 6461 7469 6f6e  cross-validation
-00013690: 206d 6574 686f 6420 7573 6564 2062 7920   method used by 
-000136a0: 6465 6661 756c 742e 2049 7420 7769 6c6c  default. It will
-000136b0: 2070 7275 6e65 2061 6363 6f72 6469 6e67   prune according
-000136c0: 0a20 2020 2020 2020 2074 6f20 7468 6520  .        to the 
-000136d0: 6631 2d73 636f 7265 206f 6620 7468 6520  f1-score of the 
-000136e0: 7661 6c69 6461 7469 6f6e 2064 6174 612c  validation data,
-000136f0: 2077 6869 6368 2077 6f75 6c64 2062 6520   which would be 
-00013700: 3130 2520 6f66 2074 6865 2074 7261 696e  10% of the train
-00013710: 696e 6720 6461 7461 2069 6620 6f70 745f  ing data if opt_
-00013720: 6376 3d30 2e31 2c20 666f 7220 6578 616d  cv=0.1, for exam
-00013730: 706c 652e 200a 2020 2020 2020 2020 4e65  ple. .        Ne
-00013740: 6564 206d 6f72 6520 7465 7374 696e 6720  ed more testing 
-00013750: 746f 206d 616b 6520 7468 6973 206d 6f72  to make this mor
-00013760: 6520 726f 6275 7374 2e0a 2020 2020 2020  e robust..      
-00013770: 2020 0a20 2020 2041 7267 733a 0a20 2020    .    Args:.   
-00013780: 2020 2020 2064 6174 615f 7820 286e 6461       data_x (nda
-00013790: 7272 6179 293a 2032 4420 6172 7261 7920  rray): 2D array 
-000137a0: 6f66 2073 697a 6520 286e 2078 206d 292c  of size (n x m),
-000137b0: 2077 6865 7265 206e 2069 7320 7468 650a   where n is the.
-000137c0: 2020 2020 2020 2020 2020 2020 6e75 6d62              numb
-000137d0: 6572 206f 6620 7361 6d70 6c65 732c 2061  er of samples, a
-000137e0: 6e64 206d 2074 6865 206e 756d 6265 7220  nd m the number 
-000137f0: 6f66 2066 6561 7475 7265 732e 0a20 2020  of features..   
-00013800: 2020 2020 2064 6174 615f 7920 286e 6461       data_y (nda
-00013810: 7272 6179 2c20 7374 7229 3a20 3144 2061  rray, str): 1D a
-00013820: 7272 6179 2063 6f6e 7461 696e 696e 6720  rray containing 
-00013830: 7468 6520 636f 7272 6573 706f 6e69 6e67  the corresponing
-00013840: 206c 6162 656c 732e 200a 2020 2020 2020   labels. .      
-00013850: 2020 6c69 6d69 745f 7365 6172 6368 2028    limit_search (
-00013860: 626f 6f6c 293a 2049 6620 5472 7565 2c20  bool): If True, 
-00013870: 7468 6520 7365 6172 6368 2073 7061 6365  the search space
-00013880: 2066 6f72 2074 6865 2070 6172 616d 6574   for the paramet
-00013890: 6572 7320 7769 6c6c 2062 6520 6578 7061  ers will be expa
-000138a0: 6e64 6564 2c0a 2020 2020 2020 2020 2020  nded,.          
-000138b0: 2020 6173 2074 6865 7265 2061 7265 2073    as there are s
-000138c0: 6f6d 6520 6879 7065 7270 6172 616d 6574  ome hyperparamet
-000138d0: 6572 7320 7468 6174 2063 616e 2072 616e  ers that can ran
-000138e0: 6765 2066 726f 6d20 3020 746f 2069 6e66  ge from 0 to inf
-000138f0: 2e20 4465 6661 756c 7473 2074 6f20 4661  . Defaults to Fa
-00013900: 6c73 652e 0a20 2020 2020 2020 206f 7074  lse..        opt
-00013910: 5f63 7620 2869 6e74 293a 2043 726f 7373  _cv (int): Cross
-00013920: 2d76 616c 6964 6174 696f 6e73 2074 6f20  -validations to 
-00013930: 7065 7266 6f72 6d20 7768 656e 2061 7373  perform when ass
-00013940: 6573 696e 6720 7468 6520 7065 7266 6f72  esing the perfor
-00013950: 6d61 6e63 6520 6174 2065 6163 680a 2020  mance at each.  
-00013960: 2020 2020 2020 2020 2020 6879 7065 7270            hyperp
-00013970: 6172 616d 6574 6572 206f 7074 696d 697a  arameter optimiz
-00013980: 6174 696f 6e20 7472 6961 6c2e 2046 6f72  ation trial. For
-00013990: 2065 7861 6d70 6c65 2c20 6966 2063 763d   example, if cv=
-000139a0: 332c 2074 6865 6e20 6561 6368 206f 7074  3, then each opt
-000139b0: 696d 697a 6174 696f 6e20 7472 6961 6c0a  imization trial.
-000139c0: 2020 2020 2020 2020 2020 2020 7769 6c6c              will
-000139d0: 2062 6520 6173 7365 7373 6564 2061 6363   be assessed acc
-000139e0: 6f72 6469 6e67 2074 6f20 7468 6520 332d  ording to the 3-
-000139f0: 666f 6c64 2063 726f 7373 2076 616c 6964  fold cross valid
-00013a00: 6174 696f 6e20 6163 6375 7261 6379 2e20  ation accuracy. 
-00013a10: 4966 2074 6869 7320 6973 0a20 2020 2020  If this is.     
-00013a20: 2020 2020 2020 2062 6574 7765 656e 2030         between 0
-00013a30: 2061 6e64 2031 2c20 7468 6973 2076 616c   and 1, this val
-00013a40: 7565 2077 6f75 6c64 2062 6520 7573 6564  ue would be used
-00013a50: 2061 7320 7468 6520 7261 7469 6f20 6f66   as the ratio of
-00013a60: 2074 6865 2076 616c 6964 6174 696f 6e20   the validation 
-00013a70: 746f 2074 7261 696e 696e 6720 6461 7461  to training data
-00013a80: 2e0a 2020 2020 2020 2020 2020 2020 4465  ..            De
-00013a90: 6661 756c 7473 2074 6f20 4e6f 6e65 2c20  faults to None, 
-00013aa0: 696e 2077 6869 6368 2063 6173 6520 7468  in which case th
-00013ab0: 6520 6372 6f73 732d 7661 6c69 6461 7469  e cross-validati
-00013ac0: 6f6e 2070 726f 6365 6475 7265 2077 696c  on procedure wil
-00013ad0: 6c20 6265 2065 6d70 6c6f 7965 642e 0a20  l be employed.. 
-00013ae0: 2020 2020 2020 2065 7661 6c5f 6d65 7472         eval_metr
-00013af0: 6963 2028 7374 7229 3a20 5468 6520 6576  ic (str): The ev
-00013b00: 616c 7561 7469 6f6e 206d 6574 7269 6320  aluation metric 
-00013b10: 7768 656e 2065 7661 6c75 6174 696e 6720  when evaluating 
-00013b20: 7468 6520 7661 6c69 6461 7469 6f6e 2064  the validation d
-00013b30: 6174 612c 2075 7365 6420 7768 656e 0a20  ata, used when. 
-00013b40: 2020 2020 2020 2020 2020 206f 7074 5f63             opt_c
-00013b50: 7620 6973 206c 6573 7320 7468 616e 2031  v is less than 1
-00013b60: 2e20 4465 6661 756c 7473 2074 6f20 2266  . Defaults to "f
-00013b70: 3122 2e20 466f 7220 616c 6c20 6f70 7469  1". For all opti
-00013b80: 6f6e 7320 7365 6520 6576 616c 5f6d 6574  ons see eval_met
-00013b90: 7269 6320 6672 6f6d 3a20 6874 7470 733a  ric from: https:
-00013ba0: 2f2f 7867 626f 6f73 742e 7265 6164 7468  //xgboost.readth
-00013bb0: 6564 6f63 732e 696f 2f65 6e2f 6c61 7465  edocs.io/en/late
-00013bc0: 7374 2f70 6172 616d 6574 6572 2e68 746d  st/parameter.htm
-00013bd0: 6c23 6d65 7472 6963 730a 0a20 2020 2052  l#metrics..    R
-00013be0: 6574 7572 6e73 3a0a 2020 2020 2020 2020  eturns:.        
-00013bf0: 5468 6520 6372 6f73 732d 7661 6c69 6461  The cross-valida
-00013c00: 7469 6f6e 2061 6363 7572 6163 7920 2869  tion accuracy (i
-00013c10: 6620 6f70 745f 6376 2069 7320 6772 6561  f opt_cv is grea
-00013c20: 7465 7220 7468 616e 2031 2c20 3120 776f  ter than 1, 1 wo
-00013c30: 756c 6420 6265 2073 696e 676c 6520 696e  uld be single in
-00013c40: 7374 616e 6365 2061 6363 7572 6163 7929  stance accuracy)
-00013c50: 0a20 2020 2020 2020 206f 722c 2069 6620  .        or, if 
-00013c60: 6f70 745f 6376 2069 7320 6265 7477 6565  opt_cv is betwee
-00013c70: 6e20 3020 616e 6420 312c 2074 6865 2076  n 0 and 1, the v
-00013c80: 616c 6964 6174 696f 6e20 6163 6375 7261  alidation accura
-00013c90: 6379 2061 6363 6f72 6469 6e67 2074 6f20  cy according to 
-00013ca0: 7468 6520 636f 7272 6573 706f 6e64 696e  the correspondin
-00013cb0: 6720 7465 7374 2073 697a 652e 0a20 2020  g test size..   
-00013cc0: 2022 2222 0a0a 2020 2020 6465 6620 5f5f   """..    def __
-00013cd0: 696e 6974 5f5f 2873 656c 662c 2064 6174  init__(self, dat
-00013ce0: 615f 782c 2064 6174 615f 792c 206c 696d  a_x, data_y, lim
-00013cf0: 6974 5f73 6561 7263 683d 4661 6c73 652c  it_search=False,
-00013d00: 206f 7074 5f63 763d 332c 2065 7661 6c5f   opt_cv=3, eval_
-00013d10: 6d65 7472 6963 3d22 6631 2229 3a0a 2020  metric="f1"):.  
-00013d20: 2020 2020 2020 7365 6c66 2e64 6174 615f        self.data_
-00013d30: 7820 3d20 6461 7461 5f78 0a20 2020 2020  x = data_x.     
-00013d40: 2020 2073 656c 662e 6461 7461 5f79 203d     self.data_y =
-00013d50: 2064 6174 615f 790a 2020 2020 2020 2020   data_y.        
-00013d60: 7365 6c66 2e6c 696d 6974 5f73 6561 7263  self.limit_searc
-00013d70: 6820 3d20 6c69 6d69 745f 7365 6172 6368  h = limit_search
-00013d80: 0a20 2020 2020 2020 2073 656c 662e 6f70  .        self.op
-00013d90: 745f 6376 203d 206f 7074 5f63 7620 0a20  t_cv = opt_cv . 
-00013da0: 2020 2020 2020 2073 656c 662e 6576 616c         self.eval
-00013db0: 5f6d 6574 7269 6320 3d20 6576 616c 5f6d  _metric = eval_m
-00013dc0: 6574 7269 6320 0a0a 2020 2020 6465 6620  etric ..    def 
-00013dd0: 5f5f 6361 6c6c 5f5f 2873 656c 662c 2074  __call__(self, t
-00013de0: 7269 616c 293a 0a0a 2020 2020 2020 2020  rial):..        
-00013df0: 7061 7261 6d73 203d 207b 226f 626a 6563  params = {"objec
-00013e00: 7469 7665 223a 2022 6269 6e61 7279 3a6c  tive": "binary:l
-00013e10: 6f67 6973 7469 6322 2c20 2265 7661 6c5f  ogistic", "eval_
-00013e20: 6d65 7472 6963 223a 2073 656c 662e 6576  metric": self.ev
-00013e30: 616c 5f6d 6574 7269 637d 200a 2020 2020  al_metric} .    
-00013e40: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-00013e50: 2e6f 7074 5f63 7620 3c20 313a 0a20 2020  .opt_cv < 1:.   
-00013e60: 2020 2020 2020 2020 2074 7261 696e 5f78           train_x
-00013e70: 2c20 7661 6c69 645f 782c 2074 7261 696e  , valid_x, train
-00013e80: 5f79 2c20 7661 6c69 645f 7920 3d20 7472  _y, valid_y = tr
-00013e90: 6169 6e5f 7465 7374 5f73 706c 6974 2873  ain_test_split(s
-00013ea0: 656c 662e 6461 7461 5f78 2c20 7365 6c66  elf.data_x, self
-00013eb0: 2e64 6174 615f 792c 2074 6573 745f 7369  .data_y, test_si
-00013ec0: 7a65 3d73 656c 662e 6f70 745f 6376 2c20  ze=self.opt_cv, 
-00013ed0: 7261 6e64 6f6d 5f73 7461 7465 3d31 3930  random_state=190
-00013ee0: 3929 236e 702e 7261 6e64 6f6d 2e72 616e  9)#np.random.ran
-00013ef0: 6469 6e74 2831 2c20 3165 3929 290a 2020  dint(1, 1e9)).  
-00013f00: 2020 2020 2020 2020 2020 6474 7261 696e            dtrain
-00013f10: 2c20 6476 616c 6964 203d 2044 4d61 7472  , dvalid = DMatr
-00013f20: 6978 2874 7261 696e 5f78 2c20 6c61 6265  ix(train_x, labe
-00013f30: 6c3d 7472 6169 6e5f 7929 2c20 444d 6174  l=train_y), DMat
-00013f40: 7269 7828 7661 6c69 645f 782c 206c 6162  rix(valid_x, lab
-00013f50: 656c 3d76 616c 6964 5f79 290a 2020 2020  el=valid_y).    
-00013f60: 2020 2020 2020 2020 2370 7269 6e74 2827          #print('
-00013f70: 496e 6974 6961 6c69 7a69 6e67 2058 4742  Initializing XGB
-00013f80: 6f6f 7374 2050 7275 6e65 722e 2e2e 2729  oost Pruner...')
-00013f90: 0a20 2020 2020 2020 2020 2020 2070 7275  .            pru
-00013fa0: 6e69 6e67 5f63 616c 6c62 6163 6b20 3d20  ning_callback = 
-00013fb0: 6f70 7475 6e61 2e69 6e74 6567 7261 7469  optuna.integrati
-00013fc0: 6f6e 2e58 4742 6f6f 7374 5072 756e 696e  on.XGBoostPrunin
-00013fd0: 6743 616c 6c62 6163 6b28 7472 6961 6c2c  gCallback(trial,
-00013fe0: 2022 7661 6c69 6461 7469 6f6e 2d22 202b   "validation-" +
-00013ff0: 2073 656c 662e 6576 616c 5f6d 6574 7269   self.eval_metri
-00014000: 6329 0a0a 2020 2020 2020 2020 6966 2073  c)..        if s
-00014010: 656c 662e 6c69 6d69 745f 7365 6172 6368  elf.limit_search
-00014020: 3a0a 2020 2020 2020 2020 2020 2020 7061  :.            pa
-00014030: 7261 6d73 5b27 6e5f 6573 7469 6d61 746f  rams['n_estimato
-00014040: 7273 275d 203d 2074 7269 616c 2e73 7567  rs'] = trial.sug
-00014050: 6765 7374 5f69 6e74 2827 6e5f 6573 7469  gest_int('n_esti
-00014060: 6d61 746f 7273 272c 2031 3030 2c20 3235  mators', 100, 25
-00014070: 3029 0a20 2020 2020 2020 2020 2020 2070  0).            p
-00014080: 6172 616d 735b 2762 6f6f 7374 6572 275d  arams['booster']
-00014090: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-000140a0: 5f63 6174 6567 6f72 6963 616c 2827 626f  _categorical('bo
-000140b0: 6f73 7465 7227 2c20 5b27 6762 7472 6565  oster', ['gbtree
-000140c0: 272c 2027 6461 7274 275d 290a 2020 2020  ', 'dart']).    
-000140d0: 2020 2020 2020 2020 7061 7261 6d73 5b27          params['
-000140e0: 7265 675f 6c61 6d62 6461 275d 203d 2074  reg_lambda'] = t
-000140f0: 7269 616c 2e73 7567 6765 7374 5f6c 6f67  rial.suggest_log
-00014100: 756e 6966 6f72 6d28 2772 6567 5f6c 616d  uniform('reg_lam
-00014110: 6264 6127 2c20 3165 2d38 2c20 3129 0a20  bda', 1e-8, 1). 
-00014120: 2020 2020 2020 2020 2020 2070 6172 616d             param
-00014130: 735b 2772 6567 5f61 6c70 6861 275d 203d  s['reg_alpha'] =
-00014140: 2074 7269 616c 2e73 7567 6765 7374 5f6c   trial.suggest_l
-00014150: 6f67 756e 6966 6f72 6d28 2772 6567 5f61  oguniform('reg_a
-00014160: 6c70 6861 272c 2031 652d 382c 2031 290a  lpha', 1e-8, 1).
-00014170: 2020 2020 2020 2020 2020 2020 7061 7261              para
-00014180: 6d73 5b27 6d61 785f 6465 7074 6827 5d20  ms['max_depth'] 
-00014190: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
-000141a0: 696e 7428 276d 6178 5f64 6570 7468 272c  int('max_depth',
-000141b0: 2032 2c20 3235 290a 2020 2020 2020 2020   2, 25).        
-000141c0: 2020 2020 7061 7261 6d73 5b27 6574 6127      params['eta'
-000141d0: 5d20 3d20 7472 6961 6c2e 7375 6767 6573  ] = trial.sugges
-000141e0: 745f 6c6f 6775 6e69 666f 726d 2827 6574  t_loguniform('et
-000141f0: 6127 2c20 3165 2d38 2c20 3129 0a20 2020  a', 1e-8, 1).   
-00014200: 2020 2020 2020 2020 2070 6172 616d 735b           params[
-00014210: 2767 616d 6d61 275d 203d 2074 7269 616c  'gamma'] = trial
-00014220: 2e73 7567 6765 7374 5f6c 6f67 756e 6966  .suggest_logunif
-00014230: 6f72 6d28 2767 616d 6d61 272c 2031 652d  orm('gamma', 1e-
-00014240: 382c 2031 290a 2020 2020 2020 2020 2020  8, 1).          
-00014250: 2020 7061 7261 6d73 5b27 6772 6f77 5f70    params['grow_p
-00014260: 6f6c 6963 7927 5d20 3d20 7472 6961 6c2e  olicy'] = trial.
-00014270: 7375 6767 6573 745f 6361 7465 676f 7269  suggest_categori
-00014280: 6361 6c28 2767 726f 775f 706f 6c69 6379  cal('grow_policy
-00014290: 272c 205b 2764 6570 7468 7769 7365 272c  ', ['depthwise',
-000142a0: 2027 6c6f 7373 6775 6964 6527 5d29 0a0a   'lossguide'])..
-000142b0: 2020 2020 2020 2020 2020 2020 6966 2070              if p
-000142c0: 6172 616d 735b 2762 6f6f 7374 6572 275d  arams['booster']
-000142d0: 203d 3d20 2264 6172 7422 3a0a 2020 2020   == "dart":.    
-000142e0: 2020 2020 2020 2020 2020 2020 7061 7261              para
-000142f0: 6d73 5b27 7361 6d70 6c65 5f74 7970 6527  ms['sample_type'
-00014300: 5d20 3d20 7472 6961 6c2e 7375 6767 6573  ] = trial.sugges
-00014310: 745f 6361 7465 676f 7269 6361 6c28 2773  t_categorical('s
-00014320: 616d 706c 655f 7479 7065 272c 205b 2775  ample_type', ['u
-00014330: 6e69 666f 726d 272c 2027 7765 6967 6874  niform', 'weight
-00014340: 6564 275d 290a 2020 2020 2020 2020 2020  ed']).          
-00014350: 2020 2020 2020 7061 7261 6d73 5b27 6e6f        params['no
-00014360: 726d 616c 697a 655f 7479 7065 275d 203d  rmalize_type'] =
-00014370: 2074 7269 616c 2e73 7567 6765 7374 5f63   trial.suggest_c
-00014380: 6174 6567 6f72 6963 616c 2827 6e6f 726d  ategorical('norm
-00014390: 616c 697a 655f 7479 7065 272c 205b 2774  alize_type', ['t
-000143a0: 7265 6527 2c20 2766 6f72 6573 7427 5d29  ree', 'forest'])
-000143b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000143c0: 2070 6172 616d 735b 2772 6174 655f 6472   params['rate_dr
-000143d0: 6f70 275d 203d 2074 7269 616c 2e73 7567  op'] = trial.sug
-000143e0: 6765 7374 5f6c 6f67 756e 6966 6f72 6d28  gest_loguniform(
-000143f0: 2772 6174 655f 6472 6f70 272c 2031 652d  'rate_drop', 1e-
-00014400: 382c 2031 290a 2020 2020 2020 2020 2020  8, 1).          
-00014410: 2020 2020 2020 7061 7261 6d73 5b27 736b        params['sk
-00014420: 6970 5f64 726f 7027 5d20 3d20 7472 6961  ip_drop'] = tria
-00014430: 6c2e 7375 6767 6573 745f 6c6f 6775 6e69  l.suggest_loguni
-00014440: 666f 726d 2827 736b 6970 5f64 726f 7027  form('skip_drop'
-00014450: 2c20 3165 2d38 2c20 3129 0a20 2020 2020  , 1e-8, 1).     
-00014460: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-00014470: 6c66 2e6f 7074 5f63 7620 3e3d 2031 3a0a  lf.opt_cv >= 1:.
-00014480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014490: 2020 2020 636c 6620 3d20 5847 4243 6c61      clf = XGBCla
-000144a0: 7373 6966 6965 7228 626f 6f73 7465 723d  ssifier(booster=
-000144b0: 7061 7261 6d73 5b27 626f 6f73 7465 7227  params['booster'
-000144c0: 5d2c 206e 5f65 7374 696d 6174 6f72 733d  ], n_estimators=
-000144d0: 7061 7261 6d73 5b27 6e5f 6573 7469 6d61  params['n_estima
-000144e0: 746f 7273 275d 2c20 7265 675f 6c61 6d62  tors'], reg_lamb
-000144f0: 6461 3d70 6172 616d 735b 2772 6567 5f6c  da=params['reg_l
-00014500: 616d 6264 6127 5d2c 200a 2020 2020 2020  ambda'], .      
-00014510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014520: 2020 7265 675f 616c 7068 613d 7061 7261    reg_alpha=para
-00014530: 6d73 5b27 7265 675f 616c 7068 6127 5d2c  ms['reg_alpha'],
-00014540: 206d 6178 5f64 6570 7468 3d70 6172 616d   max_depth=param
-00014550: 735b 276d 6178 5f64 6570 7468 275d 2c20  s['max_depth'], 
-00014560: 6574 613d 7061 7261 6d73 5b27 6574 6127  eta=params['eta'
-00014570: 5d2c 2067 616d 6d61 3d70 6172 616d 735b  ], gamma=params[
-00014580: 2767 616d 6d61 275d 2c20 0a20 2020 2020  'gamma'], .     
-00014590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000145a0: 2020 2067 726f 775f 706f 6c69 6379 3d70     grow_policy=p
-000145b0: 6172 616d 735b 2767 726f 775f 706f 6c69  arams['grow_poli
-000145c0: 6379 275d 2c20 7361 6d70 6c65 5f74 7970  cy'], sample_typ
-000145d0: 653d 7061 7261 6d73 5b27 7361 6d70 6c65  e=params['sample
-000145e0: 5f74 7970 6527 5d2c 206e 6f72 6d61 6c69  _type'], normali
-000145f0: 7a65 5f74 7970 653d 7061 7261 6d73 5b27  ze_type=params['
-00014600: 6e6f 726d 616c 697a 655f 7479 7065 275d  normalize_type']
-00014610: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00014620: 2020 2020 2020 2020 2020 7261 7465 5f64            rate_d
-00014630: 726f 703d 7061 7261 6d73 5b27 7261 7465  rop=params['rate
-00014640: 5f64 726f 7027 5d2c 2073 6b69 705f 6472  _drop'], skip_dr
-00014650: 6f70 3d70 6172 616d 735b 2773 6b69 705f  op=params['skip_
-00014660: 6472 6f70 275d 2c20 7261 6e64 6f6d 5f73  drop'], random_s
-00014670: 7461 7465 3d31 3930 3929 232c 2074 7265  tate=1909)#, tre
-00014680: 655f 6d65 7468 6f64 3d27 6869 7374 2729  e_method='hist')
-00014690: 0a20 2020 2020 2020 2020 2020 200a 2020  .            .  
-000146a0: 2020 2020 2020 2020 2020 656c 6966 2070            elif p
-000146b0: 6172 616d 735b 2762 6f6f 7374 6572 275d  arams['booster']
-000146c0: 203d 3d20 2767 6274 7265 6527 3a0a 2020   == 'gbtree':.  
-000146d0: 2020 2020 2020 2020 2020 2020 2020 7061                pa
-000146e0: 7261 6d73 5b27 7375 6273 616d 706c 6527  rams['subsample'
-000146f0: 5d20 3d20 7472 6961 6c2e 7375 6767 6573  ] = trial.sugges
-00014700: 745f 6c6f 6775 6e69 666f 726d 2827 7375  t_loguniform('su
-00014710: 6273 616d 706c 6527 2c20 3165 2d36 2c20  bsample', 1e-6, 
-00014720: 312e 3029 0a20 2020 2020 2020 2020 2020  1.0).           
-00014730: 2020 2020 2069 6620 7365 6c66 2e6f 7074       if self.opt
-00014740: 5f63 7620 3e3d 2031 3a0a 2020 2020 2020  _cv >= 1:.      
-00014750: 2020 2020 2020 2020 2020 2020 2020 636c                cl
-00014760: 6620 3d20 5847 4243 6c61 7373 6966 6965  f = XGBClassifie
-00014770: 7228 626f 6f73 7465 723d 7061 7261 6d73  r(booster=params
-00014780: 5b27 626f 6f73 7465 7227 5d2c 206e 5f65  ['booster'], n_e
-00014790: 7374 696d 6174 6f72 733d 7061 7261 6d73  stimators=params
-000147a0: 5b27 6e5f 6573 7469 6d61 746f 7273 275d  ['n_estimators']
-000147b0: 2c20 7265 675f 6c61 6d62 6461 3d70 6172  , reg_lambda=par
-000147c0: 616d 735b 2772 6567 5f6c 616d 6264 6127  ams['reg_lambda'
-000147d0: 5d2c 200a 2020 2020 2020 2020 2020 2020  ], .            
-000147e0: 2020 2020 2020 2020 2020 2020 7265 675f              reg_
-000147f0: 616c 7068 613d 7061 7261 6d73 5b27 7265  alpha=params['re
-00014800: 675f 616c 7068 6127 5d2c 206d 6178 5f64  g_alpha'], max_d
-00014810: 6570 7468 3d70 6172 616d 735b 276d 6178  epth=params['max
-00014820: 5f64 6570 7468 275d 2c20 6574 613d 7061  _depth'], eta=pa
-00014830: 7261 6d73 5b27 6574 6127 5d2c 2067 616d  rams['eta'], gam
-00014840: 6d61 3d70 6172 616d 735b 2767 616d 6d61  ma=params['gamma
-00014850: 275d 2c20 0a20 2020 2020 2020 2020 2020  '], .           
-00014860: 2020 2020 2020 2020 2020 2020 2067 726f               gro
-00014870: 775f 706f 6c69 6379 3d70 6172 616d 735b  w_policy=params[
-00014880: 2767 726f 775f 706f 6c69 6379 275d 2c20  'grow_policy'], 
-00014890: 7375 6273 616d 706c 653d 7061 7261 6d73  subsample=params
-000148a0: 5b27 7375 6273 616d 706c 6527 5d2c 2072  ['subsample'], r
-000148b0: 616e 646f 6d5f 7374 6174 653d 3139 3039  andom_state=1909
-000148c0: 2923 2c20 7472 6565 5f6d 6574 686f 643d  )#, tree_method=
-000148d0: 2768 6973 7427 290a 0a20 2020 2020 2020  'hist')..       
-000148e0: 2020 2020 2069 6620 7365 6c66 2e6f 7074       if self.opt
-000148f0: 5f63 7620 3c20 313a 0a20 2020 2020 2020  _cv < 1:.       
-00014900: 2020 2020 2020 2020 2062 7374 203d 2074           bst = t
-00014910: 7261 696e 2870 6172 616d 732c 2064 7472  rain(params, dtr
-00014920: 6169 6e2c 2065 7661 6c73 3d5b 2864 7661  ain, evals=[(dva
-00014930: 6c69 642c 2022 7661 6c69 6461 7469 6f6e  lid, "validation
-00014940: 2229 5d2c 2063 616c 6c62 6163 6b73 3d5b  ")], callbacks=[
-00014950: 7072 756e 696e 675f 6361 6c6c 6261 636b  pruning_callback
-00014960: 5d29 0a20 2020 2020 2020 2020 2020 2020  ]).             
-00014970: 2020 2070 7265 6473 203d 2062 7374 2e70     preds = bst.p
-00014980: 7265 6469 6374 2864 7661 6c69 6429 0a20  redict(dvalid). 
-00014990: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-000149a0: 7265 645f 6c61 6265 6c73 203d 206e 702e  red_labels = np.
-000149b0: 7269 6e74 2870 7265 6473 290a 2020 2020  rint(preds).    
-000149c0: 2020 2020 2020 2020 2020 2020 6163 6375              accu
-000149d0: 7261 6379 203d 2061 6363 7572 6163 795f  racy = accuracy_
-000149e0: 7363 6f72 6528 7661 6c69 645f 792c 2070  score(valid_y, p
-000149f0: 7265 645f 6c61 6265 6c73 290a 2020 2020  red_labels).    
-00014a00: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00014a10: 2020 2020 2020 2020 2020 2020 2020 2346                #F
-00014a20: 524f 4d20 534b 4c45 4152 4e20 444f 4355  ROM SKLEARN DOCU
-00014a30: 4d45 4e54 4154 494f 4e3a 2046 6f72 2069  MENTATION: For i
-00014a40: 6e74 2f4e 6f6e 6520 696e 7075 7473 2c20  nt/None inputs, 
-00014a50: 6966 2074 6865 2065 7374 696d 6174 6f72  if the estimator
-00014a60: 2069 7320 6120 636c 6173 7369 6669 6572   is a classifier
-00014a70: 2061 6e64 2079 2069 7320 6569 7468 6572   and y is either
-00014a80: 2062 696e 6172 7920 6f72 206d 756c 7469   binary or multi
-00014a90: 636c 6173 732c 2053 7472 6174 6966 6965  class, Stratifie
-00014aa0: 644b 466f 6c64 2069 7320 7573 6564 2e20  dKFold is used. 
-00014ab0: 496e 2061 6c6c 206f 7468 6572 2063 6173  In all other cas
-00014ac0: 6573 2c20 466f 6c64 2069 7320 7573 6564  es, Fold is used
-00014ad0: 2e0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00014ae0: 2020 6376 203d 2063 726f 7373 5f76 616c    cv = cross_val
-00014af0: 6964 6174 6528 636c 662c 2073 656c 662e  idate(clf, self.
-00014b00: 6461 7461 5f78 2c20 7365 6c66 2e64 6174  data_x, self.dat
-00014b10: 615f 792c 2063 763d 7365 6c66 2e6f 7074  a_y, cv=self.opt
-00014b20: 5f63 7629 200a 2020 2020 2020 2020 2020  _cv) .          
-00014b30: 2020 2020 2020 6163 6375 7261 6379 203d        accuracy =
-00014b40: 206e 702e 6d65 616e 2863 765b 2774 6573   np.mean(cv['tes
-00014b50: 745f 7363 6f72 6527 5d29 0a0a 2020 2020  t_score'])..    
-00014b60: 2020 2020 2020 2020 7265 7475 726e 2061          return a
-00014b70: 6363 7572 6163 790a 0a20 2020 2020 2020  ccuracy..       
-00014b80: 2070 6172 616d 735b 2762 6f6f 7374 6572   params['booster
-00014b90: 275d 203d 2074 7269 616c 2e73 7567 6765  '] = trial.sugge
-00014ba0: 7374 5f63 6174 6567 6f72 6963 616c 2827  st_categorical('
-00014bb0: 626f 6f73 7465 7227 2c20 5b27 6762 7472  booster', ['gbtr
-00014bc0: 6565 272c 2027 6461 7274 275d 290a 2020  ee', 'dart']).  
-00014bd0: 2020 2020 2020 7061 7261 6d73 5b27 6e5f        params['n_
-00014be0: 6573 7469 6d61 746f 7273 275d 203d 2074  estimators'] = t
-00014bf0: 7269 616c 2e73 7567 6765 7374 5f69 6e74  rial.suggest_int
-00014c00: 2827 6e5f 6573 7469 6d61 746f 7273 272c  ('n_estimators',
-00014c10: 2031 3030 2c20 3530 3029 0a20 2020 2020   100, 500).     
-00014c20: 2020 2070 6172 616d 735b 2772 6567 5f6c     params['reg_l
-00014c30: 616d 6264 6127 5d20 3d20 7472 6961 6c2e  ambda'] = trial.
-00014c40: 7375 6767 6573 745f 666c 6f61 7428 2772  suggest_float('r
-00014c50: 6567 5f6c 616d 6264 6127 2c20 302c 2031  eg_lambda', 0, 1
-00014c60: 3030 290a 2020 2020 2020 2020 7061 7261  00).        para
-00014c70: 6d73 5b27 7265 675f 616c 7068 6127 5d20  ms['reg_alpha'] 
-00014c80: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
-00014c90: 696e 7428 2772 6567 5f61 6c70 6861 272c  int('reg_alpha',
-00014ca0: 2030 2c20 3130 3029 0a20 2020 2020 2020   0, 100).       
-00014cb0: 2070 6172 616d 735b 276d 6178 5f64 6570   params['max_dep
-00014cc0: 7468 275d 203d 2074 7269 616c 2e73 7567  th'] = trial.sug
-00014cd0: 6765 7374 5f69 6e74 2827 6d61 785f 6465  gest_int('max_de
-00014ce0: 7074 6827 2c20 322c 2032 3529 0a20 2020  pth', 2, 25).   
-00014cf0: 2020 2020 2070 6172 616d 735b 2765 7461       params['eta
-00014d00: 275d 203d 2074 7269 616c 2e73 7567 6765  '] = trial.sugge
-00014d10: 7374 5f66 6c6f 6174 2827 6574 6127 2c20  st_float('eta', 
-00014d20: 3165 2d38 2c20 3129 0a20 2020 2020 2020  1e-8, 1).       
-00014d30: 2070 6172 616d 735b 2767 616d 6d61 275d   params['gamma']
-00014d40: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-00014d50: 5f69 6e74 2827 6761 6d6d 6127 2c20 312c  _int('gamma', 1,
-00014d60: 2031 3030 290a 2020 2020 2020 2020 7061   100).        pa
-00014d70: 7261 6d73 5b27 6772 6f77 5f70 6f6c 6963  rams['grow_polic
-00014d80: 7927 5d20 3d20 7472 6961 6c2e 7375 6767  y'] = trial.sugg
-00014d90: 6573 745f 6361 7465 676f 7269 6361 6c28  est_categorical(
-00014da0: 2767 726f 775f 706f 6c69 6379 272c 205b  'grow_policy', [
-00014db0: 2764 6570 7468 7769 7365 272c 2027 6c6f  'depthwise', 'lo
-00014dc0: 7373 6775 6964 6527 5d29 0a20 2020 2020  ssguide']).     
-00014dd0: 2020 2070 6172 616d 735b 276d 696e 5f63     params['min_c
-00014de0: 6869 6c64 5f77 6569 6768 7427 5d20 3d20  hild_weight'] = 
-00014df0: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
-00014e00: 7428 276d 696e 5f63 6869 6c64 5f77 6569  t('min_child_wei
-00014e10: 6768 7427 2c20 312c 2031 3030 290a 2020  ght', 1, 100).  
-00014e20: 2020 2020 2020 7061 7261 6d73 5b27 6d61        params['ma
-00014e30: 785f 6465 6c74 615f 7374 6570 275d 203d  x_delta_step'] =
-00014e40: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
-00014e50: 6e74 2827 6d61 785f 6465 6c74 615f 7374  nt('max_delta_st
-00014e60: 6570 272c 2031 2c20 3130 3029 0a20 2020  ep', 1, 100).   
-00014e70: 2020 2020 2070 6172 616d 735b 2773 7562       params['sub
-00014e80: 7361 6d70 6c65 275d 203d 2074 7269 616c  sample'] = trial
-00014e90: 2e73 7567 6765 7374 5f66 6c6f 6174 2827  .suggest_float('
-00014ea0: 7375 6273 616d 706c 6527 2c20 302e 352c  subsample', 0.5,
-00014eb0: 2031 2e30 290a 2020 2020 2020 2020 7061   1.0).        pa
-00014ec0: 7261 6d73 5b27 636f 6c73 616d 706c 655f  rams['colsample_
-00014ed0: 6279 7472 6565 275d 203d 2074 7269 616c  bytree'] = trial
-00014ee0: 2e73 7567 6765 7374 5f66 6c6f 6174 2827  .suggest_float('
-00014ef0: 636f 6c73 616d 706c 655f 6279 7472 6565  colsample_bytree
-00014f00: 272c 2030 2e35 2c20 3129 0a0a 2020 2020  ', 0.5, 1)..    
-00014f10: 2020 2020 6966 2070 6172 616d 735b 2762      if params['b
-00014f20: 6f6f 7374 6572 275d 203d 3d20 2264 6172  ooster'] == "dar
-00014f30: 7422 3a0a 2020 2020 2020 2020 2020 2020  t":.            
-00014f40: 7061 7261 6d73 5b27 7361 6d70 6c65 5f74  params['sample_t
-00014f50: 7970 6527 5d20 3d20 7472 6961 6c2e 7375  ype'] = trial.su
-00014f60: 6767 6573 745f 6361 7465 676f 7269 6361  ggest_categorica
-00014f70: 6c28 2773 616d 706c 655f 7479 7065 272c  l('sample_type',
-00014f80: 205b 2775 6e69 666f 726d 272c 2027 7765   ['uniform', 'we
-00014f90: 6967 6874 6564 275d 290a 2020 2020 2020  ighted']).      
-00014fa0: 2020 2020 2020 7061 7261 6d73 5b27 6e6f        params['no
-00014fb0: 726d 616c 697a 655f 7479 7065 275d 203d  rmalize_type'] =
-00014fc0: 2074 7269 616c 2e73 7567 6765 7374 5f63   trial.suggest_c
-00014fd0: 6174 6567 6f72 6963 616c 2827 6e6f 726d  ategorical('norm
-00014fe0: 616c 697a 655f 7479 7065 272c 205b 2774  alize_type', ['t
-00014ff0: 7265 6527 2c20 2766 6f72 6573 7427 5d29  ree', 'forest'])
-00015000: 0a20 2020 2020 2020 2020 2020 2070 6172  .            par
-00015010: 616d 735b 2772 6174 655f 6472 6f70 275d  ams['rate_drop']
-00015020: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
-00015030: 5f66 6c6f 6174 2827 7261 7465 5f64 726f  _float('rate_dro
-00015040: 7027 2c20 3165 2d38 2c20 3129 0a20 2020  p', 1e-8, 1).   
-00015050: 2020 2020 2020 2020 2070 6172 616d 735b           params[
-00015060: 2773 6b69 705f 6472 6f70 275d 203d 2074  'skip_drop'] = t
-00015070: 7269 616c 2e73 7567 6765 7374 5f66 6c6f  rial.suggest_flo
-00015080: 6174 2827 736b 6970 5f64 726f 7027 2c20  at('skip_drop', 
-00015090: 3165 2d38 2c20 3129 0a20 2020 2020 2020  1e-8, 1).       
-000150a0: 2020 2020 2069 6620 7365 6c66 2e6f 7074       if self.opt
-000150b0: 5f63 7620 3e3d 2031 3a0a 2020 2020 2020  _cv >= 1:.      
-000150c0: 2020 2020 2020 2020 2020 636c 6620 3d20            clf = 
-000150d0: 5847 4243 6c61 7373 6966 6965 7228 626f  XGBClassifier(bo
-000150e0: 6f73 7465 723d 7061 7261 6d73 5b27 626f  oster=params['bo
-000150f0: 6f73 7465 7227 5d2c 206e 5f65 7374 696d  oster'], n_estim
-00015100: 6174 6f72 733d 7061 7261 6d73 5b27 6e5f  ators=params['n_
-00015110: 6573 7469 6d61 746f 7273 275d 2c20 636f  estimators'], co
-00015120: 6c73 616d 706c 655f 6279 7472 6565 3d70  lsample_bytree=p
-00015130: 6172 616d 735b 2763 6f6c 7361 6d70 6c65  arams['colsample
-00015140: 5f62 7974 7265 6527 5d2c 200a 2020 2020  _bytree'], .    
-00015150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015160: 7265 675f 6c61 6d62 6461 3d70 6172 616d  reg_lambda=param
-00015170: 735b 2772 6567 5f6c 616d 6264 6127 5d2c  s['reg_lambda'],
-00015180: 2072 6567 5f61 6c70 6861 3d70 6172 616d   reg_alpha=param
-00015190: 735b 2772 6567 5f61 6c70 6861 275d 2c20  s['reg_alpha'], 
-000151a0: 6d61 785f 6465 7074 683d 7061 7261 6d73  max_depth=params
-000151b0: 5b27 6d61 785f 6465 7074 6827 5d2c 2065  ['max_depth'], e
-000151c0: 7461 3d70 6172 616d 735b 2765 7461 275d  ta=params['eta']
-000151d0: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
-000151e0: 2020 2020 2020 2067 616d 6d61 3d70 6172         gamma=par
-000151f0: 616d 735b 2767 616d 6d61 275d 2c20 6772  ams['gamma'], gr
-00015200: 6f77 5f70 6f6c 6963 793d 7061 7261 6d73  ow_policy=params
-00015210: 5b27 6772 6f77 5f70 6f6c 6963 7927 5d2c  ['grow_policy'],
-00015220: 206d 696e 5f63 6869 6c64 5f77 6569 6768   min_child_weigh
-00015230: 743d 7061 7261 6d73 5b27 6d69 6e5f 6368  t=params['min_ch
-00015240: 696c 645f 7765 6967 6874 275d 2c20 0a20  ild_weight'], . 
-00015250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015260: 2020 206d 6178 5f64 656c 7461 5f73 7465     max_delta_ste
-00015270: 703d 7061 7261 6d73 5b27 6d61 785f 6465  p=params['max_de
-00015280: 6c74 615f 7374 6570 275d 2c20 7375 6273  lta_step'], subs
-00015290: 616d 706c 653d 7061 7261 6d73 5b27 7375  ample=params['su
-000152a0: 6273 616d 706c 6527 5d2c 2073 616d 706c  bsample'], sampl
-000152b0: 655f 7479 7065 3d70 6172 616d 735b 2773  e_type=params['s
-000152c0: 616d 706c 655f 7479 7065 275d 2c20 0a20  ample_type'], . 
-000152d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000152e0: 2020 206e 6f72 6d61 6c69 7a65 5f74 7970     normalize_typ
-000152f0: 653d 7061 7261 6d73 5b27 6e6f 726d 616c  e=params['normal
-00015300: 697a 655f 7479 7065 275d 2c20 7261 7465  ize_type'], rate
-00015310: 5f64 726f 703d 7061 7261 6d73 5b27 7261  _drop=params['ra
-00015320: 7465 5f64 726f 7027 5d2c 2073 6b69 705f  te_drop'], skip_
-00015330: 6472 6f70 3d70 6172 616d 735b 2773 6b69  drop=params['ski
-00015340: 705f 6472 6f70 275d 2c20 7261 6e64 6f6d  p_drop'], random
-00015350: 5f73 7461 7465 3d31 3930 3929 232c 2074  _state=1909)#, t
-00015360: 7265 655f 6d65 7468 6f64 3d27 6869 7374  ree_method='hist
-00015370: 2729 0a20 2020 2020 2020 2065 6c69 6620  ').        elif 
-00015380: 7061 7261 6d73 5b27 626f 6f73 7465 7227  params['booster'
-00015390: 5d20 3d3d 2027 6762 7472 6565 273a 0a20  ] == 'gbtree':. 
-000153a0: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-000153b0: 6c66 2e6f 7074 5f63 7620 3e3d 2031 3a0a  lf.opt_cv >= 1:.
-000153c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000153d0: 636c 6620 3d20 5847 4243 6c61 7373 6966  clf = XGBClassif
-000153e0: 6965 7228 626f 6f73 7465 723d 7061 7261  ier(booster=para
-000153f0: 6d73 5b27 626f 6f73 7465 7227 5d2c 206e  ms['booster'], n
-00015400: 5f65 7374 696d 6174 6f72 733d 7061 7261  _estimators=para
-00015410: 6d73 5b27 6e5f 6573 7469 6d61 746f 7273  ms['n_estimators
-00015420: 275d 2c20 636f 6c73 616d 706c 655f 6279  '], colsample_by
-00015430: 7472 6565 3d70 6172 616d 735b 2763 6f6c  tree=params['col
-00015440: 7361 6d70 6c65 5f62 7974 7265 6527 5d2c  sample_bytree'],
-00015450: 2020 7265 675f 6c61 6d62 6461 3d70 6172    reg_lambda=par
-00015460: 616d 735b 2772 6567 5f6c 616d 6264 6127  ams['reg_lambda'
-00015470: 5d2c 200a 2020 2020 2020 2020 2020 2020  ], .            
-00015480: 2020 2020 2020 2020 7265 675f 616c 7068          reg_alph
-00015490: 613d 7061 7261 6d73 5b27 7265 675f 616c  a=params['reg_al
-000154a0: 7068 6127 5d2c 206d 6178 5f64 6570 7468  pha'], max_depth
-000154b0: 3d70 6172 616d 735b 276d 6178 5f64 6570  =params['max_dep
-000154c0: 7468 275d 2c20 6574 613d 7061 7261 6d73  th'], eta=params
-000154d0: 5b27 6574 6127 5d2c 2067 616d 6d61 3d70  ['eta'], gamma=p
-000154e0: 6172 616d 735b 2767 616d 6d61 275d 2c20  arams['gamma'], 
-000154f0: 6772 6f77 5f70 6f6c 6963 793d 7061 7261  grow_policy=para
-00015500: 6d73 5b27 6772 6f77 5f70 6f6c 6963 7927  ms['grow_policy'
-00015510: 5d2c 200a 2020 2020 2020 2020 2020 2020  ], .            
-00015520: 2020 2020 2020 2020 6d69 6e5f 6368 696c          min_chil
-00015530: 645f 7765 6967 6874 3d70 6172 616d 735b  d_weight=params[
-00015540: 276d 696e 5f63 6869 6c64 5f77 6569 6768  'min_child_weigh
-00015550: 7427 5d2c 206d 6178 5f64 656c 7461 5f73  t'], max_delta_s
-00015560: 7465 703d 7061 7261 6d73 5b27 6d61 785f  tep=params['max_
-00015570: 6465 6c74 615f 7374 6570 275d 2c20 7375  delta_step'], su
-00015580: 6273 616d 706c 653d 7061 7261 6d73 5b27  bsample=params['
-00015590: 7375 6273 616d 706c 6527 5d2c 2072 616e  subsample'], ran
-000155a0: 646f 6d5f 7374 6174 653d 3139 3039 2923  dom_state=1909)#
-000155b0: 2c20 7472 6565 5f6d 6574 686f 643d 2768  , tree_method='h
-000155c0: 6973 7427 290a 2020 2020 2020 2020 2020  ist').          
-000155d0: 2020 0a20 2020 2020 2020 2069 6620 7365    .        if se
-000155e0: 6c66 2e6f 7074 5f63 7620 3c20 313a 0a20  lf.opt_cv < 1:. 
-000155f0: 2020 2020 2020 2020 2020 2062 7374 203d             bst =
-00015600: 2074 7261 696e 2870 6172 616d 732c 2064   train(params, d
-00015610: 7472 6169 6e2c 2065 7661 6c73 3d5b 2864  train, evals=[(d
-00015620: 7661 6c69 642c 2022 7661 6c69 6461 7469  valid, "validati
-00015630: 6f6e 2229 5d2c 2063 616c 6c62 6163 6b73  on")], callbacks
-00015640: 3d5b 7072 756e 696e 675f 6361 6c6c 6261  =[pruning_callba
-00015650: 636b 5d29 0a20 2020 2020 2020 2020 2020  ck]).           
-00015660: 2070 7265 6473 203d 2062 7374 2e70 7265   preds = bst.pre
-00015670: 6469 6374 2864 7661 6c69 6429 0a20 2020  dict(dvalid).   
-00015680: 2020 2020 2020 2020 2070 7265 645f 6c61           pred_la
-00015690: 6265 6c73 203d 206e 702e 7269 6e74 2870  bels = np.rint(p
-000156a0: 7265 6473 290a 2020 2020 2020 2020 2020  reds).          
-000156b0: 2020 6163 6375 7261 6379 203d 2061 6363    accuracy = acc
-000156c0: 7572 6163 795f 7363 6f72 6528 7661 6c69  uracy_score(vali
-000156d0: 645f 792c 2070 7265 645f 6c61 6265 6c73  d_y, pred_labels
-000156e0: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-000156f0: 2020 2020 2020 2020 2020 2020 6376 203d              cv =
-00015700: 2063 726f 7373 5f76 616c 6964 6174 6528   cross_validate(
-00015710: 636c 662c 2073 656c 662e 6461 7461 5f78  clf, self.data_x
-00015720: 2c20 7365 6c66 2e64 6174 615f 792c 2063  , self.data_y, c
-00015730: 763d 7365 6c66 2e6f 7074 5f63 7629 0a20  v=self.opt_cv). 
-00015740: 2020 2020 2020 2020 2020 2061 6363 7572             accur
-00015750: 6163 7920 3d20 6e70 2e6d 6561 6e28 6376  acy = np.mean(cv
-00015760: 5b27 7465 7374 5f73 636f 7265 275d 290a  ['test_score']).
-00015770: 2020 2020 2020 2020 0a20 2020 2020 2020          .       
-00015780: 2072 6574 7572 6e20 6163 6375 7261 6379   return accuracy
-00015790: 0a0a 636c 6173 7320 6f62 6a65 6374 6976  ..class objectiv
-000157a0: 655f 6e6e 286f 626a 6563 7429 3a0a 2020  e_nn(object):.  
-000157b0: 2020 2222 220a 2020 2020 4f70 7469 6d69    """.    Optimi
-000157c0: 7a61 7469 6f6e 206f 626a 6563 7469 7665  zation objective
-000157d0: 2066 756e 6374 696f 6e20 666f 7220 7468   function for th
-000157e0: 6520 7363 696b 6974 2d6c 6561 726e 2069  e scikit-learn i
-000157f0: 6d70 6c65 6d65 6e74 6174 696e 206f 6620  mplementatin of 
-00015800: 7468 650a 2020 2020 4d4c 5020 636c 6173  the.    MLP clas
-00015810: 7369 6669 6572 2e20 5468 6520 4f70 7475  sifier. The Optu
-00015820: 6e61 2073 6f66 7477 6172 6520 666f 7220  na software for 
-00015830: 6879 7065 7270 6172 616d 6574 6572 206f  hyperparameter o
-00015840: 7074 696d 697a 6174 696f 6e0a 2020 2020  ptimization.    
-00015850: 7761 7320 7075 626c 6973 6865 6420 696e  was published in
-00015860: 2032 3031 3920 6279 2041 6b69 6261 2065   2019 by Akiba e
-00015870: 7420 616c 2e20 5061 7065 723a 2068 7474  t al. Paper: htt
-00015880: 7073 3a2f 2f61 7278 6976 2e6f 7267 2f61  ps://arxiv.org/a
-00015890: 6273 2f31 3930 372e 3130 3930 322e 0a0a  bs/1907.10902...
-000158a0: 2020 2020 5468 6520 746f 7461 6c20 6e75      The total nu
-000158b0: 6d62 6572 206f 6620 6869 6464 656e 206c  mber of hidden l
-000158c0: 6179 6572 7320 746f 2074 6573 7420 6973  ayers to test is
-000158d0: 206c 696d 6974 6564 2074 6f20 3130 2c20   limited to 10, 
-000158e0: 7769 7468 2031 3030 2d35 3030 3020 706f  with 100-5000 po
-000158f0: 7373 6962 6c65 200a 2020 2020 6e75 6d62  ssible .    numb
-00015900: 6572 206f 6620 6e65 7572 6f6e 7320 696e  er of neurons in
-00015910: 2065 6163 682e 0a0a 2020 2020 4172 6773   each...    Args
-00015920: 3a0a 2020 2020 2020 2020 6461 7461 5f78  :.        data_x
-00015930: 2028 6e64 6172 7261 7929 3a20 3244 2061   (ndarray): 2D a
-00015940: 7272 6179 206f 6620 7369 7a65 2028 6e20  rray of size (n 
-00015950: 7820 6d29 2c20 7768 6572 6520 6e20 6973  x m), where n is
-00015960: 2074 6865 0a20 2020 2020 2020 2020 2020   the.           
-00015970: 206e 756d 6265 7220 6f66 2073 616d 706c   number of sampl
-00015980: 6573 2c20 616e 6420 6d20 7468 6520 6e75  es, and m the nu
-00015990: 6d62 6572 206f 6620 6665 6174 7572 6573  mber of features
-000159a0: 2e0a 2020 2020 2020 2020 6461 7461 5f79  ..        data_y
-000159b0: 2028 6e64 6172 7261 792c 2073 7472 293a   (ndarray, str):
-000159c0: 2031 4420 6172 7261 7920 636f 6e74 6169   1D array contai
-000159d0: 6e69 6e67 2074 6865 2063 6f72 7265 7370  ning the corresp
-000159e0: 6f6e 696e 6720 6c61 6265 6c73 2e20 0a20  oning labels. . 
-000159f0: 2020 2020 2020 206f 7074 5f63 7620 2869         opt_cv (i
-00015a00: 6e74 293a 2043 726f 7373 2d76 616c 6964  nt): Cross-valid
-00015a10: 6174 696f 6e73 2074 6f20 7065 7266 6f72  ations to perfor
-00015a20: 6d20 7768 656e 2061 7373 6573 696e 6720  m when assesing 
-00015a30: 7468 6520 7065 7266 6f72 6d61 6e63 6520  the performance 
-00015a40: 6174 2065 6163 680a 2020 2020 2020 2020  at each.        
-00015a50: 2020 2020 6879 7065 7270 6172 616d 6574      hyperparamet
-00015a60: 6572 206f 7074 696d 697a 6174 696f 6e20  er optimization 
-00015a70: 7472 6961 6c2e 2046 6f72 2065 7861 6d70  trial. For examp
-00015a80: 6c65 2c20 6966 2063 763d 332c 2074 6865  le, if cv=3, the
-00015a90: 6e20 6561 6368 206f 7074 696d 697a 6174  n each optimizat
-00015aa0: 696f 6e20 7472 6961 6c0a 2020 2020 2020  ion trial.      
-00015ab0: 2020 2020 2020 7769 6c6c 2062 6520 6173        will be as
-00015ac0: 7365 7373 6564 2061 6363 6f72 6469 6e67  sessed according
-00015ad0: 2074 6f20 7468 6520 332d 666f 6c64 2063   to the 3-fold c
-00015ae0: 726f 7373 2076 616c 6964 6174 696f 6e20  ross validation 
-00015af0: 6163 6375 7261 6379 2e20 0a0a 2020 2020  accuracy. ..    
-00015b00: 5265 7475 726e 733a 0a20 2020 2020 2020  Returns:.       
-00015b10: 2054 6865 2070 6572 666f 726d 616e 6365   The performance
-00015b20: 206d 6574 7269 632c 2064 6574 6572 6d69   metric, determi
-00015b30: 6e65 6420 7573 696e 6720 7468 6520 6372  ned using the cr
-00015b40: 6f73 732d 666f 6c64 2076 616c 6964 6174  oss-fold validat
-00015b50: 696f 6e20 6d65 7468 6f64 2e0a 2020 2020  ion method..    
-00015b60: 2222 220a 0a20 2020 2064 6566 205f 5f69  """..    def __i
-00015b70: 6e69 745f 5f28 7365 6c66 2c20 6461 7461  nit__(self, data
-00015b80: 5f78 2c20 6461 7461 5f79 2c20 6f70 745f  _x, data_y, opt_
-00015b90: 6376 293a 0a20 2020 2020 2020 2073 656c  cv):.        sel
-00015ba0: 662e 6461 7461 5f78 203d 2064 6174 615f  f.data_x = data_
-00015bb0: 780a 2020 2020 2020 2020 7365 6c66 2e64  x.        self.d
-00015bc0: 6174 615f 7920 3d20 6461 7461 5f79 0a20  ata_y = data_y. 
-00015bd0: 2020 2020 2020 2073 656c 662e 6f70 745f         self.opt_
-00015be0: 6376 203d 206f 7074 5f63 760a 0a20 2020  cv = opt_cv..   
-00015bf0: 2064 6566 205f 5f63 616c 6c5f 5f28 7365   def __call__(se
-00015c00: 6c66 2c20 7472 6961 6c29 3a0a 2020 2020  lf, trial):.    
-00015c10: 2020 2020 6c65 6172 6e69 6e67 5f72 6174      learning_rat
-00015c20: 655f 696e 6974 203d 2074 7269 616c 2e73  e_init = trial.s
-00015c30: 7567 6765 7374 5f66 6c6f 6174 2827 6c65  uggest_float('le
-00015c40: 6172 6e69 6e67 5f72 6174 655f 696e 6974  arning_rate_init
-00015c50: 272c 2031 652d 352c 2030 2e31 2c20 7374  ', 1e-5, 0.1, st
-00015c60: 6570 3d31 652d 3529 0a20 2020 2020 2020  ep=1e-5).       
-00015c70: 2073 6f6c 7665 7220 3d20 7472 6961 6c2e   solver = trial.
-00015c80: 7375 6767 6573 745f 6361 7465 676f 7269  suggest_categori
-00015c90: 6361 6c28 2273 6f6c 7665 7222 2c20 5b22  cal("solver", ["
-00015ca0: 7367 6422 2c20 2261 6461 6d22 5d29 2023  sgd", "adam"]) #
-00015cb0: 226c 6266 6773 220a 2020 2020 2020 2020  "lbfgs".        
-00015cc0: 6163 7469 7661 7469 6f6e 203d 2074 7269  activation = tri
-00015cd0: 616c 2e73 7567 6765 7374 5f63 6174 6567  al.suggest_categ
-00015ce0: 6f72 6963 616c 2822 6163 7469 7661 7469  orical("activati
-00015cf0: 6f6e 222c 205b 226c 6f67 6973 7469 6322  on", ["logistic"
-00015d00: 2c20 2274 616e 6822 2c20 2272 656c 7522  , "tanh", "relu"
-00015d10: 5d29 0a20 2020 2020 2020 206c 6561 726e  ]).        learn
-00015d20: 696e 675f 7261 7465 203d 2074 7269 616c  ing_rate = trial
-00015d30: 2e73 7567 6765 7374 5f63 6174 6567 6f72  .suggest_categor
-00015d40: 6963 616c 2822 6c65 6172 6e69 6e67 5f72  ical("learning_r
-00015d50: 6174 6522 2c20 5b22 636f 6e73 7461 6e74  ate", ["constant
-00015d60: 222c 2022 696e 7673 6361 6c69 6e67 222c  ", "invscaling",
-00015d70: 2022 6164 6170 7469 7665 225d 290a 2020   "adaptive"]).  
-00015d80: 2020 2020 2020 616c 7068 6120 3d20 7472        alpha = tr
-00015d90: 6961 6c2e 7375 6767 6573 745f 666c 6f61  ial.suggest_floa
-00015da0: 7428 2261 6c70 6861 222c 2031 652d 372c  t("alpha", 1e-7,
-00015db0: 2031 2c20 7374 6570 3d31 652d 3629 0a20   1, step=1e-6). 
-00015dc0: 2020 2020 2020 2062 6174 6368 5f73 697a         batch_siz
-00015dd0: 6520 3d20 7472 6961 6c2e 7375 6767 6573  e = trial.sugges
-00015de0: 745f 696e 7428 2762 6174 6368 5f73 697a  t_int('batch_siz
-00015df0: 6527 2c20 312c 2031 3030 3029 0a20 2020  e', 1, 1000).   
-00015e00: 2020 2020 206e 5f6c 6179 6572 7320 3d20       n_layers = 
-00015e10: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
-00015e20: 7428 2768 6964 6465 6e5f 6c61 7965 725f  t('hidden_layer_
-00015e30: 7369 7a65 7327 2c20 312c 2031 3029 0a0a  sizes', 1, 10)..
-00015e40: 2020 2020 2020 2020 6c61 7965 7273 203d          layers =
-00015e50: 205b 5d0a 2020 2020 2020 2020 666f 7220   [].        for 
-00015e60: 6920 696e 2072 616e 6765 286e 5f6c 6179  i in range(n_lay
-00015e70: 6572 7329 3a0a 2020 2020 2020 2020 2020  ers):.          
-00015e80: 2020 6c61 7965 7273 2e61 7070 656e 6428    layers.append(
-00015e90: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
-00015ea0: 7428 6627 6e5f 756e 6974 735f 7b69 7d27  t(f'n_units_{i}'
-00015eb0: 2c20 3130 302c 2035 3030 3029 290a 0a20  , 100, 5000)).. 
-00015ec0: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-00015ed0: 2020 2020 2020 2020 636c 6620 3d20 4d4c          clf = ML
-00015ee0: 5043 6c61 7373 6966 6965 7228 6869 6464  PClassifier(hidd
-00015ef0: 656e 5f6c 6179 6572 5f73 697a 6573 3d74  en_layer_sizes=t
-00015f00: 7570 6c65 286c 6179 6572 7329 2c6c 6561  uple(layers),lea
-00015f10: 726e 696e 675f 7261 7465 5f69 6e69 743d  rning_rate_init=
-00015f20: 6c65 6172 6e69 6e67 5f72 6174 655f 696e  learning_rate_in
-00015f30: 6974 2c20 0a20 2020 2020 2020 2020 2020  it, .           
-00015f40: 2020 2020 2073 6f6c 7665 723d 736f 6c76       solver=solv
-00015f50: 6572 2c20 6163 7469 7661 7469 6f6e 3d61  er, activation=a
-00015f60: 6374 6976 6174 696f 6e2c 2061 6c70 6861  ctivation, alpha
-00015f70: 3d61 6c70 6861 2c20 6261 7463 685f 7369  =alpha, batch_si
-00015f80: 7a65 3d62 6174 6368 5f73 697a 652c 206d  ze=batch_size, m
-00015f90: 6178 5f69 7465 723d 3235 3030 2c20 7261  ax_iter=2500, ra
-00015fa0: 6e64 6f6d 5f73 7461 7465 3d31 3930 3929  ndom_state=1909)
-00015fb0: 0a20 2020 2020 2020 2065 7863 6570 743a  .        except:
-00015fc0: 0a20 2020 2020 2020 2020 2020 2070 7269  .            pri
-00015fd0: 6e74 2822 496e 7661 6c69 6420 6879 7065  nt("Invalid hype
-00015fe0: 7270 6172 616d 6574 6572 2063 6f6d 6269  rparameter combi
-00015ff0: 6e61 7469 6f6e 2c20 736b 6970 7069 6e67  nation, skipping
-00016000: 2074 7269 616c 2229 0a20 2020 2020 2020   trial").       
-00016010: 2020 2020 2072 6574 7572 6e20 302e 300a       return 0.0.
-00016020: 0a20 2020 2020 2020 2063 7620 3d20 6372  .        cv = cr
-00016030: 6f73 735f 7661 6c69 6461 7465 2863 6c66  oss_validate(clf
-00016040: 2c20 7365 6c66 2e64 6174 615f 782c 2073  , self.data_x, s
-00016050: 656c 662e 6461 7461 5f79 2c20 6376 3d73  elf.data_y, cv=s
-00016060: 656c 662e 6f70 745f 6376 290a 2020 2020  elf.opt_cv).    
-00016070: 2020 2020 6669 6e61 6c5f 7363 6f72 6520      final_score 
-00016080: 3d20 6e70 2e6d 6561 6e28 6376 5b27 7465  = np.mean(cv['te
-00016090: 7374 5f73 636f 7265 275d 290a 0a20 2020  st_score'])..   
-000160a0: 2020 2020 2072 6574 7572 6e20 6669 6e61       return fina
-000160b0: 6c5f 7363 6f72 650a 0a63 6c61 7373 206f  l_score..class o
-000160c0: 626a 6563 7469 7665 5f72 6628 6f62 6a65  bjective_rf(obje
-000160d0: 6374 293a 0a20 2020 2022 2222 0a20 2020  ct):.    """.   
-000160e0: 204f 7074 696d 697a 6174 696f 6e20 6f62   Optimization ob
-000160f0: 6a65 6374 6976 6520 6675 6e63 7469 6f6e  jective function
-00016100: 2066 6f72 2074 6865 2073 6369 6b69 742d   for the scikit-
-00016110: 6c65 6172 6e20 696d 706c 656d 656e 7461  learn implementa
-00016120: 7469 6e20 6f66 2074 6865 0a20 2020 2052  tin of the.    R
-00016130: 616e 646f 6d20 466f 7265 7374 2063 6c61  andom Forest cla
-00016140: 7373 6966 6965 722e 2054 6865 204f 7074  ssifier. The Opt
-00016150: 756e 6120 736f 6674 7761 7265 2066 6f72  una software for
-00016160: 2068 7970 6572 7061 7261 6d65 7465 7220   hyperparameter 
-00016170: 6f70 7469 6d69 7a61 7469 6f6e 0a20 2020  optimization.   
-00016180: 2077 6173 2070 7562 6c69 7368 6564 2069   was published i
-00016190: 6e20 3230 3139 2062 7920 416b 6962 6120  n 2019 by Akiba 
-000161a0: 6574 2061 6c2e 2050 6170 6572 3a20 6874  et al. Paper: ht
-000161b0: 7470 733a 2f2f 6172 7869 762e 6f72 672f  tps://arxiv.org/
-000161c0: 6162 732f 3139 3037 2e31 3039 3032 0a0a  abs/1907.10902..
-000161d0: 2020 2020 4172 6773 3a0a 2020 2020 2020      Args:.      
-000161e0: 2020 6461 7461 5f78 2028 6e64 6172 7261    data_x (ndarra
-000161f0: 7929 3a20 3244 2061 7272 6179 206f 6620  y): 2D array of 
-00016200: 7369 7a65 2028 6e20 7820 6d29 2c20 7768  size (n x m), wh
-00016210: 6572 6520 6e20 6973 2074 6865 0a20 2020  ere n is the.   
-00016220: 2020 2020 2020 2020 206e 756d 6265 7220           number 
-00016230: 6f66 2073 616d 706c 6573 2c20 616e 6420  of samples, and 
-00016240: 6d20 7468 6520 6e75 6d62 6572 206f 6620  m the number of 
-00016250: 6665 6174 7572 6573 2e0a 2020 2020 2020  features..      
-00016260: 2020 6461 7461 5f79 2028 6e64 6172 7261    data_y (ndarra
-00016270: 792c 2073 7472 293a 2031 4420 6172 7261  y, str): 1D arra
-00016280: 7920 636f 6e74 6169 6e69 6e67 2074 6865  y containing the
-00016290: 2063 6f72 7265 7370 6f6e 696e 6720 6c61   corresponing la
-000162a0: 6265 6c73 2e20 0a20 2020 2020 2020 206f  bels. .        o
-000162b0: 7074 5f63 7620 2869 6e74 293a 2043 726f  pt_cv (int): Cro
-000162c0: 7373 2d76 616c 6964 6174 696f 6e73 2074  ss-validations t
-000162d0: 6f20 7065 7266 6f72 6d20 7768 656e 2061  o perform when a
-000162e0: 7373 6573 696e 6720 7468 6520 7065 7266  ssesing the perf
-000162f0: 6f72 6d61 6e63 6520 6174 2065 6163 680a  ormance at each.
-00016300: 2020 2020 2020 2020 2020 2020 6879 7065              hype
-00016310: 7270 6172 616d 6574 6572 206f 7074 696d  rparameter optim
-00016320: 697a 6174 696f 6e20 7472 6961 6c2e 2046  ization trial. F
-00016330: 6f72 2065 7861 6d70 6c65 2c20 6966 2063  or example, if c
-00016340: 763d 332c 2074 6865 6e20 6561 6368 206f  v=3, then each o
-00016350: 7074 696d 697a 6174 696f 6e20 7472 6961  ptimization tria
-00016360: 6c0a 2020 2020 2020 2020 2020 2020 7769  l.            wi
-00016370: 6c6c 2062 6520 6173 7365 7373 6564 2061  ll be assessed a
-00016380: 6363 6f72 6469 6e67 2074 6f20 7468 6520  ccording to the 
-00016390: 332d 666f 6c64 2063 726f 7373 2076 616c  3-fold cross val
-000163a0: 6964 6174 696f 6e20 6163 6375 7261 6379  idation accuracy
-000163b0: 2e20 0a0a 2020 2020 5265 7475 726e 733a  . ..    Returns:
-000163c0: 0a20 2020 2020 2020 2054 6865 2070 6572  .        The per
-000163d0: 666f 726d 616e 6365 206d 6574 7269 632c  formance metric,
-000163e0: 2064 6574 6572 6d69 6e65 6420 7573 696e   determined usin
-000163f0: 6720 7468 6520 6372 6f73 732d 666f 6c64  g the cross-fold
-00016400: 2076 616c 6964 6174 696f 6e20 6d65 7468   validation meth
-00016410: 6f64 2e0a 2020 2020 2222 220a 2020 2020  od..    """.    
-00016420: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00016430: 5f28 7365 6c66 2c20 6461 7461 5f78 2c20  _(self, data_x, 
-00016440: 6461 7461 5f79 2c20 6f70 745f 6376 293a  data_y, opt_cv):
-00016450: 0a0a 2020 2020 2020 2020 7365 6c66 2e64  ..        self.d
-00016460: 6174 615f 7820 3d20 6461 7461 5f78 0a20  ata_x = data_x. 
-00016470: 2020 2020 2020 2073 656c 662e 6461 7461         self.data
-00016480: 5f79 203d 2064 6174 615f 790a 2020 2020  _y = data_y.    
-00016490: 2020 2020 7365 6c66 2e6f 7074 5f63 7620      self.opt_cv 
-000164a0: 3d20 6f70 745f 6376 0a0a 2020 2020 6465  = opt_cv..    de
-000164b0: 6620 5f5f 6361 6c6c 5f5f 2873 656c 662c  f __call__(self,
-000164c0: 2074 7269 616c 293a 0a0a 2020 2020 2020   trial):..      
-000164d0: 2020 6e5f 6573 7469 6d61 746f 7273 203d    n_estimators =
-000164e0: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
-000164f0: 6e74 2827 6e5f 6573 7469 6d61 746f 7273  nt('n_estimators
-00016500: 272c 2031 3030 2c20 3330 3030 290a 2020  ', 100, 3000).  
-00016510: 2020 2020 2020 6372 6974 6572 696f 6e20        criterion 
-00016520: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
-00016530: 6361 7465 676f 7269 6361 6c28 2763 7269  categorical('cri
-00016540: 7465 7269 6f6e 272c 205b 2767 696e 6927  terion', ['gini'
-00016550: 2c20 2765 6e74 726f 7079 275d 290a 2020  , 'entropy']).  
-00016560: 2020 2020 2020 6d61 785f 6465 7074 6820        max_depth 
-00016570: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
-00016580: 696e 7428 276d 6178 5f64 6570 7468 272c  int('max_depth',
-00016590: 2032 2c20 3235 290a 2020 2020 2020 2020   2, 25).        
-000165a0: 6d69 6e5f 7361 6d70 6c65 735f 7370 6c69  min_samples_spli
-000165b0: 7420 3d20 7472 6961 6c2e 7375 6767 6573  t = trial.sugges
-000165c0: 745f 696e 7428 276d 696e 5f73 616d 706c  t_int('min_sampl
-000165d0: 6573 5f73 706c 6974 272c 2032 2c20 3235  es_split', 2, 25
-000165e0: 290a 2020 2020 2020 2020 6d69 6e5f 7361  ).        min_sa
-000165f0: 6d70 6c65 735f 6c65 6166 203d 2074 7269  mples_leaf = tri
-00016600: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
-00016610: 6d69 6e5f 7361 6d70 6c65 735f 6c65 6166  min_samples_leaf
-00016620: 272c 2031 2c20 3135 290a 2020 2020 2020  ', 1, 15).      
-00016630: 2020 6d61 785f 6665 6174 7572 6573 203d    max_features =
-00016640: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
-00016650: 6e74 2827 6d61 785f 6665 6174 7572 6573  nt('max_features
-00016660: 272c 2031 2c20 7365 6c66 2e64 6174 615f  ', 1, self.data_
-00016670: 782e 7368 6170 655b 315d 290a 2020 2020  x.shape[1]).    
-00016680: 2020 2020 626f 6f74 7374 7261 7020 3d20      bootstrap = 
-00016690: 7472 6961 6c2e 7375 6767 6573 745f 6361  trial.suggest_ca
-000166a0: 7465 676f 7269 6361 6c28 2762 6f6f 7473  tegorical('boots
-000166b0: 7472 6170 272c 205b 5472 7565 2c20 4661  trap', [True, Fa
-000166c0: 6c73 655d 290a 2020 2020 2020 2020 0a20  lse]).        . 
-000166d0: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-000166e0: 2020 2020 2020 2020 636c 6620 3d20 5261          clf = Ra
-000166f0: 6e64 6f6d 466f 7265 7374 436c 6173 7369  ndomForestClassi
-00016700: 6669 6572 286e 5f65 7374 696d 6174 6f72  fier(n_estimator
-00016710: 733d 6e5f 6573 7469 6d61 746f 7273 2c20  s=n_estimators, 
-00016720: 6372 6974 6572 696f 6e3d 6372 6974 6572  criterion=criter
-00016730: 696f 6e2c 206d 6178 5f64 6570 7468 3d6d  ion, max_depth=m
-00016740: 6178 5f64 6570 7468 2c0a 2020 2020 2020  ax_depth,.      
-00016750: 2020 2020 2020 2020 2020 6d69 6e5f 7361            min_sa
-00016760: 6d70 6c65 735f 7370 6c69 743d 6d69 6e5f  mples_split=min_
-00016770: 7361 6d70 6c65 735f 7370 6c69 742c 206d  samples_split, m
-00016780: 696e 5f73 616d 706c 6573 5f6c 6561 663d  in_samples_leaf=
-00016790: 6d69 6e5f 7361 6d70 6c65 735f 6c65 6166  min_samples_leaf
-000167a0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000167b0: 2020 6d61 785f 6665 6174 7572 6573 3d6d    max_features=m
-000167c0: 6178 5f66 6561 7475 7265 732c 2062 6f6f  ax_features, boo
-000167d0: 7473 7472 6170 3d62 6f6f 7473 7472 6170  tstrap=bootstrap
-000167e0: 2c20 7261 6e64 6f6d 5f73 7461 7465 3d31  , random_state=1
-000167f0: 3930 3929 0a20 2020 2020 2020 2065 7863  909).        exc
-00016800: 6570 743a 0a20 2020 2020 2020 2020 2020  ept:.           
-00016810: 2070 7269 6e74 2822 496e 7661 6c69 6420   print("Invalid 
-00016820: 6879 7065 7270 6172 616d 6574 6572 2063  hyperparameter c
-00016830: 6f6d 6269 6e61 7469 6f6e 2c20 736b 6970  ombination, skip
-00016840: 7069 6e67 2074 7269 616c 2229 0a20 2020  ping trial").   
-00016850: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00016860: 302e 300a 0a20 2020 2020 2020 2063 7620  0.0..        cv 
-00016870: 3d20 6372 6f73 735f 7661 6c69 6461 7465  = cross_validate
-00016880: 2863 6c66 2c20 7365 6c66 2e64 6174 615f  (clf, self.data_
-00016890: 782c 2073 656c 662e 6461 7461 5f79 2c20  x, self.data_y, 
-000168a0: 6376 3d73 656c 662e 6f70 745f 6376 290a  cv=self.opt_cv).
-000168b0: 2020 2020 2020 2020 6669 6e61 6c5f 7363          final_sc
-000168c0: 6f72 6520 3d20 6e70 2e6d 6561 6e28 6376  ore = np.mean(cv
-000168d0: 5b27 7465 7374 5f73 636f 7265 275d 290a  ['test_score']).
-000168e0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-000168f0: 6669 6e61 6c5f 7363 6f72 650a 0a63 6c61  final_score..cla
-00016900: 7373 204d 6f6e 6974 6f72 5f54 7261 636b  ss Monitor_Track
-00016910: 6572 2843 616c 6c62 6163 6b29 3a0a 2020  er(Callback):.  
-00016920: 2020 2222 220a 2020 2020 4375 7374 6f6d    """.    Custom
-00016930: 2063 616c 6c62 6163 6b20 7468 6174 2061   callback that a
-00016940: 6c6c 6f77 7320 666f 7220 7477 6f20 6469  llows for two di
-00016950: 6666 6572 656e 7420 6d6f 6e69 746f 7273  fferent monitors
-00016960: 2e0a 2020 2020 5468 6973 2063 6c61 7373  ..    This class
-00016970: 2069 7320 7573 6564 2062 7920 7468 6520   is used by the 
-00016980: 606f 626a 6563 7469 7665 5f63 6e6e 6020  `objective_cnn` 
-00016990: 726f 7574 696e 6520 6173 2069 7420 696e  routine as it in
-000169a0: 6865 7269 7473 2074 6865 2060 6d6f 6e69  herits the `moni
-000169b0: 746f 7231 6020 0a20 2020 2061 6e64 2060  tor1` .    and `
-000169c0: 6d6f 6e69 746f 7232 6020 6174 7472 6962  monitor2` attrib
-000169d0: 7574 6573 2c20 6173 2077 656c 6c20 6173  utes, as well as
-000169e0: 2074 6865 6972 2063 6f72 7265 7370 6f6e   their correspon
-000169f0: 6469 6e67 2074 6872 6573 686f 6c64 732e  ding thresholds.
-00016a00: 2054 6869 7320 6561 726c 7920 7374 6f70   This early stop
-00016a10: 7069 6e67 0a20 2020 2063 7573 746f 6d20  ping.    custom 
-00016a20: 6361 6c6c 6261 636b 2077 696c 6c20 7465  callback will te
-00016a30: 726d 696e 6174 6520 7468 6520 7472 6169  rminate the trai
-00016a40: 6e69 6e67 2065 6172 6c79 2069 6620 6569  ning early if ei
-00016a50: 7468 6572 206d 6f6e 6974 6f72 7320 6372  ther monitors cr
-00016a60: 6f73 7320 7468 6569 7220 7265 7370 6563  oss their respec
-00016a70: 7469 7665 0a20 2020 2074 6872 6573 686f  tive.    thresho
-00016a80: 6c64 2c20 7468 6572 6566 6f72 6520 7468  ld, therefore th
-00016a90: 6520 7061 7469 656e 6365 2069 6e70 7574  e patience input
-00016aa0: 2069 7320 6e6f 7420 7573 6564 2e20 5768   is not used. Wh
-00016ab0: 6574 6865 7220 7468 6520 7468 7265 7368  ether the thresh
-00016ac0: 6f6c 6420 7368 6f75 6c64 2062 6520 6120  old should be a 
-00016ad0: 6365 696c 696e 670a 2020 2020 6f72 2066  ceiling.    or f
-00016ae0: 6c6f 6f72 2076 616c 7565 2077 696c 6c20  loor value will 
-00016af0: 6265 2064 6574 6572 6d69 6e65 6420 6163  be determined ac
-00016b00: 636f 7264 696e 6720 746f 2074 6865 206d  cording to the m
-00016b10: 6574 7269 632c 2062 7920 6368 6563 6b69  etric, by checki
-00016b20: 6e67 2077 6865 7468 6572 2074 6865 206d  ng whether the m
-00016b30: 6f6e 6974 6f72 206e 616d 650a 2020 2020  onitor name.    
-00016b40: 636f 6e74 6169 6e73 2074 6865 2077 6f72  contains the wor
-00016b50: 6420 276c 6f73 7327 2e0a 0a20 2020 2041  d 'loss'...    A
-00016b60: 7267 733a 0a20 2020 2020 2020 206d 6f6e  rgs:.        mon
-00016b70: 6974 6f72 3120 2873 7472 293a 204e 616d  itor1 (str): Nam
-00016b80: 6520 6f66 2074 6865 206d 6574 7269 6320  e of the metric 
-00016b90: 746f 206d 6f6e 6974 6f72 2e20 4966 2060  to monitor. If `
-00016ba0: 4e6f 6e65 602c 2074 6869 7320 6d6f 6e69  None`, this moni
-00016bb0: 746f 7220 7769 6c6c 206e 6f74 2062 6520  tor will not be 
-00016bc0: 7573 6564 2e0a 2020 2020 2020 2020 6d6f  used..        mo
-00016bd0: 6e69 746f 7232 2028 7374 7229 3a20 4e61  nitor2 (str): Na
-00016be0: 6d65 206f 6620 7468 6520 6d65 7472 6963  me of the metric
-00016bf0: 2074 6f20 6d6f 6e69 746f 722e 2049 6620   to monitor. If 
-00016c00: 604e 6f6e 6560 2c20 7468 6973 206d 6f6e  `None`, this mon
-00016c10: 6974 6f72 2077 696c 6c20 6e6f 7420 6265  itor will not be
-00016c20: 2075 7365 642e 0a20 2020 2020 2020 206d   used..        m
-00016c30: 6f6e 6974 6f72 315f 7468 7265 7368 2028  onitor1_thresh (
-00016c40: 666c 6f61 7429 3a20 5468 7265 7368 6f6c  float): Threshol
-00016c50: 6420 7661 6c75 6520 666f 7220 606d 6f6e  d value for `mon
-00016c60: 6974 6f72 3160 2e0a 2020 2020 2020 2020  itor1`..        
-00016c70: 6d6f 6e69 746f 7232 5f74 6872 6573 6820  monitor2_thresh 
-00016c80: 2866 6c6f 6174 293a 2054 6872 6573 686f  (float): Thresho
-00016c90: 6c64 2076 616c 7565 2066 6f72 2060 6d6f  ld value for `mo
-00016ca0: 6e69 746f 7232 602e 0a0a 2020 2020 4174  nitor2`...    At
-00016cb0: 7472 6962 7574 6573 3a0a 2020 2020 2020  tributes:.      
-00016cc0: 2020 7374 6f70 7065 645f 6570 6f63 6820    stopped_epoch 
-00016cd0: 2869 6e74 293a 2054 6865 2065 706f 6368  (int): The epoch
-00016ce0: 2061 7420 7768 6963 6820 7468 6520 7472   at which the tr
-00016cf0: 6169 6e69 6e67 2077 6173 2073 746f 7070  aining was stopp
-00016d00: 6564 2e0a 2020 2020 2020 2020 6265 7374  ed..        best
-00016d10: 5f6d 6574 7269 6320 2866 6c6f 6174 293a  _metric (float):
-00016d20: 2054 6865 2062 6573 7420 6d65 7472 6963   The best metric
-00016d30: 2076 616c 7565 2061 6368 6965 7665 6420   value achieved 
-00016d40: 6475 7269 6e67 2074 6865 2074 7261 696e  during the train
-00016d50: 696e 672e 0a20 2020 2020 2020 2062 6573  ing..        bes
-00016d60: 745f 7765 6967 6874 7320 286e 6461 7272  t_weights (ndarr
-00016d70: 6179 293a 2054 6865 2077 6569 6768 7473  ay): The weights
-00016d80: 206f 6620 7468 6520 6d6f 6465 6c20 6174   of the model at
-00016d90: 2074 6865 2065 706f 6368 2077 6974 6820   the epoch with 
-00016da0: 7468 6520 6265 7374 206d 6574 7269 6320  the best metric 
-00016db0: 7661 6c75 652e 0a0a 2020 2020 5265 7475  value...    Retu
-00016dc0: 726e 733a 0a20 2020 2020 2020 204e 6f6e  rns:.        Non
-00016dd0: 650a 2020 2020 2222 220a 2020 2020 0a20  e.    """.    . 
-00016de0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00016df0: 7365 6c66 2c20 6d6f 6e69 746f 7231 3d4e  self, monitor1=N
-00016e00: 6f6e 652c 206d 6f6e 6974 6f72 323d 4e6f  one, monitor2=No
-00016e10: 6e65 2c20 6d6f 6e69 746f 7231 5f74 6872  ne, monitor1_thr
-00016e20: 6573 683d 4e6f 6e65 2c20 6d6f 6e69 746f  esh=None, monito
-00016e30: 7232 5f74 6872 6573 683d 4e6f 6e65 293a  r2_thresh=None):
-00016e40: 0a20 2020 2020 2020 2073 7570 6572 2829  .        super()
-00016e50: 2e5f 5f69 6e69 745f 5f28 2920 2323 496e  .__init__() ##In
-00016e60: 6974 6961 6c69 7a65 7320 7468 6520 696e  itializes the in
-00016e70: 6865 7269 7465 6420 6174 7472 6962 7574  herited attribut
-00016e80: 6573 2061 6e64 206d 6574 686f 6473 2066  es and methods f
-00016e90: 726f 6d20 7468 6520 7061 7265 6e74 2063  rom the parent c
-00016ea0: 6c61 7373 2061 7320 6974 2077 696c 6c20  lass as it will 
-00016eb0: 696e 6865 7269 7420 6672 6f6d 2043 616c  inherit from Cal
-00016ec0: 6c62 6163 6b0a 2020 2020 2020 2020 7365  lback.        se
-00016ed0: 6c66 2e6d 6f6e 6974 6f72 3120 3d20 6d6f  lf.monitor1 = mo
-00016ee0: 6e69 746f 7231 0a20 2020 2020 2020 2073  nitor1.        s
-00016ef0: 656c 662e 6d6f 6e69 746f 7232 203d 206d  elf.monitor2 = m
-00016f00: 6f6e 6974 6f72 320a 2020 2020 2020 2020  onitor2.        
-00016f10: 7365 6c66 2e6d 6f6e 6974 6f72 315f 7468  self.monitor1_th
-00016f20: 7265 7368 203d 206d 6f6e 6974 6f72 315f  resh = monitor1_
-00016f30: 7468 7265 7368 0a20 2020 2020 2020 2073  thresh.        s
-00016f40: 656c 662e 6d6f 6e69 746f 7232 5f74 6872  elf.monitor2_thr
-00016f50: 6573 6820 3d20 6d6f 6e69 746f 7232 5f74  esh = monitor2_t
-00016f60: 6872 6573 680a 2020 2020 2020 2020 7365  hresh.        se
-00016f70: 6c66 2e73 746f 7070 6564 5f65 706f 6368  lf.stopped_epoch
-00016f80: 203d 2030 0a20 2020 2020 2020 2073 656c   = 0.        sel
-00016f90: 662e 6265 7374 5f6d 6574 7269 6320 3d20  f.best_metric = 
-00016fa0: 666c 6f61 7428 2769 6e66 2729 200a 2020  float('inf') .  
-00016fb0: 2020 2020 2020 7365 6c66 2e62 6573 745f        self.best_
-00016fc0: 7765 6967 6874 7320 3d20 4e6f 6e65 2023  weights = None #
-00016fd0: 5769 6c6c 2075 7365 2074 6869 7320 746f  Will use this to
-00016fe0: 2073 746f 7265 2074 6865 2077 6569 6768   store the weigh
-00016ff0: 7473 2077 6974 6820 7468 6520 6265 7374  ts with the best
-00017000: 206d 6574 7269 6320 7661 6c75 6520 6275   metric value bu
-00017010: 7420 6e6f 7420 6375 7272 656e 746c 7920  t not currently 
-00017020: 6361 6c6c 6564 2069 6e20 7468 6520 726f  called in the ro
-00017030: 7574 696e 650a 0a20 2020 2064 6566 206f  utine..    def o
-00017040: 6e5f 6570 6f63 685f 656e 6428 7365 6c66  n_epoch_end(self
-00017050: 2c20 6570 6f63 682c 206c 6f67 733d 7b7d  , epoch, logs={}
-00017060: 293a 0a20 2020 2020 2020 2022 2222 0a20  ):.        """. 
-00017070: 2020 2020 2020 2054 6869 7320 6d65 7468         This meth
-00017080: 6f64 2077 696c 6c20 6265 2063 616c 6c65  od will be calle
-00017090: 6420 6174 2074 6865 2065 6e64 206f 6620  d at the end of 
-000170a0: 6561 6368 2065 706f 6368 2064 7572 696e  each epoch durin
-000170b0: 6720 7472 6169 6e69 6e67 2e0a 0a20 2020  g training...   
-000170c0: 2020 2020 2041 7267 733a 0a20 2020 2020       Args:.     
-000170d0: 2020 2020 2020 2065 706f 6368 2028 696e         epoch (in
-000170e0: 7429 3a20 4375 7272 656e 7420 6570 6f63  t): Current epoc
-000170f0: 6820 6e75 6d62 6572 2e0a 2020 2020 2020  h number..      
-00017100: 2020 2020 2020 6c6f 6773 2028 6469 6374        logs (dict
-00017110: 293a 2044 6963 7469 6f6e 6172 7920 636f  ): Dictionary co
-00017120: 6e74 6169 6e69 6e67 2074 6865 206d 6574  ntaining the met
-00017130: 7269 6373 2066 6f72 2074 6865 2063 7572  rics for the cur
-00017140: 7265 6e74 2065 706f 6368 2e0a 0a20 2020  rent epoch...   
-00017150: 2020 2020 2052 6574 7572 6e73 3a0a 2020       Returns:.  
-00017160: 2020 2020 2020 2020 2020 4e6f 6e65 0a20            None. 
-00017170: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
-00017180: 2020 2020 6966 2073 656c 662e 6d6f 6e69      if self.moni
-00017190: 746f 7231 2069 7320 6e6f 7420 4e6f 6e65  tor1 is not None
-000171a0: 2061 6e64 2073 656c 662e 6d6f 6e69 746f   and self.monito
-000171b0: 7232 2069 7320 6e6f 7420 4e6f 6e65 3a0a  r2 is not None:.
-000171c0: 2020 2020 2020 2020 2020 2020 6375 7272              curr
-000171d0: 656e 745f 3120 3d20 6c6f 6773 2e67 6574  ent_1 = logs.get
-000171e0: 2873 656c 662e 6d6f 6e69 746f 7231 290a  (self.monitor1).
-000171f0: 2020 2020 2020 2020 2020 2020 6375 7272              curr
-00017200: 656e 745f 3220 3d20 6c6f 6773 2e67 6574  ent_2 = logs.get
-00017210: 2873 656c 662e 6d6f 6e69 746f 7232 290a  (self.monitor2).
-00017220: 2020 2020 2020 2020 2020 2020 6966 2027              if '
-00017230: 6c6f 7373 2720 6e6f 7420 696e 2073 656c  loss' not in sel
-00017240: 662e 6d6f 6e69 746f 7231 2061 6e64 2027  f.monitor1 and '
-00017250: 6c6f 7373 2720 696e 2073 656c 662e 6d6f  loss' in self.mo
-00017260: 6e69 746f 7232 3a0a 2020 2020 2020 2020  nitor2:.        
-00017270: 2020 2020 2020 2020 6966 206e 702e 6772          if np.gr
-00017280: 6561 7465 7228 6375 7272 656e 745f 312c  eater(current_1,
-00017290: 2073 656c 662e 6d6f 6e69 746f 7231 5f74   self.monitor1_t
-000172a0: 6872 6573 6829 206f 7220 6e70 2e6c 6573  hresh) or np.les
-000172b0: 735f 6571 7561 6c28 6375 7272 656e 745f  s_equal(current_
-000172c0: 322c 2073 656c 662e 6d6f 6e69 746f 7232  2, self.monitor2
-000172d0: 5f74 6872 6573 6829 3a0a 2020 2020 2020  _thresh):.      
-000172e0: 2020 2020 2020 2020 2020 2020 2020 7365                se
-000172f0: 6c66 2e73 746f 7070 6564 5f65 706f 6368  lf.stopped_epoch
-00017300: 203d 2065 706f 6368 0a20 2020 2020 2020   = epoch.       
-00017310: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-00017320: 662e 6d6f 6465 6c2e 7374 6f70 5f74 7261  f.model.stop_tra
-00017330: 696e 696e 6720 3d20 5472 7565 0a20 2020  ining = True.   
-00017340: 2020 2020 2020 2020 2020 2020 2063 7572               cur
-00017350: 7265 6e74 5f6d 6574 7269 6320 3d20 6375  rent_metric = cu
-00017360: 7272 656e 745f 310a 2020 2020 2020 2020  rrent_1.        
-00017370: 2020 2020 656c 6966 2027 6c6f 7373 2720      elif 'loss' 
-00017380: 6e6f 7420 696e 2073 656c 662e 6d6f 6e69  not in self.moni
-00017390: 746f 7231 2061 6e64 2027 6c6f 7373 2720  tor1 and 'loss' 
-000173a0: 6e6f 7420 696e 2073 656c 662e 6d6f 6e69  not in self.moni
-000173b0: 746f 7232 3a0a 2020 2020 2020 2020 2020  tor2:.          
-000173c0: 2020 2020 2020 6966 206e 702e 6772 6561        if np.grea
-000173d0: 7465 7228 6375 7272 656e 745f 312c 2073  ter(current_1, s
-000173e0: 656c 662e 6d6f 6e69 746f 7231 5f74 6872  elf.monitor1_thr
-000173f0: 6573 6829 206f 7220 6e70 2e67 7265 6174  esh) or np.great
-00017400: 6572 2863 7572 7265 6e74 5f32 2c20 7365  er(current_2, se
-00017410: 6c66 2e6d 6f6e 6974 6f72 325f 7468 7265  lf.monitor2_thre
-00017420: 7368 293a 0a20 2020 2020 2020 2020 2020  sh):.           
-00017430: 2020 2020 2020 2020 2073 656c 662e 7374           self.st
-00017440: 6f70 7065 645f 6570 6f63 6820 3d20 6570  opped_epoch = ep
-00017450: 6f63 680a 2020 2020 2020 2020 2020 2020  och.            
-00017460: 2020 2020 2020 2020 7365 6c66 2e6d 6f64          self.mod
-00017470: 656c 2e73 746f 705f 7472 6169 6e69 6e67  el.stop_training
-00017480: 203d 2054 7275 650a 2020 2020 2020 2020   = True.        
-00017490: 2020 2020 2020 2020 6375 7272 656e 745f          current_
-000174a0: 6d65 7472 6963 203d 2063 7572 7265 6e74  metric = current
-000174b0: 5f31 0a20 2020 2020 2020 2020 2020 2065  _1.            e
-000174c0: 6c69 6620 276c 6f73 7327 2069 6e20 7365  lif 'loss' in se
-000174d0: 6c66 2e6d 6f6e 6974 6f72 3120 616e 6420  lf.monitor1 and 
-000174e0: 276c 6f73 7327 2069 6e20 7365 6c66 2e6d  'loss' in self.m
-000174f0: 6f6e 6974 6f72 323a 0a20 2020 2020 2020  onitor2:.       
-00017500: 2020 2020 2020 2020 2069 6620 6e70 2e6c           if np.l
-00017510: 6573 735f 6571 7561 6c28 6375 7272 656e  ess_equal(curren
-00017520: 745f 312c 2073 656c 662e 6d6f 6e69 746f  t_1, self.monito
-00017530: 7231 5f74 6872 6573 6829 206f 7220 6e70  r1_thresh) or np
-00017540: 2e6c 6573 735f 6571 7561 6c28 6375 7272  .less_equal(curr
-00017550: 656e 745f 322c 2073 656c 662e 6d6f 6e69  ent_2, self.moni
-00017560: 746f 7232 5f74 6872 6573 6829 3a0a 2020  tor2_thresh):.  
-00017570: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017580: 2020 7365 6c66 2e73 746f 7070 6564 5f65    self.stopped_e
-00017590: 706f 6368 203d 2065 706f 6368 0a20 2020  poch = epoch.   
-000175a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000175b0: 2073 656c 662e 6d6f 6465 6c2e 7374 6f70   self.model.stop
-000175c0: 5f74 7261 696e 696e 6720 3d20 5472 7565  _training = True
-000175d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000175e0: 2063 7572 7265 6e74 5f6d 6574 7269 6320   current_metric 
-000175f0: 3d20 6375 7272 656e 745f 310a 2020 2020  = current_1.    
-00017600: 2020 2020 2020 2020 656c 6966 2027 6c6f          elif 'lo
-00017610: 7373 2720 696e 2073 656c 662e 6d6f 6e69  ss' in self.moni
-00017620: 746f 7231 2061 6e64 2027 6c6f 7373 2720  tor1 and 'loss' 
-00017630: 6e6f 7420 696e 2073 656c 662e 6d6f 6e69  not in self.moni
-00017640: 746f 7232 3a0a 2020 2020 2020 2020 2020  tor2:.          
-00017650: 2020 2020 2020 6966 206e 702e 6c65 7373        if np.less
-00017660: 5f65 7175 616c 2863 7572 7265 6e74 5f31  _equal(current_1
-00017670: 2c20 7365 6c66 2e6d 6f6e 6974 6f72 315f  , self.monitor1_
-00017680: 7468 7265 7368 2920 6f72 206e 702e 6772  thresh) or np.gr
-00017690: 6561 7465 7228 6375 7272 656e 745f 322c  eater(current_2,
-000176a0: 2073 656c 662e 6d6f 6e69 746f 7232 5f74   self.monitor2_t
-000176b0: 6872 6573 6829 3a0a 2020 2020 2020 2020  hresh):.        
-000176c0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-000176d0: 2e73 746f 7070 6564 5f65 706f 6368 203d  .stopped_epoch =
-000176e0: 2065 706f 6368 0a20 2020 2020 2020 2020   epoch.         
-000176f0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00017700: 6d6f 6465 6c2e 7374 6f70 5f74 7261 696e  model.stop_train
-00017710: 696e 6720 3d20 5472 7565 0a20 2020 2020  ing = True.     
-00017720: 2020 2020 2020 2020 2020 2063 7572 7265             curre
-00017730: 6e74 5f6d 6574 7269 6320 3d20 6375 7272  nt_metric = curr
-00017740: 656e 745f 310a 2020 2020 2020 2020 2020  ent_1.          
-00017750: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00017760: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
-00017770: 6c75 6545 7272 6f72 2827 496e 7661 6c69  lueError('Invali
-00017780: 6420 6d6f 6e69 746f 7220 696e 7075 742e  d monitor input.
-00017790: 2729 0a20 2020 2020 2020 2020 2020 200a  ').            .
-000177a0: 2020 2020 2020 2020 2020 2020 6966 2063              if c
-000177b0: 7572 7265 6e74 5f6d 6574 7269 6320 3c20  urrent_metric < 
-000177c0: 7365 6c66 2e62 6573 745f 6d65 7472 6963  self.best_metric
-000177d0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000177e0: 2020 7365 6c66 2e62 6573 745f 6d65 7472    self.best_metr
-000177f0: 6963 203d 2063 7572 7265 6e74 5f6d 6574  ic = current_met
-00017800: 7269 630a 2020 2020 2020 2020 2020 2020  ric.            
-00017810: 2020 2020 7365 6c66 2e62 6573 745f 7765      self.best_we
-00017820: 6967 6874 7320 3d20 7365 6c66 2e6d 6f64  ights = self.mod
-00017830: 656c 2e67 6574 5f77 6569 6768 7473 2829  el.get_weights()
-00017840: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017850: 200a 2020 2020 2020 2020 656c 7365 3a0a   .        else:.
-00017860: 2020 2020 2020 2020 2020 2020 6375 7272              curr
-00017870: 656e 745f 6d65 7472 6963 203d 206c 6f67  ent_metric = log
-00017880: 732e 6765 7428 7365 6c66 2e6d 6f6e 6974  s.get(self.monit
-00017890: 6f72 3129 0a20 2020 2020 2020 2020 2020  or1).           
-000178a0: 2069 6620 276c 6f73 7327 206e 6f74 2069   if 'loss' not i
-000178b0: 6e20 7365 6c66 2e6d 6f6e 6974 6f72 313a  n self.monitor1:
-000178c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000178d0: 2069 6620 6e70 2e67 7265 6174 6572 2863   if np.greater(c
-000178e0: 7572 7265 6e74 5f6d 6574 7269 632c 2073  urrent_metric, s
-000178f0: 656c 662e 6d6f 6e69 746f 7231 5f74 6872  elf.monitor1_thr
-00017900: 6573 6829 3a0a 2020 2020 2020 2020 2020  esh):.          
-00017910: 2020 2020 2020 2020 2020 7365 6c66 2e73            self.s
-00017920: 746f 7070 6564 5f65 706f 6368 203d 2065  topped_epoch = e
-00017930: 706f 6368 0a20 2020 2020 2020 2020 2020  poch.           
-00017940: 2020 2020 2020 2020 2073 656c 662e 6d6f           self.mo
-00017950: 6465 6c2e 7374 6f70 5f74 7261 696e 696e  del.stop_trainin
-00017960: 6720 3d20 5472 7565 0a20 2020 2020 2020  g = True.       
-00017970: 2020 2020 2020 2020 2069 6620 6375 7272           if curr
-00017980: 656e 745f 6d65 7472 6963 203c 2073 656c  ent_metric < sel
-00017990: 662e 6265 7374 5f6d 6574 7269 633a 0a20  f.best_metric:. 
-000179a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000179b0: 2020 2073 656c 662e 6265 7374 5f6d 6574     self.best_met
-000179c0: 7269 6320 3d20 6375 7272 656e 745f 6d65  ric = current_me
-000179d0: 7472 6963 0a20 2020 2020 2020 2020 2020  tric.           
-000179e0: 2020 2020 2020 2020 2073 656c 662e 6265           self.be
-000179f0: 7374 5f77 6569 6768 7473 203d 2073 656c  st_weights = sel
-00017a00: 662e 6d6f 6465 6c2e 6765 745f 7765 6967  f.model.get_weig
-00017a10: 6874 7328 290a 2020 2020 2020 2020 2020  hts().          
-00017a20: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00017a30: 2020 2020 2020 2020 6966 206e 702e 6c65          if np.le
-00017a40: 7373 5f65 7175 616c 2863 7572 7265 6e74  ss_equal(current
-00017a50: 5f6d 6574 7269 632c 2073 656c 662e 6d6f  _metric, self.mo
-00017a60: 6e69 746f 7231 5f74 6872 6573 6829 3a0a  nitor1_thresh):.
-00017a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017a80: 2020 2020 7365 6c66 2e73 746f 7070 6564      self.stopped
-00017a90: 5f65 706f 6368 203d 2065 706f 6368 0a20  _epoch = epoch. 
-00017aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ab0: 2020 2073 656c 662e 6d6f 6465 6c2e 7374     self.model.st
-00017ac0: 6f70 5f74 7261 696e 696e 6720 3d20 5472  op_training = Tr
-00017ad0: 7565 0a20 2020 2020 2020 2020 2020 2020  ue.             
-00017ae0: 2020 2069 6620 6375 7272 656e 745f 6d65     if current_me
-00017af0: 7472 6963 203c 2073 656c 662e 6265 7374  tric < self.best
-00017b00: 5f6d 6574 7269 633a 0a20 2020 2020 2020  _metric:.       
-00017b10: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-00017b20: 662e 6265 7374 5f6d 6574 7269 6320 3d20  f.best_metric = 
-00017b30: 6375 7272 656e 745f 6d65 7472 6963 0a20  current_metric. 
-00017b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b50: 2020 2073 656c 662e 6265 7374 5f77 6569     self.best_wei
-00017b60: 6768 7473 203d 2073 656c 662e 6d6f 6465  ghts = self.mode
-00017b70: 6c2e 6765 745f 7765 6967 6874 7328 290a  l.get_weights().
-00017b80: 0a0a 6465 6620 6879 7065 725f 6f70 7428  ..def hyper_opt(
-00017b90: 6461 7461 5f78 3d4e 6f6e 652c 2064 6174  data_x=None, dat
-00017ba0: 615f 793d 4e6f 6e65 2c20 7661 6c5f 583d  a_y=None, val_X=
-00017bb0: 4e6f 6e65 2c20 7661 6c5f 593d 4e6f 6e65  None, val_Y=None
-00017bc0: 2c20 696d 675f 6e75 6d5f 6368 616e 6e65  , img_num_channe
-00017bd0: 6c73 3d31 2c20 636c 663d 2761 6c65 786e  ls=1, clf='alexn
-00017be0: 6574 272c 200a 2020 2020 6e6f 726d 616c  et', .    normal
-00017bf0: 697a 653d 5472 7565 2c20 6d69 6e5f 7069  ize=True, min_pi
-00017c00: 7865 6c3d 302c 206d 6178 5f70 6978 656c  xel=0, max_pixel
-00017c10: 3d31 3030 302c 206e 5f69 7465 723d 3235  =1000, n_iter=25
-00017c20: 2c20 7061 7469 656e 6365 3d35 2c20 6d65  , patience=5, me
-00017c30: 7472 6963 3d27 6c6f 7373 272c 2061 7665  tric='loss', ave
-00017c40: 7261 6765 3d54 7275 652c 200a 2020 2020  rage=True, .    
-00017c50: 7465 7374 5f70 6f73 6974 6976 653d 4e6f  test_positive=No
-00017c60: 6e65 2c20 7465 7374 5f6e 6567 6174 6976  ne, test_negativ
-00017c70: 653d 4e6f 6e65 2c20 6f70 745f 6d6f 6465  e=None, opt_mode
-00017c80: 6c3d 5472 7565 2c20 6261 7463 685f 7369  l=True, batch_si
-00017c90: 7a65 5f6d 696e 3d31 362c 2062 6174 6368  ze_min=16, batch
-00017ca0: 5f73 697a 655f 6d61 783d 3634 2c20 7472  _size_max=64, tr
-00017cb0: 6169 6e5f 6570 6f63 6873 3d32 352c 206f  ain_epochs=25, o
-00017cc0: 7074 5f63 763d 4e6f 6e65 2c0a 2020 2020  pt_cv=None,.    
-00017cd0: 6f70 745f 6175 673d 4661 6c73 652c 2062  opt_aug=False, b
-00017ce0: 6174 6368 5f6d 696e 3d32 2c20 6261 7463  atch_min=2, batc
-00017cf0: 685f 6d61 783d 3235 2c20 6261 7463 685f  h_max=25, batch_
-00017d00: 6f74 6865 723d 312c 2062 616c 616e 6365  other=1, balance
-00017d10: 3d54 7275 652c 2069 6d61 6765 5f73 697a  =True, image_siz
-00017d20: 655f 6d69 6e3d 3530 2c20 696d 6167 655f  e_min=50, image_
-00017d30: 7369 7a65 5f6d 6178 3d31 3030 2c20 7368  size_max=100, sh
-00017d40: 6966 743d 3130 2c20 6f70 745f 6d61 785f  ift=10, opt_max_
-00017d50: 6d69 6e5f 7069 783d 4e6f 6e65 2c20 6f70  min_pix=None, op
-00017d60: 745f 6d61 785f 6d61 785f 7069 783d 4e6f  t_max_max_pix=No
-00017d70: 6e65 2c20 0a20 2020 206d 6173 6b5f 7369  ne, .    mask_si
-00017d80: 7a65 3d4e 6f6e 652c 206e 756d 5f6d 6173  ze=None, num_mas
-00017d90: 6b73 3d4e 6f6e 652c 2073 6d6f 7465 5f73  ks=None, smote_s
-00017da0: 616d 706c 696e 673d 302c 2062 6c65 6e64  ampling=0, blend
-00017db0: 5f6d 6178 3d30 2c20 6e75 6d5f 696d 6167  _max=0, num_imag
-00017dc0: 6573 5f74 6f5f 626c 656e 643d 322c 2062  es_to_blend=2, b
-00017dd0: 6c65 6e64 696e 675f 6675 6e63 3d27 6d65  lending_func='me
-00017de0: 616e 272c 2062 6c65 6e64 5f6f 7468 6572  an', blend_other
-00017df0: 3d31 2c20 7a6f 6f6d 5f72 616e 6765 3d28  =1, zoom_range=(
-00017e00: 302e 392c 312e 3129 2c20 736b 6577 5f61  0.9,1.1), skew_a
-00017e10: 6e67 6c65 3d30 2c0a 2020 2020 6c69 6d69  ngle=0,.    limi
-00017e20: 745f 7365 6172 6368 3d54 7275 652c 206d  t_search=True, m
-00017e30: 6f6e 6974 6f72 313d 4e6f 6e65 2c20 6d6f  onitor1=None, mo
-00017e40: 6e69 746f 7232 3d4e 6f6e 652c 206d 6f6e  nitor2=None, mon
-00017e50: 6974 6f72 315f 7468 7265 7368 3d4e 6f6e  itor1_thresh=Non
-00017e60: 652c 206d 6f6e 6974 6f72 325f 7468 7265  e, monitor2_thre
-00017e70: 7368 3d4e 6f6e 652c 2076 6572 626f 7365  sh=None, verbose
-00017e80: 3d30 2c20 7265 7475 726e 5f73 7475 6479  =0, return_study
-00017e90: 3d54 7275 6529 3a20 0a20 2020 2022 2222  =True): .    """
-00017ea0: 0a20 2020 204f 7074 696d 697a 6573 2068  .    Optimizes h
-00017eb0: 7970 6572 7061 7261 6d65 7465 7273 2075  yperparameters u
-00017ec0: 7369 6e67 2061 206b 2d66 6f6c 6420 6372  sing a k-fold cr
-00017ed0: 6f73 7320 7661 6c69 6461 7469 6f6e 2073  oss validation s
-00017ee0: 706c 6974 7469 6e67 2073 7472 6174 6567  plitting strateg
-00017ef0: 792e 0a0a 2020 2020 2a2a 494d 504f 5254  y...    **IMPORT
-00017f00: 414e 542a 2a20 496e 2074 6865 2063 6173  ANT** In the cas
-00017f10: 6520 6f66 2043 4e4e 206f 7074 696d 697a  e of CNN optimiz
-00017f20: 6174 696f 6e2c 2064 6174 615f 7820 616e  ation, data_x an
-00017f30: 6420 6461 7461 5f79 2061 7265 206e 6f74  d data_y are not
-00017f40: 2074 6865 2073 7461 6e64 6172 640a 2020   the standard.  
-00017f50: 2020 6461 7461 2070 6c75 7320 6c61 6265    data plus labe
-00017f60: 6c73 202d 2d20 4d69 6372 6f4c 4941 2061  ls -- MicroLIA a
-00017f70: 7373 756d 6573 2062 696e 6172 7920 636c  ssumes binary cl
-00017f80: 6173 7369 6669 6361 7469 6f6e 2061 6c77  assification alw
-00017f90: 6179 7320 7468 6572 6566 6f72 6520 6966  ays therefore if
-00017fa0: 206f 7074 696d 697a 696e 6720 6120 0a20   optimizing a . 
-00017fb0: 2020 2043 4e4e 2074 6865 2073 616d 706c     CNN the sampl
-00017fc0: 6573 2066 6f72 2074 6865 2066 6972 7374  es for the first
-00017fd0: 2063 6c61 7373 2073 686f 756c 6420 6265   class should be
-00017fe0: 2070 6173 7365 6420 7468 726f 7567 6820   passed through 
-00017ff0: 7468 6520 6461 7461 5f78 2070 6172 616d  the data_x param
-00018000: 6574 6572 2c20 616e 6420 7468 6520 0a20  eter, and the . 
-00018010: 2020 2073 616d 706c 6573 2066 6f72 2074     samples for t
-00018020: 6865 2073 6563 6f6e 6420 636c 6173 7320  he second class 
-00018030: 7368 6f75 6c64 2062 6520 6769 7665 6e20  should be given 
-00018040: 6173 2064 6174 615f 792e 2054 6865 7365  as data_y. These
-00018050: 2074 776f 2063 6c61 7373 6573 2077 696c   two classes wil
-00018060: 6c20 6175 746f 6d61 7469 6361 6c6c 7920  l automatically 
-00018070: 0a20 2020 2062 6520 6173 7369 676e 6564  .    be assigned
-00018080: 2074 6865 2070 6f73 6974 6976 6520 616e   the positive an
-00018090: 6420 6e65 6761 7469 7665 206c 6162 656c  d negative label
-000180a0: 7320 3120 616e 6420 302c 2072 6573 7065  s 1 and 0, respe
-000180b0: 6374 6976 656c 792e 204c 696b 6577 6973  ctively. Likewis
-000180c0: 652c 2069 6620 6f70 7469 6d69 7a69 6e67  e, if optimizing
-000180d0: 2061 200a 2020 2020 434e 4e20 6d6f 6465   a .    CNN mode
-000180e0: 6c2c 2076 616c 5f58 2063 6f72 7265 7370  l, val_X corresp
-000180f0: 6f6e 6473 2074 6f20 7468 6520 696d 6167  onds to the imag
-00018100: 6573 206f 6620 7468 6520 6669 7273 7420  es of the first 
-00018110: 636c 6173 732c 2061 6e64 2076 616c 5f59  class, and val_Y
-00018120: 2074 6865 2069 6d61 6765 7320 6f66 2074   the images of t
-00018130: 6865 2073 6563 6f6e 6420 636c 6173 732e  he second class.
-00018140: 200a 2020 2020 0a20 2020 2049 6620 7361   .    .    If sa
-00018150: 7665 5f73 7475 6479 3d54 7275 652c 2074  ve_study=True, t
-00018160: 6865 204f 7074 756e 6120 7374 7564 7920  he Optuna study 
-00018170: 6f62 6a65 6374 2077 696c 6c20 6265 2074  object will be t
-00018180: 6865 2074 6869 7264 206f 7574 7075 742e  he third output.
-00018190: 2054 6869 730a 2020 2020 6f62 6a65 6374   This.    object
-000181a0: 2063 616e 2062 6520 7573 6564 2066 6f72   can be used for
-000181b0: 2076 6172 696f 7573 2061 6e61 6c79 7369   various analysi
-000181c0: 732c 2069 6e63 6c75 6469 6e67 206f 7074  s, including opt
-000181d0: 696d 697a 6174 696f 6e20 7669 7375 616c  imization visual
-000181e0: 697a 6174 696f 6e73 2e0a 2020 2020 5365  izations..    Se
-000181f0: 653a 2068 7474 7073 3a2f 2f6f 7074 756e  e: https://optun
-00018200: 612e 7265 6164 7468 6564 6f63 732e 696f  a.readthedocs.io
-00018210: 2f65 6e2f 7374 6162 6c65 2f72 6566 6572  /en/stable/refer
-00018220: 656e 6365 2f67 656e 6572 6174 6564 2f6f  ence/generated/o
-00018230: 7074 756e 612e 7374 7564 792e 5374 7564  ptuna.study.Stud
-00018240: 792e 6874 6d6c 0a0a 2020 2020 4578 616d  y.html..    Exam
-00018250: 706c 653a 0a20 2020 2020 2020 2054 6865  ple:.        The
-00018260: 2066 756e 6374 696f 6e20 7769 6c6c 2063   function will c
-00018270: 7265 6174 6520 7468 6520 636c 6173 7369  reate the classi
-00018280: 6669 6361 7469 6f6e 2065 6e67 696e 6520  fication engine 
-00018290: 616e 6420 6f70 7469 6d69 7a65 2074 6865  and optimize the
-000182a0: 2068 7970 6572 7061 7261 6d65 7465 7273   hyperparameters
-000182b0: 0a20 2020 2020 2020 2075 7369 6e67 2061  .        using a
-000182c0: 6e20 6974 6572 6174 6976 6520 6170 7072  n iterative appr
-000182d0: 6f61 6368 3a0a 0a20 2020 2020 2020 203e  oach:..        >
-000182e0: 3e3e 206d 6f64 656c 2c20 7061 7261 6d73  >> model, params
-000182f0: 203d 2068 7970 6572 5f6f 7074 2864 6174   = hyper_opt(dat
-00018300: 615f 782c 2064 6174 615f 792c 2063 6c66  a_x, data_y, clf
-00018310: 3d27 7266 2729 200a 2020 2020 2020 2020  ='rf') .        
-00018320: 0a20 2020 2020 2020 2054 6865 2066 6972  .        The fir
-00018330: 7374 206f 7574 7075 7420 6973 206f 7572  st output is our
-00018340: 206f 7074 696d 616c 2063 6c61 7373 6966   optimal classif
-00018350: 6965 722c 2061 6e64 2077 696c 6c20 6265  ier, and will be
-00018360: 2075 7365 6420 746f 206d 616b 6520 7072   used to make pr
-00018370: 6564 6963 7469 6f6e 733a 0a20 2020 2020  edictions:.     
-00018380: 2020 200a 2020 2020 2020 2020 3e3e 3e20     .        >>> 
-00018390: 7072 6564 6963 7469 6f6e 203d 206d 6f64  prediction = mod
-000183a0: 656c 2e70 7265 6469 6374 286e 6577 5f64  el.predict(new_d
-000183b0: 6174 6129 0a20 2020 2020 2020 200a 2020  ata).        .  
-000183c0: 2020 2020 2020 5468 6520 7365 636f 6e64        The second
-000183d0: 206f 7574 7075 7420 6f66 2074 6865 206f   output of the o
-000183e0: 7074 696d 697a 6520 6675 6e63 7469 6f6e  ptimize function
-000183f0: 2069 7320 7468 6520 6469 6374 696f 6e61   is the dictiona
-00018400: 7279 2063 6f6e 7461 696e 696e 670a 2020  ry containing.  
-00018410: 2020 2020 2020 7468 6520 6879 7065 7270        the hyperp
-00018420: 6172 616d 6574 6572 2063 6f6d 6269 6e61  arameter combina
-00018430: 7469 6f6e 2074 6861 7420 7969 656c 6465  tion that yielde
-00018440: 6420 7468 6520 6869 6768 6573 7420 6d65  d the highest me
-00018450: 616e 2061 6363 7572 6163 792e 0a0a 2020  an accuracy...  
-00018460: 2020 2020 2020 4966 2073 6176 655f 7374        If save_st
-00018470: 7564 7920 3d20 5472 7565 2c20 7468 6520  udy = True, the 
-00018480: 4f70 7475 6e61 2073 7475 6479 206f 626a  Optuna study obj
-00018490: 6563 7420 7769 6c6c 2061 6c73 6f20 6265  ect will also be
-000184a0: 2072 6574 7572 6e65 6420 6173 2074 6865   returned as the
-000184b0: 2074 6869 7264 206f 7574 7075 742e 0a20   third output.. 
-000184c0: 2020 2020 2020 2054 6869 7320 6361 6e20         This can 
-000184d0: 6265 2075 7365 6420 746f 2070 6c6f 7420  be used to plot 
-000184e0: 7468 6520 6f70 7469 6d69 7a61 7469 6f6e  the optimization
-000184f0: 2072 6573 756c 7473 2c20 7365 653a 2068   results, see: h
-00018500: 7474 7073 3a2f 2f6f 7074 756e 612e 7265  ttps://optuna.re
-00018510: 6164 7468 6564 6f63 732e 696f 2f65 6e2f  adthedocs.io/en/
-00018520: 6c61 7465 7374 2f74 7574 6f72 6961 6c2f  latest/tutorial/
-00018530: 3130 5f6b 6579 5f66 6561 7475 7265 732f  10_key_features/
-00018540: 3030 355f 7669 7375 616c 697a 6174 696f  005_visualizatio
-00018550: 6e2e 6874 6d6c 2373 7068 782d 676c 722d  n.html#sphx-glr-
-00018560: 7475 746f 7269 616c 2d31 302d 6b65 792d  tutorial-10-key-
-00018570: 6665 6174 7572 6573 2d30 3035 2d76 6973  features-005-vis
-00018580: 7561 6c69 7a61 7469 6f6e 2d70 790a 0a20  ualization-py.. 
-00018590: 2020 2020 2020 203e 3e3e 2066 726f 6d20         >>> from 
-000185a0: 6f70 7475 6e61 2e76 6973 7561 6c69 7a61  optuna.visualiza
-000185b0: 7469 6f6e 2e6d 6174 706c 6f74 6c69 6220  tion.matplotlib 
-000185c0: 696d 706f 7274 2070 6c6f 745f 636f 6e74  import plot_cont
-000185d0: 6f75 720a 2020 2020 2020 2020 3e3e 3e20  our.        >>> 
-000185e0: 0a20 2020 2020 2020 203e 3e3e 206d 6f64  .        >>> mod
-000185f0: 656c 2c20 7061 7261 6d73 2c20 7374 7564  el, params, stud
-00018600: 7920 3d20 6879 7065 725f 6f70 7428 6461  y = hyper_opt(da
-00018610: 7461 5f78 2c20 6461 7461 5f79 2c20 636c  ta_x, data_y, cl
-00018620: 663d 2772 6627 2c20 7361 7665 5f73 7475  f='rf', save_stu
-00018630: 6479 3d54 7275 6529 200a 2020 2020 2020  dy=True) .      
-00018640: 2020 3e3e 3e20 706c 6f74 5f63 6f6e 746f    >>> plot_conto
-00018650: 7572 2873 7475 6479 290a 0a20 2020 2020  ur(study)..     
-00018660: 2020 2049 6620 636c 663d 2761 6c65 786e     If clf='alexn
-00018670: 6574 2720 6f72 2061 6e79 206f 6620 7468  et' or any of th
-00018680: 6520 434e 4e20 6f70 7469 6f6e 732c 2074  e CNN options, t
-00018690: 6865 206d 6f64 656c 2069 7320 6e6f 7420  he model is not 
-000186a0: 7265 7475 726e 6564 2e0a 2020 2020 2020  returned..      
-000186b0: 2020 0a20 2020 2041 7267 733a 0a20 2020    .    Args:.   
-000186c0: 2020 2020 2064 6174 615f 7820 286e 6461       data_x (nda
-000186d0: 7272 6179 293a 2032 4420 6172 7261 7920  rray): 2D array 
-000186e0: 6f66 2073 697a 6520 286e 2078 206d 292c  of size (n x m),
-000186f0: 2077 6865 7265 206e 2069 7320 7468 650a   where n is the.
-00018700: 2020 2020 2020 2020 2020 2020 6e75 6d62              numb
-00018710: 6572 206f 6620 7361 6d70 6c65 732c 2061  er of samples, a
-00018720: 6e64 206d 2074 6865 206e 756d 6265 7220  nd m the number 
-00018730: 6f66 2066 6561 7475 7265 732e 2049 6620  of features. If 
-00018740: 636c 663d 2761 6c65 786e 6574 2720 6f72  clf='alexnet' or
-00018750: 2061 6e79 206f 6620 7468 6520 434e 4e20   any of the CNN 
-00018760: 6f70 7469 6f6e 732c 200a 2020 2020 2020  options, .      
-00018770: 2020 2020 2020 7468 6520 7361 6d70 6c65        the sample
-00018780: 7320 666f 7220 7468 6520 6669 7273 7420  s for the first 
-00018790: 636c 6173 7320 7368 6f75 6c64 2062 6520  class should be 
-000187a0: 7061 7373 6564 2c20 7768 6963 6820 7769  passed, which wi
-000187b0: 6c6c 2061 7574 6f6d 6174 6963 616c 6c79  ll automatically
-000187c0: 200a 2020 2020 2020 2020 2020 2020 6265   .            be
-000187d0: 2061 7373 6967 6e65 6420 7468 6520 706f   assigned the po
-000187e0: 7369 7469 7665 206c 6162 656c 2027 3127  sitive label '1'
-000187f0: 2e0a 2020 2020 2020 2020 6461 7461 5f79  ..        data_y
-00018800: 2028 6e64 6172 7261 792c 2073 7472 293a   (ndarray, str):
-00018810: 2031 4420 6172 7261 7920 636f 6e74 6169   1D array contai
-00018820: 6e69 6e67 2074 6865 2063 6f72 7265 7370  ning the corresp
-00018830: 6f6e 696e 6720 6c61 6265 6c73 2e20 4966  oning labels. If
-00018840: 2063 6c66 3d27 616c 6578 6e65 7427 206f   clf='alexnet' o
-00018850: 7220 616e 7920 6f66 2074 6865 2043 4e4e  r any of the CNN
-00018860: 206f 7074 696f 6e73 2c20 0a20 2020 2020   options, .     
-00018870: 2020 2020 2020 2074 6865 2073 616d 706c         the sampl
-00018880: 6573 2066 6f72 2074 6865 2073 6563 6f6e  es for the secon
-00018890: 6420 636c 6173 7320 7368 6f75 6c64 2062  d class should b
-000188a0: 6520 7061 7373 6564 2c20 7768 6963 6820  e passed, which 
-000188b0: 7769 6c6c 2061 7574 6f6d 6174 6963 616c  will automatical
-000188c0: 6c79 0a20 2020 2020 2020 2020 2020 2062  ly.            b
-000188d0: 6520 6173 7369 676e 6564 2074 6865 206e  e assigned the n
-000188e0: 6567 6174 6976 6520 6c61 6265 6c20 2730  egative label '0
-000188f0: 272e 0a20 2020 2020 2020 2063 6c66 2028  '..        clf (
-00018900: 7374 7229 3a20 5468 6520 6d61 6368 696e  str): The machin
-00018910: 6520 6c65 6172 6e69 6e67 2063 6c61 7373  e learning class
-00018920: 6966 6965 7220 746f 206f 7074 696d 697a  ifier to optimiz
-00018930: 652e 2043 616e 2065 6974 6865 7220 6265  e. Can either be
-00018940: 0a20 2020 2020 2020 2020 2020 2027 7266  .            'rf
-00018950: 2720 666f 7220 5261 6e64 6f6d 2046 6f72  ' for Random For
-00018960: 6573 742c 2027 6e6e 2720 666f 7220 4e65  est, 'nn' for Ne
-00018970: 7572 616c 204e 6574 776f 726b 2c20 2778  ural Network, 'x
-00018980: 6762 2720 666f 7220 6558 7472 656d 6520  gb' for eXtreme 
-00018990: 4772 6164 6965 6e74 2042 6f6f 7374 696e  Gradient Boostin
-000189a0: 672c 0a20 2020 2020 2020 2020 2020 206f  g,.            o
-000189b0: 7220 2761 6c65 786e 6574 2720 6f72 2061  r 'alexnet' or a
-000189c0: 6e79 206f 6620 7468 6520 434e 4e20 6f70  ny of the CNN op
-000189d0: 7469 6f6e 732c 2066 6f72 2043 6f6e 766f  tions, for Convo
-000189e0: 6c75 7469 6f6e 616c 204e 6575 7261 6c20  lutional Neural 
-000189f0: 4e65 7477 6f72 6b2e 2044 6566 6175 6c74  Network. Default
-00018a00: 7320 746f 2027 7266 272e 0a20 2020 2020  s to 'rf'..     
-00018a10: 2020 206e 5f69 7465 7220 2869 6e74 2c20     n_iter (int, 
-00018a20: 6f70 7469 6f6e 616c 293a 2054 6865 206d  optional): The m
-00018a30: 6178 696d 756d 206e 756d 6265 7220 6f66  aximum number of
-00018a40: 2069 7465 7261 7469 6f6e 7320 746f 2070   iterations to p
-00018a50: 6572 666f 726d 2064 7572 696e 6720 0a20  erform during . 
-00018a60: 2020 2020 2020 2020 2020 2074 6865 2068             the h
-00018a70: 7970 6572 7061 7261 6d65 7465 7220 7365  yperparameter se
-00018a80: 6172 6368 2e20 4465 6661 756c 7473 2074  arch. Defaults t
-00018a90: 6f20 3235 2e0a 2020 2020 2020 2020 6f70  o 25..        op
-00018aa0: 745f 6376 2028 696e 7429 3a20 4372 6f73  t_cv (int): Cros
-00018ab0: 732d 7661 6c69 6461 7469 6f6e 7320 746f  s-validations to
-00018ac0: 2070 6572 666f 726d 2077 6865 6e20 6173   perform when as
-00018ad0: 7365 7369 6e67 2074 6865 2070 6572 666f  sesing the perfo
-00018ae0: 726d 616e 6365 2061 7420 6561 6368 0a20  rmance at each. 
-00018af0: 2020 2020 2020 2020 2020 2068 7970 6572             hyper
-00018b00: 7061 7261 6d65 7465 7220 6f70 7469 6d69  parameter optimi
-00018b10: 7a61 7469 6f6e 2074 7269 616c 2e20 466f  zation trial. Fo
-00018b20: 7220 6578 616d 706c 652c 2069 6620 6376  r example, if cv
-00018b30: 3d33 2c20 7468 656e 2065 6163 6820 6f70  =3, then each op
-00018b40: 7469 6d69 7a61 7469 6f6e 2074 7269 616c  timization trial
-00018b50: 0a20 2020 2020 2020 2020 2020 2077 696c  .            wil
-00018b60: 6c20 6265 2061 7373 6573 7365 6420 6163  l be assessed ac
-00018b70: 636f 7264 696e 6720 746f 2074 6865 2033  cording to the 3
-00018b80: 2d66 6f6c 6420 6372 6f73 7320 7661 6c69  -fold cross vali
-00018b90: 6461 7469 6f6e 2061 6363 7572 6163 792e  dation accuracy.
-00018ba0: 200a 2020 2020 2020 2020 2020 2020 4966   .            If
-00018bb0: 2063 6c66 3d27 7867 6227 2061 6e64 2074   clf='xgb' and t
-00018bc0: 6869 7320 7661 6c75 6520 6973 2073 6574  his value is set
-00018bd0: 2062 6574 7765 656e 2030 2061 6e64 2031   between 0 and 1
-00018be0: 2c20 7468 6973 2073 6574 7320 7468 6520  , this sets the 
-00018bf0: 7369 7a65 206f 6620 7468 6520 7661 6c69  size of the vali
-00018c00: 6461 7469 6f6e 2064 6174 612c 200a 2020  dation data, .  
-00018c10: 2020 2020 2020 2020 2020 7768 6963 6820            which 
-00018c20: 7769 6c6c 2062 6520 6368 6f73 656e 2072  will be chosen r
-00018c30: 616e 646f 6d6c 7920 6561 6368 2074 7269  andomly each tri
-00018c40: 616c 2e20 5468 6973 2069 7320 7573 6564  al. This is used
-00018c50: 2074 6f20 656e 6162 6c65 2061 6e20 6561   to enable an ea
-00018c60: 726c 7920 7374 6f70 7069 6e67 2063 616c  rly stopping cal
-00018c70: 6c62 6163 6b20 7768 6963 6820 0a20 2020  lback which .   
-00018c80: 2020 2020 2020 2020 2069 7320 6e6f 7420           is not 
-00018c90: 706f 7373 6962 6c65 2077 6974 6820 7468  possible with th
-00018ca0: 6520 6372 6f73 732d 7661 6c69 6461 7469  e cross-validati
-00018cb0: 6f6e 206d 6574 686f 642e 2044 6566 6175  on method. Defau
-00018cc0: 6c74 7320 746f 2031 302e 200a 2020 2020  lts to 10. .    
-00018cd0: 2020 2020 6c69 6d69 745f 7365 6172 6368      limit_search
-00018ce0: 2028 626f 6f6c 293a 2049 6620 5472 7565   (bool): If True
-00018cf0: 2074 6865 206f 7074 696d 697a 6174 696f   the optimizatio
-00018d00: 6e20 7365 6172 6368 2073 7061 6365 7320  n search spaces 
-00018d10: 7769 6c6c 2062 6520 6c69 6d69 7465 642c  will be limited,
-00018d20: 2066 6f72 2063 6f6d 7075 7461 7469 6f6e   for computation
-00018d30: 616c 2061 6e64 2074 696d 6520 7075 7270  al and time purp
-00018d40: 6f73 6573 2e20 0a20 2020 2020 2020 2020  oses. .         
-00018d50: 2020 2054 6869 7320 6973 2065 7370 6563     This is espec
-00018d60: 6961 6c6c 7920 696d 706f 7274 616e 7420  ially important 
-00018d70: 6966 2074 756e 696e 6720 6120 434e 4e20  if tuning a CNN 
-00018d80: 6d6f 6465 6c2c 2061 7320 6d65 6d6f 7279  model, as memory
-00018d90: 2065 7272 6f72 7320 6361 6e20 6265 2065   errors can be e
-00018da0: 6e63 6f75 6e74 6572 6564 2e20 4465 6661  ncountered. Defa
-00018db0: 756c 7473 2074 6f20 5472 7565 2e0a 2020  ults to True..  
-00018dc0: 2020 2020 2020 6261 6c61 6e63 6520 2862        balance (b
-00018dd0: 6f6f 6c2c 206f 7074 696f 6e61 6c29 3a20  ool, optional): 
-00018de0: 4966 2054 7275 652c 2061 2077 6569 6768  If True, a weigh
-00018df0: 7473 2061 7272 6179 2077 696c 6c20 6265  ts array will be
-00018e00: 2063 616c 6375 6c61 7465 6420 616e 6420   calculated and 
-00018e10: 7573 6564 0a20 2020 2020 2020 2020 2020  used.           
-00018e20: 2077 6865 6e20 6669 7474 696e 6720 7468   when fitting th
-00018e30: 6520 636c 6173 7369 6669 6572 2e20 5468  e classifier. Th
-00018e40: 6973 2063 616e 2069 6d70 726f 7665 2063  is can improve c
-00018e50: 6c61 7373 6966 6963 6174 696f 6e20 7768  lassification wh
-00018e60: 656e 2063 6c61 7373 6573 0a20 2020 2020  en classes.     
-00018e70: 2020 2020 2020 2061 7265 2069 6d62 616c         are imbal
-00018e80: 616e 6365 642e 2054 6869 7320 6973 206f  anced. This is o
-00018e90: 6e6c 7920 6170 706c 6965 6420 6966 2074  nly applied if t
-00018ea0: 6865 2063 6c61 7373 6966 6963 6174 696f  he classificatio
-00018eb0: 6e20 6973 2061 2062 696e 6172 7920 7461  n is a binary ta
-00018ec0: 736b 2e20 0a20 2020 2020 2020 2020 2020  sk. .           
-00018ed0: 2044 6566 6175 6c74 7320 746f 2054 7275   Defaults to Tru
-00018ee0: 652e 2049 6620 636c 663d 2761 6c65 786e  e. If clf='alexn
-00018ef0: 6574 2720 6f72 2061 6e79 206f 6620 7468  et' or any of th
-00018f00: 6520 434e 4e20 6f70 7469 6f6e 732c 2074  e CNN options, t
-00018f10: 6869 7320 7769 6c6c 2064 6574 6572 6d69  his will determi
-00018f20: 6e65 2077 6865 7468 6572 2074 6865 2074  ne whether the t
-00018f30: 776f 2063 6c61 7373 6573 0a20 2020 2020  wo classes.     
-00018f40: 2020 2020 2020 2061 7265 206b 6570 7420         are kept 
-00018f50: 7468 6520 7361 6d65 2073 697a 6520 6475  the same size du
-00018f60: 7269 6e67 206f 7074 696d 697a 6174 696f  ring optimizatio
-00018f70: 6e2c 2061 7070 6c69 6361 626c 6520 6966  n, applicable if
-00018f80: 2074 756e 696e 6720 7468 6520 6175 676d   tuning the augm
-00018f90: 656e 7461 7469 6f6e 0a20 2020 2020 2020  entation.       
-00018fa0: 2020 2020 2070 6172 616d 6574 6572 732e       parameters.
-00018fb0: 2044 6566 6175 6c74 7320 746f 2054 7275   Defaults to Tru
-00018fc0: 652e 0a20 2020 2020 2020 2072 6574 7572  e..        retur
-00018fd0: 6e5f 7374 7564 7920 2862 6f6f 6c2c 206f  n_study (bool, o
-00018fe0: 7074 696f 6e61 6c29 3a20 4966 2054 7275  ptional): If Tru
-00018ff0: 6520 7468 6520 4f70 7475 6e61 2073 7475  e the Optuna stu
-00019000: 6479 206f 626a 6563 7420 7769 6c6c 2062  dy object will b
-00019010: 6520 7265 7475 726e 6564 2e20 5468 6973  e returned. This
-00019020: 0a20 2020 2020 2020 2020 2020 2063 616e  .            can
-00019030: 2062 6520 7573 6564 2074 6f20 7265 7669   be used to revi
-00019040: 6577 2074 6865 206d 6574 686f 6420 6174  ew the method at
-00019050: 7472 6962 7574 6573 2c20 7375 6368 2061  tributes, such a
-00019060: 7320 6f70 7469 6d69 7a61 7469 6f6e 2070  s optimization p
-00019070: 6c6f 7473 2e20 4465 6661 756c 7473 2074  lots. Defaults t
-00019080: 6f20 5472 7565 2e0a 0a20 2020 2054 6865  o True...    The
-00019090: 2066 6f6c 6c6c 6f77 696e 6720 6172 6775   folllowing argu
-000190a0: 6d65 6e74 7320 6172 6520 6f6e 6c79 2075  ments are only u
-000190b0: 7365 6420 7768 656e 206f 7074 696d 697a  sed when optimiz
-000190c0: 696e 6720 7468 6520 434e 4e20 6e65 7477  ing the CNN netw
-000190d0: 6f72 6b3a 0a0a 2020 2020 4172 6773 3a0a  ork:..    Args:.
-000190e0: 2020 2020 2020 2020 696d 675f 6e75 6d5f          img_num_
-000190f0: 6368 616e 6e65 6c73 2028 696e 7429 3a20  channels (int): 
-00019100: 5468 6520 6e75 6d62 6572 206f 6620 6669  The number of fi
-00019110: 6c74 6572 732e 2044 6566 6175 6c74 7320  lters. Defaults 
-00019120: 746f 2031 2e0a 2020 2020 2020 2020 6e6f  to 1..        no
-00019130: 726d 616c 697a 6520 2862 6f6f 6c2c 206f  rmalize (bool, o
-00019140: 7074 696f 6e61 6c29 3a20 4966 2054 7275  ptional): If Tru
-00019150: 6520 7468 6520 6461 7461 2077 696c 6c20  e the data will 
-00019160: 6265 206d 696e 2d6d 6178 206e 6f72 6d61  be min-max norma
-00019170: 6c69 7a65 6420 7573 696e 6720 7468 6520  lized using the 
-00019180: 0a20 2020 2020 2020 2020 2020 2069 6e70  .            inp
-00019190: 7574 206d 696e 2061 6e64 206d 6178 2070  ut min and max p
-000191a0: 6978 656c 732e 2044 6566 6175 6c74 7320  ixels. Defaults 
-000191b0: 746f 2054 7275 652e 0a20 2020 2020 2020  to True..       
-000191c0: 206d 696e 5f70 6978 656c 2028 696e 742c   min_pixel (int,
-000191d0: 206f 7074 696f 6e61 6c29 3a20 5468 6520   optional): The 
-000191e0: 6d69 6e69 6d75 6d20 7069 7865 6c20 636f  minimum pixel co
-000191f0: 756e 742c 2070 6978 656c 7320 7769 7468  unt, pixels with
-00019200: 2063 6f75 6e74 7320 0a20 2020 2020 2020   counts .       
-00019210: 2020 2020 2062 656c 6f77 2074 6869 7320       below this 
-00019220: 7468 7265 7368 6f6c 6420 7769 6c6c 2062  threshold will b
-00019230: 6520 7365 7420 746f 2074 6869 7320 6c69  e set to this li
-00019240: 6d69 742e 2044 6566 6175 6c74 7320 746f  mit. Defaults to
-00019250: 2030 2e0a 2020 2020 2020 2020 6d61 785f   0..        max_
-00019260: 7069 7865 6c20 2869 6e74 2c20 6c69 7374  pixel (int, list
-00019270: 2c20 6f70 7469 6f6e 616c 293a 2054 6865  , optional): The
-00019280: 206d 6178 696d 756d 2070 6978 656c 2063   maximum pixel c
-00019290: 6f75 6e74 2c20 7069 7865 6c73 2077 6974  ount, pixels wit
-000192a0: 6820 636f 756e 7473 200a 2020 2020 2020  h counts .      
-000192b0: 2020 2020 2020 6162 6f76 6520 7468 6973        above this
-000192c0: 2074 6872 6573 686f 6c64 2077 696c 6c20   threshold will 
-000192d0: 6265 2073 6574 2074 6f20 7468 6973 206c  be set to this l
-000192e0: 696d 6974 2e20 4465 6661 756c 7473 2074  imit. Defaults t
-000192f0: 6f20 3130 302e 2049 6620 696d 675f 6e75  o 100. If img_nu
-00019300: 6d5f 6368 616e 6e65 6c73 0a20 2020 2020  m_channels.     
-00019310: 2020 2020 2020 2069 7320 6e6f 7420 312c         is not 1,
-00019320: 2074 6865 206d 6178 5f70 6978 656c 2073   the max_pixel s
-00019330: 686f 756c 6420 6265 2061 206c 6973 7420  hould be a list 
-00019340: 636f 6e74 6169 6e69 6e67 2074 776f 2076  containing two v
-00019350: 616c 7565 732c 206f 6e65 2066 6f72 2065  alues, one for e
-00019360: 6163 6820 6261 6e64 2e0a 2020 2020 2020  ach band..      
-00019370: 2020 7661 6c5f 706f 7369 7469 7665 2028    val_positive (
-00019380: 6e64 6172 7261 792c 206f 7074 696f 6e61  ndarray, optiona
-00019390: 6c29 3a20 506f 7369 7469 7665 2063 6c61  l): Positive cla
-000193a0: 7373 2064 6174 6120 746f 2062 6520 7573  ss data to be us
-000193b0: 6564 2066 6f72 2076 616c 6964 6174 696f  ed for validatio
-000193c0: 6e2e 2044 6566 6175 6c74 7320 746f 204e  n. Defaults to N
-000193d0: 6f6e 652e 0a20 2020 2020 2020 2076 616c  one..        val
-000193e0: 5f6e 6567 6174 6976 6520 286e 6461 7272  _negative (ndarr
-000193f0: 6179 2c20 6f70 7469 6f6e 616c 293a 204e  ay, optional): N
-00019400: 6567 6174 6976 6520 636c 6173 7320 6461  egative class da
-00019410: 7461 2074 6f20 6265 2075 7365 6420 666f  ta to be used fo
-00019420: 7220 7661 6c69 6461 7469 6f6e 2e20 4465  r validation. De
-00019430: 6661 756c 7473 2074 6f20 4e6f 6e65 2e0a  faults to None..
-00019440: 2020 2020 2020 2020 7465 7374 5f70 6f73          test_pos
-00019450: 6974 6976 6520 286e 6461 7272 6179 2c20  itive (ndarray, 
-00019460: 6f70 7469 6f6e 616c 293a 2050 6f73 6974  optional): Posit
-00019470: 6976 6520 636c 6173 7320 6461 7461 2074  ive class data t
-00019480: 6f20 6265 2075 7365 6420 666f 7220 706f  o be used for po
-00019490: 7374 2d74 7269 616c 2074 6573 7469 6e67  st-trial testing
-000194a0: 2e20 4465 6661 756c 7473 2074 6f20 4e6f  . Defaults to No
-000194b0: 6e65 2e0a 2020 2020 2020 2020 7465 7374  ne..        test
-000194c0: 5f6e 6567 6174 6976 6520 286e 6461 7272  _negative (ndarr
-000194d0: 6179 2c20 6f70 7469 6f6e 616c 293a 204e  ay, optional): N
-000194e0: 6567 6174 6976 6520 636c 6173 7320 6461  egative class da
-000194f0: 7461 2074 6f20 6265 2075 7365 6420 666f  ta to be used fo
-00019500: 7220 706f 7374 2d74 7269 616c 2074 6573  r post-trial tes
-00019510: 7469 6e67 2e20 4465 6661 756c 7473 2074  ting. Defaults t
-00019520: 6f20 4e6f 6e65 2e0a 2020 2020 2020 2020  o None..        
-00019530: 7472 6169 6e5f 6570 6f63 6873 2028 696e  train_epochs (in
-00019540: 7429 3a20 4e75 6d62 6572 206f 6620 6570  t): Number of ep
-00019550: 6f63 6873 2074 6f20 7468 6520 7472 6169  ochs to the trai
-00019560: 6e20 7468 6520 434e 4e20 746f 2064 7572  n the CNN to dur
-00019570: 696e 6720 7468 6520 6f70 7469 6d69 7a61  ing the optimiza
-00019580: 7469 6f6e 2074 7269 616c 732e 2044 6566  tion trials. Def
-00019590: 6175 6c74 7320 746f 2032 352e 0a20 2020  aults to 25..   
-000195a0: 2020 2020 206d 6574 7269 6320 2873 7472       metric (str
-000195b0: 293a 2041 7373 6573 6d65 6e74 206d 6574  ): Assesment met
-000195c0: 7269 6320 746f 2075 7365 2077 6865 6e20  ric to use when 
-000195d0: 626f 7468 2070 7275 6e69 6e67 2061 6e64  both pruning and
-000195e0: 2073 636f 7269 6e67 2074 6865 2068 7970   scoring the hyp
-000195f0: 6572 7061 7261 6d65 7465 7220 6f70 7469  erparameter opti
-00019600: 6d69 7a61 7469 6f6e 2074 7269 616c 2e0a  mization trial..
-00019610: 2020 2020 2020 2020 2020 2020 4465 6661              Defa
-00019620: 756c 7473 2074 6f20 276c 6f73 7327 2e20  ults to 'loss'. 
-00019630: 4f70 7469 6f6e 7320 696e 636c 7564 653a  Options include:
-00019640: 2027 6c6f 7373 2720 2762 696e 6172 795f   'loss' 'binary_
-00019650: 6163 6375 7261 6379 272c 2027 6631 5f73  accuracy', 'f1_s
-00019660: 636f 7265 2720 2761 6c6c 2720 6f72 2074  core' 'all' or t
-00019670: 6865 2076 616c 6964 6174 696f 6e20 6571  he validation eq
-00019680: 7569 7661 6c65 6e74 7320 2865 2e67 2e20  uivalents (e.g. 
-00019690: 2776 616c 5f6c 6f73 7327 292e 0a20 2020  'val_loss')..   
-000196a0: 2020 2020 2070 6174 6965 6e63 6520 2869       patience (i
-000196b0: 6e74 293a 204e 756d 6265 7220 6f66 2065  nt): Number of e
-000196c0: 706f 6368 7320 7769 7468 6f75 7420 696d  pochs without im
-000196d0: 7072 6f76 656d 656e 7420 6265 666f 7265  provement before
-000196e0: 2074 6865 206f 7074 696d 697a 6174 696f   the optimizatio
-000196f0: 6e20 7472 6961 6c20 6973 2074 6572 6d69  n trial is termi
-00019700: 6e61 7465 642e 2044 6566 6175 6c74 7320  nated. Defaults 
-00019710: 746f 2030 2c20 7768 6963 680a 2020 2020  to 0, which.    
-00019720: 2020 2020 2020 2020 6469 7361 626c 6573          disables
-00019730: 2074 6869 7320 6665 6174 7572 652e 0a20   this feature.. 
-00019740: 2020 2020 2020 2061 7665 7261 6765 2028         average (
-00019750: 626f 6f6c 293a 2049 6620 4661 6c73 652c  bool): If False,
-00019760: 2074 6865 2064 6573 6967 6e61 7465 6420   the designated 
-00019770: 6d65 7472 6963 2077 696c 6c20 6265 2063  metric will be c
-00019780: 616c 6375 6c61 7465 6420 6163 636f 7264  alculated accord
-00019790: 696e 6720 746f 2069 7473 2076 616c 7565  ing to its value
-000197a0: 2061 7420 7468 6520 656e 6420 6f66 2074   at the end of t
-000197b0: 6865 2074 7261 696e 5f65 706f 6368 732e  he train_epochs.
-000197c0: 200a 2020 2020 2020 2020 2020 2020 4966   .            If
-000197d0: 2054 7275 652c 2074 6865 206d 6574 7269   True, the metri
-000197e0: 6320 7769 6c6c 2062 6520 6176 6572 6167  c will be averag
-000197f0: 6564 206f 7574 2061 6372 6f73 7320 616c  ed out across al
-00019800: 6c20 7472 6169 6e5f 6570 6f63 6873 2e20  l train_epochs. 
-00019810: 4465 6661 756c 7473 2074 6f20 5472 7565  Defaults to True
-00019820: 2e0a 0a20 2020 2020 2020 206f 7074 5f6d  ...        opt_m
-00019830: 6f64 656c 2028 626f 6f6c 293a 2049 6620  odel (bool): If 
-00019840: 5472 7565 2c20 7468 6520 6172 6368 6974  True, the archit
-00019850: 6563 7475 7265 2070 6172 616d 6574 6572  ecture parameter
-00019860: 7320 7769 6c6c 2062 6520 6f70 7469 6d69  s will be optimi
-00019870: 7a65 642e 2044 6566 6175 6c74 7320 746f  zed. Defaults to
-00019880: 2054 7275 652e 0a20 2020 2020 2020 206f   True..        o
-00019890: 7074 5f61 7567 2028 626f 6f6c 293a 2049  pt_aug (bool): I
-000198a0: 6620 5472 7565 2c20 7468 6520 6175 676d  f True, the augm
-000198b0: 656e 7461 7469 6f6e 2070 726f 6365 6475  entation procedu
-000198c0: 7265 2077 696c 6c20 6265 206f 7074 696d  re will be optim
-000198d0: 697a 6564 2e20 4465 6661 756c 7473 2074  ized. Defaults t
-000198e0: 6f20 4661 6c73 652e 0a20 2020 2020 2020  o False..       
-000198f0: 2062 6174 6368 5f6d 696e 2028 696e 7429   batch_min (int)
-00019900: 3a20 5468 6520 6d69 6e69 6d75 6d20 6e75  : The minimum nu
-00019910: 6d62 6572 206f 6620 6175 676d 656e 7461  mber of augmenta
-00019920: 7469 6f6e 7320 746f 2070 6572 666f 726d  tions to perform
-00019930: 2070 6572 2069 6d61 6765 206f 6e20 7468   per image on th
-00019940: 6520 706f 7369 7469 7665 2063 6c61 7373  e positive class
-00019950: 2c20 6f6e 6c79 2061 7070 6c69 6361 626c  , only applicabl
-00019960: 6520 0a20 2020 2020 2020 2020 2020 2069  e .            i
-00019970: 6620 6f70 745f 6175 673d 5472 7565 2e20  f opt_aug=True. 
-00019980: 4465 6661 756c 7473 2074 6f20 322e 0a20  Defaults to 2.. 
-00019990: 2020 2020 2020 2062 6174 6368 5f6d 6178         batch_max
-000199a0: 2028 696e 7429 3a20 5468 6520 6d61 7869   (int): The maxi
-000199b0: 6d75 6d20 6e75 6d62 6572 206f 6620 6175  mum number of au
-000199c0: 676d 656e 7461 7469 6f6e 7320 746f 2070  gmentations to p
-000199d0: 6572 666f 726d 2070 6572 2069 6d61 6765  erform per image
-000199e0: 206f 6e20 7468 6520 706f 7369 7469 7665   on the positive
-000199f0: 2063 6c61 7373 2c20 6f6e 6c79 2061 7070   class, only app
-00019a00: 6c69 6361 626c 6520 0a20 2020 2020 2020  licable .       
-00019a10: 2020 2020 2069 6620 6f70 745f 6175 673d       if opt_aug=
-00019a20: 5472 7565 2e20 4465 6661 756c 7473 2074  True. Defaults t
-00019a30: 6f20 3235 2e0a 2020 2020 2020 2020 6261  o 25..        ba
-00019a40: 7463 685f 6f74 6865 7220 2869 6e74 293a  tch_other (int):
-00019a50: 2054 6865 206e 756d 6265 7220 6f66 2061   The number of a
-00019a60: 7567 6d65 6e74 6174 696f 6e73 2074 6f20  ugmentations to 
-00019a70: 7065 7266 6f72 6d20 746f 2074 6865 206f  perform to the o
-00019a80: 7468 6572 2063 6c61 7373 2c20 7072 6573  ther class, pres
-00019a90: 756d 6564 2074 6f20 6265 2074 6865 206d  umed to be the m
-00019aa0: 616a 6f72 6974 7920 636c 6173 732e 0a20  ajority class.. 
-00019ab0: 2020 2020 2020 2020 2020 2044 6566 6175             Defau
-00019ac0: 6c74 7320 746f 2031 2e20 5468 6973 2069  lts to 1. This i
-00019ad0: 7320 646f 6e65 2074 6f20 656e 7375 7265  s done to ensure
-00019ae0: 2061 7567 6d65 6e74 6174 696f 6e20 7465   augmentation te
-00019af0: 6368 6e69 7175 6573 2061 7265 2061 7070  chniques are app
-00019b00: 6c69 6564 2063 6f6e 7369 7374 656e 746c  lied consistentl
-00019b10: 7920 6163 726f 7373 2062 6f74 6820 636c  y across both cl
-00019b20: 6173 7365 732e 2020 2020 2020 2020 0a20  asses.        . 
-00019b30: 2020 2020 2020 2069 6d61 6765 5f73 697a         image_siz
-00019b40: 655f 6d69 6e20 2869 6e74 293a 2054 6865  e_min (int): The
-00019b50: 206d 696e 696d 756d 2069 6d61 6765 2073   minimum image s
-00019b60: 697a 6520 746f 2061 7373 6573 732c 206f  ize to assess, o
-00019b70: 6e6c 7920 6170 706c 6963 6162 6c65 2069  nly applicable i
-00019b80: 6620 6f70 745f 6175 673d 5472 7565 2e20  f opt_aug=True. 
-00019b90: 4465 6661 756c 7473 2074 6f20 3530 2e0a  Defaults to 50..
-00019ba0: 2020 2020 2020 2020 696d 6167 655f 7369          image_si
-00019bb0: 7a65 5f6d 6178 2028 696e 7429 3a20 5468  ze_max (int): Th
-00019bc0: 6520 6d61 7869 6d75 6d20 696d 6167 6520  e maximum image 
-00019bd0: 7369 7a65 2074 6f20 6173 7365 7373 2c20  size to assess, 
-00019be0: 6f6e 6c79 2061 7070 6c69 6361 626c 6520  only applicable 
-00019bf0: 6966 206f 7074 5f61 7567 3d54 7275 652e  if opt_aug=True.
-00019c00: 2044 6566 6175 6c74 7320 746f 2031 3030   Defaults to 100
-00019c10: 2e0a 2020 2020 2020 2020 6f70 745f 6d61  ..        opt_ma
-00019c20: 785f 6d69 6e5f 7069 7820 2869 6e74 2c20  x_min_pix (int, 
-00019c30: 6f70 7469 6f6e 616c 293a 2054 6865 206d  optional): The m
-00019c40: 696e 696d 756d 206d 6178 2070 6978 656c  inimum max pixel
-00019c50: 2076 616c 7565 2074 6f20 7573 6520 7768   value to use wh
-00019c60: 656e 2074 756e 696e 6720 7468 6520 6e6f  en tuning the no
-00019c70: 726d 616c 697a 6174 696f 6e20 7072 6f63  rmalization proc
-00019c80: 6564 7572 652c 200a 2020 2020 2020 2020  edure, .        
-00019c90: 2020 2020 6f6e 6c79 2061 7070 6c69 6361      only applica
-00019ca0: 626c 6520 6966 206f 7074 5f61 7567 3d54  ble if opt_aug=T
-00019cb0: 7275 652e 2044 6566 6175 6c74 7320 746f  rue. Defaults to
-00019cc0: 204e 6f6e 652e 0a20 2020 2020 2020 206f   None..        o
-00019cd0: 7074 5f6d 6178 5f6d 6178 5f70 6978 2028  pt_max_max_pix (
-00019ce0: 696e 742c 206f 7074 696f 6e61 6c29 3a20  int, optional): 
-00019cf0: 5468 6520 6d61 7869 6d75 6d20 6d61 7820  The maximum max 
-00019d00: 7069 7865 6c20 7661 6c75 6520 746f 2075  pixel value to u
-00019d10: 7365 2077 6865 6e20 7475 6e69 6e67 2074  se when tuning t
-00019d20: 6865 206e 6f72 6d61 6c69 7a61 7469 6f6e  he normalization
-00019d30: 2070 726f 6365 6475 7265 2c20 0a20 2020   procedure, .   
-00019d40: 2020 2020 2020 2020 206f 6e6c 7920 6170           only ap
-00019d50: 706c 6963 6162 6c65 2069 6620 6f70 745f  plicable if opt_
-00019d60: 6175 673d 5472 7565 2e20 4465 6661 756c  aug=True. Defaul
-00019d70: 7473 2074 6f20 4e6f 6e65 2e0a 2020 2020  ts to None..    
-00019d80: 2020 2020 7368 6966 7420 2869 6e74 293a      shift (int):
-00019d90: 2054 6865 206d 6178 2061 6c6c 6f77 6564   The max allowed
-00019da0: 2076 6572 7469 6361 6c2f 686f 7269 7a6f   vertical/horizo
-00019db0: 6e74 616c 2073 6869 6674 7320 746f 2075  ntal shifts to u
-00019dc0: 7365 2064 7572 696e 6720 7468 6520 6461  se during the da
-00019dd0: 7461 2061 7567 6d65 6e74 6174 696f 6e20  ta augmentation 
-00019de0: 726f 7574 696e 652c 206f 6e6c 7920 6170  routine, only ap
-00019df0: 706c 6963 6162 6c65 0a20 2020 2020 2020  plicable.       
-00019e00: 2020 2020 2069 6620 6f70 745f 6175 673d       if opt_aug=
-00019e10: 5472 7565 2e20 4465 6661 756c 7473 2074  True. Defaults t
-00019e20: 6f20 3130 2070 6978 656c 732e 0a20 2020  o 10 pixels..   
-00019e30: 2020 2020 206d 6173 6b5f 7369 7a65 2028       mask_size (
-00019e40: 696e 742c 206f 7074 696f 6e61 6c29 3a20  int, optional): 
-00019e50: 4966 2065 6e61 626c 6564 2c20 7468 6973  If enabled, this
-00019e60: 2077 696c 6c20 7365 7420 7468 6520 7069   will set the pi
-00019e70: 7865 6c20 6c65 6e67 7468 206f 6620 6120  xel length of a 
-00019e80: 7371 7561 7265 2063 7574 6f75 742c 2074  square cutout, t
-00019e90: 6f20 6265 2072 616e 646f 6d6c 7920 706c  o be randomly pl
-00019ea0: 6163 6564 0a20 2020 2020 2020 2020 2020  aced.           
-00019eb0: 2073 6f6d 6577 6865 7265 2069 6e20 7468   somewhere in th
-00019ec0: 6520 6175 676d 656e 7465 6420 696d 6167  e augmented imag
-00019ed0: 652e 2054 6869 7320 6375 746f 7574 2077  e. This cutout w
-00019ee0: 696c 6c20 7265 706c 6163 6520 7468 6520  ill replace the 
-00019ef0: 696d 6167 6520 7661 6c75 6573 2077 6974  image values wit
-00019f00: 6820 302c 2074 6865 7265 666f 7265 2073  h 0, therefore s
-00019f10: 6572 7669 6e67 2061 7320 6120 0a20 2020  erving as a .   
-00019f20: 2020 2020 2020 2020 2072 6567 756c 6172           regular
-00019f30: 697a 6572 2e20 4f6e 6c79 2061 7070 6c69  izer. Only appli
-00019f40: 6361 626c 6520 6966 206f 7074 5f61 7567  cable if opt_aug
-00019f50: 3d54 7275 652e 2044 6566 6175 6c74 7320  =True. Defaults 
-00019f60: 746f 204e 6f6e 652e 0a20 2020 2020 2020  to None..       
-00019f70: 206e 756d 5f6d 6173 6b73 2028 696e 742c   num_masks (int,
-00019f80: 206f 7074 696f 6e61 6c29 3a20 5468 6520   optional): The 
-00019f90: 6e75 6d62 6572 206f 6620 6d61 736b 7320  number of masks 
-00019fa0: 746f 2063 7265 6174 652c 2074 6f20 6265  to create, to be
-00019fb0: 2075 7365 6420 616c 6f6e 6773 6964 6520   used alongside 
-00019fc0: 7468 6520 6d61 736b 5f73 697a 6520 7061  the mask_size pa
-00019fd0: 7261 6d65 7465 722e 2049 6620 0a20 2020  rameter. If .   
-00019fe0: 2020 2020 2020 2020 2074 6869 7320 6973           this is
-00019ff0: 2073 6574 2074 6f20 6120 7661 6c75 6520   set to a value 
-0001a000: 6772 6561 7465 7220 7468 616e 206f 6e65  greater than one
-0001a010: 2c20 6f76 6572 6c61 7020 6d61 7920 6f63  , overlap may oc
-0001a020: 6375 722e 200a 2020 2020 2020 2020 7665  cur. .        ve
-0001a030: 7262 6f73 6520 2869 6e74 293a 2043 6f6e  rbose (int): Con
-0001a040: 7472 6f6c 7320 7468 6520 616d 6f75 6e74  trols the amount
-0001a050: 206f 6620 6f75 7470 7574 2070 7269 6e74   of output print
-0001a060: 6564 2064 7572 696e 6720 7468 6520 7472  ed during the tr
-0001a070: 6169 6e69 6e67 2070 726f 6365 7373 2e20  aining process. 
-0001a080: 4120 7661 6c75 6520 6f66 2030 2069 7320  A value of 0 is 
-0001a090: 666f 7220 7369 6c65 6e74 206d 6f64 652c  for silent mode,
-0001a0a0: 200a 2020 2020 2020 2020 2020 2020 6120   .            a 
-0001a0b0: 7661 6c75 6520 6f66 2031 2069 7320 7573  value of 1 is us
-0001a0c0: 6564 2066 6f72 2070 726f 6772 6573 7320  ed for progress 
-0001a0d0: 6261 7220 6d6f 6465 2c20 616e 6420 3220  bar mode, and 2 
-0001a0e0: 666f 7220 6f6e 6520 6c69 6e65 2070 6572  for one line per
-0001a0f0: 2065 706f 6368 206d 6f64 652e 2044 6566   epoch mode. Def
-0001a100: 6175 6c74 7320 746f 2031 2e0a 2020 2020  aults to 1..    
-0001a110: 2020 2020 736d 6f74 655f 7361 6d70 6c69      smote_sampli
-0001a120: 6e67 2028 666c 6f61 7429 3a20 5468 6520  ng (float): The 
-0001a130: 736d 6f74 655f 7361 6d70 6c69 6e67 2070  smote_sampling p
-0001a140: 6172 616d 6574 6572 2069 7320 7573 6564  arameter is used
-0001a150: 2069 6e20 7468 6520 534d 4f54 4520 616c   in the SMOTE al
-0001a160: 676f 7269 7468 6d20 746f 2073 7065 6369  gorithm to speci
-0001a170: 6679 2074 6865 2064 6573 6972 6564 200a  fy the desired .
-0001a180: 2020 2020 2020 2020 2020 2020 7261 7469              rati
-0001a190: 6f20 6f66 2074 6865 206d 696e 6f72 6974  o of the minorit
-0001a1a0: 7920 636c 6173 7320 746f 2074 6865 206d  y class to the m
-0001a1b0: 616a 6f72 6974 7920 636c 6173 732e 2044  ajority class. D
-0001a1c0: 6566 6175 6c74 7320 746f 2030 2077 6869  efaults to 0 whi
-0001a1d0: 6368 2064 6973 6162 6c65 7320 7468 6520  ch disables the 
-0001a1e0: 7072 6f63 6564 7572 652e 0a20 2020 2020  procedure..     
-0001a1f0: 2020 200a 2020 2020 5468 6520 666f 6c6c     .    The foll
-0001a200: 6c6f 7769 6e67 2061 7267 756d 656e 7473  lowing arguments
-0001a210: 2063 616e 2062 6520 7573 6564 2074 6f20   can be used to 
-0001a220: 7365 7420 6561 726c 792d 7374 6f70 7069  set early-stoppi
-0001a230: 6e67 2063 616c 6c62 6163 6b73 2e20 5468  ng callbacks. Th
-0001a240: 6573 6520 6361 6e20 6265 2075 7365 6420  ese can be used 
-0001a250: 746f 2074 6572 6d69 6e61 7465 2074 7269  to terminate tri
-0001a260: 616c 7320 7468 6174 2065 7863 6565 640a  als that exceed.
-0001a270: 2020 2020 7072 652d 6465 7465 726d 696e      pre-determin
-0001a280: 6564 2074 6872 6573 686f 6c64 732c 2077  ed thresholds, w
-0001a290: 6869 6368 206d 6179 2062 6520 696e 6469  hich may be indi
-0001a2a0: 6361 7469 7665 206f 6620 616e 206f 7665  cative of an ove
-0001a2b0: 7266 6974 206d 6f64 656c 2e0a 0a20 2020  rfit model...   
-0001a2c0: 2041 7267 733a 0a20 2020 2020 2020 206d   Args:.        m
-0001a2d0: 6f6e 6974 6f72 3120 2873 7472 2c20 6f70  onitor1 (str, op
-0001a2e0: 7469 6f6e 616c 293a 2054 6865 2066 6972  tional): The fir
-0001a2f0: 7374 206d 6574 7269 6320 746f 206d 6f6e  st metric to mon
-0001a300: 6974 6f72 2c20 6361 6e20 7461 6b65 2074  itor, can take t
-0001a310: 6865 2073 616d 6520 7661 6c75 6573 2061  he same values a
-0001a320: 7320 7468 6520 6d65 7472 6963 2061 7267  s the metric arg
-0001a330: 756d 656e 742e 2044 6566 6175 6c74 7320  ument. Defaults 
-0001a340: 746f 204e 6f6e 652e 0a20 2020 2020 2020  to None..       
-0001a350: 206d 6f6e 6974 6f72 3220 2873 7472 2c20   monitor2 (str, 
-0001a360: 6f70 7469 6f6e 616c 293a 2054 6865 2073  optional): The s
-0001a370: 6563 6f6e 6420 6d65 7472 6963 2074 6f20  econd metric to 
-0001a380: 6d6f 6e69 746f 722c 2063 616e 2074 616b  monitor, can tak
-0001a390: 6520 7468 6520 7361 6d65 2076 616c 7565  e the same value
-0001a3a0: 7320 6173 2074 6865 206d 6574 7269 6320  s as the metric 
-0001a3b0: 6172 6775 6d65 6e74 2e20 4465 6661 756c  argument. Defaul
-0001a3c0: 7473 2074 6f20 4e6f 6e65 2e0a 2020 2020  ts to None..    
-0001a3d0: 2020 2020 6d6f 6e69 746f 7231 5f74 6872      monitor1_thr
-0001a3e0: 6573 6820 2866 6c6f 6174 2c20 6f70 7469  esh (float, opti
-0001a3f0: 6f6e 616c 293a 2054 6865 2074 6872 6573  onal): The thres
-0001a400: 686f 6c64 2076 616c 7565 206f 6620 7468  hold value of th
-0001a410: 6520 6669 7273 7420 6d6f 6e69 746f 7220  e first monitor 
-0001a420: 6d65 7472 6963 2e20 4966 2074 6865 206d  metric. If the m
-0001a430: 6574 7269 6320 6973 206c 6f73 732d 7265  etric is loss-re
-0001a440: 6c61 7465 640a 2020 2020 2020 2020 2020  lated.          
-0001a450: 2020 7468 6520 7472 6169 6e69 6e67 2077    the training w
-0001a460: 696c 6c20 7374 6f70 2065 6172 6c79 2069  ill stop early i
-0001a470: 6620 7468 6520 7661 6c75 6520 6661 6c6c  f the value fall
-0001a480: 7320 6265 6c6f 7720 7468 6973 2074 6872  s below this thr
-0001a490: 6573 686f 6c64 2e20 5369 6d69 6c61 726c  eshold. Similarl
-0001a4a0: 792c 2069 6620 7468 6520 6d65 7472 6963  y, if the metric
-0001a4b0: 2069 7320 6163 6375 7261 6379 2d72 656c   is accuracy-rel
-0001a4c0: 6174 6564 2c0a 2020 2020 2020 2020 2020  ated,.          
-0001a4d0: 2020 7468 656e 2074 6865 2074 7261 696e    then the train
-0001a4e0: 696e 6720 7769 6c6c 2073 746f 7020 6561  ing will stop ea
-0001a4f0: 726c 7920 6966 2074 6865 2076 616c 7565  rly if the value
-0001a500: 2066 616c 6c73 2061 626f 7665 2074 6869   falls above thi
-0001a510: 7320 7468 7265 7368 6f6c 642e 2044 6566  s threshold. Def
-0001a520: 6175 6c74 7320 746f 204e 6f6e 652e 0a20  aults to None.. 
-0001a530: 2020 2020 2020 206d 6f6e 6974 6f72 325f         monitor2_
-0001a540: 7468 7265 7368 2028 666c 6f61 742c 206f  thresh (float, o
-0001a550: 7074 696f 6e61 6c29 3a20 5468 6520 7468  ptional): The th
-0001a560: 7265 7368 6f6c 6420 7661 6c75 6520 6f66  reshold value of
-0001a570: 2074 6865 2073 6563 6f6e 6420 6d6f 6e69   the second moni
-0001a580: 746f 7220 6d65 7472 6963 2e20 4966 2074  tor metric. If t
-0001a590: 6865 206d 6574 7269 6320 6973 206c 6f73  he metric is los
-0001a5a0: 732d 7265 6c61 7465 640a 2020 2020 2020  s-related.      
-0001a5b0: 2020 2020 2020 7468 6520 7472 6169 6e69        the traini
-0001a5c0: 6e67 2077 696c 6c20 7374 6f70 2065 6172  ng will stop ear
-0001a5d0: 6c79 2069 6620 7468 6520 7661 6c75 6520  ly if the value 
-0001a5e0: 6661 6c6c 7320 6265 6c6f 7720 7468 6973  falls below this
-0001a5f0: 2074 6872 6573 686f 6c64 2e20 5369 6d69   threshold. Simi
-0001a600: 6c61 726c 792c 2069 6620 7468 6520 6d65  larly, if the me
-0001a610: 7472 6963 2069 7320 6163 6375 7261 6379  tric is accuracy
-0001a620: 2d72 656c 6174 6564 2c0a 2020 2020 2020  -related,.      
-0001a630: 2020 2020 2020 7468 656e 2074 6865 2074        then the t
-0001a640: 7261 696e 696e 6720 7769 6c6c 2073 746f  raining will sto
-0001a650: 7020 6561 726c 7920 6966 2074 6865 2076  p early if the v
-0001a660: 616c 7565 2066 616c 6c73 2061 626f 7665  alue falls above
-0001a670: 2074 6869 7320 7468 7265 7368 6f6c 642e   this threshold.
-0001a680: 2044 6566 6175 6c74 7320 746f 204e 6f6e   Defaults to Non
-0001a690: 652e 0a20 2020 2020 2020 200a 2020 2020  e..        .    
-0001a6a0: 5265 7475 726e 733a 0a20 2020 2020 2020  Returns:.       
-0001a6b0: 2054 6865 2066 6972 7374 206f 7574 7075   The first outpu
-0001a6c0: 7420 6973 2074 6865 2063 6c61 7373 6966  t is the classif
-0001a6d0: 6965 7220 7769 7468 2074 6865 206f 7074  ier with the opt
-0001a6e0: 696d 616c 2068 7970 6572 7061 7261 6d65  imal hyperparame
-0001a6f0: 7465 7273 2e0a 2020 2020 2020 2020 5365  ters..        Se
-0001a700: 636f 6e64 206f 7574 7075 7420 6973 2061  cond output is a
-0001a710: 2064 6963 7469 6f6e 6172 7920 636f 6e74   dictionary cont
-0001a720: 6169 6e69 6e67 2074 6865 206f 7074 696d  aining the optim
-0001a730: 616c 2068 7970 6572 7061 7261 6d65 7465  al hyperparamete
-0001a740: 7273 2e0a 2020 2020 2020 2020 4966 2073  rs..        If s
-0001a750: 6176 655f 7374 7564 793d 5472 7565 2c20  ave_study=True, 
-0001a760: 7468 6520 4f70 7475 6e61 2073 7475 6479  the Optuna study
-0001a770: 206f 626a 6563 7420 7769 6c6c 2062 6520   object will be 
-0001a780: 7468 6520 7468 6972 6420 6f75 7470 7574  the third output
-0001a790: 2e0a 2020 2020 2222 220a 0a20 2020 2069  ..    """..    i
-0001a7a0: 6620 636c 6620 3d3d 2027 7266 273a 0a20  f clf == 'rf':. 
-0001a7b0: 2020 2020 2020 206d 6f64 656c 5f30 203d         model_0 =
-0001a7c0: 2052 616e 646f 6d46 6f72 6573 7443 6c61   RandomForestCla
-0001a7d0: 7373 6966 6965 7228 7261 6e64 6f6d 5f73  ssifier(random_s
-0001a7e0: 7461 7465 3d31 3930 3929 0a20 2020 2065  tate=1909).    e
-0001a7f0: 6c69 6620 636c 6620 3d3d 2027 6e6e 273a  lif clf == 'nn':
-0001a800: 0a20 2020 2020 2020 206d 6f64 656c 5f30  .        model_0
-0001a810: 203d 204d 4c50 436c 6173 7369 6669 6572   = MLPClassifier
-0001a820: 2872 616e 646f 6d5f 7374 6174 653d 3139  (random_state=19
-0001a830: 3039 290a 2020 2020 656c 6966 2063 6c66  09).    elif clf
-0001a840: 203d 3d20 2778 6762 273a 0a20 2020 2020   == 'xgb':.     
-0001a850: 2020 206d 6f64 656c 5f30 203d 2058 4742     model_0 = XGB
-0001a860: 436c 6173 7369 6669 6572 2872 616e 646f  Classifier(rando
-0001a870: 6d5f 7374 6174 653d 3139 3039 290a 2020  m_state=1909).  
-0001a880: 2020 2020 2020 6966 2061 6c6c 2869 7369        if all(isi
-0001a890: 6e73 7461 6e63 6528 7661 6c2c 2028 696e  nstance(val, (in
-0001a8a0: 742c 2073 7472 2929 2066 6f72 2076 616c  t, str)) for val
-0001a8b0: 2069 6e20 6461 7461 5f79 293a 0a20 2020   in data_y):.   
-0001a8c0: 2020 2020 2020 2020 2070 7269 6e74 2827           print('
-0001a8d0: 5847 426f 6f73 7420 636c 6173 7369 6669  XGBoost classifi
-0001a8e0: 6572 2072 6571 7569 7265 7320 6e75 6d65  er requires nume
-0001a8f0: 7269 6361 6c20 636c 6173 7320 6c61 6265  rical class labe
-0001a900: 6c73 2120 436f 6e76 6572 7469 6e67 2063  ls! Converting c
-0001a910: 6c61 7373 206c 6162 656c 7320 6173 2066  lass labels as f
-0001a920: 6f6c 6c6f 7773 3a27 290a 2020 2020 2020  ollows:').      
-0001a930: 2020 2020 2020 7072 696e 7428 275f 5f5f        print('___
-0001a940: 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f  ________________
-0001a950: 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f  ________________
-0001a960: 5f27 290a 2020 2020 2020 2020 2020 2020  _').            
-0001a970: 7920 3d20 6e70 2e7a 6572 6f73 286c 656e  y = np.zeros(len
-0001a980: 2864 6174 615f 7929 290a 2020 2020 2020  (data_y)).      
-0001a990: 2020 2020 2020 666f 7220 6920 696e 2072        for i in r
-0001a9a0: 616e 6765 286c 656e 286e 702e 756e 6971  ange(len(np.uniq
-0001a9b0: 7565 2864 6174 615f 7929 2929 3a0a 2020  ue(data_y))):.  
-0001a9c0: 2020 2020 2020 2020 2020 2020 2020 7072                pr
-0001a9d0: 696e 7428 7374 7228 6e70 2e75 6e69 7175  int(str(np.uniqu
-0001a9e0: 6528 6461 7461 5f79 295b 695d 292e 6c6a  e(data_y)[i]).lj
-0001a9f0: 7573 7428 3130 292b 2720 202d 2d2d 2d2d  ust(10)+'  -----
-0001aa00: 2d2d 2d2d 2d2d 2d2d 3e20 2020 2020 272b  -------->     '+
-0001aa10: 7374 7228 6929 290a 2020 2020 2020 2020  str(i)).        
-0001aa20: 2020 2020 2020 2020 696e 6465 7820 3d20          index = 
-0001aa30: 6e70 2e77 6865 7265 2864 6174 615f 7920  np.where(data_y 
-0001aa40: 3d3d 206e 702e 756e 6971 7565 2864 6174  == np.unique(dat
-0001aa50: 615f 7929 5b69 5d29 5b30 5d0a 2020 2020  a_y)[i])[0].    
-0001aa60: 2020 2020 2020 2020 2020 2020 795b 696e              y[in
-0001aa70: 6465 785d 203d 2069 0a20 2020 2020 2020  dex] = i.       
-0001aa80: 2020 2020 2064 6174 615f 7920 3d20 7920       data_y = y 
-0001aa90: 0a20 2020 2020 2020 2020 2020 2070 7269  .            pri
-0001aaa0: 6e74 2827 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  nt('------------
-0001aab0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-0001aac0: 2d2d 2d2d 2d2d 2d2d 2729 0a20 2020 2065  --------').    e
-0001aad0: 6c69 6620 636c 6620 3d3d 2027 616c 6578  lif clf == 'alex
-0001aae0: 6e65 7427 206f 7220 636c 6620 3d3d 2027  net' or clf == '
-0001aaf0: 7667 6731 3627 206f 7220 636c 6620 3d3d  vgg16' or clf ==
-0001ab00: 2027 7265 736e 6574 3138 2720 6f72 2063   'resnet18' or c
-0001ab10: 6c66 203d 3d20 2763 7573 746f 6d5f 636e  lf == 'custom_cn
-0001ab20: 6e27 3a0a 2020 2020 2020 2020 7061 7373  n':.        pass
-0001ab30: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
-0001ab40: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-0001ab50: 726f 7228 2763 6c66 2061 7267 756d 656e  ror('clf argumen
-0001ab60: 7420 6d75 7374 2065 6974 6865 7220 6265  t must either be
-0001ab70: 2022 7266 222c 2022 7867 6222 2c20 226e   "rf", "xgb", "n
-0001ab80: 6e22 2c20 6f72 2022 616c 6578 6e65 7422  n", or "alexnet"
-0001ab90: 2c20 2276 6767 3136 222c 2022 7265 736e  , "vgg16", "resn
-0001aba0: 6574 3138 222c 2022 6375 7374 6f6d 5f63  et18", "custom_c
-0001abb0: 6e6e 222e 2729 0a0a 2020 2020 6966 206e  nn".')..    if n
-0001abc0: 5f69 7465 7220 3d3d 2030 3a0a 2020 2020  _iter == 0:.    
-0001abd0: 2020 2020 6966 2063 6c66 203d 3d20 2772      if clf == 'r
-0001abe0: 6627 206f 7220 636c 6620 3d3d 2027 7867  f' or clf == 'xg
-0001abf0: 6227 206f 7220 636c 6620 3d3d 2027 6e6e  b' or clf == 'nn
-0001ac00: 273a 0a20 2020 2020 2020 2020 2020 2070  ':.            p
-0001ac10: 7269 6e74 2827 4e6f 206f 7074 696d 697a  rint('No optimiz
-0001ac20: 6174 696f 6e20 7472 6961 6c73 2063 6f6e  ation trials con
-0001ac30: 6669 6775 7265 6420 286e 5f69 7465 723d  figured (n_iter=
-0001ac40: 3029 2c20 7265 7475 726e 696e 6720 6261  0), returning ba
-0001ac50: 7365 207b 7d20 6d6f 6465 6c2e 2e2e 272e  se {} model...'.
-0001ac60: 666f 726d 6174 2863 6c66 2929 0a20 2020  format(clf)).   
-0001ac70: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-0001ac80: 6d6f 6465 6c5f 3020 0a20 2020 2020 2020  model_0 .       
-0001ac90: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-0001aca0: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-0001acb0: 726f 7228 274e 6f20 6f70 7469 6d69 7a61  ror('No optimiza
-0001acc0: 7469 6f6e 2074 7269 616c 7320 636f 6e66  tion trials conf
-0001acd0: 6967 7572 6564 2c20 7365 7420 6e5f 6974  igured, set n_it
-0001ace0: 6572 203e 2030 2127 290a 0a20 2020 2069  er > 0!')..    i
-0001acf0: 6620 636c 6620 3d3d 2027 7266 2720 6f72  f clf == 'rf' or
-0001ad00: 2063 6c66 203d 3d20 2778 6762 2720 6f72   clf == 'xgb' or
-0001ad10: 2063 6c66 203d 3d20 276e 6e27 3a0a 2020   clf == 'nn':.  
-0001ad20: 2020 2020 2020 6376 203d 2063 726f 7373        cv = cross
-0001ad30: 5f76 616c 6964 6174 6528 6d6f 6465 6c5f  _validate(model_
-0001ad40: 302c 2064 6174 615f 782c 2064 6174 615f  0, data_x, data_
-0001ad50: 792c 2063 763d 6f70 745f 6376 290a 2020  y, cv=opt_cv).  
-0001ad60: 2020 2020 2020 696e 6974 6961 6c5f 7363        initial_sc
-0001ad70: 6f72 6520 3d20 6e70 2e6d 6561 6e28 6376  ore = np.mean(cv
-0001ad80: 5b27 7465 7374 5f73 636f 7265 275d 290a  ['test_score']).
-0001ad90: 0a20 2020 2073 616d 706c 6572 203d 206f  .    sampler = o
-0001ada0: 7074 756e 612e 7361 6d70 6c65 7273 2e54  ptuna.samplers.T
-0001adb0: 5045 5361 6d70 6c65 7228 7365 6564 3d31  PESampler(seed=1
-0001adc0: 3930 3929 0a20 2020 2073 7475 6479 203d  909).    study =
-0001add0: 206f 7074 756e 612e 6372 6561 7465 5f73   optuna.create_s
-0001ade0: 7475 6479 2864 6972 6563 7469 6f6e 3d27  tudy(direction='
-0001adf0: 6d61 7869 6d69 7a65 272c 2073 616d 706c  maximize', sampl
-0001ae00: 6572 3d73 616d 706c 6572 2923 2c20 7072  er=sampler)#, pr
-0001ae10: 756e 6572 3d6f 7074 756e 612e 7072 756e  uner=optuna.prun
-0001ae20: 6572 732e 4d65 6469 616e 5072 756e 6572  ers.MedianPruner
-0001ae30: 286e 5f73 7461 7274 7570 5f74 7269 616c  (n_startup_trial
-0001ae40: 733d 352c 206e 5f77 6172 6d75 705f 7374  s=5, n_warmup_st
-0001ae50: 6570 733d 3330 2c20 696e 7465 7276 616c  eps=30, interval
-0001ae60: 5f73 7465 7073 3d31 3029 290a 2020 2020  _steps=10)).    
-0001ae70: 7072 696e 7428 2753 7461 7274 696e 6720  print('Starting 
-0001ae80: 6879 7065 7270 6172 616d 6574 6572 206f  hyperparameter o
-0001ae90: 7074 696d 697a 6174 696f 6e2c 2074 6869  ptimization, thi
-0001aea0: 7320 7769 6c6c 2074 616b 6520 6120 7768  s will take a wh
-0001aeb0: 696c 652e 2e2e 2729 0a0a 2020 2020 2349  ile...')..    #I
-0001aec0: 6620 6269 6e61 7279 2063 6c61 7373 6966  f binary classif
-0001aed0: 6963 6174 696f 6e20 7461 736b 2c20 6361  ication task, ca
-0001aee0: 6e20 6465 616c 2077 6974 6820 696d 6261  n deal with imba
-0001aef0: 6c61 6e63 6520 636c 6173 7365 7320 7769  lance classes wi
-0001af00: 7468 2077 6569 6768 7473 2068 7970 6572  th weights hyper
-0001af10: 7061 7261 6d65 7465 720a 2020 2020 6966  parameter.    if
-0001af20: 206c 656e 286e 702e 756e 6971 7565 2864   len(np.unique(d
-0001af30: 6174 615f 7929 2920 3d3d 2032 3a0a 2020  ata_y)) == 2:.  
-0001af40: 2020 2020 2020 6966 2063 6c66 203d 3d20        if clf == 
-0001af50: 2772 6627 206f 7220 636c 6620 3d3d 2027  'rf' or clf == '
-0001af60: 7867 6227 206f 7220 636c 6620 3d3d 2027  xgb' or clf == '
-0001af70: 6e6e 273a 0a20 2020 2020 2020 2020 2020  nn':.           
-0001af80: 2063 6f75 6e74 6572 203d 2043 6f75 6e74   counter = Count
-0001af90: 6572 2864 6174 615f 7929 0a20 2020 2020  er(data_y).     
-0001afa0: 2020 2020 2020 2069 6620 636f 756e 7465         if counte
-0001afb0: 725b 6e70 2e75 6e69 7175 6528 6461 7461  r[np.unique(data
-0001afc0: 5f79 295b 305d 5d20 213d 2063 6f75 6e74  _y)[0]] != count
-0001afd0: 6572 5b6e 702e 756e 6971 7565 2864 6174  er[np.unique(dat
-0001afe0: 615f 7929 5b31 5d5d 3a0a 2020 2020 2020  a_y)[1]]:.      
-0001aff0: 2020 2020 2020 2020 2020 6966 2062 616c            if bal
-0001b000: 616e 6365 3a0a 2020 2020 2020 2020 2020  ance:.          
-0001b010: 2020 2020 2020 2020 2020 7072 696e 7428            print(
-0001b020: 2755 6e62 616c 616e 6365 6420 6461 7461  'Unbalanced data
-0001b030: 7365 7420 6465 7465 6374 6564 2c20 7769  set detected, wi
-0001b040: 6c6c 2074 7261 696e 2063 6c61 7373 6966  ll train classif
-0001b050: 6965 7220 7769 7468 2077 6569 6768 7473  ier with weights
-0001b060: 2120 546f 2064 6973 6162 6c65 2c20 7365  ! To disable, se
-0001b070: 7420 6261 6c61 6e63 653d 4661 6c73 6527  t balance=False'
-0001b080: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-0001b090: 2020 2020 2020 6966 2063 6c66 203d 3d20        if clf == 
-0001b0a0: 2778 6762 273a 0a20 2020 2020 2020 2020  'xgb':.         
-0001b0b0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-0001b0c0: 6f74 616c 5f6e 6567 6174 6976 6520 3d20  otal_negative = 
-0001b0d0: 6c65 6e28 6e70 2e77 6865 7265 2864 6174  len(np.where(dat
-0001b0e0: 615f 7920 3d3d 2063 6f75 6e74 6572 2e6d  a_y == counter.m
-0001b0f0: 6f73 745f 636f 6d6d 6f6e 2831 295b 305d  ost_common(1)[0]
-0001b100: 5b30 5d29 5b30 5d29 0a20 2020 2020 2020  [0])[0]).       
-0001b110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b120: 2074 6f74 616c 5f70 6f73 6974 6976 6520   total_positive 
-0001b130: 3d20 6c65 6e28 6461 7461 5f79 2920 2d20  = len(data_y) - 
-0001b140: 746f 7461 6c5f 6e65 6761 7469 7665 0a20  total_negative. 
-0001b150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b160: 2020 2020 2020 2073 616d 706c 655f 7765         sample_we
-0001b170: 6967 6874 203d 2074 6f74 616c 5f6e 6567  ight = total_neg
-0001b180: 6174 6976 6520 2f20 746f 7461 6c5f 706f  ative / total_po
-0001b190: 7369 7469 7665 0a20 2020 2020 2020 2020  sitive.         
-0001b1a0: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
-0001b1b0: 636c 6620 3d3d 2027 7266 273a 0a20 2020  clf == 'rf':.   
-0001b1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b1d0: 2020 2020 2073 616d 706c 655f 7765 6967       sample_weig
-0001b1e0: 6874 203d 2027 6261 6c61 6e63 6564 270a  ht = 'balanced'.
-0001b1f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b200: 2020 2020 656c 6966 2063 6c66 203d 3d20      elif clf == 
-0001b210: 276e 6e27 3a0a 2020 2020 2020 2020 2020  'nn':.          
-0001b220: 2020 2020 2020 2020 2020 2020 2020 7072                pr
-0001b230: 696e 7428 2757 4152 4e49 4e47 3a20 4d4c  int('WARNING: ML
-0001b240: 5043 6c61 7373 6966 6965 7228 2920 646f  PClassifier() do
-0001b250: 6573 206e 6f74 2073 7570 706f 7274 2073  es not support s
-0001b260: 616d 706c 6520 7765 6967 6874 732e 2729  ample weights.')
-0001b270: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b280: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-0001b290: 2020 2020 2020 2020 2020 2073 616d 706c             sampl
-0001b2a0: 655f 7765 6967 6874 203d 204e 6f6e 650a  e_weight = None.
-0001b2b0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-0001b2c0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001b2d0: 2020 7361 6d70 6c65 5f77 6569 6768 7420    sample_weight 
-0001b2e0: 3d20 4e6f 6e65 0a20 2020 2020 2020 2065  = None.        e
-0001b2f0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-0001b300: 2070 7269 6e74 2827 556e 6261 6c61 6e63   print('Unbalanc
-0001b310: 6564 2064 6174 6173 6574 2064 6574 6563  ed dataset detec
-0001b320: 7465 6420 6275 7420 7468 6520 6f70 7469  ted but the opti
-0001b330: 6d69 7a61 7469 6f6e 2072 6f75 7469 6e65  mization routine
-0001b340: 2064 6f65 7320 6e6f 7420 6375 7272 656e   does not curren
-0001b350: 746c 7920 7375 7070 6f72 7420 7765 6967  tly support weig
-0001b360: 6874 732e 2054 6f20 7573 6520 7468 6520  hts. To use the 
-0001b370: 7765 6967 6874 6564 5f62 696e 6172 795f  weighted_binary_
-0001b380: 6372 6f73 7365 6e74 726f 7079 206c 6f73  crossentropy los
-0001b390: 7320 6675 6e63 7469 6f6e 2c20 6c6f 6164  s function, load
-0001b3a0: 2074 6865 2064 6573 6972 6564 206d 6f64   the desired mod
-0001b3b0: 656c 2064 6972 6563 746c 7920 616e 6420  el directly and 
-0001b3c0: 7365 7420 6c6f 7373 3d22 7765 6967 6874  set loss="weight
-0001b3d0: 6564 5f62 696e 6172 795f 6372 6f73 7365  ed_binary_crosse
-0001b3e0: 6e74 726f 7079 2220 2872 6566 6572 2074  ntropy" (refer t
-0001b3f0: 6f20 7468 6520 4d69 6372 6f4c 4941 2e63  o the MicroLIA.c
-0001b400: 6e6e 5f6d 6f64 656c 2041 5049 2064 6f63  nn_model API doc
-0001b410: 756d 656e 7461 7469 6f6e 292e 2729 0a20  umentation).'). 
-0001b420: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0001b430: 2073 616d 706c 655f 7765 6967 6874 203d   sample_weight =
-0001b440: 204e 6f6e 650a 0a20 2020 2069 6620 636c   None..    if cl
-0001b450: 6620 3d3d 2027 7266 273a 0a20 2020 2020  f == 'rf':.     
-0001b460: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
-0001b470: 2020 2020 6f62 6a65 6374 6976 6520 3d20      objective = 
-0001b480: 6f62 6a65 6374 6976 655f 7266 2864 6174  objective_rf(dat
-0001b490: 615f 782c 2064 6174 615f 792c 206f 7074  a_x, data_y, opt
-0001b4a0: 5f63 763d 6f70 745f 6376 290a 2020 2020  _cv=opt_cv).    
-0001b4b0: 2020 2020 2020 2020 7374 7564 792e 6f70          study.op
-0001b4c0: 7469 6d69 7a65 286f 626a 6563 7469 7665  timize(objective
-0001b4d0: 2c20 6e5f 7472 6961 6c73 3d6e 5f69 7465  , n_trials=n_ite
-0001b4e0: 722c 2073 686f 775f 7072 6f67 7265 7373  r, show_progress
-0001b4f0: 5f62 6172 3d54 7275 6529 232c 2067 635f  _bar=True)#, gc_
-0001b500: 6166 7465 725f 7472 6961 6c3d 5472 7565  after_trial=True
-0001b510: 290a 2020 2020 2020 2020 2020 2020 7061  ).            pa
-0001b520: 7261 6d73 203d 2073 7475 6479 2e62 6573  rams = study.bes
-0001b530: 745f 7472 6961 6c2e 7061 7261 6d73 0a20  t_trial.params. 
-0001b540: 2020 2020 2020 2020 2020 206d 6f64 656c             model
-0001b550: 203d 2052 616e 646f 6d46 6f72 6573 7443   = RandomForestC
-0001b560: 6c61 7373 6966 6965 7228 6e5f 6573 7469  lassifier(n_esti
-0001b570: 6d61 746f 7273 3d70 6172 616d 735b 276e  mators=params['n
-0001b580: 5f65 7374 696d 6174 6f72 7327 5d2c 2063  _estimators'], c
-0001b590: 7269 7465 7269 6f6e 3d70 6172 616d 735b  riterion=params[
-0001b5a0: 2763 7269 7465 7269 6f6e 275d 2c20 0a20  'criterion'], . 
-0001b5b0: 2020 2020 2020 2020 2020 2020 2020 206d                 m
-0001b5c0: 6178 5f64 6570 7468 3d70 6172 616d 735b  ax_depth=params[
-0001b5d0: 276d 6178 5f64 6570 7468 275d 2c20 6d69  'max_depth'], mi
-0001b5e0: 6e5f 7361 6d70 6c65 735f 7370 6c69 743d  n_samples_split=
-0001b5f0: 7061 7261 6d73 5b27 6d69 6e5f 7361 6d70  params['min_samp
-0001b600: 6c65 735f 7370 6c69 7427 5d2c 200a 2020  les_split'], .  
-0001b610: 2020 2020 2020 2020 2020 2020 2020 6d69                mi
-0001b620: 6e5f 7361 6d70 6c65 735f 6c65 6166 3d70  n_samples_leaf=p
-0001b630: 6172 616d 735b 276d 696e 5f73 616d 706c  arams['min_sampl
-0001b640: 6573 5f6c 6561 6627 5d2c 206d 6178 5f66  es_leaf'], max_f
-0001b650: 6561 7475 7265 733d 7061 7261 6d73 5b27  eatures=params['
-0001b660: 6d61 785f 6665 6174 7572 6573 275d 2c20  max_features'], 
-0001b670: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b680: 2062 6f6f 7473 7472 6170 3d70 6172 616d   bootstrap=param
-0001b690: 735b 2762 6f6f 7473 7472 6170 275d 2c20  s['bootstrap'], 
-0001b6a0: 636c 6173 735f 7765 6967 6874 3d73 616d  class_weight=sam
-0001b6b0: 706c 655f 7765 6967 6874 2c20 7261 6e64  ple_weight, rand
-0001b6c0: 6f6d 5f73 7461 7465 3d31 3930 3929 0a20  om_state=1909). 
-0001b6d0: 2020 2020 2020 2065 7863 6570 743a 0a20         except:. 
-0001b6e0: 2020 2020 2020 2020 2020 2070 7269 6e74             print
-0001b6f0: 2827 4661 696c 6564 2074 6f20 6f70 7469  ('Failed to opti
-0001b700: 6d69 7a65 2077 6974 6820 4f70 7475 6e61  mize with Optuna
-0001b710: 2c20 7377 6974 6368 696e 6720 6f76 6572  , switching over
-0001b720: 2074 6f20 4261 7965 7353 6561 7263 6843   to BayesSearchC
-0001b730: 562e 2e2e 2729 0a20 2020 2020 2020 2020  V...').         
-0001b740: 2020 2070 6172 616d 7320 3d20 7b0a 2020     params = {.  
-0001b750: 2020 2020 2020 2020 2020 2020 2020 2763                'c
-0001b760: 7269 7465 7269 6f6e 273a 205b 2267 696e  riterion': ["gin
-0001b770: 6922 2c20 2265 6e74 726f 7079 225d 2c0a  i", "entropy"],.
-0001b780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b790: 276e 5f65 7374 696d 6174 6f72 7327 3a20  'n_estimators': 
-0001b7a0: 5b69 6e74 2878 2920 666f 7220 7820 696e  [int(x) for x in
-0001b7b0: 206e 702e 6c69 6e73 7061 6365 2835 302c   np.linspace(50,
-0001b7c0: 3130 3030 2c20 6e75 6d3d 3230 295d 2c20  1000, num=20)], 
-0001b7d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b7e0: 2027 6d61 785f 6665 6174 7572 6573 273a   'max_features':
-0001b7f0: 205b 6461 7461 5f78 2e73 6861 7065 5b31   [data_x.shape[1
-0001b800: 5d2c 2022 7371 7274 222c 2022 6c6f 6732  ], "sqrt", "log2
-0001b810: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
-0001b820: 2020 2020 276d 6178 5f64 6570 7468 273a      'max_depth':
-0001b830: 205b 696e 7428 7829 2066 6f72 2078 2069   [int(x) for x i
-0001b840: 6e20 6e70 2e6c 696e 7370 6163 6528 352c  n np.linspace(5,
-0001b850: 3530 2c6e 756d 3d35 295d 2c0a 2020 2020  50,num=5)],.    
-0001b860: 2020 2020 2020 2020 2020 2020 276d 696e              'min
-0001b870: 5f73 616d 706c 6573 5f73 706c 6974 273a  _samples_split':
-0001b880: 205b 332c 342c 362c 372c 382c 392c 3130   [3,4,6,7,8,9,10
-0001b890: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-0001b8a0: 2020 2027 6d69 6e5f 7361 6d70 6c65 735f     'min_samples_
-0001b8b0: 6c65 6166 273a 205b 312c 332c 352c 372c  leaf': [1,3,5,7,
-0001b8c0: 392c 3130 5d2c 0a20 2020 2020 2020 2020  9,10],.         
-0001b8d0: 2020 2020 2020 2027 6d61 785f 6c65 6166         'max_leaf
-0001b8e0: 5f6e 6f64 6573 273a 205b 696e 7428 7829  _nodes': [int(x)
-0001b8f0: 2066 6f72 2078 2069 6e20 6e70 2e6c 696e   for x in np.lin
-0001b900: 7370 6163 6528 322c 3230 3029 5d2c 0a20  space(2,200)],. 
-0001b910: 2020 2020 2020 2020 2020 2020 2020 2027                 '
-0001b920: 626f 6f74 7374 7261 7027 3a20 5b54 7275  bootstrap': [Tru
-0001b930: 652c 4661 6c73 655d 2020 200a 2020 2020  e,False]   .    
-0001b940: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
-0001b950: 2020 2020 2020 6773 203d 2042 6179 6573        gs = Bayes
-0001b960: 5365 6172 6368 4356 286e 5f69 7465 723d  SearchCV(n_iter=
-0001b970: 6e5f 6974 6572 2c20 6573 7469 6d61 746f  n_iter, estimato
-0001b980: 723d 6d6f 6465 6c5f 302c 2073 6561 7263  r=model_0, searc
-0001b990: 685f 7370 6163 6573 3d70 6172 616d 732c  h_spaces=params,
-0001b9a0: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-0001b9b0: 2020 6f70 7469 6d69 7a65 725f 6b77 6172    optimizer_kwar
-0001b9c0: 6773 3d7b 2762 6173 655f 6573 7469 6d61  gs={'base_estima
-0001b9d0: 746f 7227 3a20 2752 4627 7d2c 2063 763d  tor': 'RF'}, cv=
-0001b9e0: 6f70 745f 6376 290a 2020 2020 2020 2020  opt_cv).        
-0001b9f0: 2020 2020 6773 2e66 6974 2864 6174 615f      gs.fit(data_
-0001ba00: 782c 2064 6174 615f 7929 0a20 2020 2020  x, data_y).     
-0001ba10: 2020 2020 2020 2062 6573 745f 6573 742c         best_est,
-0001ba20: 2062 6573 745f 7363 6f72 6520 3d20 6773   best_score = gs
-0001ba30: 2e62 6573 745f 6573 7469 6d61 746f 725f  .best_estimator_
-0001ba40: 2c20 6e70 2e72 6f75 6e64 2867 732e 6265  , np.round(gs.be
-0001ba50: 7374 5f73 636f 7265 5f2c 2034 290a 2020  st_score_, 4).  
-0001ba60: 2020 2020 2020 2020 2020 7072 696e 7428            print(
-0001ba70: 2748 6967 6865 7374 206d 6561 6e20 6163  'Highest mean ac
-0001ba80: 6375 7261 6379 3a20 7b7d 272e 666f 726d  curacy: {}'.form
-0001ba90: 6174 2862 6573 745f 7363 6f72 6529 290a  at(best_score)).
-0001baa0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0001bab0: 726e 2067 732e 6265 7374 5f65 7374 696d  rn gs.best_estim
-0001bac0: 6174 6f72 5f2c 2067 732e 6265 7374 5f70  ator_, gs.best_p
-0001bad0: 6172 616d 735f 0a0a 2020 2020 656c 6966  arams_..    elif
-0001bae0: 2063 6c66 203d 3d20 276e 6e27 3a0a 2020   clf == 'nn':.  
-0001baf0: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
-0001bb00: 2020 2020 2020 206f 626a 6563 7469 7665         objective
-0001bb10: 203d 206f 626a 6563 7469 7665 5f6e 6e28   = objective_nn(
-0001bb20: 6461 7461 5f78 2c20 6461 7461 5f79 2c20  data_x, data_y, 
-0001bb30: 6f70 745f 6376 3d6f 7074 5f63 7629 0a20  opt_cv=opt_cv). 
-0001bb40: 2020 2020 2020 2020 2020 2073 7475 6479             study
-0001bb50: 2e6f 7074 696d 697a 6528 6f62 6a65 6374  .optimize(object
-0001bb60: 6976 652c 206e 5f74 7269 616c 733d 6e5f  ive, n_trials=n_
-0001bb70: 6974 6572 2c20 7368 6f77 5f70 726f 6772  iter, show_progr
-0001bb80: 6573 735f 6261 723d 5472 7565 2923 2c20  ess_bar=True)#, 
-0001bb90: 6763 5f61 6674 6572 5f74 7269 616c 3d54  gc_after_trial=T
-0001bba0: 7275 6529 0a20 2020 2020 2020 2020 2020  rue).           
-0001bbb0: 2070 6172 616d 7320 3d20 7374 7564 792e   params = study.
-0001bbc0: 6265 7374 5f74 7269 616c 2e70 6172 616d  best_trial.param
-0001bbd0: 730a 2020 2020 2020 2020 2020 2020 6c61  s.            la
-0001bbe0: 7965 7273 203d 205b 7061 7261 6d20 666f  yers = [param fo
-0001bbf0: 7220 7061 7261 6d20 696e 2070 6172 616d  r param in param
-0001bc00: 7320 6966 2027 6e5f 756e 6974 735f 2720  s if 'n_units_' 
-0001bc10: 696e 2070 6172 616d 5d0a 2020 2020 2020  in param].      
-0001bc20: 2020 2020 2020 6c61 7965 7273 203d 2074        layers = t
-0001bc30: 7570 6c65 2870 6172 616d 735b 6c61 7965  uple(params[laye
-0001bc40: 725d 2066 6f72 206c 6179 6572 2069 6e20  r] for layer in 
-0001bc50: 6c61 7965 7273 290a 2020 2020 2020 2020  layers).        
-0001bc60: 2020 2020 6d6f 6465 6c20 3d20 4d4c 5043      model = MLPC
-0001bc70: 6c61 7373 6966 6965 7228 6869 6464 656e  lassifier(hidden
-0001bc80: 5f6c 6179 6572 5f73 697a 6573 3d74 7570  _layer_sizes=tup
-0001bc90: 6c65 286c 6179 6572 7329 2c20 6c65 6172  le(layers), lear
-0001bca0: 6e69 6e67 5f72 6174 655f 696e 6974 3d70  ning_rate_init=p
-0001bcb0: 6172 616d 735b 276c 6561 726e 696e 675f  arams['learning_
-0001bcc0: 7261 7465 5f69 6e69 7427 5d2c 200a 2020  rate_init'], .  
-0001bcd0: 2020 2020 2020 2020 2020 2020 2020 6163                ac
-0001bce0: 7469 7661 7469 6f6e 3d70 6172 616d 735b  tivation=params[
-0001bcf0: 2761 6374 6976 6174 696f 6e27 5d2c 206c  'activation'], l
-0001bd00: 6561 726e 696e 675f 7261 7465 3d70 6172  earning_rate=par
-0001bd10: 616d 735b 276c 6561 726e 696e 675f 7261  ams['learning_ra
-0001bd20: 7465 275d 2c20 616c 7068 613d 7061 7261  te'], alpha=para
-0001bd30: 6d73 5b27 616c 7068 6127 5d2c 200a 2020  ms['alpha'], .  
-0001bd40: 2020 2020 2020 2020 2020 2020 2020 6261                ba
-0001bd50: 7463 685f 7369 7a65 3d70 6172 616d 735b  tch_size=params[
-0001bd60: 2762 6174 6368 5f73 697a 6527 5d2c 2073  'batch_size'], s
-0001bd70: 6f6c 7665 723d 7061 7261 6d73 5b27 736f  olver=params['so
-0001bd80: 6c76 6572 275d 2c20 6d61 785f 6974 6572  lver'], max_iter
-0001bd90: 3d32 3530 302c 2072 616e 646f 6d5f 7374  =2500, random_st
-0001bda0: 6174 653d 3139 3039 290a 2020 2020 2020  ate=1909).      
-0001bdb0: 2020 6578 6365 7074 3a0a 2020 2020 2020    except:.      
-0001bdc0: 2020 2020 2020 7072 696e 7428 2746 6169        print('Fai
-0001bdd0: 6c65 6420 746f 206f 7074 696d 697a 6520  led to optimize 
-0001bde0: 7769 7468 204f 7074 756e 612c 2073 7769  with Optuna, swi
-0001bdf0: 7463 6869 6e67 206f 7665 7220 746f 2042  tching over to B
-0001be00: 6179 6573 5365 6172 6368 4356 2e2e 2e27  ayesSearchCV...'
-0001be10: 290a 2020 2020 2020 2020 2020 2020 7061  ).            pa
-0001be20: 7261 6d73 203d 207b 0a20 2020 2020 2020  rams = {.       
-0001be30: 2020 2020 2020 2020 2027 6869 6464 656e           'hidden
-0001be40: 5f6c 6179 6572 5f73 697a 6573 273a 205b  _layer_sizes': [
-0001be50: 2831 3030 2c29 2c28 3530 2c31 3030 2c35  (100,),(50,100,5
-0001be60: 3029 2c28 3735 2c35 302c 3230 292c 2831  0),(75,50,20),(1
-0001be70: 3530 2c31 3030 2c35 3029 2c28 3132 302c  50,100,50),(120,
-0001be80: 3830 2c34 3029 2c28 3130 302c 3530 2c33  80,40),(100,50,3
-0001be90: 3029 5d2c 0a20 2020 2020 2020 2020 2020  0)],.           
-0001bea0: 2020 2020 2027 6c65 6172 6e69 6e67 5f72       'learning_r
-0001beb0: 6174 6527 3a20 5b27 636f 6e73 7461 6e74  ate': ['constant
-0001bec0: 272c 2027 696e 7673 6361 6c69 6e67 272c  ', 'invscaling',
-0001bed0: 2027 6164 6170 7469 7665 275d 2c0a 2020   'adaptive'],.  
-0001bee0: 2020 2020 2020 2020 2020 2020 2020 2761                'a
-0001bef0: 6c70 6861 273a 205b 302e 3030 3030 312c  lpha': [0.00001,
-0001bf00: 2030 2e35 5d2c 200a 2020 2020 2020 2020   0.5], .        
-0001bf10: 2020 2020 2020 2020 2761 6374 6976 6174          'activat
-0001bf20: 696f 6e27 3a20 5b27 7461 6e68 272c 2027  ion': ['tanh', '
-0001bf30: 6c6f 6769 7374 6963 272c 2027 7265 6c75  logistic', 'relu
-0001bf40: 275d 2c0a 2020 2020 2020 2020 2020 2020  '],.            
-0001bf50: 2020 2020 2773 6f6c 7665 7227 3a20 5b27      'solver': ['
-0001bf60: 7367 6427 2c20 2761 6461 6d27 5d2c 0a20  sgd', 'adam'],. 
-0001bf70: 2020 2020 2020 2020 2020 2020 2020 2027                 '
-0001bf80: 6d61 785f 6974 6572 273a 205b 3130 302c  max_iter': [100,
-0001bf90: 2031 3530 2c20 3230 305d 200a 2020 2020   150, 200] .    
-0001bfa0: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
-0001bfb0: 2020 2020 2020 6773 203d 2042 6179 6573        gs = Bayes
-0001bfc0: 5365 6172 6368 4356 286e 5f69 7465 723d  SearchCV(n_iter=
-0001bfd0: 6e5f 6974 6572 2c20 6573 7469 6d61 746f  n_iter, estimato
-0001bfe0: 723d 6d6f 6465 6c5f 302c 2073 6561 7263  r=model_0, searc
-0001bff0: 685f 7370 6163 6573 3d70 6172 616d 732c  h_spaces=params,
-0001c000: 2063 763d 6f70 745f 6376 290a 2020 2020   cv=opt_cv).    
-0001c010: 2020 2020 2020 2020 6773 2e66 6974 2864          gs.fit(d
-0001c020: 6174 615f 782c 2064 6174 615f 7929 0a20  ata_x, data_y). 
-0001c030: 2020 2020 2020 2020 2020 2062 6573 745f             best_
-0001c040: 6573 742c 2062 6573 745f 7363 6f72 6520  est, best_score 
-0001c050: 3d20 6773 2e62 6573 745f 6573 7469 6d61  = gs.best_estima
-0001c060: 746f 725f 2c20 6e70 2e72 6f75 6e64 2867  tor_, np.round(g
-0001c070: 732e 6265 7374 5f73 636f 7265 5f2c 2034  s.best_score_, 4
-0001c080: 290a 2020 2020 2020 2020 2020 2020 7072  ).            pr
-0001c090: 696e 7428 2748 6967 6865 7374 206d 6561  int('Highest mea
-0001c0a0: 6e20 6163 6375 7261 6379 3a20 7b7d 272e  n accuracy: {}'.
-0001c0b0: 666f 726d 6174 2862 6573 745f 7363 6f72  format(best_scor
-0001c0c0: 6529 290a 2020 2020 2020 2020 2020 2020  e)).            
-0001c0d0: 7265 7475 726e 2067 732e 6265 7374 5f65  return gs.best_e
-0001c0e0: 7374 696d 6174 6f72 5f2c 2067 732e 6265  stimator_, gs.be
-0001c0f0: 7374 5f70 6172 616d 735f 0a20 2020 2020  st_params_.     
-0001c100: 2020 2020 200a 2020 2020 656c 6966 2063       .    elif c
-0001c110: 6c66 203d 3d20 2778 6762 273a 0a20 2020  lf == 'xgb':.   
-0001c120: 2020 2020 206f 626a 6563 7469 7665 203d       objective =
-0001c130: 206f 626a 6563 7469 7665 5f78 6762 2864   objective_xgb(d
-0001c140: 6174 615f 782c 2064 6174 615f 792c 206c  ata_x, data_y, l
-0001c150: 696d 6974 5f73 6561 7263 683d 6c69 6d69  imit_search=limi
-0001c160: 745f 7365 6172 6368 2c20 6f70 745f 6376  t_search, opt_cv
-0001c170: 3d6f 7074 5f63 7629 0a20 2020 2020 2020  =opt_cv).       
-0001c180: 2069 6620 6c69 6d69 745f 7365 6172 6368   if limit_search
-0001c190: 3a0a 2020 2020 2020 2020 2020 2020 7072  :.            pr
-0001c1a0: 696e 7428 274e 4f54 453a 2054 6f20 6578  int('NOTE: To ex
-0001c1b0: 7061 6e64 2068 7970 6572 7061 7261 6d65  pand hyperparame
-0001c1c0: 7465 7220 7365 6172 6368 2073 7061 6365  ter search space
-0001c1d0: 2c20 7365 7420 6c69 6d69 745f 7365 6172  , set limit_sear
-0001c1e0: 6368 3d46 616c 7365 2c20 616c 7468 6f75  ch=False, althou
-0001c1f0: 6768 2074 6869 7320 7769 6c6c 2069 6e63  gh this will inc
-0001c200: 7265 6173 6520 7468 6520 6f70 7469 6d69  rease the optimi
-0001c210: 7a61 7469 6f6e 2074 696d 6520 7369 676e  zation time sign
-0001c220: 6966 6963 616e 746c 792e 2729 0a20 2020  ificantly.').   
-0001c230: 2020 2020 2073 7475 6479 2e6f 7074 696d       study.optim
-0001c240: 697a 6528 6f62 6a65 6374 6976 652c 206e  ize(objective, n
-0001c250: 5f74 7269 616c 733d 6e5f 6974 6572 2c20  _trials=n_iter, 
-0001c260: 7368 6f77 5f70 726f 6772 6573 735f 6261  show_progress_ba
-0001c270: 723d 5472 7565 2923 2c20 6763 5f61 6674  r=True)#, gc_aft
-0001c280: 6572 5f74 7269 616c 3d54 7275 6529 0a20  er_trial=True). 
-0001c290: 2020 2020 2020 2070 6172 616d 7320 3d20         params = 
-0001c2a0: 7374 7564 792e 6265 7374 5f74 7269 616c  study.best_trial
-0001c2b0: 2e70 6172 616d 730a 2020 2020 2020 2020  .params.        
-0001c2c0: 6966 206c 696d 6974 5f73 6561 7263 683a  if limit_search:
-0001c2d0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-0001c2e0: 7061 7261 6d73 5b27 626f 6f73 7465 7227  params['booster'
-0001c2f0: 5d20 3d3d 2027 6461 7274 273a 0a20 2020  ] == 'dart':.   
-0001c300: 2020 2020 2020 2020 2020 2020 206d 6f64               mod
-0001c310: 656c 203d 2058 4742 436c 6173 7369 6669  el = XGBClassifi
-0001c320: 6572 2862 6f6f 7374 6572 3d70 6172 616d  er(booster=param
-0001c330: 735b 2762 6f6f 7374 6572 275d 2c20 206e  s['booster'],  n
-0001c340: 5f65 7374 696d 6174 6f72 733d 7061 7261  _estimators=para
-0001c350: 6d73 5b27 6e5f 6573 7469 6d61 746f 7273  ms['n_estimators
-0001c360: 275d 2c20 7265 675f 6c61 6d62 6461 3d70  '], reg_lambda=p
-0001c370: 6172 616d 735b 2772 6567 5f6c 616d 6264  arams['reg_lambd
-0001c380: 6127 5d2c 200a 2020 2020 2020 2020 2020  a'], .          
-0001c390: 2020 2020 2020 2020 2020 7265 675f 616c            reg_al
-0001c3a0: 7068 613d 7061 7261 6d73 5b27 7265 675f  pha=params['reg_
-0001c3b0: 616c 7068 6127 5d2c 206d 6178 5f64 6570  alpha'], max_dep
-0001c3c0: 7468 3d70 6172 616d 735b 276d 6178 5f64  th=params['max_d
-0001c3d0: 6570 7468 275d 2c20 6574 613d 7061 7261  epth'], eta=para
-0001c3e0: 6d73 5b27 6574 6127 5d2c 2067 616d 6d61  ms['eta'], gamma
-0001c3f0: 3d70 6172 616d 735b 2767 616d 6d61 275d  =params['gamma']
-0001c400: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
-0001c410: 2020 2020 2020 2067 726f 775f 706f 6c69         grow_poli
-0001c420: 6379 3d70 6172 616d 735b 2767 726f 775f  cy=params['grow_
-0001c430: 706f 6c69 6379 275d 2c20 7361 6d70 6c65  policy'], sample
-0001c440: 5f74 7970 653d 7061 7261 6d73 5b27 7361  _type=params['sa
-0001c450: 6d70 6c65 5f74 7970 6527 5d2c 206e 6f72  mple_type'], nor
-0001c460: 6d61 6c69 7a65 5f74 7970 653d 7061 7261  malize_type=para
-0001c470: 6d73 5b27 6e6f 726d 616c 697a 655f 7479  ms['normalize_ty
-0001c480: 7065 275d 2c0a 2020 2020 2020 2020 2020  pe'],.          
-0001c490: 2020 2020 2020 2020 2020 7261 7465 5f64            rate_d
-0001c4a0: 726f 703d 7061 7261 6d73 5b27 7261 7465  rop=params['rate
-0001c4b0: 5f64 726f 7027 5d2c 2073 6b69 705f 6472  _drop'], skip_dr
-0001c4c0: 6f70 3d70 6172 616d 735b 2773 6b69 705f  op=params['skip_
-0001c4d0: 6472 6f70 275d 2c20 7363 616c 655f 706f  drop'], scale_po
-0001c4e0: 735f 7765 6967 6874 3d73 616d 706c 655f  s_weight=sample_
-0001c4f0: 7765 6967 6874 2c20 7261 6e64 6f6d 5f73  weight, random_s
-0001c500: 7461 7465 3d31 3930 3929 0a20 2020 2020  tate=1909).     
-0001c510: 2020 2020 2020 2065 6c69 6620 7061 7261         elif para
-0001c520: 6d73 5b27 626f 6f73 7465 7227 5d20 3d3d  ms['booster'] ==
-0001c530: 2027 6762 7472 6565 273a 0a20 2020 2020   'gbtree':.     
-0001c540: 2020 2020 2020 2020 2020 206d 6f64 656c             model
-0001c550: 203d 2058 4742 436c 6173 7369 6669 6572   = XGBClassifier
-0001c560: 2862 6f6f 7374 6572 3d70 6172 616d 735b  (booster=params[
-0001c570: 2762 6f6f 7374 6572 275d 2c20 206e 5f65  'booster'],  n_e
-0001c580: 7374 696d 6174 6f72 733d 7061 7261 6d73  stimators=params
-0001c590: 5b27 6e5f 6573 7469 6d61 746f 7273 275d  ['n_estimators']
-0001c5a0: 2c20 7265 675f 6c61 6d62 6461 3d70 6172  , reg_lambda=par
-0001c5b0: 616d 735b 2772 6567 5f6c 616d 6264 6127  ams['reg_lambda'
-0001c5c0: 5d2c 200a 2020 2020 2020 2020 2020 2020  ], .            
-0001c5d0: 2020 2020 2020 2020 7265 675f 616c 7068          reg_alph
-0001c5e0: 613d 7061 7261 6d73 5b27 7265 675f 616c  a=params['reg_al
-0001c5f0: 7068 6127 5d2c 206d 6178 5f64 6570 7468  pha'], max_depth
-0001c600: 3d70 6172 616d 735b 276d 6178 5f64 6570  =params['max_dep
-0001c610: 7468 275d 2c20 6574 613d 7061 7261 6d73  th'], eta=params
-0001c620: 5b27 6574 6127 5d2c 2067 616d 6d61 3d70  ['eta'], gamma=p
-0001c630: 6172 616d 735b 2767 616d 6d61 275d 2c20  arams['gamma'], 
-0001c640: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001c650: 2020 2020 2067 726f 775f 706f 6c69 6379       grow_policy
-0001c660: 3d70 6172 616d 735b 2767 726f 775f 706f  =params['grow_po
-0001c670: 6c69 6379 275d 2c20 7375 6273 616d 706c  licy'], subsampl
-0001c680: 653d 7061 7261 6d73 5b27 7375 6273 616d  e=params['subsam
-0001c690: 706c 6527 5d2c 2073 6361 6c65 5f70 6f73  ple'], scale_pos
-0001c6a0: 5f77 6569 6768 743d 7361 6d70 6c65 5f77  _weight=sample_w
-0001c6b0: 6569 6768 742c 2072 616e 646f 6d5f 7374  eight, random_st
-0001c6c0: 6174 653d 3139 3039 290a 2020 2020 2020  ate=1909).      
-0001c6d0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-0001c6e0: 2020 2020 6966 2070 6172 616d 735b 2762      if params['b
-0001c6f0: 6f6f 7374 6572 275d 203d 3d20 2764 6172  ooster'] == 'dar
-0001c700: 7427 3a0a 2020 2020 2020 2020 2020 2020  t':.            
-0001c710: 2020 2020 6d6f 6465 6c20 3d20 5847 4243      model = XGBC
-0001c720: 6c61 7373 6966 6965 7228 626f 6f73 7465  lassifier(booste
-0001c730: 723d 7061 7261 6d73 5b27 626f 6f73 7465  r=params['booste
-0001c740: 7227 5d2c 206e 5f65 7374 696d 6174 6f72  r'], n_estimator
-0001c750: 733d 7061 7261 6d73 5b27 6e5f 6573 7469  s=params['n_esti
-0001c760: 6d61 746f 7273 275d 2c20 636f 6c73 616d  mators'], colsam
-0001c770: 706c 655f 6279 7472 6565 3d70 6172 616d  ple_bytree=param
-0001c780: 735b 2763 6f6c 7361 6d70 6c65 5f62 7974  s['colsample_byt
-0001c790: 7265 6527 5d2c 200a 2020 2020 2020 2020  ree'], .        
-0001c7a0: 2020 2020 2020 2020 2020 2020 7265 675f              reg_
-0001c7b0: 6c61 6d62 6461 3d70 6172 616d 735b 2772  lambda=params['r
-0001c7c0: 6567 5f6c 616d 6264 6127 5d2c 2072 6567  eg_lambda'], reg
-0001c7d0: 5f61 6c70 6861 3d70 6172 616d 735b 2772  _alpha=params['r
-0001c7e0: 6567 5f61 6c70 6861 275d 2c20 6d61 785f  eg_alpha'], max_
-0001c7f0: 6465 7074 683d 7061 7261 6d73 5b27 6d61  depth=params['ma
-0001c800: 785f 6465 7074 6827 5d2c 2065 7461 3d70  x_depth'], eta=p
-0001c810: 6172 616d 735b 2765 7461 275d 2c20 6761  arams['eta'], ga
-0001c820: 6d6d 613d 7061 7261 6d73 5b27 6761 6d6d  mma=params['gamm
-0001c830: 6127 5d2c 200a 2020 2020 2020 2020 2020  a'], .          
-0001c840: 2020 2020 2020 2020 2020 6772 6f77 5f70            grow_p
-0001c850: 6f6c 6963 793d 7061 7261 6d73 5b27 6772  olicy=params['gr
-0001c860: 6f77 5f70 6f6c 6963 7927 5d2c 2073 616d  ow_policy'], sam
-0001c870: 706c 655f 7479 7065 3d70 6172 616d 735b  ple_type=params[
-0001c880: 2773 616d 706c 655f 7479 7065 275d 2c20  'sample_type'], 
-0001c890: 6e6f 726d 616c 697a 655f 7479 7065 3d70  normalize_type=p
-0001c8a0: 6172 616d 735b 276e 6f72 6d61 6c69 7a65  arams['normalize
-0001c8b0: 5f74 7970 6527 5d2c 7261 7465 5f64 726f  _type'],rate_dro
-0001c8c0: 703d 7061 7261 6d73 5b27 7261 7465 5f64  p=params['rate_d
-0001c8d0: 726f 7027 5d2c 200a 2020 2020 2020 2020  rop'], .        
-0001c8e0: 2020 2020 2020 2020 2020 2020 736b 6970              skip
-0001c8f0: 5f64 726f 703d 7061 7261 6d73 5b27 736b  _drop=params['sk
-0001c900: 6970 5f64 726f 7027 5d2c 206d 696e 5f63  ip_drop'], min_c
-0001c910: 6869 6c64 5f77 6569 6768 743d 7061 7261  hild_weight=para
-0001c920: 6d73 5b27 6d69 6e5f 6368 696c 645f 7765  ms['min_child_we
-0001c930: 6967 6874 275d 2c20 6d61 785f 6465 6c74  ight'], max_delt
-0001c940: 615f 7374 6570 3d70 6172 616d 735b 276d  a_step=params['m
-0001c950: 6178 5f64 656c 7461 5f73 7465 7027 5d2c  ax_delta_step'],
-0001c960: 2073 7562 7361 6d70 6c65 3d70 6172 616d   subsample=param
-0001c970: 735b 2773 7562 7361 6d70 6c65 275d 2c0a  s['subsample'],.
-0001c980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001c990: 2020 2020 7363 616c 655f 706f 735f 7765      scale_pos_we
-0001c9a0: 6967 6874 3d73 616d 706c 655f 7765 6967  ight=sample_weig
-0001c9b0: 6874 2c20 7261 6e64 6f6d 5f73 7461 7465  ht, random_state
-0001c9c0: 3d31 3930 3929 0a20 2020 2020 2020 2020  =1909).         
-0001c9d0: 2020 2065 6c69 6620 7061 7261 6d73 5b27     elif params['
-0001c9e0: 626f 6f73 7465 7227 5d20 3d3d 2027 6762  booster'] == 'gb
-0001c9f0: 7472 6565 273a 0a20 2020 2020 2020 2020  tree':.         
-0001ca00: 2020 2020 2020 206d 6f64 656c 203d 2058         model = X
-0001ca10: 4742 436c 6173 7369 6669 6572 2862 6f6f  GBClassifier(boo
-0001ca20: 7374 6572 3d70 6172 616d 735b 2762 6f6f  ster=params['boo
-0001ca30: 7374 6572 275d 2c20 6e5f 6573 7469 6d61  ster'], n_estima
-0001ca40: 746f 7273 3d70 6172 616d 735b 276e 5f65  tors=params['n_e
-0001ca50: 7374 696d 6174 6f72 7327 5d2c 2063 6f6c  stimators'], col
-0001ca60: 7361 6d70 6c65 5f62 7974 7265 653d 7061  sample_bytree=pa
-0001ca70: 7261 6d73 5b27 636f 6c73 616d 706c 655f  rams['colsample_
-0001ca80: 6279 7472 6565 275d 2c20 0a20 2020 2020  bytree'], .     
-0001ca90: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0001caa0: 6567 5f6c 616d 6264 613d 7061 7261 6d73  eg_lambda=params
-0001cab0: 5b27 7265 675f 6c61 6d62 6461 275d 2c20  ['reg_lambda'], 
-0001cac0: 7265 675f 616c 7068 613d 7061 7261 6d73  reg_alpha=params
-0001cad0: 5b27 7265 675f 616c 7068 6127 5d2c 206d  ['reg_alpha'], m
-0001cae0: 6178 5f64 6570 7468 3d70 6172 616d 735b  ax_depth=params[
-0001caf0: 276d 6178 5f64 6570 7468 275d 2c20 6574  'max_depth'], et
-0001cb00: 613d 7061 7261 6d73 5b27 6574 6127 5d2c  a=params['eta'],
-0001cb10: 2067 616d 6d61 3d70 6172 616d 735b 2767   gamma=params['g
-0001cb20: 616d 6d61 275d 2c20 0a20 2020 2020 2020  amma'], .       
-0001cb30: 2020 2020 2020 2020 2020 2020 2067 726f               gro
-0001cb40: 775f 706f 6c69 6379 3d70 6172 616d 735b  w_policy=params[
-0001cb50: 2767 726f 775f 706f 6c69 6379 275d 2c20  'grow_policy'], 
-0001cb60: 7375 6273 616d 706c 653d 7061 7261 6d73  subsample=params
-0001cb70: 5b27 7375 6273 616d 706c 6527 5d2c 206d  ['subsample'], m
-0001cb80: 696e 5f63 6869 6c64 5f77 6569 6768 743d  in_child_weight=
-0001cb90: 7061 7261 6d73 5b27 6d69 6e5f 6368 696c  params['min_chil
-0001cba0: 645f 7765 6967 6874 275d 2c20 6d61 785f  d_weight'], max_
-0001cbb0: 6465 6c74 615f 7374 6570 3d70 6172 616d  delta_step=param
-0001cbc0: 735b 276d 6178 5f64 656c 7461 5f73 7465  s['max_delta_ste
-0001cbd0: 7027 5d2c 0a20 2020 2020 2020 2020 2020  p'],.           
-0001cbe0: 2020 2020 2020 2020 2073 6361 6c65 5f70           scale_p
-0001cbf0: 6f73 5f77 6569 6768 743d 7361 6d70 6c65  os_weight=sample
-0001cc00: 5f77 6569 6768 742c 2072 616e 646f 6d5f  _weight, random_
-0001cc10: 7374 6174 653d 3139 3039 290a 2020 2020  state=1909).    
-0001cc20: 2020 200a 2020 2020 656c 7365 3a0a 2020     .    else:.  
-0001cc30: 2020 2020 2020 6f62 6a65 6374 6976 6520        objective 
-0001cc40: 3d20 6f62 6a65 6374 6976 655f 636e 6e28  = objective_cnn(
-0001cc50: 6461 7461 5f78 2c20 6461 7461 5f79 2c20  data_x, data_y, 
-0001cc60: 7661 6c5f 706f 7369 7469 7665 3d76 616c  val_positive=val
-0001cc70: 5f58 2c20 7661 6c5f 6e65 6761 7469 7665  _X, val_negative
-0001cc80: 3d76 616c 5f59 2c20 696d 675f 6e75 6d5f  =val_Y, img_num_
-0001cc90: 6368 616e 6e65 6c73 3d69 6d67 5f6e 756d  channels=img_num
-0001cca0: 5f63 6861 6e6e 656c 732c 2063 6c66 3d63  _channels, clf=c
-0001ccb0: 6c66 2c20 0a20 2020 2020 2020 2020 2020  lf, .           
-0001ccc0: 206e 6f72 6d61 6c69 7a65 3d6e 6f72 6d61   normalize=norma
-0001ccd0: 6c69 7a65 2c20 6d69 6e5f 7069 7865 6c3d  lize, min_pixel=
-0001cce0: 6d69 6e5f 7069 7865 6c2c 206d 6178 5f70  min_pixel, max_p
-0001ccf0: 6978 656c 3d6d 6178 5f70 6978 656c 2c20  ixel=max_pixel, 
-0001cd00: 7061 7469 656e 6365 3d70 6174 6965 6e63  patience=patienc
-0001cd10: 652c 206d 6574 7269 633d 6d65 7472 6963  e, metric=metric
-0001cd20: 2c20 6176 6572 6167 653d 6176 6572 6167  , average=averag
-0001cd30: 652c 2020 0a20 2020 2020 2020 2020 2020  e,  .           
-0001cd40: 2074 6573 745f 706f 7369 7469 7665 3d74   test_positive=t
-0001cd50: 6573 745f 706f 7369 7469 7665 2c20 7465  est_positive, te
-0001cd60: 7374 5f6e 6567 6174 6976 653d 7465 7374  st_negative=test
-0001cd70: 5f6e 6567 6174 6976 652c 206f 7074 5f6d  _negative, opt_m
-0001cd80: 6f64 656c 3d6f 7074 5f6d 6f64 656c 2c20  odel=opt_model, 
-0001cd90: 6261 7463 685f 7369 7a65 5f6d 696e 3d62  batch_size_min=b
-0001cda0: 6174 6368 5f73 697a 655f 6d69 6e2c 2062  atch_size_min, b
-0001cdb0: 6174 6368 5f73 697a 655f 6d61 783d 6261  atch_size_max=ba
-0001cdc0: 7463 685f 7369 7a65 5f6d 6178 2c20 7472  tch_size_max, tr
-0001cdd0: 6169 6e5f 6570 6f63 6873 3d74 7261 696e  ain_epochs=train
-0001cde0: 5f65 706f 6368 732c 206f 7074 5f63 763d  _epochs, opt_cv=
-0001cdf0: 6f70 745f 6376 2c0a 2020 2020 2020 2020  opt_cv,.        
-0001ce00: 2020 2020 6f70 745f 6175 673d 6f70 745f      opt_aug=opt_
-0001ce10: 6175 672c 2062 6174 6368 5f6d 696e 3d62  aug, batch_min=b
-0001ce20: 6174 6368 5f6d 696e 2c20 6261 7463 685f  atch_min, batch_
-0001ce30: 6d61 783d 6261 7463 685f 6d61 782c 2062  max=batch_max, b
-0001ce40: 6174 6368 5f6f 7468 6572 3d62 6174 6368  atch_other=batch
-0001ce50: 5f6f 7468 6572 2c20 6261 6c61 6e63 653d  _other, balance=
-0001ce60: 6261 6c61 6e63 652c 2069 6d61 6765 5f73  balance, image_s
-0001ce70: 697a 655f 6d69 6e3d 696d 6167 655f 7369  ize_min=image_si
-0001ce80: 7a65 5f6d 696e 2c20 696d 6167 655f 7369  ze_min, image_si
-0001ce90: 7a65 5f6d 6178 3d69 6d61 6765 5f73 697a  ze_max=image_siz
-0001cea0: 655f 6d61 782c 200a 2020 2020 2020 2020  e_max, .        
-0001ceb0: 2020 2020 7368 6966 743d 7368 6966 742c      shift=shift,
-0001cec0: 206f 7074 5f6d 6178 5f6d 696e 5f70 6978   opt_max_min_pix
-0001ced0: 3d6f 7074 5f6d 6178 5f6d 696e 5f70 6978  =opt_max_min_pix
-0001cee0: 2c20 6f70 745f 6d61 785f 6d61 785f 7069  , opt_max_max_pi
-0001cef0: 783d 6f70 745f 6d61 785f 6d61 785f 7069  x=opt_max_max_pi
-0001cf00: 782c 206d 6173 6b5f 7369 7a65 3d6d 6173  x, mask_size=mas
-0001cf10: 6b5f 7369 7a65 2c20 6e75 6d5f 6d61 736b  k_size, num_mask
-0001cf20: 733d 6e75 6d5f 6d61 736b 732c 2073 6d6f  s=num_masks, smo
-0001cf30: 7465 5f73 616d 706c 696e 673d 736d 6f74  te_sampling=smot
-0001cf40: 655f 7361 6d70 6c69 6e67 2c20 0a20 2020  e_sampling, .   
-0001cf50: 2020 2020 2020 2020 2062 6c65 6e64 5f6d           blend_m
-0001cf60: 6178 3d62 6c65 6e64 5f6d 6178 2c20 6e75  ax=blend_max, nu
-0001cf70: 6d5f 696d 6167 6573 5f74 6f5f 626c 656e  m_images_to_blen
-0001cf80: 643d 6e75 6d5f 696d 6167 6573 5f74 6f5f  d=num_images_to_
-0001cf90: 626c 656e 642c 2062 6c65 6e64 696e 675f  blend, blending_
-0001cfa0: 6675 6e63 3d62 6c65 6e64 696e 675f 6675  func=blending_fu
-0001cfb0: 6e63 2c20 626c 656e 645f 6f74 6865 723d  nc, blend_other=
-0001cfc0: 626c 656e 645f 6f74 6865 722c 207a 6f6f  blend_other, zoo
-0001cfd0: 6d5f 7261 6e67 653d 7a6f 6f6d 5f72 616e  m_range=zoom_ran
-0001cfe0: 6765 2c20 736b 6577 5f61 6e67 6c65 3d73  ge, skew_angle=s
-0001cff0: 6b65 775f 616e 676c 652c 0a20 2020 2020  kew_angle,.     
-0001d000: 2020 2020 2020 206c 696d 6974 5f73 6561         limit_sea
-0001d010: 7263 683d 6c69 6d69 745f 7365 6172 6368  rch=limit_search
-0001d020: 2c20 6d6f 6e69 746f 7231 3d6d 6f6e 6974  , monitor1=monit
-0001d030: 6f72 312c 206d 6f6e 6974 6f72 323d 6d6f  or1, monitor2=mo
-0001d040: 6e69 746f 7232 2c20 6d6f 6e69 746f 7231  nitor2, monitor1
-0001d050: 5f74 6872 6573 683d 6d6f 6e69 746f 7231  _thresh=monitor1
-0001d060: 5f74 6872 6573 682c 206d 6f6e 6974 6f72  _thresh, monitor
-0001d070: 325f 7468 7265 7368 3d6d 6f6e 6974 6f72  2_thresh=monitor
-0001d080: 325f 7468 7265 7368 2c20 7665 7262 6f73  2_thresh, verbos
-0001d090: 653d 7665 7262 6f73 6529 2020 2020 2020  e=verbose)      
-0001d0a0: 0a20 2020 2020 2020 2073 7475 6479 2e6f  .        study.o
-0001d0b0: 7074 696d 697a 6528 6f62 6a65 6374 6976  ptimize(objectiv
-0001d0c0: 652c 206e 5f74 7269 616c 733d 6e5f 6974  e, n_trials=n_it
-0001d0d0: 6572 2c20 7368 6f77 5f70 726f 6772 6573  er, show_progres
-0001d0e0: 735f 6261 723d 5472 7565 2c20 6763 5f61  s_bar=True, gc_a
-0001d0f0: 6674 6572 5f74 7269 616c 3d54 7275 6529  fter_trial=True)
-0001d100: 232c 206e 5f6a 6f62 733d 3129 0a20 2020  #, n_jobs=1).   
-0001d110: 2020 2020 2070 6172 616d 7320 3d20 7374       params = st
-0001d120: 7564 792e 6265 7374 5f74 7269 616c 2e70  udy.best_trial.p
-0001d130: 6172 616d 730a 0a20 2020 2066 696e 616c  arams..    final
-0001d140: 5f73 636f 7265 203d 2073 7475 6479 2e62  _score = study.b
-0001d150: 6573 745f 7661 6c75 650a 0a20 2020 2069  est_value..    i
-0001d160: 6620 636c 6620 3d3d 2027 7266 2720 6f72  f clf == 'rf' or
-0001d170: 2063 6c66 203d 3d20 2778 6762 2720 6f72   clf == 'xgb' or
-0001d180: 2063 6c66 203d 3d20 276e 6e27 3a0a 2020   clf == 'nn':.  
-0001d190: 2020 2020 2020 6966 2069 6e69 7469 616c        if initial
-0001d1a0: 5f73 636f 7265 203e 2066 696e 616c 5f73  _score > final_s
-0001d1b0: 636f 7265 3a0a 2020 2020 2020 2020 2020  core:.          
-0001d1c0: 2020 7072 696e 7428 2748 7970 6572 7061    print('Hyperpa
-0001d1d0: 7261 6d65 7465 7220 6f70 7469 6d69 7a61  rameter optimiza
-0001d1e0: 7469 6f6e 2063 6f6d 706c 6574 6521 204f  tion complete! O
-0001d1f0: 7074 696d 616c 2070 6572 666f 726d 616e  ptimal performan
-0001d200: 6365 206f 6620 7b7d 2069 7320 4c4f 5745  ce of {} is LOWE
-0001d210: 5220 7468 616e 2074 6865 2062 6173 6520  R than the base 
-0001d220: 7065 7266 6f72 6d61 6e63 6520 6f66 207b  performance of {
-0001d230: 7d2c 2074 7279 2069 6e63 7265 6173 696e  }, try increasin
-0001d240: 6720 7468 6520 7661 6c75 6520 6f66 206e  g the value of n
-0001d250: 5f69 7465 7220 616e 6420 7275 6e20 6167  _iter and run ag
-0001d260: 6169 6e2e 272e 666f 726d 6174 286e 702e  ain.'.format(np.
-0001d270: 726f 756e 6428 6669 6e61 6c5f 7363 6f72  round(final_scor
-0001d280: 652c 2038 292c 206e 702e 726f 756e 6428  e, 8), np.round(
-0001d290: 696e 6974 6961 6c5f 7363 6f72 652c 2038  initial_score, 8
-0001d2a0: 2929 290a 2020 2020 2020 2020 656c 7365  ))).        else
-0001d2b0: 3a0a 2020 2020 2020 2020 2020 2020 7072  :.            pr
-0001d2c0: 696e 7428 2748 7970 6572 7061 7261 6d65  int('Hyperparame
-0001d2d0: 7465 7220 6f70 7469 6d69 7a61 7469 6f6e  ter optimization
-0001d2e0: 2063 6f6d 706c 6574 6521 204f 7074 696d   complete! Optim
-0001d2f0: 616c 2070 6572 666f 726d 616e 6365 206f  al performance o
-0001d300: 6620 7b7d 2069 7320 4849 4748 4552 2074  f {} is HIGHER t
-0001d310: 6861 6e20 7468 6520 6261 7365 2070 6572  han the base per
-0001d320: 666f 726d 616e 6365 206f 6620 7b7d 2e27  formance of {}.'
-0001d330: 2e66 6f72 6d61 7428 6e70 2e72 6f75 6e64  .format(np.round
-0001d340: 2866 696e 616c 5f73 636f 7265 2c20 3829  (final_score, 8)
-0001d350: 2c20 6e70 2e72 6f75 6e64 2869 6e69 7469  , np.round(initi
-0001d360: 616c 5f73 636f 7265 2c20 3829 2929 0a20  al_score, 8))). 
-0001d370: 2020 2020 2020 2069 6620 7265 7475 726e         if return
-0001d380: 5f73 7475 6479 3a0a 2020 2020 2020 2020  _study:.        
-0001d390: 2020 2020 7265 7475 726e 206d 6f64 656c      return model
-0001d3a0: 2c20 7061 7261 6d73 2c20 7374 7564 790a  , params, study.
-0001d3b0: 2020 2020 2020 2020 7265 7475 726e 206d          return m
-0001d3c0: 6f64 656c 2c20 7061 7261 6d73 0a20 2020  odel, params.   
-0001d3d0: 2065 6c73 653a 0a20 2020 2020 2020 2070   else:.        p
-0001d3e0: 7269 6e74 2827 4879 7065 7270 6172 616d  rint('Hyperparam
-0001d3f0: 6574 6572 206f 7074 696d 697a 6174 696f  eter optimizatio
-0001d400: 6e20 636f 6d70 6c65 7465 2120 4f70 7469  n complete! Opti
-0001d410: 6d61 6c20 7065 7266 6f72 6d61 6e63 653a  mal performance:
-0001d420: 207b 7d27 2e66 6f72 6d61 7428 6e70 2e72   {}'.format(np.r
-0001d430: 6f75 6e64 2866 696e 616c 5f73 636f 7265  ound(final_score
-0001d440: 2c20 3829 2929 0a20 2020 2020 2020 2069  , 8))).        i
-0001d450: 6620 7265 7475 726e 5f73 7475 6479 3a0a  f return_study:.
-0001d460: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-0001d470: 726e 2070 6172 616d 732c 2073 7475 6479  rn params, study
-0001d480: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0001d490: 7061 7261 6d73 0a0a 6465 6620 626f 7275  params..def boru
-0001d4a0: 7461 7368 6170 5f6f 7074 2864 6174 615f  tashap_opt(data_
-0001d4b0: 782c 2064 6174 615f 792c 2062 6f72 7574  x, data_y, borut
-0001d4c0: 615f 7472 6961 6c73 3d35 302c 206d 6f64  a_trials=50, mod
-0001d4d0: 656c 3d27 7266 272c 2069 6d70 6f72 7461  el='rf', importa
-0001d4e0: 6e63 655f 7479 7065 3d27 6761 696e 2729  nce_type='gain')
-0001d4f0: 3a0a 2020 2020 2222 220a 2020 2020 4170  :.    """.    Ap
-0001d500: 706c 6965 7320 6120 636f 6d62 696e 6174  plies a combinat
-0001d510: 696f 6e20 6f66 2074 6865 2042 6f72 7574  ion of the Borut
-0001d520: 6120 616c 676f 7269 7468 6d20 616e 640a  a algorithm and.
-0001d530: 2020 2020 5368 6170 6c65 7920 7661 6c75      Shapley valu
-0001d540: 6573 2c20 6120 6d65 7468 6f64 2064 6576  es, a method dev
-0001d550: 656c 6f70 6564 2062 7920 456f 6768 616e  eloped by Eoghan
-0001d560: 204b 6561 6e79 2028 3230 3230 292e 0a0a   Keany (2020)...
-0001d570: 2020 2020 5365 653a 2068 7474 7073 3a2f      See: https:/
-0001d580: 2f64 6f69 2e6f 7267 2f31 302e 3532 3831  /doi.org/10.5281
-0001d590: 2f7a 656e 6f64 6f2e 3432 3437 3631 380a  /zenodo.4247618.
-0001d5a0: 0a20 2020 2041 7267 733a 0a20 2020 2020  .    Args:.     
-0001d5b0: 2020 2064 6174 615f 7820 286e 6461 7272     data_x (ndarr
-0001d5c0: 6179 293a 2032 4420 6172 7261 7920 6f66  ay): 2D array of
-0001d5d0: 2073 697a 6520 286e 2078 206d 292c 2077   size (n x m), w
-0001d5e0: 6865 7265 206e 2069 7320 7468 650a 2020  here n is the.  
-0001d5f0: 2020 2020 2020 2020 2020 6e75 6d62 6572            number
-0001d600: 206f 6620 7361 6d70 6c65 732c 2061 6e64   of samples, and
-0001d610: 206d 2074 6865 206e 756d 6265 7220 6f66   m the number of
-0001d620: 2066 6561 7475 7265 732e 0a20 2020 2020   features..     
-0001d630: 2020 2064 6174 615f 7920 286e 6461 7272     data_y (ndarr
-0001d640: 6179 2c20 7374 7229 3a20 3144 2061 7272  ay, str): 1D arr
-0001d650: 6179 2063 6f6e 7461 696e 696e 6720 7468  ay containing th
-0001d660: 6520 636f 7272 6573 706f 6e69 6e67 206c  e corresponing l
-0001d670: 6162 656c 732e 0a20 2020 2020 2020 2062  abels..        b
-0001d680: 6f72 7574 615f 7472 6961 6c73 2028 696e  oruta_trials (in
-0001d690: 7429 3a20 5468 6520 6e75 6d62 6572 206f  t): The number o
-0001d6a0: 6620 7472 6961 6c73 2074 6f20 7275 6e2e  f trials to run.
-0001d6b0: 2041 206c 6172 6765 7220 6e75 6d62 6572   A larger number
-0001d6c0: 2069 730a 2020 2020 2020 2020 2020 2020   is.            
-0001d6d0: 6265 7474 6572 2061 7320 7468 6520 6469  better as the di
-0001d6e0: 7374 7269 6275 7469 6f6e 2077 696c 6c20  stribution will 
-0001d6f0: 6265 206d 6f72 6520 726f 6275 7374 2074  be more robust t
-0001d700: 6f20 7261 6e64 6f6d 2066 6c75 6374 7561  o random fluctua
-0001d710: 7469 6f6e 732e 200a 2020 2020 2020 2020  tions. .        
-0001d720: 2020 2020 4465 6661 756c 7473 2074 6f20      Defaults to 
-0001d730: 3530 2e0a 2020 2020 2020 2020 6d6f 6465  50..        mode
-0001d740: 6c20 2873 7472 293a 2054 6865 2065 6e73  l (str): The ens
-0001d750: 656d 626c 6520 6d65 7468 6f64 2074 6f20  emble method to 
-0001d760: 7573 6520 7768 656e 2066 6974 7469 6e67  use when fitting
-0001d770: 2061 6e64 2063 616c 6375 6c61 7469 6e67   and calculating
-0001d780: 0a20 2020 2020 2020 2020 2020 2074 6865  .            the
-0001d790: 2066 6561 7475 7265 2069 6d70 6f72 7461   feature importa
-0001d7a0: 6e63 6520 6d65 7472 6963 2e20 4f6e 6c79  nce metric. Only
-0001d7b0: 2074 776f 206f 7074 696f 6e73 2061 7265   two options are
-0001d7c0: 2063 7572 7265 6e74 6c79 0a20 2020 2020   currently.     
-0001d7d0: 2020 2020 2020 2073 7570 706f 7274 6564         supported
-0001d7e0: 2c20 2772 6627 2066 6f72 2052 616e 646f  , 'rf' for Rando
-0001d7f0: 6d20 466f 7265 7374 2061 6e64 2027 7867  m Forest and 'xg
-0001d800: 6227 2066 6f72 2045 7874 7265 6d65 2047  b' for Extreme G
-0001d810: 7261 6469 656e 7420 426f 6f73 7469 6e67  radient Boosting
-0001d820: 2e0a 2020 2020 2020 2020 2020 2020 4465  ..            De
-0001d830: 6661 756c 7473 2074 6f20 2772 6627 2e0a  faults to 'rf'..
-0001d840: 2020 2020 2020 2020 696d 706f 7274 616e          importan
-0001d850: 6365 5f74 7970 6520 2873 7472 293a 2054  ce_type (str): T
-0001d860: 6865 2066 6561 7475 7265 2069 6d70 6f72  he feature impor
-0001d870: 7461 6e63 6520 7479 7065 2074 6f20 7573  tance type to us
-0001d880: 652c 206f 6e6c 7920 6170 706c 6963 6162  e, only applicab
-0001d890: 6c65 0a20 2020 2020 2020 2020 2020 2077  le.            w
-0001d8a0: 6865 6e20 7573 696e 6720 636c 663d 2778  hen using clf='x
-0001d8b0: 6762 272e 2054 6865 206f 7074 696f 6e73  gb'. The options
-0001d8c0: 2069 6e63 6c75 6465 20e2 809c 6761 696e   include ...gain
-0001d8d0: e280 9d2c 20e2 809c 7765 6967 6874 e280  ..., ...weight..
-0001d8e0: 9d2c 20e2 809c 636f 7665 72e2 809d 2c0a  ., ...cover...,.
-0001d8f0: 2020 2020 2020 2020 2020 2020 e280 9c74              ...t
-0001d900: 6f74 616c 5f67 6169 6ee2 809d 206f 7220  otal_gain... or 
-0001d910: e280 9c74 6f74 616c 5f63 6f76 6572 e280  ...total_cover..
-0001d920: 9d2e 2044 6566 6175 6c74 7320 746f 2027  .. Defaults to '
-0001d930: 6761 696e 272e 0a0a 2020 2020 5265 7475  gain'...    Retu
-0001d940: 726e 733a 0a20 2020 2020 2020 2046 6972  rns:.        Fir
-0001d950: 7374 206f 7574 7075 7420 6973 2061 2031  st output is a 1
-0001d960: 4420 6172 7261 7920 636f 6e74 6169 6e69  D array containi
-0001d970: 6e67 2074 6865 2069 6e64 6963 6573 206f  ng the indices o
-0001d980: 6620 7468 6520 7365 6c65 6374 6564 2066  f the selected f
-0001d990: 6561 7475 7265 732e 200a 2020 2020 2020  eatures. .      
-0001d9a0: 2020 5468 6573 6520 696e 6469 6365 7320    These indices 
-0001d9b0: 6361 6e20 7468 656e 2062 6520 7573 6564  can then be used
-0001d9c0: 2074 6f20 7365 6c65 6374 2074 6865 2063   to select the c
-0001d9d0: 6f6c 756d 6e73 2069 6e20 7468 6520 6461  olumns in the da
-0001d9e0: 7461 5f78 2061 7272 6179 2e0a 2020 2020  ta_x array..    
-0001d9f0: 2020 2020 5365 636f 6e64 206f 7574 7075      Second outpu
-0001da00: 7420 6973 2074 6865 2066 6561 7475 7265  t is the feature
-0001da10: 2073 656c 6563 7469 6f6e 206f 626a 6563   selection objec
-0001da20: 742c 2077 6869 6368 2063 6f6e 7461 696e  t, which contain
-0001da30: 7320 6665 6174 7572 6520 7365 6c65 6374  s feature select
-0001da40: 696f 6e0a 2020 2020 2020 2020 6869 7374  ion.        hist
-0001da50: 6f72 7920 696e 666f 726d 6174 696f 6e20  ory information 
-0001da60: 616e 6420 7669 7375 616c 697a 6174 696f  and visualizatio
-0001da70: 6e20 6f70 7469 6f6e 732e 0a20 2020 2022  n options..    "
-0001da80: 2222 0a20 2020 200a 2020 2020 6966 2062  "".    .    if b
-0001da90: 6f72 7574 615f 7472 6961 6c73 203d 3d20  oruta_trials == 
-0001daa0: 303a 2023 5468 6973 2069 7320 7468 6520  0: #This is the 
-0001dab0: 666c 6167 2074 6861 7420 7468 6520 656e  flag that the en
-0001dac0: 7365 6d62 6c65 5f6d 6f64 656c 2e43 6c61  semble_model.Cla
-0001dad0: 7373 6966 6965 7220 636c 6173 7320 7573  ssifier class us
-0001dae0: 6573 2074 6f20 6469 7361 626c 6520 6665  es to disable fe
-0001daf0: 6174 7572 6520 7365 6c65 6374 696f 6e0a  ature selection.
-0001db00: 2020 2020 2020 2020 7265 7475 726e 206e          return n
-0001db10: 702e 6172 616e 6765 2864 6174 615f 782e  p.arange(data_x.
-0001db20: 7368 6170 655b 315d 292c 204e 6f6e 650a  shape[1]), None.
-0001db30: 0a20 2020 2069 6620 626f 7275 7461 5f74  .    if boruta_t
-0001db40: 7269 616c 7320 3c20 3230 3a0a 2020 2020  rials < 20:.    
-0001db50: 2020 2020 7072 696e 7428 2757 4152 4e49      print('WARNI
-0001db60: 4e47 3a20 5265 7375 6c74 7320 6172 6520  NG: Results are 
-0001db70: 756e 7374 6162 6c65 2069 6620 626f 7275  unstable if boru
-0001db80: 7461 5f74 7269 616c 7320 6973 2074 6f6f  ta_trials is too
-0001db90: 206c 6f77 2127 290a 2020 2020 6966 206e   low!').    if n
-0001dba0: 702e 616e 7928 6e70 2e69 736e 616e 2864  p.any(np.isnan(d
-0001dbb0: 6174 615f 7829 293a 0a20 2020 2020 2020  ata_x)):.       
-0001dbc0: 2023 7072 696e 7428 274e 614e 2076 616c   #print('NaN val
-0001dbd0: 7565 7320 6465 7465 6374 6564 2c20 6170  ues detected, ap
-0001dbe0: 706c 7969 6e67 2053 7472 6177 6d61 6e20  plying Strawman 
-0001dbf0: 696d 7075 7461 7469 6f6e 2e2e 2e27 290a  imputation...').
-0001dc00: 2020 2020 2020 2020 6461 7461 5f78 203d          data_x =
-0001dc10: 2053 7472 6177 6d61 6e5f 696d 7075 7461   Strawman_imputa
-0001dc20: 7469 6f6e 2864 6174 615f 7829 0a0a 2020  tion(data_x)..  
-0001dc30: 2020 6966 206d 6f64 656c 203d 3d20 2772    if model == 'r
-0001dc40: 6627 3a0a 2020 2020 2020 2020 636c 6173  f':.        clas
-0001dc50: 7369 6669 6572 203d 2052 616e 646f 6d46  sifier = RandomF
-0001dc60: 6f72 6573 7443 6c61 7373 6966 6965 7228  orestClassifier(
-0001dc70: 7261 6e64 6f6d 5f73 7461 7465 3d31 3930  random_state=190
-0001dc80: 3929 0a20 2020 2065 6c69 6620 6d6f 6465  9).    elif mode
-0001dc90: 6c20 3d3d 2027 7867 6227 3a0a 2020 2020  l == 'xgb':.    
-0001dca0: 2020 2020 636c 6173 7369 6669 6572 203d      classifier =
-0001dcb0: 2058 4742 436c 6173 7369 6669 6572 2874   XGBClassifier(t
-0001dcc0: 7265 655f 6d65 7468 6f64 3d27 6578 6163  ree_method='exac
-0001dcd0: 7427 2c20 6d61 785f 6465 7074 683d 3230  t', max_depth=20
-0001dce0: 2c20 696d 706f 7274 616e 6365 5f74 7970  , importance_typ
-0001dcf0: 653d 696d 706f 7274 616e 6365 5f74 7970  e=importance_typ
-0001dd00: 652c 2072 616e 646f 6d5f 7374 6174 653d  e, random_state=
-0001dd10: 3139 3039 290a 2020 2020 656c 7365 3a0a  1909).    else:.
-0001dd20: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
-0001dd30: 6c75 6545 7272 6f72 2827 4d6f 6465 6c20  lueError('Model 
-0001dd40: 6172 6775 6d65 6e74 206d 7573 7420 6569  argument must ei
-0001dd50: 7468 6572 2062 6520 2272 6622 206f 7220  ther be "rf" or 
-0001dd60: 2278 6762 222e 2729 0a20 2020 200a 2020  "xgb".').    .  
-0001dd70: 2020 7472 793a 0a20 2020 2020 2020 2023    try:.        #
-0001dd80: 426f 7275 7461 5368 6170 2070 726f 6772  BorutaShap progr
-0001dd90: 616d 2072 6571 7569 7265 7320 696e 7075  am requires inpu
-0001dda0: 7420 746f 2068 6176 6520 7468 6520 636f  t to have the co
-0001ddb0: 6c75 6d6e 7320 6174 7472 6962 7574 650a  lumns attribute.
-0001ddc0: 2020 2020 2020 2020 2343 6f6e 7665 7274          #Convert
-0001ddd0: 696e 6720 746f 2050 616e 6461 7320 6461  ing to Pandas da
-0001dde0: 7461 6672 616d 650a 2020 2020 2020 2020  taframe.        
-0001ddf0: 636f 6c73 203d 205b 7374 7228 6929 2066  cols = [str(i) f
-0001de00: 6f72 2069 2069 6e20 6e70 2e61 7261 6e67  or i in np.arang
-0001de10: 6528 6461 7461 5f78 2e73 6861 7065 5b31  e(data_x.shape[1
-0001de20: 5d29 5d0a 2020 2020 2020 2020 5820 3d20  ])].        X = 
-0001de30: 4461 7461 4672 616d 6528 6461 7461 5f78  DataFrame(data_x
-0001de40: 2c20 636f 6c75 6d6e 733d 636f 6c73 290a  , columns=cols).
-0001de50: 2020 2020 2020 2020 7920 3d20 6e70 2e7a          y = np.z
-0001de60: 6572 6f73 286c 656e 2864 6174 615f 7929  eros(len(data_y)
-0001de70: 290a 0a20 2020 2020 2020 2023 4265 6c6f  )..        #Belo
-0001de80: 7720 6973 2074 6f20 636f 6e76 6572 7420  w is to convert 
-0001de90: 6361 7465 676f 7269 6361 6c20 6c61 6265  categorical labe
-0001dea0: 6c73 2074 6f20 6e75 6d65 7269 6361 6c2c  ls to numerical,
-0001deb0: 2061 7320 7065 7220 426f 7275 7461 5368   as per BorutaSh
-0001dec0: 6170 2072 6571 7569 7265 6d65 6e74 730a  ap requirements.
-0001ded0: 2020 2020 2020 2020 666f 7220 692c 206c          for i, l
-0001dee0: 6162 656c 2069 6e20 656e 756d 6572 6174  abel in enumerat
-0001def0: 6528 6e70 2e75 6e69 7175 6528 6461 7461  e(np.unique(data
-0001df00: 5f79 2929 3a0a 2020 2020 2020 2020 2020  _y)):.          
-0001df10: 2020 6d61 736b 203d 206e 702e 7768 6572    mask = np.wher
-0001df20: 6528 6461 7461 5f79 203d 3d20 6c61 6265  e(data_y == labe
-0001df30: 6c29 5b30 5d0a 2020 2020 2020 2020 2020  l)[0].          
-0001df40: 2020 795b 6d61 736b 5d20 3d20 690a 0a20    y[mask] = i.. 
-0001df50: 2020 2020 2020 2066 6561 745f 7365 6c65         feat_sele
-0001df60: 6374 6f72 203d 2042 6f72 7574 6153 6861  ctor = BorutaSha
-0001df70: 7028 6d6f 6465 6c3d 636c 6173 7369 6669  p(model=classifi
-0001df80: 6572 2c20 696d 706f 7274 616e 6365 5f6d  er, importance_m
-0001df90: 6561 7375 7265 3d27 7368 6170 272c 2063  easure='shap', c
-0001dfa0: 6c61 7373 6966 6963 6174 696f 6e3d 5472  lassification=Tr
-0001dfb0: 7565 290a 2020 2020 2020 2020 7072 696e  ue).        prin
-0001dfc0: 7428 2752 756e 6e69 6e67 2066 6561 7475  t('Running featu
-0001dfd0: 7265 2073 656c 6563 7469 6f6e 2e2e 2e27  re selection...'
-0001dfe0: 290a 2020 2020 2020 2020 6665 6174 5f73  ).        feat_s
-0001dff0: 656c 6563 746f 722e 6669 7428 583d 582c  elector.fit(X=X,
-0001e000: 2079 3d79 2c20 6e5f 7472 6961 6c73 3d62   y=y, n_trials=b
-0001e010: 6f72 7574 615f 7472 6961 6c73 2c20 7665  oruta_trials, ve
-0001e020: 7262 6f73 653d 4661 6c73 652c 2072 616e  rbose=False, ran
-0001e030: 646f 6d5f 7374 6174 653d 3139 3039 290a  dom_state=1909).
-0001e040: 0a20 2020 2020 2020 2069 6e64 6578 203d  .        index =
-0001e050: 206e 702e 6172 7261 7928 5b69 6e74 2866   np.array([int(f
-0001e060: 6561 7429 2066 6f72 2066 6561 7420 696e  eat) for feat in
-0001e070: 2066 6561 745f 7365 6c65 6374 6f72 2e61   feat_selector.a
-0001e080: 6363 6570 7465 645d 290a 2020 2020 2020  ccepted]).      
-0001e090: 2020 696e 6465 782e 736f 7274 2829 0a20    index.sort(). 
-0001e0a0: 2020 2020 2020 2070 7269 6e74 2827 4665         print('Fe
-0001e0b0: 6174 7572 6520 7365 6c65 6374 696f 6e20  ature selection 
-0001e0c0: 636f 6d70 6c65 7465 2c20 7b7d 2073 656c  complete, {} sel
-0001e0d0: 6563 7465 6420 6f75 7420 6f66 207b 7d21  ected out of {}!
-0001e0e0: 272e 666f 726d 6174 286c 656e 2869 6e64  '.format(len(ind
-0001e0f0: 6578 292c 2064 6174 615f 782e 7368 6170  ex), data_x.shap
-0001e100: 655b 315d 2929 0a20 2020 2065 7863 6570  e[1])).    excep
-0001e110: 743a 0a20 2020 2020 2020 2070 7269 6e74  t:.        print
-0001e120: 2827 426f 7275 7461 2077 6974 6820 5368  ('Boruta with Sh
-0001e130: 6170 6c65 7920 7661 6c75 6573 2066 6169  apley values fai
-0001e140: 6c65 642c 2073 7769 7463 6869 6e67 2074  led, switching t
-0001e150: 6f20 6f72 6967 696e 616c 2042 6f72 7574  o original Borut
-0001e160: 612e 2e2e 2729 0a20 2020 2020 2020 2069  a...').        i
-0001e170: 6e64 6578 203d 2062 6f72 7574 615f 6f70  ndex = boruta_op
-0001e180: 7428 6461 7461 5f78 2c20 6461 7461 5f79  t(data_x, data_y
-0001e190: 290a 0a20 2020 2072 6574 7572 6e20 696e  )..    return in
-0001e1a0: 6465 782c 2066 6561 745f 7365 6c65 6374  dex, feat_select
-0001e1b0: 6f72 0a0a 6465 6620 626f 7275 7461 5f6f  or..def boruta_o
-0001e1c0: 7074 2864 6174 615f 782c 2064 6174 615f  pt(data_x, data_
-0001e1d0: 7929 3a0a 2020 2020 2222 220a 2020 2020  y):.    """.    
-0001e1e0: 4170 706c 6965 7320 7468 6520 426f 7275  Applies the Boru
-0001e1f0: 7461 2061 6c67 6f72 6974 686d 2028 4b75  ta algorithm (Ku
-0001e200: 7273 6120 2620 5275 646e 6963 6b69 2032  rsa & Rudnicki 2
-0001e210: 3031 3129 2074 6f20 6964 656e 7469 6679  011) to identify
-0001e220: 2066 6561 7475 7265 730a 2020 2020 7468   features.    th
-0001e230: 6174 2070 6572 666f 726d 2077 6f72 7365  at perform worse
-0001e240: 2074 6861 6e20 7261 6e64 6f6d 2e0a 0a20   than random... 
-0001e250: 2020 2053 6565 3a20 6874 7470 733a 2f2f     See: https://
-0001e260: 6172 7869 762e 6f72 672f 7064 662f 3131  arxiv.org/pdf/11
-0001e270: 3036 2e35 3131 322e 7064 660a 0a20 2020  06.5112.pdf..   
-0001e280: 2041 7267 733a 0a20 2020 2020 2020 2064   Args:.        d
-0001e290: 6174 615f 7820 286e 6461 7272 6179 293a  ata_x (ndarray):
-0001e2a0: 2032 4420 6172 7261 7920 6f66 2073 697a   2D array of siz
-0001e2b0: 6520 286e 2078 206d 292c 2077 6865 7265  e (n x m), where
-0001e2c0: 206e 2069 7320 7468 650a 2020 2020 2020   n is the.      
-0001e2d0: 2020 2020 2020 6e75 6d62 6572 206f 6620        number of 
-0001e2e0: 7361 6d70 6c65 732c 2061 6e64 206d 2074  samples, and m t
-0001e2f0: 6865 206e 756d 6265 7220 6f66 2066 6561  he number of fea
-0001e300: 7475 7265 732e 0a20 2020 2020 2020 2064  tures..        d
-0001e310: 6174 615f 7920 286e 6461 7272 6179 2c20  ata_y (ndarray, 
-0001e320: 7374 7229 3a20 3144 2061 7272 6179 2063  str): 1D array c
-0001e330: 6f6e 7461 696e 696e 6720 7468 6520 636f  ontaining the co
-0001e340: 7272 6573 706f 6e69 6e67 206c 6162 656c  rresponing label
-0001e350: 732e 0a20 2020 2020 2020 2020 2020 200a  s..            .
-0001e360: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
-0001e370: 2020 2020 2031 4420 6172 7261 7920 636f       1D array co
-0001e380: 6e74 6169 6e69 6e67 2074 6865 2069 6e64  ntaining the ind
-0001e390: 6963 6573 206f 6620 7468 6520 7365 6c65  ices of the sele
-0001e3a0: 6374 6564 2066 6561 7475 7265 732e 2054  cted features. T
-0001e3b0: 6869 7320 6361 6e20 7468 656e 0a20 2020  his can then.   
-0001e3c0: 2020 2020 2062 6520 7573 6564 2074 6f20       be used to 
-0001e3d0: 696e 6465 7820 7468 6520 636f 6c75 6d6e  index the column
-0001e3e0: 7320 696e 2074 6865 2064 6174 615f 7820  s in the data_x 
-0001e3f0: 6172 7261 792e 0a20 2020 2022 2222 0a0a  array..    """..
-0001e400: 2020 2020 636c 6173 7369 6669 6572 203d      classifier =
-0001e410: 2052 616e 646f 6d46 6f72 6573 7443 6c61   RandomForestCla
-0001e420: 7373 6966 6965 7228 7261 6e64 6f6d 5f73  ssifier(random_s
-0001e430: 7461 7465 3d31 3930 3929 0a0a 2020 2020  tate=1909)..    
-0001e440: 6665 6174 5f73 656c 6563 746f 7220 3d20  feat_selector = 
-0001e450: 426f 7275 7461 5079 2863 6c61 7373 6966  BorutaPy(classif
-0001e460: 6965 722c 206e 5f65 7374 696d 6174 6f72  ier, n_estimator
-0001e470: 733d 2761 7574 6f27 2c20 7261 6e64 6f6d  s='auto', random
-0001e480: 5f73 7461 7465 3d31 3930 3929 0a20 2020  _state=1909).   
-0001e490: 2070 7269 6e74 2827 5275 6e6e 696e 6720   print('Running 
-0001e4a0: 6665 6174 7572 6520 7365 6c65 6374 696f  feature selectio
-0001e4b0: 6e2e 2e2e 2729 0a20 2020 2066 6561 745f  n...').    feat_
-0001e4c0: 7365 6c65 6374 6f72 2e66 6974 2864 6174  selector.fit(dat
-0001e4d0: 615f 782c 2064 6174 615f 7929 0a0a 2020  a_x, data_y)..  
-0001e4e0: 2020 6665 6174 7320 3d20 6e70 2e61 7272    feats = np.arr
-0001e4f0: 6179 285b 7374 7228 6665 6174 2920 666f  ay([str(feat) fo
-0001e500: 7220 6665 6174 2069 6e20 6665 6174 5f73  r feat in feat_s
-0001e510: 656c 6563 746f 722e 7375 7070 6f72 745f  elector.support_
-0001e520: 5d29 0a20 2020 2069 6e64 6578 203d 206e  ]).    index = n
-0001e530: 702e 7768 6572 6528 6665 6174 7320 3d3d  p.where(feats ==
-0001e540: 2027 5472 7565 2729 5b30 5d0a 2020 2020   'True')[0].    
-0001e550: 7072 696e 7428 2746 6561 7475 7265 2073  print('Feature s
-0001e560: 656c 6563 7469 6f6e 2063 6f6d 706c 6574  election complet
-0001e570: 652c 207b 7d20 7365 6c65 6374 6564 206f  e, {} selected o
-0001e580: 7574 206f 6620 7b7d 2127 2e66 6f72 6d61  ut of {}!'.forma
-0001e590: 7428 6c65 6e28 696e 6465 7829 2c6c 656e  t(len(index),len
-0001e5a0: 2866 6561 745f 7365 6c65 6374 6f72 2e73  (feat_selector.s
-0001e5b0: 7570 706f 7274 2929 290a 2020 2020 7265  upport))).    re
-0001e5c0: 7475 726e 2069 6e64 6578 0a0a 6465 6620  turn index..def 
-0001e5d0: 5374 7261 776d 616e 5f69 6d70 7574 6174  Strawman_imputat
-0001e5e0: 696f 6e28 6461 7461 293a 0a20 2020 2022  ion(data):.    "
-0001e5f0: 2222 0a20 2020 2050 6572 666f 726d 2053  "".    Perform S
-0001e600: 7472 6177 6d61 6e20 696d 7075 7461 7469  trawman imputati
-0001e610: 6f6e 2c20 6120 7469 6d65 2d65 6666 6963  on, a time-effic
-0001e620: 6965 6e74 2061 6c67 6f72 6974 686d 0a20  ient algorithm. 
-0001e630: 2020 2069 6e20 7768 6963 6820 6d69 7373     in which miss
-0001e640: 696e 6720 6461 7461 2076 616c 7565 7320  ing data values 
-0001e650: 6172 6520 7265 706c 6163 6564 2077 6974  are replaced wit
-0001e660: 6820 7468 6520 6d65 6469 616e 0a20 2020  h the median.   
-0001e670: 2076 616c 7565 206f 6620 7468 6520 656e   value of the en
-0001e680: 7469 7265 2c20 6e6f 6e2d 4e61 4e20 7361  tire, non-NaN sa
-0001e690: 6d70 6c65 2e20 4966 2074 6865 2064 6174  mple. If the dat
-0001e6a0: 6120 6973 2061 2068 6f74 2d65 6e63 6f64  a is a hot-encod
-0001e6b0: 6564 0a20 2020 2062 6f6f 6c65 616e 2028  ed.    boolean (
-0001e6c0: 6173 2074 6865 2052 4620 646f 6573 206e  as the RF does n
-0001e6d0: 6f74 2061 6c6c 6f77 2054 7275 6520 6f72  ot allow True or
-0001e6e0: 2046 616c 7365 292c 2074 6865 6e20 7468   False), then th
-0001e6f0: 6520 0a20 2020 2069 6e73 7461 6e63 6520  e .    instance 
-0001e700: 7468 6174 2069 7320 7573 6564 2074 6865  that is used the
-0001e710: 206d 6f73 7420 7769 6c6c 2062 6520 636f   most will be co
-0001e720: 6d70 7574 6564 2061 7320 7468 6520 6d65  mputed as the me
-0001e730: 6469 616e 2e20 0a0a 2020 2020 5468 6973  dian. ..    This
-0001e740: 2069 7320 7468 6520 6261 7365 6c69 6e65   is the baseline
-0001e750: 2061 6c67 6f72 6974 686d 2075 7365 6420   algorithm used 
-0001e760: 6279 2028 5461 6e67 2026 2049 7368 7761  by (Tang & Ishwa
-0001e770: 7261 6e20 3230 3137 292e 0a20 2020 2053  ran 2017)..    S
-0001e780: 6565 3a20 6874 7470 733a 2f2f 6172 7869  ee: https://arxi
-0001e790: 762e 6f72 672f 7064 662f 3137 3031 2e30  v.org/pdf/1701.0
-0001e7a0: 3533 3035 2e70 6466 0a0a 2020 2020 4e6f  5305.pdf..    No
-0001e7b0: 7465 3a0a 2020 2020 2020 2020 5468 6973  te:.        This
-0001e7c0: 2066 756e 6374 696f 6e20 6173 7375 6d65   function assume
-0001e7d0: 7320 6561 6368 2072 6f77 2063 6f72 7265  s each row corre
-0001e7e0: 7370 6f6e 6473 2074 6f20 6f6e 6520 7361  sponds to one sa
-0001e7f0: 6d70 6c65 2c20 616e 6420 0a20 2020 2020  mple, and .     
-0001e800: 2020 2074 6861 7420 6d69 7373 696e 6720     that missing 
-0001e810: 7661 6c75 6573 2061 7265 206d 6173 6b65  values are maske
-0001e820: 6420 6173 2065 6974 6865 7220 4e61 4e20  d as either NaN 
-0001e830: 6f72 2069 6e66 2e20 0a0a 2020 2020 4172  or inf. ..    Ar
-0001e840: 6773 3a0a 2020 2020 2020 2020 6461 7461  gs:.        data
-0001e850: 2028 6e64 6172 7261 7929 3a20 3144 2061   (ndarray): 1D a
-0001e860: 7272 6179 2069 6620 7369 6e67 6c65 2070  rray if single p
-0001e870: 6172 616d 6574 6572 2069 7320 696e 7075  arameter is inpu
-0001e880: 742e 2049 660a 2020 2020 2020 2020 2020  t. If.          
-0001e890: 2020 6461 7461 2069 7320 322d 6469 6d65    data is 2-dime
-0001e8a0: 6e73 696f 6e61 6c2c 2074 6865 206d 6564  nsional, the med
-0001e8b0: 6961 6e73 2077 696c 6c20 6265 2063 616c  ians will be cal
-0001e8c0: 6375 6c61 7465 640a 2020 2020 2020 2020  culated.        
-0001e8d0: 2020 2020 7573 696e 6720 7468 6520 6e6f      using the no
-0001e8e0: 6e2d 6d69 7373 696e 6720 7661 6c75 6573  n-missing values
-0001e8f0: 2069 6e20 6561 6368 2063 6f72 7265 7370   in each corresp
-0001e900: 6f6e 6469 6e67 2063 6f6c 756d 6e2e 0a0a  onding column...
-0001e910: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
-0001e920: 2020 2020 2054 6865 2064 6174 6120 6172       The data ar
-0001e930: 7261 7920 7769 7468 2074 6865 206d 6973  ray with the mis
-0001e940: 7369 6e67 2076 616c 7565 7320 6669 6c6c  sing values fill
-0001e950: 6564 2069 6e2e 200a 2020 2020 2222 220a  ed in. .    """.
-0001e960: 0a20 2020 2069 6620 6e70 2e61 6c6c 286e  .    if np.all(n
-0001e970: 702e 6973 6669 6e69 7465 2864 6174 6129  p.isfinite(data)
-0001e980: 293a 0a20 2020 2020 2020 2070 7269 6e74  ):.        print
-0001e990: 2827 4e6f 206d 6973 7369 6e67 2076 616c  ('No missing val
-0001e9a0: 7565 7320 696e 2064 6174 612c 2072 6574  ues in data, ret
-0001e9b0: 7572 6e69 6e67 206f 7269 6769 6e61 6c20  urning original 
-0001e9c0: 6172 7261 792e 2729 0a20 2020 2020 2020  array.').       
-0001e9d0: 2072 6574 7572 6e20 6461 7461 200a 0a20   return data .. 
-0001e9e0: 2020 2069 6620 6c65 6e28 6461 7461 2e73     if len(data.s
-0001e9f0: 6861 7065 2920 3d3d 2031 3a0a 2020 2020  hape) == 1:.    
-0001ea00: 2020 2020 6d61 736b 203d 206e 702e 7768      mask = np.wh
-0001ea10: 6572 6528 6e70 2e69 7366 696e 6974 6528  ere(np.isfinite(
-0001ea20: 6461 7461 2929 5b30 5d0a 2020 2020 2020  data))[0].      
-0001ea30: 2020 6d65 6469 616e 203d 206e 702e 6d65    median = np.me
-0001ea40: 6469 616e 2864 6174 615b 6d61 736b 5d29  dian(data[mask])
-0001ea50: 0a20 2020 2020 2020 2064 6174 615b 6e70  .        data[np
-0001ea60: 2e69 736e 616e 2864 6174 6129 5d20 3d20  .isnan(data)] = 
-0001ea70: 6d65 6469 616e 200a 0a20 2020 2020 2020  median ..       
-0001ea80: 2072 6574 7572 6e20 6461 7461 0a0a 2020   return data..  
-0001ea90: 2020 4e79 2c20 4e78 203d 2064 6174 612e    Ny, Nx = data.
-0001eaa0: 7368 6170 650a 2020 2020 696d 7075 7465  shape.    impute
-0001eab0: 645f 6461 7461 203d 206e 702e 7a65 726f  d_data = np.zero
-0001eac0: 7328 284e 792c 4e78 2929 0a0a 2020 2020  s((Ny,Nx))..    
-0001ead0: 666f 7220 6920 696e 2072 616e 6765 284e  for i in range(N
-0001eae0: 7829 3a0a 2020 2020 2020 2020 6d61 736b  x):.        mask
-0001eaf0: 203d 206e 702e 7768 6572 6528 6e70 2e69   = np.where(np.i
-0001eb00: 7366 696e 6974 6528 6461 7461 5b3a 2c69  sfinite(data[:,i
-0001eb10: 5d29 295b 305d 0a20 2020 2020 2020 206d  ]))[0].        m
-0001eb20: 6564 6961 6e20 3d20 6e70 2e6d 6564 6961  edian = np.media
-0001eb30: 6e28 6461 7461 5b3a 2c69 5d5b 6d61 736b  n(data[:,i][mask
-0001eb40: 5d29 0a0a 2020 2020 2020 2020 666f 7220  ])..        for 
-0001eb50: 6a20 696e 2072 616e 6765 284e 7929 3a0a  j in range(Ny):.
-0001eb60: 2020 2020 2020 2020 2020 2020 6966 206e              if n
-0001eb70: 702e 6973 6e61 6e28 6461 7461 5b6a 2c69  p.isnan(data[j,i
-0001eb80: 5d29 203d 3d20 5472 7565 206f 7220 6e70  ]) == True or np
-0001eb90: 2e69 7369 6e66 2864 6174 615b 6a2c 695d  .isinf(data[j,i]
-0001eba0: 2920 3d3d 2054 7275 653a 0a20 2020 2020  ) == True:.     
-0001ebb0: 2020 2020 2020 2020 2020 2069 6d70 7574             imput
-0001ebc0: 6564 5f64 6174 615b 6a2c 695d 203d 206d  ed_data[j,i] = m
-0001ebd0: 6564 6961 6e0a 2020 2020 2020 2020 2020  edian.          
-0001ebe0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-0001ebf0: 2020 2020 2020 2020 696d 7075 7465 645f          imputed_
-0001ec00: 6461 7461 5b6a 2c69 5d20 3d20 6461 7461  data[j,i] = data
-0001ec10: 5b6a 2c69 5d0a 0a20 2020 2072 6574 7572  [j,i]..    retur
-0001ec20: 6e20 696d 7075 7465 645f 6461 7461 200a  n imputed_data .
-0001ec30: 0a64 6566 204b 4e4e 5f69 6d70 7574 6174  .def KNN_imputat
-0001ec40: 696f 6e28 6461 7461 2c20 696d 7075 7465  ion(data, impute
-0001ec50: 723d 4e6f 6e65 2c20 6b3d 3329 3a0a 2020  r=None, k=3):.  
-0001ec60: 2020 2222 220a 2020 2020 5065 7266 6f72    """.    Perfor
-0001ec70: 6d73 206b 2d4e 6561 7265 7374 204e 6569  ms k-Nearest Nei
-0001ec80: 6768 626f 7220 696d 7075 7461 7469 6f6e  ghbor imputation
-0001ec90: 2061 6e64 2074 7261 6e73 666f 726d 6174   and transformat
-0001eca0: 696f 6e2e 0a20 2020 2042 7920 6465 6661  ion..    By defa
-0001ecb0: 756c 7420 7468 6520 696d 7075 7465 7220  ult the imputer 
-0001ecc0: 7769 6c6c 2062 6520 6372 6561 7465 6420  will be created 
-0001ecd0: 616e 6420 7265 7475 726e 6564 2c20 756e  and returned, un
-0001ece0: 6c65 7373 0a20 2020 2074 6865 2069 6d70  less.    the imp
-0001ecf0: 7574 6572 2061 7267 756d 656e 7420 6973  uter argument is
-0001ed00: 2073 6574 2c20 696e 2077 6869 6368 2063   set, in which c
-0001ed10: 6173 6520 6f6e 6c79 2074 6865 2074 7261  ase only the tra
-0001ed20: 6e73 666f 726d 6564 0a20 2020 2064 6174  nsformed.    dat
-0001ed30: 6120 6973 206f 7574 7075 742e 200a 0a20  a is output. .. 
-0001ed40: 2020 2041 7320 7468 6973 2062 756e 646c     As this bundl
-0001ed50: 6573 206e 6569 6768 626f 7273 2061 6363  es neighbors acc
-0001ed60: 6f72 6469 6e67 2074 6f20 7468 6569 7220  ording to their 
-0001ed70: 6575 636c 6564 6961 6e20 6469 7374 616e  eucledian distan
-0001ed80: 6365 2c0a 2020 2020 6974 2069 7320 7365  ce,.    it is se
-0001ed90: 6e73 6974 6976 6520 746f 206f 7574 6c69  nsitive to outli
-0001eda0: 6572 732e 2043 616e 2061 6c73 6f20 7969  ers. Can also yi
-0001edb0: 656c 6420 7765 616b 2070 7265 6469 6374  eld weak predict
-0001edc0: 696f 6e73 2069 6620 7468 650a 2020 2020  ions if the.    
-0001edd0: 7472 6169 6e69 6e67 2066 6561 7475 7265  training feature
-0001ede0: 7320 6172 6520 6865 6176 696c 6979 2063  s are heaviliy c
-0001edf0: 6f72 7265 6c61 7465 642e 0a20 2020 200a  orrelated..    .
-0001ee00: 2020 2020 4172 6773 3a0a 2020 2020 2020      Args:.      
-0001ee10: 2020 696d 7075 7465 7220 286f 7074 696f    imputer (optio
-0001ee20: 6e61 6c29 3a20 4120 4b4e 4e49 6d70 7574  nal): A KNNImput
-0001ee30: 6572 2063 6c61 7373 2069 6e73 7461 6e63  er class instanc
-0001ee40: 652c 2063 6f6e 6669 6775 7265 6420 7573  e, configured us
-0001ee50: 696e 6720 736b 6c65 6172 6e2e 696d 7075  ing sklearn.impu
-0001ee60: 7465 2e4b 4e4e 496d 7075 7465 722e 0a20  te.KNNImputer.. 
-0001ee70: 2020 2020 2020 2020 2020 2044 6566 6175             Defau
-0001ee80: 6c74 7320 746f 204e 6f6e 652c 2069 6e20  lts to None, in 
-0001ee90: 7768 6963 6820 6361 7365 2074 6865 2074  which case the t
-0001eea0: 7261 6e73 666f 726d 6174 696f 6e20 6973  ransformation is
-0001eeb0: 2063 7265 6174 6564 2075 7369 6e67 0a20   created using. 
-0001eec0: 2020 2020 2020 2020 2020 2074 6865 2064             the d
-0001eed0: 6174 6120 6974 7365 6c66 2e20 0a20 2020  ata itself. .   
-0001eee0: 2020 2020 2064 6174 6120 286e 6461 7272       data (ndarr
-0001eef0: 6179 293a 2031 4420 6172 7261 7920 6966  ay): 1D array if
-0001ef00: 2073 696e 676c 6520 7061 7261 6d65 7465   single paramete
-0001ef10: 7220 6973 2069 6e70 7574 2e20 4966 0a20  r is input. If. 
-0001ef20: 2020 2020 2020 2020 2020 2064 6174 6120             data 
-0001ef30: 6973 2032 2d64 696d 656e 7369 6f6e 616c  is 2-dimensional
-0001ef40: 2c20 7468 6520 6d65 6469 616e 7320 7769  , the medians wi
-0001ef50: 6c6c 2062 6520 6361 6c63 756c 6174 6564  ll be calculated
-0001ef60: 0a20 2020 2020 2020 2020 2020 2075 7369  .            usi
-0001ef70: 6e67 2074 6865 206e 6f6e 2d6d 6973 7369  ng the non-missi
-0001ef80: 6e67 2076 616c 7565 7320 696e 2065 6163  ng values in eac
-0001ef90: 6820 636f 7272 6573 706f 6e64 696e 6720  h corresponding 
-0001efa0: 636f 6c75 6d6e 2e0a 2020 2020 2020 2020  column..        
-0001efb0: 6b20 2869 6e74 2c20 6f70 7469 6f6e 616c  k (int, optional
-0001efc0: 293a 2049 6620 696d 7075 7465 7220 6973  ): If imputer is
-0001efd0: 204e 6f6e 652c 2074 6869 7320 6973 2074   None, this is t
-0001efe0: 6865 206e 756d 6265 720a 2020 2020 2020  he number.      
-0001eff0: 2020 2020 2020 6f66 206e 6561 7265 7374        of nearest
-0001f000: 206e 6569 6768 626f 7273 2074 6f20 636f   neighbors to co
-0001f010: 6e73 6964 6572 2077 6865 6e20 636f 6d70  nsider when comp
-0001f020: 7574 696e 6720 7468 6520 696d 7075 7461  uting the imputa
-0001f030: 7469 6f6e 2e0a 2020 2020 2020 2020 2020  tion..          
-0001f040: 2020 4465 6661 756c 7473 2074 6f20 332e    Defaults to 3.
-0001f050: 2049 6620 696d 7075 7465 7220 6172 6775   If imputer argu
-0001f060: 6d65 6e74 2069 7320 7365 742c 2074 6869  ment is set, thi
-0001f070: 7320 7661 7269 6162 6c65 2069 7320 6967  s variable is ig
-0001f080: 6e6f 7265 642e 0a0a 2020 2020 4e6f 7465  nored...    Note
-0001f090: 3a0a 2020 2020 2020 2020 5461 6e67 2026  :.        Tang &
-0001f0a0: 2049 7368 7761 7261 6e20 3230 3137 2072   Ishwaran 2017 r
-0001f0b0: 6570 6f72 7465 6420 7468 6174 2069 6620  eported that if 
-0001f0c0: 7468 6572 6520 6973 206c 6f77 2074 6f20  there is low to 
-0001f0d0: 6d65 6469 756d 0a20 2020 2020 2020 2063  medium.        c
-0001f0e0: 6f72 7265 6c61 7469 6f6e 2069 6e20 7468  orrelation in th
-0001f0f0: 6520 6461 7461 7365 742c 2052 4620 696d  e dataset, RF im
-0001f100: 7075 7461 7469 6f6e 2061 6c67 6f72 6974  putation algorit
-0001f110: 686d 7320 7065 7266 6f72 6d20 0a20 2020  hms perform .   
-0001f120: 2020 2020 2062 6574 7465 7220 7468 616e       better than
-0001f130: 204b 4e4e 2069 6d70 7574 6174 696f 6e0a   KNN imputation.
-0001f140: 0a20 2020 2045 7861 6d70 6c65 3a0a 2020  .    Example:.  
-0001f150: 2020 2020 2020 4966 2077 6520 6861 7665        If we have
-0001f160: 206f 7572 2074 7261 696e 696e 6720 6461   our training da
-0001f170: 7461 2069 6e20 616e 2061 7272 6179 2063  ta in an array c
-0001f180: 616c 6c65 6420 7472 6169 6e69 6e67 5f73  alled training_s
-0001f190: 6574 2c20 7765 200a 2020 2020 2020 2020  et, we .        
-0001f1a0: 6361 6e20 6372 6561 7465 2074 6865 2069  can create the i
-0001f1b0: 6d70 7574 6572 2073 6f20 7468 6174 2077  mputer so that w
-0001f1c0: 6520 6361 6e20 6361 6c6c 2069 7420 746f  e can call it to
-0001f1d0: 2074 7261 6e73 666f 726d 206e 6577 2064   transform new d
-0001f1e0: 6174 610a 2020 2020 2020 2020 7768 656e  ata.        when
-0001f1f0: 206d 616b 696e 6720 6f6e 2d74 6865 2d66   making on-the-f
-0001f200: 6965 6c64 2070 7265 6469 6374 696f 6e73  ield predictions
-0001f210: 2e0a 0a20 2020 2020 2020 203e 3e3e 2069  ...        >>> i
-0001f220: 6d70 7574 6564 5f64 6174 612c 206b 6e6e  mputed_data, knn
-0001f230: 5f69 6d70 7574 6572 203d 204b 4e4e 5f69  _imputer = KNN_i
-0001f240: 6d70 7574 6174 696f 6e28 6461 7461 3d74  mputation(data=t
-0001f250: 7261 696e 696e 675f 7365 742c 2069 6d70  raining_set, imp
-0001f260: 7574 6572 3d4e 6f6e 6529 0a20 2020 2020  uter=None).     
-0001f270: 2020 200a 2020 2020 2020 2020 4e6f 7720     .        Now 
-0001f280: 7765 2063 616e 2075 7365 2074 6865 2069  we can use the i
-0001f290: 6d70 7574 6564 2064 6174 6120 746f 2063  mputed data to c
-0001f2a0: 7265 6174 6520 6f75 7220 6d61 6368 696e  reate our machin
-0001f2b0: 6520 6c65 6172 6e69 6e67 206d 6f64 656c  e learning model
-0001f2c0: 2e0a 2020 2020 2020 2020 4166 7465 7277  ..        Afterw
-0001f2d0: 6172 6473 2c20 7768 656e 206e 6577 2064  ards, when new d
-0001f2e0: 6174 6120 6973 2069 6e70 7574 2066 6f72  ata is input for
-0001f2f0: 2070 7265 6469 6374 696f 6e2c 2077 6520   prediction, we 
-0001f300: 7769 6c6c 2069 6e73 6572 7420 6f75 7220  will insert our 
-0001f310: 0a20 2020 2020 2020 2069 6d70 7574 6572  .        imputer
-0001f320: 2069 6e74 6f20 7468 6520 7069 7065 6c69   into the pipeli
-0001f330: 6e65 6e20 6279 2063 616c 6c69 6e67 2074  nen by calling t
-0001f340: 6869 7320 6675 6e63 7469 6f6e 2061 6761  his function aga
-0001f350: 696e 2c20 6275 7420 7468 6973 2074 696d  in, but this tim
-0001f360: 650a 2020 2020 2020 2020 7769 7468 2074  e.        with t
-0001f370: 6865 2069 6d70 7574 6572 2061 7267 756d  he imputer argum
-0001f380: 656e 7420 7365 743a 0a0a 2020 2020 2020  ent set:..      
-0001f390: 2020 3e3e 3e20 6e65 775f 6461 7461 203d    >>> new_data =
-0001f3a0: 206b 6e6e 5f69 6d70 7574 6174 696f 6e28   knn_imputation(
-0001f3b0: 6e65 775f 6461 7461 2c20 696d 7075 7465  new_data, impute
-0001f3c0: 723d 6b6e 6e5f 696d 7075 7465 7229 0a0a  r=knn_imputer)..
-0001f3d0: 2020 2020 5265 7475 726e 733a 0a20 2020      Returns:.   
-0001f3e0: 2020 2020 2054 6865 2066 6972 7374 206f       The first o
-0001f3f0: 7574 7075 7420 6973 2074 6865 2064 6174  utput is the dat
-0001f400: 6120 6172 7261 7920 7769 7468 2077 6974  a array with wit
-0001f410: 6820 7468 6520 6d69 7373 696e 6720 7661  h the missing va
-0001f420: 6c75 6573 2066 696c 6c65 6420 696e 2e20  lues filled in. 
-0001f430: 0a20 2020 2020 2020 2054 6865 2073 6563  .        The sec
-0001f440: 6f6e 6420 6f75 7470 7574 2069 7320 7468  ond output is th
-0001f450: 6520 4b4e 4e20 496d 7075 7465 7220 7468  e KNN Imputer th
-0001f460: 6174 2073 686f 756c 6420 6265 2075 7365  at should be use
-0001f470: 6420 746f 2074 7261 6e73 666f 726d 0a20  d to transform. 
-0001f480: 2020 2020 2020 206e 6577 2064 6174 612c         new data,
-0001f490: 2070 7269 6f72 2074 6f20 7072 6564 6963   prior to predic
-0001f4a0: 7469 6f6e 732e 200a 2020 2020 2222 220a  tions. .    """.
-0001f4b0: 0a20 2020 2069 6620 696d 7075 7465 7220  .    if imputer 
-0001f4c0: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
-0001f4d0: 2069 6d70 7574 6572 203d 204b 4e4e 496d   imputer = KNNIm
-0001f4e0: 7075 7465 7228 6e5f 6e65 6967 6862 6f72  puter(n_neighbor
-0001f4f0: 733d 6b29 0a20 2020 2020 2020 2069 6d70  s=k).        imp
-0001f500: 7574 6572 2e66 6974 2864 6174 6129 0a20  uter.fit(data). 
-0001f510: 2020 2020 2020 2069 6d70 7574 6564 5f64         imputed_d
-0001f520: 6174 6120 3d20 696d 7075 7465 722e 7472  ata = imputer.tr
-0001f530: 616e 7366 6f72 6d28 6461 7461 290a 2020  ansform(data).  
-0001f540: 2020 2020 2020 7265 7475 726e 2069 6d70        return imp
-0001f550: 7574 6564 5f64 6174 612c 2069 6d70 7574  uted_data, imput
-0001f560: 6572 0a0a 2020 2020 7265 7475 726e 2069  er..    return i
-0001f570: 6d70 7574 6572 2e74 7261 6e73 666f 726d  mputer.transform
-0001f580: 2864 6174 6129 200a 0a63 6c61 7373 2049  (data) ..class I
-0001f590: 6e70 7574 5469 6d65 6f75 743a 0a20 2020  nputTimeout:.   
-0001f5a0: 2022 2222 0a20 2020 2041 2063 6c61 7373   """.    A class
-0001f5b0: 2066 6f72 2072 6561 6469 6e67 2075 7365   for reading use
-0001f5c0: 7220 696e 7075 7420 7769 7468 2061 2074  r input with a t
-0001f5d0: 696d 656f 7574 206f 6e20 4c69 6e75 782c  imeout on Linux,
-0001f5e0: 2075 7365 6420 696e 2074 6865 2043 4e4e   used in the CNN
-0001f5f0: 206f 7074 696d 697a 6174 696f 6e20 726f   optimization ro
-0001f600: 7574 696e 652e 200a 0a20 2020 2045 7861  utine. ..    Exa
-0001f610: 6d70 6c65 3a0a 0a20 2020 2020 2020 2069  mple:..        i
-0001f620: 6e70 7574 5f74 696d 656f 7574 203d 2049  nput_timeout = I
-0001f630: 6e70 7574 5469 6d65 6f75 7428 2245 6e74  nputTimeout("Ent
-0001f640: 6572 2079 6f75 7220 696e 7075 743a 2022  er your input: "
-0001f650: 2c20 3529 0a20 2020 2020 2020 2074 7279  , 5).        try
-0001f660: 3a0a 2020 2020 2020 2020 2020 2020 7573  :.            us
-0001f670: 6572 5f69 6e70 7574 203d 2069 6e70 7574  er_input = input
-0001f680: 5f74 696d 656f 7574 2e69 6e70 7574 696d  _timeout.inputim
-0001f690: 656f 7574 2829 0a20 2020 2020 2020 2020  eout().         
-0001f6a0: 2020 2070 7269 6e74 2822 5573 6572 2069     print("User i
-0001f6b0: 6e70 7574 3a22 2c20 7573 6572 5f69 6e70  nput:", user_inp
-0001f6c0: 7574 290a 2020 2020 2020 2020 6578 6365  ut).        exce
-0001f6d0: 7074 2049 6e70 7574 5469 6d65 6f75 742e  pt InputTimeout.
-0001f6e0: 5469 6d65 6f75 744f 6363 7572 7265 643a  TimeoutOccurred:
-0001f6f0: 0a20 2020 2020 2020 2020 2020 2070 7269  .            pri
-0001f700: 6e74 2822 5469 6d65 6f75 7420 6f63 6375  nt("Timeout occu
-0001f710: 7272 6564 2e20 4e6f 2069 6e70 7574 2072  rred. No input r
-0001f720: 6563 6569 7665 642e 2229 0a0a 2020 2020  eceived.")..    
-0001f730: 4174 7472 6962 7574 6573 3a0a 2020 2020  Attributes:.    
-0001f740: 2020 2020 7072 6f6d 7074 2028 7374 7229      prompt (str)
-0001f750: 3a20 5468 6520 7072 6f6d 7074 206d 6573  : The prompt mes
-0001f760: 7361 6765 2074 6f20 6469 7370 6c61 7920  sage to display 
-0001f770: 746f 2074 6865 2075 7365 722e 0a20 2020  to the user..   
-0001f780: 2020 2020 2074 696d 656f 7574 2028 666c       timeout (fl
-0001f790: 6f61 7429 3a20 5468 6520 6e75 6d62 6572  oat): The number
-0001f7a0: 206f 6620 7365 636f 6e64 7320 746f 2077   of seconds to w
-0001f7b0: 6169 7420 666f 7220 696e 7075 7420 6265  ait for input be
-0001f7c0: 666f 7265 2074 696d 696e 6720 6f75 742e  fore timing out.
-0001f7d0: 0a20 2020 200a 2020 2020 4d65 7468 6f64  .    .    Method
-0001f7e0: 733a 0a20 2020 2020 2020 2069 6e70 7574  s:.        input
-0001f7f0: 696d 656f 7574 2829 3a20 5265 6164 7320  imeout(): Reads 
-0001f800: 7573 6572 2069 6e70 7574 2066 726f 6d20  user input from 
-0001f810: 7468 6520 636f 6d6d 616e 6420 6c69 6e65  the command line
-0001f820: 2077 6974 6820 6120 7469 6d65 6f75 742e   with a timeout.
-0001f830: 2049 6620 6e6f 2069 6e70 7574 2069 730a   If no input is.
-0001f840: 2020 2020 2020 2020 2020 2020 7265 6365              rece
-0001f850: 6976 6564 2077 6974 6869 6e20 7468 6520  ived within the 
-0001f860: 7370 6563 6966 6965 6420 7469 6d65 6f75  specified timeou
-0001f870: 742c 2061 2054 696d 656f 7574 4f63 6375  t, a TimeoutOccu
-0001f880: 7272 6564 2065 7863 6570 7469 6f6e 2069  rred exception i
-0001f890: 7320 7261 6973 6564 2e0a 2020 2020 2222  s raised..    ""
-0001f8a0: 220a 0a20 2020 2063 6c61 7373 2054 696d  "..    class Tim
-0001f8b0: 656f 7574 4f63 6375 7272 6564 2845 7863  eoutOccurred(Exc
-0001f8c0: 6570 7469 6f6e 293a 0a20 2020 2020 2020  eption):.       
-0001f8d0: 2070 6173 730a 2020 2020 0a20 2020 2064   pass.    .    d
-0001f8e0: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
-0001f8f0: 2c20 7072 6f6d 7074 3d27 272c 2074 696d  , prompt='', tim
-0001f900: 656f 7574 3d33 3029 3a0a 2020 2020 2020  eout=30):.      
-0001f910: 2020 7365 6c66 2e70 726f 6d70 7420 3d20    self.prompt = 
-0001f920: 7072 6f6d 7074 0a20 2020 2020 2020 2073  prompt.        s
-0001f930: 656c 662e 7469 6d65 6f75 7420 3d20 7469  elf.timeout = ti
-0001f940: 6d65 6f75 740a 2020 2020 2020 2020 7365  meout.        se
-0001f950: 6c66 2e65 6368 6f20 3d20 7365 6c66 2e5f  lf.echo = self._
-0001f960: 6563 686f 5f70 6f73 6978 0a20 2020 2020  echo_posix.     
-0001f970: 2020 2073 656c 662e 696e 7075 7469 6d65     self.inputime
-0001f980: 6f75 7420 3d20 7365 6c66 2e5f 696e 7075  out = self._inpu
-0001f990: 7469 6d65 6f75 745f 706f 7369 780a 2020  timeout_posix.  
-0001f9a0: 2020 0a20 2020 2064 6566 205f 6563 686f    .    def _echo
-0001f9b0: 5f70 6f73 6978 2873 656c 662c 2073 7472  _posix(self, str
-0001f9c0: 696e 6729 3a0a 2020 2020 2020 2020 7379  ing):.        sy
-0001f9d0: 732e 7374 646f 7574 2e77 7269 7465 2873  s.stdout.write(s
-0001f9e0: 7472 696e 6729 0a20 2020 2020 2020 2073  tring).        s
-0001f9f0: 7973 2e73 7464 6f75 742e 666c 7573 6828  ys.stdout.flush(
-0001fa00: 290a 2020 2020 2020 2020 0a20 2020 2064  ).        .    d
-0001fa10: 6566 205f 696e 7075 7469 6d65 6f75 745f  ef _inputimeout_
-0001fa20: 706f 7369 7828 7365 6c66 293a 0a20 2020  posix(self):.   
-0001fa30: 2020 2020 2073 656c 662e 6563 686f 2873       self.echo(s
-0001fa40: 656c 662e 7072 6f6d 7074 290a 2020 2020  elf.prompt).    
-0001fa50: 2020 2020 7365 6c20 3d20 7365 6c65 6374      sel = select
-0001fa60: 6f72 732e 4465 6661 756c 7453 656c 6563  ors.DefaultSelec
-0001fa70: 746f 7228 290a 2020 2020 2020 2020 7365  tor().        se
-0001fa80: 6c2e 7265 6769 7374 6572 2873 7973 2e73  l.register(sys.s
-0001fa90: 7464 696e 2c20 7365 6c65 6374 6f72 732e  tdin, selectors.
-0001faa0: 4556 454e 545f 5245 4144 290a 2020 2020  EVENT_READ).    
-0001fab0: 2020 2020 6576 656e 7473 203d 2073 656c      events = sel
-0001fac0: 2e73 656c 6563 7428 7365 6c66 2e74 696d  .select(self.tim
-0001fad0: 656f 7574 290a 0a20 2020 2020 2020 2069  eout)..        i
-0001fae0: 6620 6576 656e 7473 3a0a 2020 2020 2020  f events:.      
-0001faf0: 2020 2020 2020 6b65 792c 205f 203d 2065        key, _ = e
-0001fb00: 7665 6e74 735b 305d 0a20 2020 2020 2020  vents[0].       
-0001fb10: 2020 2020 2072 6574 7572 6e20 6b65 792e       return key.
-0001fb20: 6669 6c65 6f62 6a2e 7265 6164 6c69 6e65  fileobj.readline
-0001fb30: 2829 2e72 7374 7269 7028 275c 6e27 290a  ().rstrip('\n').
-0001fb40: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-0001fb50: 2020 2020 2020 2020 2020 7365 6c66 2e65            self.e
-0001fb60: 6368 6f28 275c 6e27 290a 2020 2020 2020  cho('\n').      
-0001fb70: 2020 2020 2020 7465 726d 696f 732e 7463        termios.tc
-0001fb80: 666c 7573 6828 7379 732e 7374 6469 6e2c  flush(sys.stdin,
-0001fb90: 2074 6572 6d69 6f73 2e54 4349 464c 5553   termios.TCIFLUS
-0001fba0: 4829 0a20 2020 2020 2020 2020 2020 2072  H).            r
-0001fbb0: 6169 7365 2073 656c 662e 5469 6d65 6f75  aise self.Timeou
-0001fbc0: 744f 6363 7572 7265 640a 2020 2020 2020  tOccurred.      
-0001fbd0: 2020 2020 2020 0a                              .
+00011b10: 2020 2020 2020 2020 6472 6f70 6f75 745f          dropout_
+00011b20: 313d 6472 6f70 6f75 745f 312c 2064 726f  1=dropout_1, dro
+00011b30: 706f 7574 5f32 3d64 726f 706f 7574 5f32  pout_2=dropout_2
+00011b40: 2c20 6472 6f70 6f75 745f 333d 6472 6f70  , dropout_3=drop
+00011b50: 6f75 745f 332c 2073 6d6f 7465 5f73 616d  out_3, smote_sam
+00011b60: 706c 696e 673d 7365 6c66 2e73 6d6f 7465  pling=self.smote
+00011b70: 5f73 616d 706c 696e 672c 200a 2020 2020  _sampling, .    
+00011b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b90: 2020 2020 2020 2020 6561 726c 795f 7374          early_st
+00011ba0: 6f70 5f63 616c 6c62 6163 6b3d 6361 6c6c  op_callback=call
+00011bb0: 6261 636b 732c 2063 6865 636b 706f 696e  backs, checkpoin
+00011bc0: 743d 4661 6c73 652c 2076 6572 626f 7365  t=False, verbose
+00011bd0: 3d73 656c 662e 7665 7262 6f73 6529 2020  =self.verbose)  
+00011be0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011bf0: 2020 2020 2065 6c69 6620 7365 6c66 2e63       elif self.c
+00011c00: 6c66 203d 3d20 2776 6767 3136 273a 0a20  lf == 'vgg16':. 
+00011c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011c20: 2020 2020 2020 2069 6620 7365 6c66 2e6c         if self.l
+00011c30: 696d 6974 5f73 6561 7263 683a 0a20 2020  imit_search:.   
+00011c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011c50: 2020 2020 2020 2020 206d 6f64 656c 2c20           model, 
+00011c60: 6869 7374 6f72 7920 3d20 636e 6e5f 6d6f  history = cnn_mo
+00011c70: 6465 6c2e 5647 4731 3628 636c 6173 735f  del.VGG16(class_
+00011c80: 312c 2063 6c61 7373 5f32 2c20 696d 675f  1, class_2, img_
+00011c90: 6e75 6d5f 6368 616e 6e65 6c73 3d73 656c  num_channels=sel
+00011ca0: 662e 696d 675f 6e75 6d5f 6368 616e 6e65  f.img_num_channe
+00011cb0: 6c73 2c20 0a20 2020 2020 2020 2020 2020  ls, .           
+00011cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011cd0: 2020 2020 206e 6f72 6d61 6c69 7a65 3d73       normalize=s
+00011ce0: 656c 662e 6e6f 726d 616c 697a 652c 206d  elf.normalize, m
+00011cf0: 696e 5f70 6978 656c 3d6d 696e 5f70 6978  in_pixel=min_pix
+00011d00: 2c20 6d61 785f 7069 7865 6c3d 6d61 785f  , max_pixel=max_
+00011d10: 7069 782c 2076 616c 5f70 6f73 6974 6976  pix, val_positiv
+00011d20: 653d 7661 6c5f 636c 6173 735f 312c 2076  e=val_class_1, v
+00011d30: 616c 5f6e 6567 6174 6976 653d 7661 6c5f  al_negative=val_
+00011d40: 636c 6173 735f 322c 200a 2020 2020 2020  class_2, .      
+00011d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011d60: 2020 2020 2020 2020 2020 6570 6f63 6873            epochs
+00011d70: 3d73 656c 662e 7472 6169 6e5f 6570 6f63  =self.train_epoc
+00011d80: 6873 2c20 6261 7463 685f 7369 7a65 3d62  hs, batch_size=b
+00011d90: 6174 6368 5f73 697a 652c 206f 7074 696d  atch_size, optim
+00011da0: 697a 6572 3d6f 7074 696d 697a 6572 2c20  izer=optimizer, 
+00011db0: 6c72 3d6c 722c 2064 6563 6179 3d64 6563  lr=lr, decay=dec
+00011dc0: 6179 2c20 6d6f 6d65 6e74 756d 3d6d 6f6d  ay, momentum=mom
+00011dd0: 656e 7475 6d2c 206e 6573 7465 726f 763d  entum, nesterov=
+00011de0: 6e65 7374 6572 6f76 2c20 0a20 2020 2020  nesterov, .     
+00011df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011e00: 2020 2020 2020 2020 2020 2062 6574 615f             beta_
+00011e10: 313d 6265 7461 5f31 2c20 6265 7461 5f32  1=beta_1, beta_2
+00011e20: 3d62 6574 615f 322c 2061 6d73 6772 6164  =beta_2, amsgrad
+00011e30: 3d61 6d73 6772 6164 2c20 6c6f 7373 3d6c  =amsgrad, loss=l
+00011e40: 6f73 732c 2061 6374 6976 6174 696f 6e5f  oss, activation_
+00011e50: 636f 6e76 3d61 6374 6976 6174 696f 6e5f  conv=activation_
+00011e60: 636f 6e76 2c20 6163 7469 7661 7469 6f6e  conv, activation
+00011e70: 5f64 656e 7365 3d61 6374 6976 6174 696f  _dense=activatio
+00011e80: 6e5f 6465 6e73 652c 200a 2020 2020 2020  n_dense, .      
+00011e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ea0: 2020 2020 2020 2020 2020 636f 6e76 5f69            conv_i
+00011eb0: 6e69 743d 636f 6e76 5f69 6e69 742c 2064  nit=conv_init, d
+00011ec0: 656e 7365 5f69 6e69 743d 6465 6e73 655f  ense_init=dense_
+00011ed0: 696e 6974 2c20 6d6f 6465 6c5f 7265 673d  init, model_reg=
+00011ee0: 6d6f 6465 6c5f 7265 672c 0a20 2020 2020  model_reg,.     
+00011ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f00: 2020 2020 2020 2020 2020 2070 6f6f 6c69             pooli
+00011f10: 6e67 5f31 3d70 6f6f 6c69 6e67 5f31 2c20  ng_1=pooling_1, 
+00011f20: 706f 6f6c 696e 675f 323d 706f 6f6c 696e  pooling_2=poolin
+00011f30: 675f 322c 2070 6f6f 6c69 6e67 5f33 3d70  g_2, pooling_3=p
+00011f40: 6f6f 6c69 6e67 5f33 2c20 706f 6f6c 696e  ooling_3, poolin
+00011f50: 675f 343d 706f 6f6c 696e 675f 342c 2070  g_4=pooling_4, p
+00011f60: 6f6f 6c69 6e67 5f35 3d70 6f6f 6c69 6e67  ooling_5=pooling
+00011f70: 5f35 2c0a 2020 2020 2020 2020 2020 2020  _5,.            
+00011f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f90: 2020 2020 736d 6f74 655f 7361 6d70 6c69      smote_sampli
+00011fa0: 6e67 3d73 656c 662e 736d 6f74 655f 7361  ng=self.smote_sa
+00011fb0: 6d70 6c69 6e67 2c20 6561 726c 795f 7374  mpling, early_st
+00011fc0: 6f70 5f63 616c 6c62 6163 6b3d 6361 6c6c  op_callback=call
+00011fd0: 6261 636b 732c 2063 6865 636b 706f 696e  backs, checkpoin
+00011fe0: 743d 4661 6c73 652c 2076 6572 626f 7365  t=False, verbose
+00011ff0: 3d73 656c 662e 7665 7262 6f73 6529 0a20  =self.verbose). 
+00012000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012010: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00012020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012030: 2020 2020 2020 2020 206d 6f64 656c 2c20           model, 
+00012040: 6869 7374 6f72 7920 3d20 636e 6e5f 6d6f  history = cnn_mo
+00012050: 6465 6c2e 5647 4731 3628 636c 6173 735f  del.VGG16(class_
+00012060: 312c 2063 6c61 7373 5f32 2c20 696d 675f  1, class_2, img_
+00012070: 6e75 6d5f 6368 616e 6e65 6c73 3d73 656c  num_channels=sel
+00012080: 662e 696d 675f 6e75 6d5f 6368 616e 6e65  f.img_num_channe
+00012090: 6c73 2c20 0a20 2020 2020 2020 2020 2020  ls, .           
+000120a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000120b0: 2020 2020 206e 6f72 6d61 6c69 7a65 3d73       normalize=s
+000120c0: 656c 662e 6e6f 726d 616c 697a 652c 206d  elf.normalize, m
+000120d0: 696e 5f70 6978 656c 3d6d 696e 5f70 6978  in_pixel=min_pix
+000120e0: 2c20 6d61 785f 7069 7865 6c3d 6d61 785f  , max_pixel=max_
+000120f0: 7069 782c 2076 616c 5f70 6f73 6974 6976  pix, val_positiv
+00012100: 653d 7661 6c5f 636c 6173 735f 312c 2076  e=val_class_1, v
+00012110: 616c 5f6e 6567 6174 6976 653d 7661 6c5f  al_negative=val_
+00012120: 636c 6173 735f 322c 200a 2020 2020 2020  class_2, .      
+00012130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012140: 2020 2020 2020 2020 2020 6570 6f63 6873            epochs
+00012150: 3d73 656c 662e 7472 6169 6e5f 6570 6f63  =self.train_epoc
+00012160: 6873 2c20 6261 7463 685f 7369 7a65 3d62  hs, batch_size=b
+00012170: 6174 6368 5f73 697a 652c 206f 7074 696d  atch_size, optim
+00012180: 697a 6572 3d6f 7074 696d 697a 6572 2c20  izer=optimizer, 
+00012190: 6c72 3d6c 722c 2064 6563 6179 3d64 6563  lr=lr, decay=dec
+000121a0: 6179 2c20 6d6f 6d65 6e74 756d 3d6d 6f6d  ay, momentum=mom
+000121b0: 656e 7475 6d2c 206e 6573 7465 726f 763d  entum, nesterov=
+000121c0: 6e65 7374 6572 6f76 2c20 0a20 2020 2020  nesterov, .     
+000121d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000121e0: 2020 2020 2020 2020 2020 2062 6574 615f             beta_
+000121f0: 313d 6265 7461 5f31 2c20 6265 7461 5f32  1=beta_1, beta_2
+00012200: 3d62 6574 615f 322c 2061 6d73 6772 6164  =beta_2, amsgrad
+00012210: 3d61 6d73 6772 6164 2c20 6c6f 7373 3d6c  =amsgrad, loss=l
+00012220: 6f73 732c 2061 6374 6976 6174 696f 6e5f  oss, activation_
+00012230: 636f 6e76 3d61 6374 6976 6174 696f 6e5f  conv=activation_
+00012240: 636f 6e76 2c20 6163 7469 7661 7469 6f6e  conv, activation
+00012250: 5f64 656e 7365 3d61 6374 6976 6174 696f  _dense=activatio
+00012260: 6e5f 6465 6e73 652c 200a 2020 2020 2020  n_dense, .      
+00012270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012280: 2020 2020 2020 2020 2020 636f 6e76 5f69            conv_i
+00012290: 6e69 743d 636f 6e76 5f69 6e69 742c 2064  nit=conv_init, d
+000122a0: 656e 7365 5f69 6e69 743d 6465 6e73 655f  ense_init=dense_
+000122b0: 696e 6974 2c20 6d6f 6465 6c5f 7265 673d  init, model_reg=
+000122c0: 6d6f 6465 6c5f 7265 672c 2020 2020 2020  model_reg,      
+000122d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000122e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000122f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012300: 2066 696c 7465 725f 313d 6669 6c74 6572   filter_1=filter
+00012310: 5f31 2c20 6669 6c74 6572 5f73 697a 655f  _1, filter_size_
+00012320: 313d 6669 6c74 6572 5f73 697a 655f 312c  1=filter_size_1,
+00012330: 2073 7472 6964 6573 5f31 3d73 7472 6964   strides_1=strid
+00012340: 6573 5f31 2c20 706f 6f6c 696e 675f 313d  es_1, pooling_1=
+00012350: 706f 6f6c 696e 675f 312c 2070 6f6f 6c5f  pooling_1, pool_
+00012360: 7369 7a65 5f31 3d70 6f6f 6c5f 7369 7a65  size_1=pool_size
+00012370: 5f31 2c20 706f 6f6c 5f73 7472 6964 655f  _1, pool_stride_
+00012380: 313d 706f 6f6c 5f73 7472 6964 655f 312c  1=pool_stride_1,
+00012390: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000123a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000123b0: 2066 696c 7465 725f 323d 6669 6c74 6572   filter_2=filter
+000123c0: 5f32 2c20 6669 6c74 6572 5f73 697a 655f  _2, filter_size_
+000123d0: 323d 6669 6c74 6572 5f73 697a 655f 322c  2=filter_size_2,
+000123e0: 2073 7472 6964 6573 5f32 3d73 7472 6964   strides_2=strid
+000123f0: 6573 5f32 2c20 706f 6f6c 696e 675f 323d  es_2, pooling_2=
+00012400: 706f 6f6c 696e 675f 322c 2070 6f6f 6c5f  pooling_2, pool_
+00012410: 7369 7a65 5f32 3d70 6f6f 6c5f 7369 7a65  size_2=pool_size
+00012420: 5f32 2c20 706f 6f6c 5f73 7472 6964 655f  _2, pool_stride_
+00012430: 323d 706f 6f6c 5f73 7472 6964 655f 322c  2=pool_stride_2,
+00012440: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012460: 2066 696c 7465 725f 333d 6669 6c74 6572   filter_3=filter
+00012470: 5f33 2c20 6669 6c74 6572 5f73 697a 655f  _3, filter_size_
+00012480: 333d 6669 6c74 6572 5f73 697a 655f 332c  3=filter_size_3,
+00012490: 2073 7472 6964 6573 5f33 3d73 7472 6964   strides_3=strid
+000124a0: 6573 5f33 2c20 706f 6f6c 696e 675f 333d  es_3, pooling_3=
+000124b0: 706f 6f6c 696e 675f 332c 2070 6f6f 6c5f  pooling_3, pool_
+000124c0: 7369 7a65 5f33 3d70 6f6f 6c5f 7369 7a65  size_3=pool_size
+000124d0: 5f33 2c20 706f 6f6c 5f73 7472 6964 655f  _3, pool_stride_
+000124e0: 333d 706f 6f6c 5f73 7472 6964 655f 332c  3=pool_stride_3,
+000124f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012510: 2066 696c 7465 725f 343d 6669 6c74 6572   filter_4=filter
+00012520: 5f34 2c20 6669 6c74 6572 5f73 697a 655f  _4, filter_size_
+00012530: 343d 6669 6c74 6572 5f73 697a 655f 342c  4=filter_size_4,
+00012540: 2073 7472 6964 6573 5f34 3d73 7472 6964   strides_4=strid
+00012550: 6573 5f34 2c20 706f 6f6c 696e 675f 343d  es_4, pooling_4=
+00012560: 706f 6f6c 696e 675f 342c 2070 6f6f 6c5f  pooling_4, pool_
+00012570: 7369 7a65 5f34 3d70 6f6f 6c5f 7369 7a65  size_4=pool_size
+00012580: 5f34 2c20 706f 6f6c 5f73 7472 6964 655f  _4, pool_stride_
+00012590: 343d 706f 6f6c 5f73 7472 6964 655f 342c  4=pool_stride_4,
+000125a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000125b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000125c0: 2066 696c 7465 725f 353d 6669 6c74 6572   filter_5=filter
+000125d0: 5f35 2c20 6669 6c74 6572 5f73 697a 655f  _5, filter_size_
+000125e0: 353d 6669 6c74 6572 5f73 697a 655f 352c  5=filter_size_5,
+000125f0: 2073 7472 6964 6573 5f35 3d73 7472 6964   strides_5=strid
+00012600: 6573 5f35 2c20 706f 6f6c 696e 675f 353d  es_5, pooling_5=
+00012610: 706f 6f6c 696e 675f 352c 2070 6f6f 6c5f  pooling_5, pool_
+00012620: 7369 7a65 5f35 3d70 6f6f 6c5f 7369 7a65  size_5=pool_size
+00012630: 5f35 2c20 706f 6f6c 5f73 7472 6964 655f  _5, pool_stride_
+00012640: 353d 706f 6f6c 5f73 7472 6964 655f 352c  5=pool_stride_5,
+00012650: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012670: 2064 656e 7365 5f6e 6575 726f 6e73 5f31   dense_neurons_1
+00012680: 3d64 656e 7365 5f6e 6575 726f 6e73 5f31  =dense_neurons_1
+00012690: 2c20 6465 6e73 655f 6e65 7572 6f6e 735f  , dense_neurons_
+000126a0: 323d 6465 6e73 655f 6e65 7572 6f6e 735f  2=dense_neurons_
+000126b0: 322c 2064 726f 706f 7574 5f31 3d64 726f  2, dropout_1=dro
+000126c0: 706f 7574 5f31 2c20 6472 6f70 6f75 745f  pout_1, dropout_
+000126d0: 323d 6472 6f70 6f75 745f 322c 200a 2020  2=dropout_2, .  
+000126e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000126f0: 2020 2020 2020 2020 2020 2020 2020 736d                sm
+00012700: 6f74 655f 7361 6d70 6c69 6e67 3d73 656c  ote_sampling=sel
+00012710: 662e 736d 6f74 655f 7361 6d70 6c69 6e67  f.smote_sampling
+00012720: 2c20 6561 726c 795f 7374 6f70 5f63 616c  , early_stop_cal
+00012730: 6c62 6163 6b3d 6361 6c6c 6261 636b 732c  lback=callbacks,
+00012740: 2063 6865 636b 706f 696e 743d 4661 6c73   checkpoint=Fals
+00012750: 652c 2076 6572 626f 7365 3d73 656c 662e  e, verbose=self.
+00012760: 7665 7262 6f73 6529 0a20 2020 2020 2020  verbose).       
+00012770: 2020 2020 2020 2020 2020 2020 2065 6c69               eli
+00012780: 6620 7365 6c66 2e63 6c66 203d 3d20 2772  f self.clf == 'r
+00012790: 6573 6e65 7431 3827 3a0a 2020 2020 2020  esnet18':.      
+000127a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000127b0: 2020 6966 2073 656c 662e 6c69 6d69 745f    if self.limit_
+000127c0: 7365 6172 6368 3a0a 2020 2020 2020 2020  search:.        
+000127d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000127e0: 2020 2020 6d6f 6465 6c2c 2068 6973 746f      model, histo
+000127f0: 7279 203d 2063 6e6e 5f6d 6f64 656c 2e52  ry = cnn_model.R
+00012800: 6573 6e65 7431 3828 636c 6173 735f 312c  esnet18(class_1,
+00012810: 2063 6c61 7373 5f32 2c20 696d 675f 6e75   class_2, img_nu
+00012820: 6d5f 6368 616e 6e65 6c73 3d73 656c 662e  m_channels=self.
+00012830: 696d 675f 6e75 6d5f 6368 616e 6e65 6c73  img_num_channels
+00012840: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+00012850: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012860: 2020 206e 6f72 6d61 6c69 7a65 3d73 656c     normalize=sel
+00012870: 662e 6e6f 726d 616c 697a 652c 206d 696e  f.normalize, min
+00012880: 5f70 6978 656c 3d6d 696e 5f70 6978 2c20  _pixel=min_pix, 
+00012890: 6d61 785f 7069 7865 6c3d 6d61 785f 7069  max_pixel=max_pi
+000128a0: 782c 2076 616c 5f70 6f73 6974 6976 653d  x, val_positive=
+000128b0: 7661 6c5f 636c 6173 735f 312c 2076 616c  val_class_1, val
+000128c0: 5f6e 6567 6174 6976 653d 7661 6c5f 636c  _negative=val_cl
+000128d0: 6173 735f 322c 200a 2020 2020 2020 2020  ass_2, .        
+000128e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000128f0: 2020 2020 2020 2020 6570 6f63 6873 3d73          epochs=s
+00012900: 656c 662e 7472 6169 6e5f 6570 6f63 6873  elf.train_epochs
+00012910: 2c20 6261 7463 685f 7369 7a65 3d62 6174  , batch_size=bat
+00012920: 6368 5f73 697a 652c 206f 7074 696d 697a  ch_size, optimiz
+00012930: 6572 3d6f 7074 696d 697a 6572 2c20 6c72  er=optimizer, lr
+00012940: 3d6c 722c 2064 6563 6179 3d64 6563 6179  =lr, decay=decay
+00012950: 2c20 6d6f 6d65 6e74 756d 3d6d 6f6d 656e  , momentum=momen
+00012960: 7475 6d2c 206e 6573 7465 726f 763d 6e65  tum, nesterov=ne
+00012970: 7374 6572 6f76 2c20 0a20 2020 2020 2020  sterov, .       
+00012980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012990: 2020 2020 2020 2020 2062 6574 615f 313d           beta_1=
+000129a0: 6265 7461 5f31 2c20 6265 7461 5f32 3d62  beta_1, beta_2=b
+000129b0: 6574 615f 322c 2061 6d73 6772 6164 3d61  eta_2, amsgrad=a
+000129c0: 6d73 6772 6164 2c20 6c6f 7373 3d6c 6f73  msgrad, loss=los
+000129d0: 732c 2061 6374 6976 6174 696f 6e5f 636f  s, activation_co
+000129e0: 6e76 3d61 6374 6976 6174 696f 6e5f 636f  nv=activation_co
+000129f0: 6e76 2c20 6163 7469 7661 7469 6f6e 5f64  nv, activation_d
+00012a00: 656e 7365 3d61 6374 6976 6174 696f 6e5f  ense=activation_
+00012a10: 6465 6e73 652c 200a 2020 2020 2020 2020  dense, .        
+00012a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012a30: 2020 2020 2020 2020 636f 6e76 5f69 6e69          conv_ini
+00012a40: 743d 636f 6e76 5f69 6e69 742c 2064 656e  t=conv_init, den
+00012a50: 7365 5f69 6e69 743d 6465 6e73 655f 696e  se_init=dense_in
+00012a60: 6974 2c20 6d6f 6465 6c5f 7265 673d 6d6f  it, model_reg=mo
+00012a70: 6465 6c5f 7265 672c 2070 6f6f 6c69 6e67  del_reg, pooling
+00012a80: 3d70 6f6f 6c69 6e67 2c0a 2020 2020 2020  =pooling,.      
+00012a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012aa0: 2020 2020 2020 2020 2020 736d 6f74 655f            smote_
+00012ab0: 7361 6d70 6c69 6e67 3d73 656c 662e 736d  sampling=self.sm
+00012ac0: 6f74 655f 7361 6d70 6c69 6e67 2c20 6561  ote_sampling, ea
+00012ad0: 726c 795f 7374 6f70 5f63 616c 6c62 6163  rly_stop_callbac
+00012ae0: 6b3d 6361 6c6c 6261 636b 732c 2063 6865  k=callbacks, che
+00012af0: 636b 706f 696e 743d 4661 6c73 652c 2076  ckpoint=False, v
+00012b00: 6572 626f 7365 3d73 656c 662e 7665 7262  erbose=self.verb
+00012b10: 6f73 6529 0a20 2020 2020 2020 2020 2020  ose).           
+00012b20: 2020 2020 2020 2020 2020 2020 2065 6c73               els
+00012b30: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00012b40: 2020 2020 2020 2020 2020 2020 2020 206d                 m
+00012b50: 6f64 656c 2c20 6869 7374 6f72 7920 3d20  odel, history = 
+00012b60: 636e 6e5f 6d6f 6465 6c2e 5265 736e 6574  cnn_model.Resnet
+00012b70: 3138 2863 6c61 7373 5f31 2c20 636c 6173  18(class_1, clas
+00012b80: 735f 322c 2069 6d67 5f6e 756d 5f63 6861  s_2, img_num_cha
+00012b90: 6e6e 656c 733d 7365 6c66 2e69 6d67 5f6e  nnels=self.img_n
+00012ba0: 756d 5f63 6861 6e6e 656c 732c 200a 2020  um_channels, .  
+00012bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012bc0: 2020 2020 2020 2020 2020 2020 2020 6e6f                no
+00012bd0: 726d 616c 697a 653d 7365 6c66 2e6e 6f72  rmalize=self.nor
+00012be0: 6d61 6c69 7a65 2c20 6d69 6e5f 7069 7865  malize, min_pixe
+00012bf0: 6c3d 6d69 6e5f 7069 782c 206d 6178 5f70  l=min_pix, max_p
+00012c00: 6978 656c 3d6d 6178 5f70 6978 2c20 7661  ixel=max_pix, va
+00012c10: 6c5f 706f 7369 7469 7665 3d76 616c 5f63  l_positive=val_c
+00012c20: 6c61 7373 5f31 2c20 7661 6c5f 6e65 6761  lass_1, val_nega
+00012c30: 7469 7665 3d76 616c 5f63 6c61 7373 5f32  tive=val_class_2
+00012c40: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+00012c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012c60: 2020 2065 706f 6368 733d 7365 6c66 2e74     epochs=self.t
+00012c70: 7261 696e 5f65 706f 6368 732c 2062 6174  rain_epochs, bat
+00012c80: 6368 5f73 697a 653d 6261 7463 685f 7369  ch_size=batch_si
+00012c90: 7a65 2c20 6f70 7469 6d69 7a65 723d 6f70  ze, optimizer=op
+00012ca0: 7469 6d69 7a65 722c 206c 723d 6c72 2c20  timizer, lr=lr, 
+00012cb0: 6465 6361 793d 6465 6361 792c 206d 6f6d  decay=decay, mom
+00012cc0: 656e 7475 6d3d 6d6f 6d65 6e74 756d 2c20  entum=momentum, 
+00012cd0: 6e65 7374 6572 6f76 3d6e 6573 7465 726f  nesterov=nestero
+00012ce0: 762c 200a 2020 2020 2020 2020 2020 2020  v, .            
+00012cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012d00: 2020 2020 6265 7461 5f31 3d62 6574 615f      beta_1=beta_
+00012d10: 312c 2062 6574 615f 323d 6265 7461 5f32  1, beta_2=beta_2
+00012d20: 2c20 616d 7367 7261 643d 616d 7367 7261  , amsgrad=amsgra
+00012d30: 642c 206c 6f73 733d 6c6f 7373 2c20 6163  d, loss=loss, ac
+00012d40: 7469 7661 7469 6f6e 5f63 6f6e 763d 6163  tivation_conv=ac
+00012d50: 7469 7661 7469 6f6e 5f63 6f6e 762c 2061  tivation_conv, a
+00012d60: 6374 6976 6174 696f 6e5f 6465 6e73 653d  ctivation_dense=
+00012d70: 6163 7469 7661 7469 6f6e 5f64 656e 7365  activation_dense
+00012d80: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+00012d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012da0: 2020 2063 6f6e 765f 696e 6974 3d63 6f6e     conv_init=con
+00012db0: 765f 696e 6974 2c20 6465 6e73 655f 696e  v_init, dense_in
+00012dc0: 6974 3d64 656e 7365 5f69 6e69 742c 206d  it=dense_init, m
+00012dd0: 6f64 656c 5f72 6567 3d6d 6f64 656c 5f72  odel_reg=model_r
+00012de0: 6567 2c20 6669 6c74 6572 733d 6669 6c74  eg, filters=filt
+00012df0: 6572 732c 2066 696c 7465 725f 7369 7a65  ers, filter_size
+00012e00: 3d66 696c 7465 725f 7369 7a65 2c20 7374  =filter_size, st
+00012e10: 7269 6465 733d 7374 7269 6465 732c 2020  rides=strides,  
+00012e20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012e40: 2070 6f6f 6c69 6e67 3d70 6f6f 6c69 6e67   pooling=pooling
+00012e50: 2c20 706f 6f6c 5f73 697a 653d 706f 6f6c  , pool_size=pool
+00012e60: 5f73 697a 652c 2070 6f6f 6c5f 7374 7269  _size, pool_stri
+00012e70: 6465 3d70 6f6f 6c5f 7374 7269 6465 2c20  de=pool_stride, 
+00012e80: 626c 6f63 6b5f 6669 6c74 6572 735f 313d  block_filters_1=
+00012e90: 626c 6f63 6b5f 6669 6c74 6572 735f 312c  block_filters_1,
+00012ea0: 2062 6c6f 636b 5f66 696c 7465 7273 5f32   block_filters_2
+00012eb0: 3d62 6c6f 636b 5f66 696c 7465 7273 5f32  =block_filters_2
+00012ec0: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+00012ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012ee0: 2020 2062 6c6f 636b 5f66 696c 7465 7273     block_filters
+00012ef0: 5f33 3d62 6c6f 636b 5f66 696c 7465 7273  _3=block_filters
+00012f00: 5f33 2c20 626c 6f63 6b5f 6669 6c74 6572  _3, block_filter
+00012f10: 735f 343d 626c 6f63 6b5f 6669 6c74 6572  s_4=block_filter
+00012f20: 735f 342c 2062 6c6f 636b 5f66 696c 7465  s_4, block_filte
+00012f30: 7273 5f73 697a 653d 626c 6f63 6b5f 6669  rs_size=block_fi
+00012f40: 6c74 6572 735f 7369 7a65 2c20 0a20 2020  lters_size, .   
+00012f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012f60: 2020 2020 2020 2020 2020 2020 2073 6d6f               smo
+00012f70: 7465 5f73 616d 706c 696e 673d 7365 6c66  te_sampling=self
+00012f80: 2e73 6d6f 7465 5f73 616d 706c 696e 672c  .smote_sampling,
+00012f90: 2065 6172 6c79 5f73 746f 705f 6361 6c6c   early_stop_call
+00012fa0: 6261 636b 3d63 616c 6c62 6163 6b73 2c20  back=callbacks, 
+00012fb0: 6368 6563 6b70 6f69 6e74 3d46 616c 7365  checkpoint=False
+00012fc0: 2c20 7665 7262 6f73 653d 7365 6c66 2e76  , verbose=self.v
+00012fd0: 6572 626f 7365 290a 0a20 2020 2020 2020  erbose)..       
+00012fe0: 2020 2020 2020 2020 2023 4966 2074 6865           #If the
+00012ff0: 2070 6174 6965 6e63 6520 6973 2072 6561   patience is rea
+00013000: 6368 6564 202d 2d20 7265 7475 726e 2073  ched -- return s
+00013010: 686f 756c 6420 6265 2061 2076 616c 7565  hould be a value
+00013020: 2074 6861 7420 636f 6e74 6169 6e73 2069   that contains i
+00013030: 6e66 6f72 6d61 7469 6f6e 2072 6567 6172  nformation regar
+00013040: 6469 6e67 2074 6865 206e 756d 206f 6620  ding the num of 
+00013050: 636f 6d70 6c65 7465 6420 6570 6f63 6873  completed epochs
+00013060: 2c20 6f74 6865 7277 6973 6520 6966 2072  , otherwise if r
+00013070: 6574 7572 6e20 3020 6576 6572 7920 7469  eturn 0 every ti
+00013080: 6d65 2074 6865 6e20 7468 6520 6f70 7469  me then the opti
+00013090: 6d69 7a65 7220 6d61 7920 6765 7420 7374  mizer may get st
+000130a0: 7563 6b23 0a20 2020 2020 2020 2020 2020  uck#.           
+000130b0: 2020 2020 2069 6620 6c65 6e28 6869 7374       if len(hist
+000130c0: 6f72 792e 6869 7374 6f72 795b 276c 6f73  ory.history['los
+000130d0: 7327 5d29 2021 3d20 7365 6c66 2e74 7261  s']) != self.tra
+000130e0: 696e 5f65 706f 6368 733a 0a20 2020 2020  in_epochs:.     
+000130f0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00013100: 7269 6e74 2829 3b20 7072 696e 7428 2754  rint(); print('T
+00013110: 6865 2074 7261 696e 696e 6720 7061 7469  he training pati
+00013120: 656e 6365 2077 6173 2072 6561 6368 6564  ence was reached
+00013130: 2e2e 2e27 293b 2070 7269 6e74 2829 0a20  ...'); print(). 
+00013140: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013150: 2020 2072 6574 7572 6e20 286c 656e 2868     return (len(h
+00013160: 6973 746f 7279 2e68 6973 746f 7279 5b27  istory.history['
+00013170: 6c6f 7373 275d 2920 2a20 302e 3030 3129  loss']) * 0.001)
+00013180: 202d 2039 3939 2e30 0a0a 2020 2020 2020   - 999.0..      
+00013190: 2020 2020 2020 2020 2020 2349 6620 7468            #If th
+000131a0: 6520 7472 6169 6e69 6e67 2066 6169 6c73  e training fails
+000131b0: 2072 6574 7572 6e20 4e61 4e20 7269 6768   return NaN righ
+000131c0: 7420 6177 6179 230a 2020 2020 2020 2020  t away#.        
+000131d0: 2020 2020 2020 2020 6966 206e 702e 6973          if np.is
+000131e0: 6669 6e69 7465 2868 6973 746f 7279 2e68  finite(history.h
+000131f0: 6973 746f 7279 5b27 6c6f 7373 275d 5b2d  istory['loss'][-
+00013200: 315d 293a 0a20 2020 2020 2020 2020 2020  1]):.           
+00013210: 2020 2020 2020 2020 206d 6f64 656c 732e           models.
+00013220: 6170 7065 6e64 286d 6f64 656c 292c 2068  append(model), h
+00013230: 6973 746f 7269 6573 2e61 7070 656e 6428  istories.append(
+00013240: 6869 7374 6f72 7929 0a20 2020 2020 2020  history).       
+00013250: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+00013260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013270: 2020 2070 7269 6e74 2829 3b20 7072 696e     print(); prin
+00013280: 7428 2754 7261 696e 696e 6720 6661 696c  t('Training fail
+00013290: 6564 2064 7565 2074 6f20 6e75 6d65 7269  ed due to numeri
+000132a0: 6361 6c20 696e 7374 6162 696c 6974 792c  cal instability,
+000132b0: 2072 6574 7572 6e69 6e67 206e 616e 2e2e   returning nan..
+000132c0: 2e27 290a 2020 2020 2020 2020 2020 2020  .').            
+000132d0: 2020 2020 2020 2020 7265 7475 726e 206e          return n
+000132e0: 702e 6e61 6e20 0a0a 2020 2020 2020 2020  p.nan ..        
+000132f0: 2323 2323 2323 2041 6464 6974 696f 6e61  ###### Additiona
+00013300: 6c20 7465 7374 2064 6174 6120 6d65 7472  l test data metr
+00013310: 6963 2c20 6f70 7469 6f6e 616c 2069 6e70  ic, optional inp
+00013320: 7574 2023 2323 2323 230a 2020 2020 2020  ut ######.      
+00013330: 2020 6966 2073 656c 662e 7465 7374 5f70    if self.test_p
+00013340: 6f73 6974 6976 6520 6973 206e 6f74 204e  ositive is not N
+00013350: 6f6e 6520 6f72 2073 656c 662e 7465 7374  one or self.test
+00013360: 5f6e 6567 6174 6976 6520 6973 206e 6f74  _negative is not
+00013370: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00013380: 2020 2069 6620 7365 6c66 2e74 6573 745f     if self.test_
+00013390: 706f 7369 7469 7665 2069 7320 6e6f 7420  positive is not 
+000133a0: 4e6f 6e65 2061 6e64 2073 656c 662e 7465  None and self.te
+000133b0: 7374 5f6e 6567 6174 6976 6520 6973 206e  st_negative is n
+000133c0: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
+000133d0: 2020 2020 2020 2020 2070 6f73 6974 6976           positiv
+000133e0: 655f 7465 7374 5f63 726f 702c 206e 6567  e_test_crop, neg
+000133f0: 6174 6976 655f 7465 7374 5f63 726f 7020  ative_test_crop 
+00013400: 3d20 7265 7369 7a65 2873 656c 662e 7465  = resize(self.te
+00013410: 7374 5f70 6f73 6974 6976 652c 2073 697a  st_positive, siz
+00013420: 653d 696d 6167 655f 7369 7a65 292c 2072  e=image_size), r
+00013430: 6573 697a 6528 7365 6c66 2e74 6573 745f  esize(self.test_
+00013440: 6e65 6761 7469 7665 2c20 7369 7a65 3d69  negative, size=i
+00013450: 6d61 6765 5f73 697a 6529 0a20 2020 2020  mage_size).     
+00013460: 2020 2020 2020 2020 2020 2058 5f74 6573             X_tes
+00013470: 742c 2059 5f74 6573 7420 3d20 6461 7461  t, Y_test = data
+00013480: 5f70 726f 6365 7373 696e 672e 6372 6561  _processing.crea
+00013490: 7465 5f74 7261 696e 696e 675f 7365 7428  te_training_set(
+000134a0: 706f 7369 7469 7665 5f74 6573 745f 6372  positive_test_cr
+000134b0: 6f70 2c20 6e65 6761 7469 7665 5f74 6573  op, negative_tes
+000134c0: 745f 6372 6f70 2c20 6e6f 726d 616c 697a  t_crop, normaliz
+000134d0: 653d 7365 6c66 2e6e 6f72 6d61 6c69 7a65  e=self.normalize
+000134e0: 2c20 6d69 6e5f 7069 7865 6c3d 6d69 6e5f  , min_pixel=min_
+000134f0: 7069 782c 206d 6178 5f70 6978 656c 3d6d  pix, max_pixel=m
+00013500: 6178 5f70 6978 2c20 696d 675f 6e75 6d5f  ax_pix, img_num_
+00013510: 6368 616e 6e65 6c73 3d73 656c 662e 696d  channels=self.im
+00013520: 675f 6e75 6d5f 6368 616e 6e65 6c73 290a  g_num_channels).
+00013530: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+00013540: 2073 656c 662e 7465 7374 5f70 6f73 6974   self.test_posit
+00013550: 6976 6520 6973 206e 6f74 204e 6f6e 653a  ive is not None:
+00013560: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00013570: 2070 6f73 6974 6976 655f 7465 7374 5f63   positive_test_c
+00013580: 726f 7020 3d20 7265 7369 7a65 2873 656c  rop = resize(sel
+00013590: 662e 7465 7374 5f70 6f73 6974 6976 652c  f.test_positive,
+000135a0: 2073 697a 653d 696d 6167 655f 7369 7a65   size=image_size
+000135b0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+000135c0: 2020 706f 7369 7469 7665 5f63 6c61 7373    positive_class
+000135d0: 5f64 6174 612c 2070 6f73 6974 6976 655f  _data, positive_
+000135e0: 636c 6173 735f 6c61 6265 6c20 3d20 6461  class_label = da
+000135f0: 7461 5f70 726f 6365 7373 696e 672e 7072  ta_processing.pr
+00013600: 6f63 6573 735f 636c 6173 7328 706f 7369  ocess_class(posi
+00013610: 7469 7665 5f74 6573 745f 6372 6f70 2c20  tive_test_crop, 
+00013620: 6c61 6265 6c3d 312c 206e 6f72 6d61 6c69  label=1, normali
+00013630: 7a65 3d73 656c 662e 6e6f 726d 616c 697a  ze=self.normaliz
+00013640: 652c 206d 696e 5f70 6978 656c 3d6d 696e  e, min_pixel=min
+00013650: 5f70 6978 2c20 6d61 785f 7069 7865 6c3d  _pix, max_pixel=
+00013660: 6d61 785f 7069 782c 2069 6d67 5f6e 756d  max_pix, img_num
+00013670: 5f63 6861 6e6e 656c 733d 7365 6c66 2e69  _channels=self.i
+00013680: 6d67 5f6e 756d 5f63 6861 6e6e 656c 7329  mg_num_channels)
+00013690: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000136a0: 2069 6620 7365 6c66 2e74 6573 745f 6e65   if self.test_ne
+000136b0: 6761 7469 7665 2069 7320 6e6f 7420 4e6f  gative is not No
+000136c0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+000136d0: 2020 2020 2020 2020 6e65 6761 7469 7665          negative
+000136e0: 5f74 6573 745f 6372 6f70 203d 2072 6573  _test_crop = res
+000136f0: 697a 6528 7365 6c66 2e74 6573 745f 6e65  ize(self.test_ne
+00013700: 6761 7469 7665 2c20 7369 7a65 3d69 6d61  gative, size=ima
+00013710: 6765 5f73 697a 6529 0a20 2020 2020 2020  ge_size).       
+00013720: 2020 2020 2020 2020 2020 2020 206e 6567               neg
+00013730: 6174 6976 655f 636c 6173 735f 6461 7461  ative_class_data
+00013740: 2c20 6e65 6761 7469 7665 5f63 6c61 7373  , negative_class
+00013750: 5f6c 6162 656c 203d 2064 6174 615f 7072  _label = data_pr
+00013760: 6f63 6573 7369 6e67 2e70 726f 6365 7373  ocessing.process
+00013770: 5f63 6c61 7373 286e 6567 6174 6976 655f  _class(negative_
+00013780: 7465 7374 5f63 726f 702c 206c 6162 656c  test_crop, label
+00013790: 3d30 2c20 6e6f 726d 616c 697a 653d 7365  =0, normalize=se
+000137a0: 6c66 2e6e 6f72 6d61 6c69 7a65 2c20 6d69  lf.normalize, mi
+000137b0: 6e5f 7069 7865 6c3d 6d69 6e5f 7069 782c  n_pixel=min_pix,
+000137c0: 206d 6178 5f70 6978 656c 3d6d 6178 5f70   max_pixel=max_p
+000137d0: 6978 2c20 696d 675f 6e75 6d5f 6368 616e  ix, img_num_chan
+000137e0: 6e65 6c73 3d73 656c 662e 696d 675f 6e75  nels=self.img_nu
+000137f0: 6d5f 6368 616e 6e65 6c73 290a 2020 2020  m_channels).    
+00013800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013810: 585f 7465 7374 2c20 595f 7465 7374 203d  X_test, Y_test =
+00013820: 206e 702e 725f 5b70 6f73 6974 6976 655f   np.r_[positive_
+00013830: 636c 6173 735f 6461 7461 2c20 6e65 6761  class_data, nega
+00013840: 7469 7665 5f63 6c61 7373 5f64 6174 615d  tive_class_data]
+00013850: 2c20 6e70 2e72 5f5b 706f 7369 7469 7665  , np.r_[positive
+00013860: 5f63 6c61 7373 5f6c 6162 656c 2c20 6e65  _class_label, ne
+00013870: 6761 7469 7665 5f63 6c61 7373 5f6c 6162  gative_class_lab
+00013880: 656c 5d0a 2020 2020 2020 2020 2020 2020  el].            
+00013890: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+000138a0: 2020 2020 2020 2020 2020 2020 2020 585f                X_
+000138b0: 7465 7374 2c20 595f 7465 7374 203d 2070  test, Y_test = p
+000138c0: 6f73 6974 6976 655f 636c 6173 735f 6461  ositive_class_da
+000138d0: 7461 2c20 706f 7369 7469 7665 5f63 6c61  ta, positive_cla
+000138e0: 7373 5f6c 6162 656c 0a20 2020 2020 2020  ss_label.       
+000138f0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00013900: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+00013910: 6c66 2e74 6573 745f 6e65 6761 7469 7665  lf.test_negative
+00013920: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
+00013930: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013940: 2020 6e65 6761 7469 7665 5f74 6573 745f    negative_test_
+00013950: 6372 6f70 203d 2072 6573 697a 6528 7365  crop = resize(se
+00013960: 6c66 2e74 6573 745f 6e65 6761 7469 7665  lf.test_negative
+00013970: 2c20 7369 7a65 3d69 6d61 6765 5f73 697a  , size=image_siz
+00013980: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+00013990: 2020 2020 2020 2058 5f74 6573 742c 2059         X_test, Y
+000139a0: 5f74 6573 7420 3d20 6461 7461 5f70 726f  _test = data_pro
+000139b0: 6365 7373 696e 672e 7072 6f63 6573 735f  cessing.process_
+000139c0: 636c 6173 7328 6e65 6761 7469 7665 5f74  class(negative_t
+000139d0: 6573 745f 6372 6f70 2c20 6c61 6265 6c3d  est_crop, label=
+000139e0: 302c 206e 6f72 6d61 6c69 7a65 3d73 656c  0, normalize=sel
+000139f0: 662e 6e6f 726d 616c 697a 652c 206d 696e  f.normalize, min
+00013a00: 5f70 6978 656c 3d6d 696e 5f70 6978 2c20  _pixel=min_pix, 
+00013a10: 6d61 785f 7069 7865 6c3d 6d61 785f 7069  max_pixel=max_pi
+00013a20: 782c 2069 6d67 5f6e 756d 5f63 6861 6e6e  x, img_num_chann
+00013a30: 656c 733d 7365 6c66 2e69 6d67 5f6e 756d  els=self.img_num
+00013a40: 5f63 6861 6e6e 656c 7329 0a20 2020 2020  _channels).     
+00013a50: 2020 2020 2020 2020 0a20 2020 2020 2020          .       
+00013a60: 2020 2020 2023 2323 4c6f 6f70 2074 6872       ###Loop thr
+00013a70: 6f75 6768 2061 6c6c 2074 6865 206d 6f64  ough all the mod
+00013a80: 656c 7320 746f 2063 616c 6375 6c61 7465  els to calculate
+00013a90: 2074 6865 2070 6572 666f 726d 616e 6365   the performance
+00013aa0: 206f 6620 6561 6368 2323 230a 2020 2020   of each###.    
+00013ab0: 2020 2020 2020 2020 7465 7374 203d 205b          test = [
+00013ac0: 5d0a 2020 2020 2020 2020 2020 2020 666f  ].            fo
+00013ad0: 7220 5f6d 6f64 656c 5f20 696e 206d 6f64  r _model_ in mod
+00013ae0: 656c 733a 0a0a 2020 2020 2020 2020 2020  els:..          
+00013af0: 2020 2020 2020 7465 7374 5f6c 6f73 732c        test_loss,
+00013b00: 2074 6573 745f 6163 632c 2074 6573 745f   test_acc, test_
+00013b10: 6631 5f73 636f 7265 203d 205f 6d6f 6465  f1_score = _mode
+00013b20: 6c5f 2e65 7661 6c75 6174 6528 585f 7465  l_.evaluate(X_te
+00013b30: 7374 2c20 595f 7465 7374 2c20 6261 7463  st, Y_test, batc
+00013b40: 685f 7369 7a65 3d6c 656e 2858 5f74 6573  h_size=len(X_tes
+00013b50: 7429 290a 0a20 2020 2020 2020 2020 2020  t))..           
+00013b60: 2020 2020 2069 6620 7365 6c66 2e74 6573       if self.tes
+00013b70: 745f 6163 635f 7468 7265 7368 6f6c 6420  t_acc_threshold 
+00013b80: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
+00013b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013ba0: 2069 6620 7465 7374 5f61 6363 203c 2073   if test_acc < s
+00013bb0: 656c 662e 7465 7374 5f61 6363 5f74 6872  elf.test_acc_thr
+00013bc0: 6573 686f 6c64 3a0a 2020 2020 2020 2020  eshold:.        
+00013bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013be0: 7072 696e 7428 293b 2070 7269 6e74 2827  print(); print('
+00013bf0: 5468 6520 7465 7374 2064 6174 6120 6163  The test data ac
+00013c00: 6375 7261 6379 2066 616c 6c73 2062 656c  curacy falls bel
+00013c10: 6f77 2074 6865 2074 6573 745f 6163 635f  ow the test_acc_
+00013c20: 7468 7265 7368 6f6c 642e 2e2e 2729 3b20  threshold...'); 
+00013c30: 7072 696e 7428 290a 2020 2020 2020 2020  print().        
+00013c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013c50: 7265 7475 726e 2028 6c65 6e28 6869 7374  return (len(hist
+00013c60: 6f72 792e 6869 7374 6f72 795b 276c 6f73  ory.history['los
+00013c70: 7327 5d29 202a 2030 2e30 3031 2920 2d20  s']) * 0.001) - 
+00013c80: 3939 392e 3020 2b20 7465 7374 5f61 6363  999.0 + test_acc
+00013c90: 200a 0a20 2020 2020 2020 2020 2020 2020   ..             
+00013ca0: 2020 2069 6620 276c 6f73 7327 2069 6e20     if 'loss' in 
+00013cb0: 7365 6c66 2e6d 6574 7269 633a 0a20 2020  self.metric:.   
+00013cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013cd0: 2074 6573 745f 6d65 7472 6963 203d 2031   test_metric = 1
+00013ce0: 202d 2074 6573 745f 6c6f 7373 0a20 2020   - test_loss.   
+00013cf0: 2020 2020 2020 2020 2020 2020 2065 6c69               eli
+00013d00: 6620 2761 6363 2720 696e 2073 656c 662e  f 'acc' in self.
+00013d10: 6d65 7472 6963 3a0a 2020 2020 2020 2020  metric:.        
+00013d20: 2020 2020 2020 2020 2020 2020 7465 7374              test
+00013d30: 5f6d 6574 7269 6320 3d20 7465 7374 5f61  _metric = test_a
+00013d40: 6363 200a 2020 2020 2020 2020 2020 2020  cc .            
+00013d50: 2020 2020 656c 6966 2027 6631 2720 696e      elif 'f1' in
+00013d60: 2073 656c 662e 6d65 7472 6963 3a0a 2020   self.metric:.  
+00013d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013d80: 2020 7465 7374 5f6d 6574 7269 6320 3d20    test_metric = 
+00013d90: 7465 7374 5f66 315f 7363 6f72 650a 2020  test_f1_score.  
+00013da0: 2020 2020 2020 2020 2020 2020 2020 656c                el
+00013db0: 6966 2027 616c 6c27 2069 6e20 7365 6c66  if 'all' in self
+00013dc0: 2e6d 6574 7269 633a 0a20 2020 2020 2020  .metric:.       
+00013dd0: 2020 2020 2020 2020 2020 2020 2074 6573               tes
+00013de0: 745f 6d65 7472 6963 203d 206e 702e 6d65  t_metric = np.me
+00013df0: 616e 285b 3120 2d20 7465 7374 5f6c 6f73  an([1 - test_los
+00013e00: 732c 2074 6573 745f 6163 632c 2074 6573  s, test_acc, tes
+00013e10: 745f 6631 5f73 636f 7265 5d29 0a20 2020  t_f1_score]).   
+00013e20: 2020 2020 2020 2020 2020 2020 2074 6573               tes
+00013e30: 742e 6170 7065 6e64 2874 6573 745f 6d65  t.append(test_me
+00013e40: 7472 6963 290a 0a20 2020 2020 2020 2020  tric)..         
+00013e50: 2020 2074 6573 745f 6d65 7472 6963 203d     test_metric =
+00013e60: 206e 702e 6d65 616e 2874 6573 7429 0a20   np.mean(test). 
+00013e70: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+00013e80: 6c66 2e76 6572 626f 7365 203d 3d20 3120  lf.verbose == 1 
+00013e90: 616e 6420 7365 6c66 2e70 6f73 745f 6d65  and self.post_me
+00013ea0: 7472 6963 3a0a 2020 2020 2020 2020 2020  tric:.          
+00013eb0: 2020 2020 2020 7072 696e 7428 293b 2070        print(); p
+00013ec0: 7269 6e74 2827 506f 7374 2d54 7269 616c  rint('Post-Trial
+00013ed0: 204d 6574 7269 633a 2027 2b73 7472 2874   Metric: '+str(t
+00013ee0: 6573 745f 6d65 7472 6963 2929 0a20 2020  est_metric)).   
+00013ef0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00013f00: 2020 2020 2020 2074 6573 745f 6d65 7472         test_metr
+00013f10: 6963 203d 204e 6f6e 650a 0a20 2020 2020  ic = None..     
+00013f20: 2020 2023 5468 6520 7465 7374 5f6d 6574     #The test_met
+00013f30: 7269 6320 6973 2063 616c 6375 6c61 7465  ric is calculate
+00013f40: 6420 6576 656e 2069 6620 706f 7374 5f6d  d even if post_m
+00013f50: 6574 7269 633d 4661 6c73 652c 2066 6f72  etric=False, for
+00013f60: 2073 696d 706c 6963 6974 792e 2e2e 2054   simplicity... T
+00013f70: 7572 6e69 6e67 206f 6666 2068 6572 652e  urning off here.
+00013f80: 2e2e 0a20 2020 2020 2020 2069 6620 7365  ...        if se
+00013f90: 6c66 2e70 6f73 745f 6d65 7472 6963 2069  lf.post_metric i
+00013fa0: 7320 4661 6c73 653a 0a20 2020 2020 2020  s False:.       
+00013fb0: 2020 2020 2074 6573 745f 6d65 7472 6963       test_metric
+00013fc0: 203d 204e 6f6e 6520 0a0a 2020 2020 2020   = None ..      
+00013fd0: 2020 2323 2320 4361 6c63 756c 6174 6520    ### Calculate 
+00013fe0: 7468 6520 6669 6e61 6c20 6f70 7469 6d69  the final optimi
+00013ff0: 7a61 7469 6f6e 206d 6574 7269 6320 2323  zation metric ##
+00014000: 230a 2020 2020 2020 2020 6d65 7472 6963  #.        metric
+00014010: 7320 3d20 5b27 6c6f 7373 272c 2027 6269  s = ['loss', 'bi
+00014020: 6e61 7279 5f61 6363 7572 6163 7927 2c20  nary_accuracy', 
+00014030: 2766 315f 7363 6f72 6527 5d0a 2020 2020  'f1_score'].    
+00014040: 2020 2020 6966 2073 656c 662e 6d65 7472      if self.metr
+00014050: 6963 203d 3d20 2761 6c6c 273a 2023 4176  ic == 'all': #Av
+00014060: 6572 6167 6520 616c 6c20 7468 6520 7472  erage all the tr
+00014070: 6169 6e69 6e67 206d 6574 7269 6373 0a20  aining metrics. 
+00014080: 2020 2020 2020 2020 2020 2074 7261 696e             train
+00014090: 696e 675f 6d65 7472 6963 735f 6d65 616e  ing_metrics_mean
+000140a0: 2c20 7472 6169 6e69 6e67 5f6c 6f73 735f  , training_loss_
+000140b0: 6d65 616e 203d 205b 5d2c 205b 5d0a 2020  mean = [], [].  
+000140c0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+000140d0: 662e 6176 6572 6167 653a 0a20 2020 2020  f.average:.     
+000140e0: 2020 2020 2020 2020 2020 2066 6f72 205f             for _
+000140f0: 6869 7374 6f72 795f 2069 6e20 6869 7374  history_ in hist
+00014100: 6f72 6965 733a 0a20 2020 2020 2020 2020  ories:.         
+00014110: 2020 2020 2020 2020 2020 2074 7261 696e             train
+00014120: 696e 675f 6d65 7472 6963 735f 6d65 616e  ing_metrics_mean
+00014130: 2e61 7070 656e 6428 6e70 2e6d 6561 6e28  .append(np.mean(
+00014140: 5b6e 702e 6d65 616e 285f 6869 7374 6f72  [np.mean(_histor
+00014150: 795f 2e68 6973 746f 7279 5b6d 6574 7269  y_.history[metri
+00014160: 635d 2920 666f 7220 6d65 7472 6963 2069  c]) for metric i
+00014170: 6e20 6d65 7472 6963 7320 6966 2027 6c6f  n metrics if 'lo
+00014180: 7373 2720 6e6f 7420 696e 206d 6574 7269  ss' not in metri
+00014190: 635d 2929 0a20 2020 2020 2020 2020 2020  c])).           
+000141a0: 2020 2020 2020 2020 2074 7261 696e 696e           trainin
+000141b0: 675f 6c6f 7373 5f6d 6561 6e2e 6170 7065  g_loss_mean.appe
+000141c0: 6e64 2831 202d 206e 702e 6d65 616e 285f  nd(1 - np.mean(_
+000141d0: 6869 7374 6f72 795f 2e68 6973 746f 7279  history_.history
+000141e0: 5b27 6c6f 7373 275d 2929 0a20 2020 2020  ['loss'])).     
+000141f0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00014200: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+00014210: 205f 6869 7374 6f72 795f 2069 6e20 6869   _history_ in hi
+00014220: 7374 6f72 6965 733a 0a20 2020 2020 2020  stories:.       
+00014230: 2020 2020 2020 2020 2020 2020 2074 7261               tra
+00014240: 696e 696e 675f 6d65 7472 6963 735f 6d65  ining_metrics_me
+00014250: 616e 2e61 7070 656e 6428 6e70 2e6d 6561  an.append(np.mea
+00014260: 6e28 5b5f 6869 7374 6f72 795f 2e68 6973  n([_history_.his
+00014270: 746f 7279 5b6d 6574 7269 635d 5b2d 315d  tory[metric][-1]
+00014280: 2066 6f72 206d 6574 7269 6320 696e 206d   for metric in m
+00014290: 6574 7269 6373 2069 6620 276c 6f73 7327  etrics if 'loss'
+000142a0: 206e 6f74 2069 6e20 6d65 7472 6963 5d29   not in metric])
+000142b0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+000142c0: 2020 2020 2020 7472 6169 6e69 6e67 5f6c        training_l
+000142d0: 6f73 735f 6d65 616e 2e61 7070 656e 6428  oss_mean.append(
+000142e0: 3120 2d20 5f68 6973 746f 7279 5f2e 6869  1 - _history_.hi
+000142f0: 7374 6f72 795b 276c 6f73 7327 5d5b 2d31  story['loss'][-1
+00014300: 5d29 0a20 2020 2020 2020 2020 2020 2069  ]).            i
+00014310: 6620 7465 7374 5f6d 6574 7269 6320 6973  f test_metric is
+00014320: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00014330: 2020 2020 2020 2066 696e 616c 5f73 636f         final_sco
+00014340: 7265 203d 206e 702e 6d65 616e 285b 7472  re = np.mean([tr
+00014350: 6169 6e69 6e67 5f6d 6574 7269 6373 5f6d  aining_metrics_m
+00014360: 6561 6e2c 2074 7261 696e 696e 675f 6c6f  ean, training_lo
+00014370: 7373 5f6d 6561 6e5d 290a 2020 2020 2020  ss_mean]).      
+00014380: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00014390: 2020 2020 2020 2020 2020 2020 6669 6e61              fina
+000143a0: 6c5f 7363 6f72 6520 3d20 6e70 2e6d 6561  l_score = np.mea
+000143b0: 6e28 5b74 7261 696e 696e 675f 6d65 7472  n([training_metr
+000143c0: 6963 735f 6d65 616e 2c20 7472 6169 6e69  ics_mean, traini
+000143d0: 6e67 5f6c 6f73 735f 6d65 616e 2c20 7465  ng_loss_mean, te
+000143e0: 7374 5f6d 6574 7269 635d 290a 2020 2020  st_metric]).    
+000143f0: 2020 2020 656c 6966 2073 656c 662e 6d65      elif self.me
+00014400: 7472 6963 203d 3d20 2776 616c 5f61 6c6c  tric == 'val_all
+00014410: 273a 2023 4176 6572 6167 6520 616c 6c20  ': #Average all 
+00014420: 7468 6520 7661 6c69 6461 7469 6f6e 206d  the validation m
+00014430: 6574 7269 6373 0a20 2020 2020 2020 2020  etrics.         
+00014440: 2020 2076 616c 5f6d 6574 7269 6373 5f6d     val_metrics_m
+00014450: 6561 6e2c 2076 616c 5f6c 6f73 735f 6d65  ean, val_loss_me
+00014460: 616e 203d 205b 5d2c 205b 5d20 0a20 2020  an = [], [] .   
+00014470: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+00014480: 2e61 7665 7261 6765 3a0a 2020 2020 2020  .average:.      
+00014490: 2020 2020 2020 2020 2020 666f 7220 5f68            for _h
+000144a0: 6973 746f 7279 5f20 696e 2068 6973 746f  istory_ in histo
+000144b0: 7269 6573 3a0a 2020 2020 2020 2020 2020  ries:.          
+000144c0: 2020 2020 2020 2020 2020 7661 6c5f 6d65            val_me
+000144d0: 7472 6963 735f 6d65 616e 2e61 7070 656e  trics_mean.appen
+000144e0: 6428 6e70 2e6d 6561 6e28 5b6e 702e 6d65  d(np.mean([np.me
+000144f0: 616e 285f 6869 7374 6f72 795f 2e68 6973  an(_history_.his
+00014500: 746f 7279 5b27 7661 6c5f 272b 6d65 7472  tory['val_'+metr
+00014510: 6963 5d29 2066 6f72 206d 6574 7269 6320  ic]) for metric 
+00014520: 696e 206d 6574 7269 6373 2069 6620 276c  in metrics if 'l
+00014530: 6f73 7327 206e 6f74 2069 6e20 6d65 7472  oss' not in metr
+00014540: 6963 5d29 290a 2020 2020 2020 2020 2020  ic])).          
+00014550: 2020 2020 2020 2020 2020 7661 6c5f 6c6f            val_lo
+00014560: 7373 5f6d 6561 6e2e 6170 7065 6e64 2831  ss_mean.append(1
+00014570: 202d 206e 702e 6d65 616e 285f 6869 7374   - np.mean(_hist
+00014580: 6f72 795f 2e68 6973 746f 7279 5b27 7661  ory_.history['va
+00014590: 6c5f 6c6f 7373 275d 2929 0a20 2020 2020  l_loss'])).     
+000145a0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+000145b0: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+000145c0: 205f 6869 7374 6f72 795f 2069 6e20 6869   _history_ in hi
+000145d0: 7374 6f72 6965 733a 0a20 2020 2020 2020  stories:.       
+000145e0: 2020 2020 2020 2020 2020 2020 2076 616c               val
+000145f0: 5f6d 6574 7269 6373 5f6d 6561 6e2e 6170  _metrics_mean.ap
+00014600: 7065 6e64 286e 702e 6d65 616e 285b 5f68  pend(np.mean([_h
+00014610: 6973 746f 7279 5f2e 6869 7374 6f72 795b  istory_.history[
+00014620: 2776 616c 5f27 2b6d 6574 7269 635d 5b2d  'val_'+metric][-
+00014630: 315d 2066 6f72 206d 6574 7269 6320 696e  1] for metric in
+00014640: 206d 6574 7269 6373 2069 6620 276c 6f73   metrics if 'los
+00014650: 7327 206e 6f74 2069 6e20 6d65 7472 6963  s' not in metric
+00014660: 5d29 290a 2020 2020 2020 2020 2020 2020  ])).            
+00014670: 2020 2020 2020 2020 7661 6c5f 6c6f 7373          val_loss
+00014680: 5f6d 6561 6e2e 6170 7065 6e64 2831 202d  _mean.append(1 -
+00014690: 205f 6869 7374 6f72 795f 2e68 6973 746f   _history_.histo
+000146a0: 7279 5b27 7661 6c5f 6c6f 7373 275d 5b2d  ry['val_loss'][-
+000146b0: 315d 290a 2020 2020 2020 2020 2020 2020  1]).            
+000146c0: 6966 2074 6573 745f 6d65 7472 6963 2069  if test_metric i
+000146d0: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+000146e0: 2020 2020 2020 2020 6669 6e61 6c5f 7363          final_sc
+000146f0: 6f72 6520 3d20 6e70 2e6d 6561 6e28 5b76  ore = np.mean([v
+00014700: 616c 5f6d 6574 7269 6373 5f6d 6561 6e2c  al_metrics_mean,
+00014710: 2076 616c 5f6c 6f73 735f 6d65 616e 5d29   val_loss_mean])
+00014720: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
+00014730: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00014740: 2020 2066 696e 616c 5f73 636f 7265 203d     final_score =
+00014750: 206e 702e 6d65 616e 285b 7661 6c5f 6d65   np.mean([val_me
+00014760: 7472 6963 735f 6d65 616e 2c20 7661 6c5f  trics_mean, val_
+00014770: 6c6f 7373 5f6d 6561 6e2c 2074 6573 745f  loss_mean, test_
+00014780: 6d65 7472 6963 5d29 0a20 2020 2020 2020  metric]).       
+00014790: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+000147a0: 2020 2073 636f 7265 7320 3d20 5b5d 0a20     scores = []. 
+000147b0: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+000147c0: 6c66 2e61 7665 7261 6765 3a0a 2020 2020  lf.average:.    
+000147d0: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+000147e0: 5f68 6973 746f 7279 5f20 696e 2068 6973  _history_ in his
+000147f0: 746f 7269 6573 3a0a 2020 2020 2020 2020  tories:.        
+00014800: 2020 2020 2020 2020 2020 2020 7363 6f72              scor
+00014810: 6573 2e61 7070 656e 6428 6e70 2e6d 6561  es.append(np.mea
+00014820: 6e28 5f68 6973 746f 7279 5f2e 6869 7374  n(_history_.hist
+00014830: 6f72 795b 7365 6c66 2e6d 6574 7269 635d  ory[self.metric]
+00014840: 2929 0a20 2020 2020 2020 2020 2020 2065  )).            e
+00014850: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00014860: 2020 2020 2066 6f72 205f 6869 7374 6f72       for _histor
+00014870: 795f 2069 6e20 6869 7374 6f72 6965 733a  y_ in histories:
+00014880: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014890: 2020 2020 2073 636f 7265 732e 6170 7065       scores.appe
+000148a0: 6e64 285f 6869 7374 6f72 795f 2e68 6973  nd(_history_.his
+000148b0: 746f 7279 5b73 656c 662e 6d65 7472 6963  tory[self.metric
+000148c0: 5d5b 2d31 5d29 0a0a 2020 2020 2020 2020  ][-1])..        
+000148d0: 2020 2020 6669 6e61 6c5f 7363 6f72 6520      final_score 
+000148e0: 3d20 6e70 2e6d 6561 6e28 7363 6f72 6573  = np.mean(scores
+000148f0: 290a 0a20 2020 2020 2020 2020 2020 2069  )..            i
+00014900: 6620 276c 6f73 7327 2069 6e20 7365 6c66  f 'loss' in self
+00014910: 2e6d 6574 7269 633a 200a 2020 2020 2020  .metric: .      
+00014920: 2020 2020 2020 2020 2020 6669 6e61 6c5f            final_
+00014930: 7363 6f72 6520 3d20 3120 2d20 6669 6e61  score = 1 - fina
+00014940: 6c5f 7363 6f72 650a 2020 2020 2020 2020  l_score.        
+00014950: 2020 2020 6966 2074 6573 745f 6d65 7472      if test_metr
+00014960: 6963 2069 7320 6e6f 7420 4e6f 6e65 3a0a  ic is not None:.
+00014970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014980: 6669 6e61 6c5f 7363 6f72 6520 3d20 2866  final_score = (f
+00014990: 696e 616c 5f73 636f 7265 202b 2074 6573  inal_score + tes
+000149a0: 745f 6d65 7472 6963 2920 2f20 322e 300a  t_metric) / 2.0.
+000149b0: 2020 2020 2020 2020 0a20 2020 2020 2020          .       
+000149c0: 2072 6574 7572 6e20 6669 6e61 6c5f 7363   return final_sc
+000149d0: 6f72 650a 2020 2020 2020 2020 0a63 6c61  ore.        .cla
+000149e0: 7373 206f 626a 6563 7469 7665 5f78 6762  ss objective_xgb
+000149f0: 286f 626a 6563 7429 3a0a 2020 2020 2222  (object):.    ""
+00014a00: 220a 2020 2020 4f70 7469 6d69 7a61 7469  ".    Optimizati
+00014a10: 6f6e 206f 626a 6563 7469 7665 2066 756e  on objective fun
+00014a20: 6374 696f 6e20 666f 7220 7468 6520 7472  ction for the tr
+00014a30: 6565 2d62 6173 6564 2058 4742 6f6f 7374  ee-based XGBoost
+00014a40: 2063 6c61 7373 6966 6965 722e 200a 2020   classifier. .  
+00014a50: 2020 5468 6520 4f70 7475 6e61 2073 6f66    The Optuna sof
+00014a60: 7477 6172 6520 666f 7220 6879 7065 7270  tware for hyperp
+00014a70: 6172 616d 6574 6572 206f 7074 696d 697a  arameter optimiz
+00014a80: 6174 696f 6e20 7761 7320 7075 626c 6973  ation was publis
+00014a90: 6865 6420 696e 200a 2020 2020 3230 3139  hed in .    2019
+00014aa0: 2062 7920 416b 6962 6120 6574 2061 6c2e   by Akiba et al.
+00014ab0: 2050 6170 6572 3a20 6874 7470 733a 2f2f   Paper: https://
+00014ac0: 6172 7869 762e 6f72 672f 6162 732f 3139  arxiv.org/abs/19
+00014ad0: 3037 2e31 3039 3032 0a20 2020 200a 2020  07.10902.    .  
+00014ae0: 2020 4e6f 7465 3a0a 2020 2020 2020 2020    Note:.        
+00014af0: 4966 206f 7074 5f63 7620 6973 2062 6574  If opt_cv is bet
+00014b00: 7765 656e 2030 2061 6e64 2031 2c20 6120  ween 0 and 1, a 
+00014b10: 7072 756e 696e 6720 7072 6f63 6564 7572  pruning procedur
+00014b20: 6520 7769 6c6c 2062 6520 696e 6974 696c  e will be initil
+00014b30: 6961 7a65 6420 2861 2070 726f 6365 6475  iazed (a procedu
+00014b40: 7265 2069 6e63 6f6d 7061 7469 626c 6520  re incompatible 
+00014b50: 7769 7468 2063 726f 7373 2d76 616c 6964  with cross-valid
+00014b60: 6174 696f 6e29 2c0a 2020 2020 2020 2020  ation),.        
+00014b70: 736f 2061 7320 746f 2073 7065 6564 2075  so as to speed u
+00014b80: 7020 7468 6520 5847 4220 6f70 7469 6d69  p the XGB optimi
+00014b90: 7a61 7469 6f6e 2e20 4120 7261 6e64 6f6d  zation. A random
+00014ba0: 2076 616c 6964 6174 696f 6e20 6461 7461   validation data
+00014bb0: 2077 696c 6c20 6265 2067 656e 6572 6174   will be generat
+00014bc0: 6564 2061 6363 6f72 6469 6e67 2074 6f20  ed according to 
+00014bd0: 7468 6973 2072 6174 696f 2c0a 2020 2020  this ratio,.    
+00014be0: 2020 2020 7768 6963 6820 7769 6c6c 2072      which will r
+00014bf0: 6570 6c61 6365 2074 6865 2063 726f 7373  eplace the cross
+00014c00: 2d76 616c 6964 6174 696f 6e20 6d65 7468  -validation meth
+00014c10: 6f64 2075 7365 6420 6279 2064 6566 6175  od used by defau
+00014c20: 6c74 2e20 4974 2077 696c 6c20 7072 756e  lt. It will prun
+00014c30: 6520 6163 636f 7264 696e 670a 2020 2020  e according.    
+00014c40: 2020 2020 746f 2074 6865 2066 312d 7363      to the f1-sc
+00014c50: 6f72 6520 6f66 2074 6865 2076 616c 6964  ore of the valid
+00014c60: 6174 696f 6e20 6461 7461 2c20 7768 6963  ation data, whic
+00014c70: 6820 776f 756c 6420 6265 2031 3025 206f  h would be 10% o
+00014c80: 6620 7468 6520 7472 6169 6e69 6e67 2064  f the training d
+00014c90: 6174 6120 6966 206f 7074 5f63 763d 302e  ata if opt_cv=0.
+00014ca0: 312c 2066 6f72 2065 7861 6d70 6c65 2e20  1, for example. 
+00014cb0: 0a20 2020 2020 2020 204e 6565 6420 6d6f  .        Need mo
+00014cc0: 7265 2074 6573 7469 6e67 2074 6f20 6d61  re testing to ma
+00014cd0: 6b65 2074 6869 7320 6d6f 7265 2072 6f62  ke this more rob
+00014ce0: 7573 742e 0a20 2020 2020 2020 200a 2020  ust..        .  
+00014cf0: 2020 4172 6773 3a0a 2020 2020 2020 2020    Args:.        
+00014d00: 6461 7461 5f78 2028 6e64 6172 7261 7929  data_x (ndarray)
+00014d10: 3a20 3244 2061 7272 6179 206f 6620 7369  : 2D array of si
+00014d20: 7a65 2028 6e20 7820 6d29 2c20 7768 6572  ze (n x m), wher
+00014d30: 6520 6e20 6973 2074 6865 0a20 2020 2020  e n is the.     
+00014d40: 2020 2020 2020 206e 756d 6265 7220 6f66         number of
+00014d50: 2073 616d 706c 6573 2c20 616e 6420 6d20   samples, and m 
+00014d60: 7468 6520 6e75 6d62 6572 206f 6620 6665  the number of fe
+00014d70: 6174 7572 6573 2e0a 2020 2020 2020 2020  atures..        
+00014d80: 6461 7461 5f79 2028 6e64 6172 7261 792c  data_y (ndarray,
+00014d90: 2073 7472 293a 2031 4420 6172 7261 7920   str): 1D array 
+00014da0: 636f 6e74 6169 6e69 6e67 2074 6865 2063  containing the c
+00014db0: 6f72 7265 7370 6f6e 696e 6720 6c61 6265  orresponing labe
+00014dc0: 6c73 2e20 0a20 2020 2020 2020 206c 696d  ls. .        lim
+00014dd0: 6974 5f73 6561 7263 6820 2862 6f6f 6c29  it_search (bool)
+00014de0: 3a20 4966 2054 7275 652c 2074 6865 2073  : If True, the s
+00014df0: 6561 7263 6820 7370 6163 6520 666f 7220  earch space for 
+00014e00: 7468 6520 7061 7261 6d65 7465 7273 2077  the parameters w
+00014e10: 696c 6c20 6265 2065 7870 616e 6465 642c  ill be expanded,
+00014e20: 0a20 2020 2020 2020 2020 2020 2061 7320  .            as 
+00014e30: 7468 6572 6520 6172 6520 736f 6d65 2068  there are some h
+00014e40: 7970 6572 7061 7261 6d65 7465 7273 2074  yperparameters t
+00014e50: 6861 7420 6361 6e20 7261 6e67 6520 6672  hat can range fr
+00014e60: 6f6d 2030 2074 6f20 696e 662e 2044 6566  om 0 to inf. Def
+00014e70: 6175 6c74 7320 746f 2046 616c 7365 2e0a  aults to False..
+00014e80: 2020 2020 2020 2020 6f70 745f 6376 2028          opt_cv (
+00014e90: 696e 7429 3a20 4372 6f73 732d 7661 6c69  int): Cross-vali
+00014ea0: 6461 7469 6f6e 7320 746f 2070 6572 666f  dations to perfo
+00014eb0: 726d 2077 6865 6e20 6173 7365 7369 6e67  rm when assesing
+00014ec0: 2074 6865 2070 6572 666f 726d 616e 6365   the performance
+00014ed0: 2061 7420 6561 6368 0a20 2020 2020 2020   at each.       
+00014ee0: 2020 2020 2068 7970 6572 7061 7261 6d65       hyperparame
+00014ef0: 7465 7220 6f70 7469 6d69 7a61 7469 6f6e  ter optimization
+00014f00: 2074 7269 616c 2e20 466f 7220 6578 616d   trial. For exam
+00014f10: 706c 652c 2069 6620 6376 3d33 2c20 7468  ple, if cv=3, th
+00014f20: 656e 2065 6163 6820 6f70 7469 6d69 7a61  en each optimiza
+00014f30: 7469 6f6e 2074 7269 616c 0a20 2020 2020  tion trial.     
+00014f40: 2020 2020 2020 2077 696c 6c20 6265 2061         will be a
+00014f50: 7373 6573 7365 6420 6163 636f 7264 696e  ssessed accordin
+00014f60: 6720 746f 2074 6865 2033 2d66 6f6c 6420  g to the 3-fold 
+00014f70: 6372 6f73 7320 7661 6c69 6461 7469 6f6e  cross validation
+00014f80: 2061 6363 7572 6163 792e 2049 6620 7468   accuracy. If th
+00014f90: 6973 2069 730a 2020 2020 2020 2020 2020  is is.          
+00014fa0: 2020 6265 7477 6565 6e20 3020 616e 6420    between 0 and 
+00014fb0: 312c 2074 6869 7320 7661 6c75 6520 776f  1, this value wo
+00014fc0: 756c 6420 6265 2075 7365 6420 6173 2074  uld be used as t
+00014fd0: 6865 2072 6174 696f 206f 6620 7468 6520  he ratio of the 
+00014fe0: 7661 6c69 6461 7469 6f6e 2074 6f20 7472  validation to tr
+00014ff0: 6169 6e69 6e67 2064 6174 612e 0a20 2020  aining data..   
+00015000: 2020 2020 2020 2020 2044 6566 6175 6c74           Default
+00015010: 7320 746f 204e 6f6e 652c 2069 6e20 7768  s to None, in wh
+00015020: 6963 6820 6361 7365 2074 6865 2063 726f  ich case the cro
+00015030: 7373 2d76 616c 6964 6174 696f 6e20 7072  ss-validation pr
+00015040: 6f63 6564 7572 6520 7769 6c6c 2062 6520  ocedure will be 
+00015050: 656d 706c 6f79 6564 2e0a 2020 2020 2020  employed..      
+00015060: 2020 6576 616c 5f6d 6574 7269 6320 2873    eval_metric (s
+00015070: 7472 293a 2054 6865 2065 7661 6c75 6174  tr): The evaluat
+00015080: 696f 6e20 6d65 7472 6963 2077 6865 6e20  ion metric when 
+00015090: 6576 616c 7561 7469 6e67 2074 6865 2076  evaluating the v
+000150a0: 616c 6964 6174 696f 6e20 6461 7461 2c20  alidation data, 
+000150b0: 7573 6564 2077 6865 6e0a 2020 2020 2020  used when.      
+000150c0: 2020 2020 2020 6f70 745f 6376 2069 7320        opt_cv is 
+000150d0: 6c65 7373 2074 6861 6e20 312e 2044 6566  less than 1. Def
+000150e0: 6175 6c74 7320 746f 2022 6631 222e 2046  aults to "f1". F
+000150f0: 6f72 2061 6c6c 206f 7074 696f 6e73 2073  or all options s
+00015100: 6565 2065 7661 6c5f 6d65 7472 6963 2066  ee eval_metric f
+00015110: 726f 6d3a 2068 7474 7073 3a2f 2f78 6762  rom: https://xgb
+00015120: 6f6f 7374 2e72 6561 6474 6865 646f 6373  oost.readthedocs
+00015130: 2e69 6f2f 656e 2f6c 6174 6573 742f 7061  .io/en/latest/pa
+00015140: 7261 6d65 7465 722e 6874 6d6c 236d 6574  rameter.html#met
+00015150: 7269 6373 0a0a 2020 2020 5265 7475 726e  rics..    Return
+00015160: 733a 0a20 2020 2020 2020 2054 6865 2063  s:.        The c
+00015170: 726f 7373 2d76 616c 6964 6174 696f 6e20  ross-validation 
+00015180: 6163 6375 7261 6379 2028 6966 206f 7074  accuracy (if opt
+00015190: 5f63 7620 6973 2067 7265 6174 6572 2074  _cv is greater t
+000151a0: 6861 6e20 3129 206f 722c 2069 6620 6f70  han 1) or, if op
+000151b0: 745f 6376 2069 7320 6265 7477 6565 6e20  t_cv is between 
+000151c0: 3020 616e 6420 312c 2074 6865 2076 616c  0 and 1, the val
+000151d0: 6964 6174 696f 6e20 6163 6375 7261 6379  idation accuracy
+000151e0: 2061 6363 6f72 6469 6e67 2074 6f20 7468   according to th
+000151f0: 6520 7465 7374 2064 6174 612e 0a20 2020  e test data..   
+00015200: 2022 2222 0a0a 2020 2020 6465 6620 5f5f   """..    def __
+00015210: 696e 6974 5f5f 2873 656c 662c 2064 6174  init__(self, dat
+00015220: 615f 782c 2064 6174 615f 792c 206c 696d  a_x, data_y, lim
+00015230: 6974 5f73 6561 7263 683d 4661 6c73 652c  it_search=False,
+00015240: 206f 7074 5f63 763d 332c 2065 7661 6c5f   opt_cv=3, eval_
+00015250: 6d65 7472 6963 3d22 6631 2229 3a0a 2020  metric="f1"):.  
+00015260: 2020 2020 2020 7365 6c66 2e64 6174 615f        self.data_
+00015270: 7820 3d20 6461 7461 5f78 0a20 2020 2020  x = data_x.     
+00015280: 2020 2073 656c 662e 6461 7461 5f79 203d     self.data_y =
+00015290: 2064 6174 615f 790a 2020 2020 2020 2020   data_y.        
+000152a0: 7365 6c66 2e6c 696d 6974 5f73 6561 7263  self.limit_searc
+000152b0: 6820 3d20 6c69 6d69 745f 7365 6172 6368  h = limit_search
+000152c0: 0a20 2020 2020 2020 2073 656c 662e 6f70  .        self.op
+000152d0: 745f 6376 203d 206f 7074 5f63 7620 0a20  t_cv = opt_cv . 
+000152e0: 2020 2020 2020 2073 656c 662e 6576 616c         self.eval
+000152f0: 5f6d 6574 7269 6320 3d20 6576 616c 5f6d  _metric = eval_m
+00015300: 6574 7269 6320 0a0a 2020 2020 6465 6620  etric ..    def 
+00015310: 5f5f 6361 6c6c 5f5f 2873 656c 662c 2074  __call__(self, t
+00015320: 7269 616c 293a 0a0a 2020 2020 2020 2020  rial):..        
+00015330: 7061 7261 6d73 203d 207b 226f 626a 6563  params = {"objec
+00015340: 7469 7665 223a 2022 6269 6e61 7279 3a6c  tive": "binary:l
+00015350: 6f67 6973 7469 6322 2c20 2265 7661 6c5f  ogistic", "eval_
+00015360: 6d65 7472 6963 223a 2073 656c 662e 6576  metric": self.ev
+00015370: 616c 5f6d 6574 7269 637d 200a 2020 2020  al_metric} .    
+00015380: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00015390: 2e6f 7074 5f63 7620 3c20 313a 0a20 2020  .opt_cv < 1:.   
+000153a0: 2020 2020 2020 2020 2074 7261 696e 5f78           train_x
+000153b0: 2c20 7661 6c69 645f 782c 2074 7261 696e  , valid_x, train
+000153c0: 5f79 2c20 7661 6c69 645f 7920 3d20 7472  _y, valid_y = tr
+000153d0: 6169 6e5f 7465 7374 5f73 706c 6974 2873  ain_test_split(s
+000153e0: 656c 662e 6461 7461 5f78 2c20 7365 6c66  elf.data_x, self
+000153f0: 2e64 6174 615f 792c 2074 6573 745f 7369  .data_y, test_si
+00015400: 7a65 3d73 656c 662e 6f70 745f 6376 2c20  ze=self.opt_cv, 
+00015410: 7261 6e64 6f6d 5f73 7461 7465 3d31 3930  random_state=190
+00015420: 3929 236e 702e 7261 6e64 6f6d 2e72 616e  9)#np.random.ran
+00015430: 6469 6e74 2831 2c20 3165 3929 290a 2020  dint(1, 1e9)).  
+00015440: 2020 2020 2020 2020 2020 6474 7261 696e            dtrain
+00015450: 2c20 6476 616c 6964 203d 2044 4d61 7472  , dvalid = DMatr
+00015460: 6978 2874 7261 696e 5f78 2c20 6c61 6265  ix(train_x, labe
+00015470: 6c3d 7472 6169 6e5f 7929 2c20 444d 6174  l=train_y), DMat
+00015480: 7269 7828 7661 6c69 645f 782c 206c 6162  rix(valid_x, lab
+00015490: 656c 3d76 616c 6964 5f79 290a 2020 2020  el=valid_y).    
+000154a0: 2020 2020 2020 2020 2370 7269 6e74 2827          #print('
+000154b0: 496e 6974 6961 6c69 7a69 6e67 2058 4742  Initializing XGB
+000154c0: 6f6f 7374 2050 7275 6e65 722e 2e2e 2729  oost Pruner...')
+000154d0: 0a20 2020 2020 2020 2020 2020 2070 7275  .            pru
+000154e0: 6e69 6e67 5f63 616c 6c62 6163 6b20 3d20  ning_callback = 
+000154f0: 6f70 7475 6e61 2e69 6e74 6567 7261 7469  optuna.integrati
+00015500: 6f6e 2e58 4742 6f6f 7374 5072 756e 696e  on.XGBoostPrunin
+00015510: 6743 616c 6c62 6163 6b28 7472 6961 6c2c  gCallback(trial,
+00015520: 2022 7661 6c69 6461 7469 6f6e 2d22 202b   "validation-" +
+00015530: 2073 656c 662e 6576 616c 5f6d 6574 7269   self.eval_metri
+00015540: 6329 0a0a 2020 2020 2020 2020 6966 2073  c)..        if s
+00015550: 656c 662e 6c69 6d69 745f 7365 6172 6368  elf.limit_search
+00015560: 3a0a 2020 2020 2020 2020 2020 2020 7061  :.            pa
+00015570: 7261 6d73 5b27 6e5f 6573 7469 6d61 746f  rams['n_estimato
+00015580: 7273 275d 203d 2074 7269 616c 2e73 7567  rs'] = trial.sug
+00015590: 6765 7374 5f69 6e74 2827 6e5f 6573 7469  gest_int('n_esti
+000155a0: 6d61 746f 7273 272c 2031 3030 2c20 3235  mators', 100, 25
+000155b0: 3029 0a20 2020 2020 2020 2020 2020 2070  0).            p
+000155c0: 6172 616d 735b 2762 6f6f 7374 6572 275d  arams['booster']
+000155d0: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
+000155e0: 5f63 6174 6567 6f72 6963 616c 2827 626f  _categorical('bo
+000155f0: 6f73 7465 7227 2c20 5b27 6762 7472 6565  oster', ['gbtree
+00015600: 272c 2027 6461 7274 275d 290a 2020 2020  ', 'dart']).    
+00015610: 2020 2020 2020 2020 7061 7261 6d73 5b27          params['
+00015620: 7265 675f 6c61 6d62 6461 275d 203d 2074  reg_lambda'] = t
+00015630: 7269 616c 2e73 7567 6765 7374 5f6c 6f67  rial.suggest_log
+00015640: 756e 6966 6f72 6d28 2772 6567 5f6c 616d  uniform('reg_lam
+00015650: 6264 6127 2c20 3165 2d38 2c20 3129 0a20  bda', 1e-8, 1). 
+00015660: 2020 2020 2020 2020 2020 2070 6172 616d             param
+00015670: 735b 2772 6567 5f61 6c70 6861 275d 203d  s['reg_alpha'] =
+00015680: 2074 7269 616c 2e73 7567 6765 7374 5f6c   trial.suggest_l
+00015690: 6f67 756e 6966 6f72 6d28 2772 6567 5f61  oguniform('reg_a
+000156a0: 6c70 6861 272c 2031 652d 382c 2031 290a  lpha', 1e-8, 1).
+000156b0: 2020 2020 2020 2020 2020 2020 7061 7261              para
+000156c0: 6d73 5b27 6d61 785f 6465 7074 6827 5d20  ms['max_depth'] 
+000156d0: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+000156e0: 696e 7428 276d 6178 5f64 6570 7468 272c  int('max_depth',
+000156f0: 2032 2c20 3235 290a 2020 2020 2020 2020   2, 25).        
+00015700: 2020 2020 7061 7261 6d73 5b27 6574 6127      params['eta'
+00015710: 5d20 3d20 7472 6961 6c2e 7375 6767 6573  ] = trial.sugges
+00015720: 745f 6c6f 6775 6e69 666f 726d 2827 6574  t_loguniform('et
+00015730: 6127 2c20 3165 2d38 2c20 3129 0a20 2020  a', 1e-8, 1).   
+00015740: 2020 2020 2020 2020 2070 6172 616d 735b           params[
+00015750: 2767 616d 6d61 275d 203d 2074 7269 616c  'gamma'] = trial
+00015760: 2e73 7567 6765 7374 5f6c 6f67 756e 6966  .suggest_logunif
+00015770: 6f72 6d28 2767 616d 6d61 272c 2031 652d  orm('gamma', 1e-
+00015780: 382c 2031 290a 2020 2020 2020 2020 2020  8, 1).          
+00015790: 2020 7061 7261 6d73 5b27 6772 6f77 5f70    params['grow_p
+000157a0: 6f6c 6963 7927 5d20 3d20 7472 6961 6c2e  olicy'] = trial.
+000157b0: 7375 6767 6573 745f 6361 7465 676f 7269  suggest_categori
+000157c0: 6361 6c28 2767 726f 775f 706f 6c69 6379  cal('grow_policy
+000157d0: 272c 205b 2764 6570 7468 7769 7365 272c  ', ['depthwise',
+000157e0: 2027 6c6f 7373 6775 6964 6527 5d29 0a0a   'lossguide'])..
+000157f0: 2020 2020 2020 2020 2020 2020 6966 2070              if p
+00015800: 6172 616d 735b 2762 6f6f 7374 6572 275d  arams['booster']
+00015810: 203d 3d20 2264 6172 7422 3a0a 2020 2020   == "dart":.    
+00015820: 2020 2020 2020 2020 2020 2020 7061 7261              para
+00015830: 6d73 5b27 7361 6d70 6c65 5f74 7970 6527  ms['sample_type'
+00015840: 5d20 3d20 7472 6961 6c2e 7375 6767 6573  ] = trial.sugges
+00015850: 745f 6361 7465 676f 7269 6361 6c28 2773  t_categorical('s
+00015860: 616d 706c 655f 7479 7065 272c 205b 2775  ample_type', ['u
+00015870: 6e69 666f 726d 272c 2027 7765 6967 6874  niform', 'weight
+00015880: 6564 275d 290a 2020 2020 2020 2020 2020  ed']).          
+00015890: 2020 2020 2020 7061 7261 6d73 5b27 6e6f        params['no
+000158a0: 726d 616c 697a 655f 7479 7065 275d 203d  rmalize_type'] =
+000158b0: 2074 7269 616c 2e73 7567 6765 7374 5f63   trial.suggest_c
+000158c0: 6174 6567 6f72 6963 616c 2827 6e6f 726d  ategorical('norm
+000158d0: 616c 697a 655f 7479 7065 272c 205b 2774  alize_type', ['t
+000158e0: 7265 6527 2c20 2766 6f72 6573 7427 5d29  ree', 'forest'])
+000158f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00015900: 2070 6172 616d 735b 2772 6174 655f 6472   params['rate_dr
+00015910: 6f70 275d 203d 2074 7269 616c 2e73 7567  op'] = trial.sug
+00015920: 6765 7374 5f6c 6f67 756e 6966 6f72 6d28  gest_loguniform(
+00015930: 2772 6174 655f 6472 6f70 272c 2031 652d  'rate_drop', 1e-
+00015940: 382c 2031 290a 2020 2020 2020 2020 2020  8, 1).          
+00015950: 2020 2020 2020 7061 7261 6d73 5b27 736b        params['sk
+00015960: 6970 5f64 726f 7027 5d20 3d20 7472 6961  ip_drop'] = tria
+00015970: 6c2e 7375 6767 6573 745f 6c6f 6775 6e69  l.suggest_loguni
+00015980: 666f 726d 2827 736b 6970 5f64 726f 7027  form('skip_drop'
+00015990: 2c20 3165 2d38 2c20 3129 0a20 2020 2020  , 1e-8, 1).     
+000159a0: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+000159b0: 6c66 2e6f 7074 5f63 7620 3e3d 2031 3a0a  lf.opt_cv >= 1:.
+000159c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000159d0: 2020 2020 636c 6620 3d20 5847 4243 6c61      clf = XGBCla
+000159e0: 7373 6966 6965 7228 626f 6f73 7465 723d  ssifier(booster=
+000159f0: 7061 7261 6d73 5b27 626f 6f73 7465 7227  params['booster'
+00015a00: 5d2c 206e 5f65 7374 696d 6174 6f72 733d  ], n_estimators=
+00015a10: 7061 7261 6d73 5b27 6e5f 6573 7469 6d61  params['n_estima
+00015a20: 746f 7273 275d 2c20 7265 675f 6c61 6d62  tors'], reg_lamb
+00015a30: 6461 3d70 6172 616d 735b 2772 6567 5f6c  da=params['reg_l
+00015a40: 616d 6264 6127 5d2c 200a 2020 2020 2020  ambda'], .      
+00015a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015a60: 2020 7265 675f 616c 7068 613d 7061 7261    reg_alpha=para
+00015a70: 6d73 5b27 7265 675f 616c 7068 6127 5d2c  ms['reg_alpha'],
+00015a80: 206d 6178 5f64 6570 7468 3d70 6172 616d   max_depth=param
+00015a90: 735b 276d 6178 5f64 6570 7468 275d 2c20  s['max_depth'], 
+00015aa0: 6574 613d 7061 7261 6d73 5b27 6574 6127  eta=params['eta'
+00015ab0: 5d2c 2067 616d 6d61 3d70 6172 616d 735b  ], gamma=params[
+00015ac0: 2767 616d 6d61 275d 2c20 0a20 2020 2020  'gamma'], .     
+00015ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015ae0: 2020 2067 726f 775f 706f 6c69 6379 3d70     grow_policy=p
+00015af0: 6172 616d 735b 2767 726f 775f 706f 6c69  arams['grow_poli
+00015b00: 6379 275d 2c20 7361 6d70 6c65 5f74 7970  cy'], sample_typ
+00015b10: 653d 7061 7261 6d73 5b27 7361 6d70 6c65  e=params['sample
+00015b20: 5f74 7970 6527 5d2c 206e 6f72 6d61 6c69  _type'], normali
+00015b30: 7a65 5f74 7970 653d 7061 7261 6d73 5b27  ze_type=params['
+00015b40: 6e6f 726d 616c 697a 655f 7479 7065 275d  normalize_type']
+00015b50: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00015b60: 2020 2020 2020 2020 2020 7261 7465 5f64            rate_d
+00015b70: 726f 703d 7061 7261 6d73 5b27 7261 7465  rop=params['rate
+00015b80: 5f64 726f 7027 5d2c 2073 6b69 705f 6472  _drop'], skip_dr
+00015b90: 6f70 3d70 6172 616d 735b 2773 6b69 705f  op=params['skip_
+00015ba0: 6472 6f70 275d 2c20 7261 6e64 6f6d 5f73  drop'], random_s
+00015bb0: 7461 7465 3d31 3930 3929 232c 2074 7265  tate=1909)#, tre
+00015bc0: 655f 6d65 7468 6f64 3d27 6869 7374 2729  e_method='hist')
+00015bd0: 0a20 2020 2020 2020 2020 2020 200a 2020  .            .  
+00015be0: 2020 2020 2020 2020 2020 656c 6966 2070            elif p
+00015bf0: 6172 616d 735b 2762 6f6f 7374 6572 275d  arams['booster']
+00015c00: 203d 3d20 2767 6274 7265 6527 3a0a 2020   == 'gbtree':.  
+00015c10: 2020 2020 2020 2020 2020 2020 2020 7061                pa
+00015c20: 7261 6d73 5b27 7375 6273 616d 706c 6527  rams['subsample'
+00015c30: 5d20 3d20 7472 6961 6c2e 7375 6767 6573  ] = trial.sugges
+00015c40: 745f 6c6f 6775 6e69 666f 726d 2827 7375  t_loguniform('su
+00015c50: 6273 616d 706c 6527 2c20 3165 2d36 2c20  bsample', 1e-6, 
+00015c60: 312e 3029 0a20 2020 2020 2020 2020 2020  1.0).           
+00015c70: 2020 2020 2069 6620 7365 6c66 2e6f 7074       if self.opt
+00015c80: 5f63 7620 3e3d 2031 3a0a 2020 2020 2020  _cv >= 1:.      
+00015c90: 2020 2020 2020 2020 2020 2020 2020 636c                cl
+00015ca0: 6620 3d20 5847 4243 6c61 7373 6966 6965  f = XGBClassifie
+00015cb0: 7228 626f 6f73 7465 723d 7061 7261 6d73  r(booster=params
+00015cc0: 5b27 626f 6f73 7465 7227 5d2c 206e 5f65  ['booster'], n_e
+00015cd0: 7374 696d 6174 6f72 733d 7061 7261 6d73  stimators=params
+00015ce0: 5b27 6e5f 6573 7469 6d61 746f 7273 275d  ['n_estimators']
+00015cf0: 2c20 7265 675f 6c61 6d62 6461 3d70 6172  , reg_lambda=par
+00015d00: 616d 735b 2772 6567 5f6c 616d 6264 6127  ams['reg_lambda'
+00015d10: 5d2c 200a 2020 2020 2020 2020 2020 2020  ], .            
+00015d20: 2020 2020 2020 2020 2020 2020 7265 675f              reg_
+00015d30: 616c 7068 613d 7061 7261 6d73 5b27 7265  alpha=params['re
+00015d40: 675f 616c 7068 6127 5d2c 206d 6178 5f64  g_alpha'], max_d
+00015d50: 6570 7468 3d70 6172 616d 735b 276d 6178  epth=params['max
+00015d60: 5f64 6570 7468 275d 2c20 6574 613d 7061  _depth'], eta=pa
+00015d70: 7261 6d73 5b27 6574 6127 5d2c 2067 616d  rams['eta'], gam
+00015d80: 6d61 3d70 6172 616d 735b 2767 616d 6d61  ma=params['gamma
+00015d90: 275d 2c20 0a20 2020 2020 2020 2020 2020  '], .           
+00015da0: 2020 2020 2020 2020 2020 2020 2067 726f               gro
+00015db0: 775f 706f 6c69 6379 3d70 6172 616d 735b  w_policy=params[
+00015dc0: 2767 726f 775f 706f 6c69 6379 275d 2c20  'grow_policy'], 
+00015dd0: 7375 6273 616d 706c 653d 7061 7261 6d73  subsample=params
+00015de0: 5b27 7375 6273 616d 706c 6527 5d2c 2072  ['subsample'], r
+00015df0: 616e 646f 6d5f 7374 6174 653d 3139 3039  andom_state=1909
+00015e00: 2923 2c20 7472 6565 5f6d 6574 686f 643d  )#, tree_method=
+00015e10: 2768 6973 7427 290a 0a20 2020 2020 2020  'hist')..       
+00015e20: 2020 2020 2069 6620 7365 6c66 2e6f 7074       if self.opt
+00015e30: 5f63 7620 3c20 313a 0a20 2020 2020 2020  _cv < 1:.       
+00015e40: 2020 2020 2020 2020 2062 7374 203d 2074           bst = t
+00015e50: 7261 696e 2870 6172 616d 732c 2064 7472  rain(params, dtr
+00015e60: 6169 6e2c 2065 7661 6c73 3d5b 2864 7661  ain, evals=[(dva
+00015e70: 6c69 642c 2022 7661 6c69 6461 7469 6f6e  lid, "validation
+00015e80: 2229 5d2c 2063 616c 6c62 6163 6b73 3d5b  ")], callbacks=[
+00015e90: 7072 756e 696e 675f 6361 6c6c 6261 636b  pruning_callback
+00015ea0: 5d29 0a20 2020 2020 2020 2020 2020 2020  ]).             
+00015eb0: 2020 2070 7265 6473 203d 2062 7374 2e70     preds = bst.p
+00015ec0: 7265 6469 6374 2864 7661 6c69 6429 0a20  redict(dvalid). 
+00015ed0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00015ee0: 7265 645f 6c61 6265 6c73 203d 206e 702e  red_labels = np.
+00015ef0: 7269 6e74 2870 7265 6473 290a 2020 2020  rint(preds).    
+00015f00: 2020 2020 2020 2020 2020 2020 6163 6375              accu
+00015f10: 7261 6379 203d 2061 6363 7572 6163 795f  racy = accuracy_
+00015f20: 7363 6f72 6528 7661 6c69 645f 792c 2070  score(valid_y, p
+00015f30: 7265 645f 6c61 6265 6c73 290a 2020 2020  red_labels).    
+00015f40: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00015f50: 2020 2020 2020 2020 2020 2020 2020 2346                #F
+00015f60: 524f 4d20 534b 4c45 4152 4e20 444f 4355  ROM SKLEARN DOCU
+00015f70: 4d45 4e54 4154 494f 4e3a 2046 6f72 2069  MENTATION: For i
+00015f80: 6e74 2f4e 6f6e 6520 696e 7075 7473 2c20  nt/None inputs, 
+00015f90: 6966 2074 6865 2065 7374 696d 6174 6f72  if the estimator
+00015fa0: 2069 7320 6120 636c 6173 7369 6669 6572   is a classifier
+00015fb0: 2061 6e64 2079 2069 7320 6569 7468 6572   and y is either
+00015fc0: 2062 696e 6172 7920 6f72 206d 756c 7469   binary or multi
+00015fd0: 636c 6173 732c 2053 7472 6174 6966 6965  class, Stratifie
+00015fe0: 644b 466f 6c64 2069 7320 7573 6564 2e20  dKFold is used. 
+00015ff0: 496e 2061 6c6c 206f 7468 6572 2063 6173  In all other cas
+00016000: 6573 2c20 466f 6c64 2069 7320 7573 6564  es, Fold is used
+00016010: 2e0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00016020: 2020 6376 203d 2063 726f 7373 5f76 616c    cv = cross_val
+00016030: 6964 6174 6528 636c 662c 2073 656c 662e  idate(clf, self.
+00016040: 6461 7461 5f78 2c20 7365 6c66 2e64 6174  data_x, self.dat
+00016050: 615f 792c 2063 763d 7365 6c66 2e6f 7074  a_y, cv=self.opt
+00016060: 5f63 7629 200a 2020 2020 2020 2020 2020  _cv) .          
+00016070: 2020 2020 2020 6163 6375 7261 6379 203d        accuracy =
+00016080: 206e 702e 6d65 616e 2863 765b 2774 6573   np.mean(cv['tes
+00016090: 745f 7363 6f72 6527 5d29 0a0a 2020 2020  t_score'])..    
+000160a0: 2020 2020 2020 2020 7265 7475 726e 2061          return a
+000160b0: 6363 7572 6163 790a 0a20 2020 2020 2020  ccuracy..       
+000160c0: 2070 6172 616d 735b 2762 6f6f 7374 6572   params['booster
+000160d0: 275d 203d 2074 7269 616c 2e73 7567 6765  '] = trial.sugge
+000160e0: 7374 5f63 6174 6567 6f72 6963 616c 2827  st_categorical('
+000160f0: 626f 6f73 7465 7227 2c20 5b27 6762 7472  booster', ['gbtr
+00016100: 6565 272c 2027 6461 7274 275d 290a 2020  ee', 'dart']).  
+00016110: 2020 2020 2020 7061 7261 6d73 5b27 6e5f        params['n_
+00016120: 6573 7469 6d61 746f 7273 275d 203d 2074  estimators'] = t
+00016130: 7269 616c 2e73 7567 6765 7374 5f69 6e74  rial.suggest_int
+00016140: 2827 6e5f 6573 7469 6d61 746f 7273 272c  ('n_estimators',
+00016150: 2031 3030 2c20 3530 3029 0a20 2020 2020   100, 500).     
+00016160: 2020 2070 6172 616d 735b 2772 6567 5f6c     params['reg_l
+00016170: 616d 6264 6127 5d20 3d20 7472 6961 6c2e  ambda'] = trial.
+00016180: 7375 6767 6573 745f 666c 6f61 7428 2772  suggest_float('r
+00016190: 6567 5f6c 616d 6264 6127 2c20 302c 2031  eg_lambda', 0, 1
+000161a0: 3030 290a 2020 2020 2020 2020 7061 7261  00).        para
+000161b0: 6d73 5b27 7265 675f 616c 7068 6127 5d20  ms['reg_alpha'] 
+000161c0: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+000161d0: 696e 7428 2772 6567 5f61 6c70 6861 272c  int('reg_alpha',
+000161e0: 2030 2c20 3130 3029 0a20 2020 2020 2020   0, 100).       
+000161f0: 2070 6172 616d 735b 276d 6178 5f64 6570   params['max_dep
+00016200: 7468 275d 203d 2074 7269 616c 2e73 7567  th'] = trial.sug
+00016210: 6765 7374 5f69 6e74 2827 6d61 785f 6465  gest_int('max_de
+00016220: 7074 6827 2c20 322c 2032 3529 0a20 2020  pth', 2, 25).   
+00016230: 2020 2020 2070 6172 616d 735b 2765 7461       params['eta
+00016240: 275d 203d 2074 7269 616c 2e73 7567 6765  '] = trial.sugge
+00016250: 7374 5f66 6c6f 6174 2827 6574 6127 2c20  st_float('eta', 
+00016260: 3165 2d38 2c20 3129 0a20 2020 2020 2020  1e-8, 1).       
+00016270: 2070 6172 616d 735b 2767 616d 6d61 275d   params['gamma']
+00016280: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
+00016290: 5f69 6e74 2827 6761 6d6d 6127 2c20 312c  _int('gamma', 1,
+000162a0: 2031 3030 290a 2020 2020 2020 2020 7061   100).        pa
+000162b0: 7261 6d73 5b27 6772 6f77 5f70 6f6c 6963  rams['grow_polic
+000162c0: 7927 5d20 3d20 7472 6961 6c2e 7375 6767  y'] = trial.sugg
+000162d0: 6573 745f 6361 7465 676f 7269 6361 6c28  est_categorical(
+000162e0: 2767 726f 775f 706f 6c69 6379 272c 205b  'grow_policy', [
+000162f0: 2764 6570 7468 7769 7365 272c 2027 6c6f  'depthwise', 'lo
+00016300: 7373 6775 6964 6527 5d29 0a20 2020 2020  ssguide']).     
+00016310: 2020 2070 6172 616d 735b 276d 696e 5f63     params['min_c
+00016320: 6869 6c64 5f77 6569 6768 7427 5d20 3d20  hild_weight'] = 
+00016330: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
+00016340: 7428 276d 696e 5f63 6869 6c64 5f77 6569  t('min_child_wei
+00016350: 6768 7427 2c20 312c 2031 3030 290a 2020  ght', 1, 100).  
+00016360: 2020 2020 2020 7061 7261 6d73 5b27 6d61        params['ma
+00016370: 785f 6465 6c74 615f 7374 6570 275d 203d  x_delta_step'] =
+00016380: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+00016390: 6e74 2827 6d61 785f 6465 6c74 615f 7374  nt('max_delta_st
+000163a0: 6570 272c 2031 2c20 3130 3029 0a20 2020  ep', 1, 100).   
+000163b0: 2020 2020 2070 6172 616d 735b 2773 7562       params['sub
+000163c0: 7361 6d70 6c65 275d 203d 2074 7269 616c  sample'] = trial
+000163d0: 2e73 7567 6765 7374 5f66 6c6f 6174 2827  .suggest_float('
+000163e0: 7375 6273 616d 706c 6527 2c20 302e 352c  subsample', 0.5,
+000163f0: 2031 2e30 290a 2020 2020 2020 2020 7061   1.0).        pa
+00016400: 7261 6d73 5b27 636f 6c73 616d 706c 655f  rams['colsample_
+00016410: 6279 7472 6565 275d 203d 2074 7269 616c  bytree'] = trial
+00016420: 2e73 7567 6765 7374 5f66 6c6f 6174 2827  .suggest_float('
+00016430: 636f 6c73 616d 706c 655f 6279 7472 6565  colsample_bytree
+00016440: 272c 2030 2e35 2c20 3129 0a0a 2020 2020  ', 0.5, 1)..    
+00016450: 2020 2020 6966 2070 6172 616d 735b 2762      if params['b
+00016460: 6f6f 7374 6572 275d 203d 3d20 2264 6172  ooster'] == "dar
+00016470: 7422 3a0a 2020 2020 2020 2020 2020 2020  t":.            
+00016480: 7061 7261 6d73 5b27 7361 6d70 6c65 5f74  params['sample_t
+00016490: 7970 6527 5d20 3d20 7472 6961 6c2e 7375  ype'] = trial.su
+000164a0: 6767 6573 745f 6361 7465 676f 7269 6361  ggest_categorica
+000164b0: 6c28 2773 616d 706c 655f 7479 7065 272c  l('sample_type',
+000164c0: 205b 2775 6e69 666f 726d 272c 2027 7765   ['uniform', 'we
+000164d0: 6967 6874 6564 275d 290a 2020 2020 2020  ighted']).      
+000164e0: 2020 2020 2020 7061 7261 6d73 5b27 6e6f        params['no
+000164f0: 726d 616c 697a 655f 7479 7065 275d 203d  rmalize_type'] =
+00016500: 2074 7269 616c 2e73 7567 6765 7374 5f63   trial.suggest_c
+00016510: 6174 6567 6f72 6963 616c 2827 6e6f 726d  ategorical('norm
+00016520: 616c 697a 655f 7479 7065 272c 205b 2774  alize_type', ['t
+00016530: 7265 6527 2c20 2766 6f72 6573 7427 5d29  ree', 'forest'])
+00016540: 0a20 2020 2020 2020 2020 2020 2070 6172  .            par
+00016550: 616d 735b 2772 6174 655f 6472 6f70 275d  ams['rate_drop']
+00016560: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
+00016570: 5f66 6c6f 6174 2827 7261 7465 5f64 726f  _float('rate_dro
+00016580: 7027 2c20 3165 2d38 2c20 3129 0a20 2020  p', 1e-8, 1).   
+00016590: 2020 2020 2020 2020 2070 6172 616d 735b           params[
+000165a0: 2773 6b69 705f 6472 6f70 275d 203d 2074  'skip_drop'] = t
+000165b0: 7269 616c 2e73 7567 6765 7374 5f66 6c6f  rial.suggest_flo
+000165c0: 6174 2827 736b 6970 5f64 726f 7027 2c20  at('skip_drop', 
+000165d0: 3165 2d38 2c20 3129 0a20 2020 2020 2020  1e-8, 1).       
+000165e0: 2020 2020 2069 6620 7365 6c66 2e6f 7074       if self.opt
+000165f0: 5f63 7620 3e3d 2031 3a0a 2020 2020 2020  _cv >= 1:.      
+00016600: 2020 2020 2020 2020 2020 636c 6620 3d20            clf = 
+00016610: 5847 4243 6c61 7373 6966 6965 7228 626f  XGBClassifier(bo
+00016620: 6f73 7465 723d 7061 7261 6d73 5b27 626f  oster=params['bo
+00016630: 6f73 7465 7227 5d2c 206e 5f65 7374 696d  oster'], n_estim
+00016640: 6174 6f72 733d 7061 7261 6d73 5b27 6e5f  ators=params['n_
+00016650: 6573 7469 6d61 746f 7273 275d 2c20 636f  estimators'], co
+00016660: 6c73 616d 706c 655f 6279 7472 6565 3d70  lsample_bytree=p
+00016670: 6172 616d 735b 2763 6f6c 7361 6d70 6c65  arams['colsample
+00016680: 5f62 7974 7265 6527 5d2c 200a 2020 2020  _bytree'], .    
+00016690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000166a0: 7265 675f 6c61 6d62 6461 3d70 6172 616d  reg_lambda=param
+000166b0: 735b 2772 6567 5f6c 616d 6264 6127 5d2c  s['reg_lambda'],
+000166c0: 2072 6567 5f61 6c70 6861 3d70 6172 616d   reg_alpha=param
+000166d0: 735b 2772 6567 5f61 6c70 6861 275d 2c20  s['reg_alpha'], 
+000166e0: 6d61 785f 6465 7074 683d 7061 7261 6d73  max_depth=params
+000166f0: 5b27 6d61 785f 6465 7074 6827 5d2c 2065  ['max_depth'], e
+00016700: 7461 3d70 6172 616d 735b 2765 7461 275d  ta=params['eta']
+00016710: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+00016720: 2020 2020 2020 2067 616d 6d61 3d70 6172         gamma=par
+00016730: 616d 735b 2767 616d 6d61 275d 2c20 6772  ams['gamma'], gr
+00016740: 6f77 5f70 6f6c 6963 793d 7061 7261 6d73  ow_policy=params
+00016750: 5b27 6772 6f77 5f70 6f6c 6963 7927 5d2c  ['grow_policy'],
+00016760: 206d 696e 5f63 6869 6c64 5f77 6569 6768   min_child_weigh
+00016770: 743d 7061 7261 6d73 5b27 6d69 6e5f 6368  t=params['min_ch
+00016780: 696c 645f 7765 6967 6874 275d 2c20 0a20  ild_weight'], . 
+00016790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000167a0: 2020 206d 6178 5f64 656c 7461 5f73 7465     max_delta_ste
+000167b0: 703d 7061 7261 6d73 5b27 6d61 785f 6465  p=params['max_de
+000167c0: 6c74 615f 7374 6570 275d 2c20 7375 6273  lta_step'], subs
+000167d0: 616d 706c 653d 7061 7261 6d73 5b27 7375  ample=params['su
+000167e0: 6273 616d 706c 6527 5d2c 2073 616d 706c  bsample'], sampl
+000167f0: 655f 7479 7065 3d70 6172 616d 735b 2773  e_type=params['s
+00016800: 616d 706c 655f 7479 7065 275d 2c20 0a20  ample_type'], . 
+00016810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016820: 2020 206e 6f72 6d61 6c69 7a65 5f74 7970     normalize_typ
+00016830: 653d 7061 7261 6d73 5b27 6e6f 726d 616c  e=params['normal
+00016840: 697a 655f 7479 7065 275d 2c20 7261 7465  ize_type'], rate
+00016850: 5f64 726f 703d 7061 7261 6d73 5b27 7261  _drop=params['ra
+00016860: 7465 5f64 726f 7027 5d2c 2073 6b69 705f  te_drop'], skip_
+00016870: 6472 6f70 3d70 6172 616d 735b 2773 6b69  drop=params['ski
+00016880: 705f 6472 6f70 275d 2c20 7261 6e64 6f6d  p_drop'], random
+00016890: 5f73 7461 7465 3d31 3930 3929 232c 2074  _state=1909)#, t
+000168a0: 7265 655f 6d65 7468 6f64 3d27 6869 7374  ree_method='hist
+000168b0: 2729 0a20 2020 2020 2020 2065 6c69 6620  ').        elif 
+000168c0: 7061 7261 6d73 5b27 626f 6f73 7465 7227  params['booster'
+000168d0: 5d20 3d3d 2027 6762 7472 6565 273a 0a20  ] == 'gbtree':. 
+000168e0: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+000168f0: 6c66 2e6f 7074 5f63 7620 3e3d 2031 3a0a  lf.opt_cv >= 1:.
+00016900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016910: 636c 6620 3d20 5847 4243 6c61 7373 6966  clf = XGBClassif
+00016920: 6965 7228 626f 6f73 7465 723d 7061 7261  ier(booster=para
+00016930: 6d73 5b27 626f 6f73 7465 7227 5d2c 206e  ms['booster'], n
+00016940: 5f65 7374 696d 6174 6f72 733d 7061 7261  _estimators=para
+00016950: 6d73 5b27 6e5f 6573 7469 6d61 746f 7273  ms['n_estimators
+00016960: 275d 2c20 636f 6c73 616d 706c 655f 6279  '], colsample_by
+00016970: 7472 6565 3d70 6172 616d 735b 2763 6f6c  tree=params['col
+00016980: 7361 6d70 6c65 5f62 7974 7265 6527 5d2c  sample_bytree'],
+00016990: 2020 7265 675f 6c61 6d62 6461 3d70 6172    reg_lambda=par
+000169a0: 616d 735b 2772 6567 5f6c 616d 6264 6127  ams['reg_lambda'
+000169b0: 5d2c 200a 2020 2020 2020 2020 2020 2020  ], .            
+000169c0: 2020 2020 2020 2020 7265 675f 616c 7068          reg_alph
+000169d0: 613d 7061 7261 6d73 5b27 7265 675f 616c  a=params['reg_al
+000169e0: 7068 6127 5d2c 206d 6178 5f64 6570 7468  pha'], max_depth
+000169f0: 3d70 6172 616d 735b 276d 6178 5f64 6570  =params['max_dep
+00016a00: 7468 275d 2c20 6574 613d 7061 7261 6d73  th'], eta=params
+00016a10: 5b27 6574 6127 5d2c 2067 616d 6d61 3d70  ['eta'], gamma=p
+00016a20: 6172 616d 735b 2767 616d 6d61 275d 2c20  arams['gamma'], 
+00016a30: 6772 6f77 5f70 6f6c 6963 793d 7061 7261  grow_policy=para
+00016a40: 6d73 5b27 6772 6f77 5f70 6f6c 6963 7927  ms['grow_policy'
+00016a50: 5d2c 200a 2020 2020 2020 2020 2020 2020  ], .            
+00016a60: 2020 2020 2020 2020 6d69 6e5f 6368 696c          min_chil
+00016a70: 645f 7765 6967 6874 3d70 6172 616d 735b  d_weight=params[
+00016a80: 276d 696e 5f63 6869 6c64 5f77 6569 6768  'min_child_weigh
+00016a90: 7427 5d2c 206d 6178 5f64 656c 7461 5f73  t'], max_delta_s
+00016aa0: 7465 703d 7061 7261 6d73 5b27 6d61 785f  tep=params['max_
+00016ab0: 6465 6c74 615f 7374 6570 275d 2c20 7375  delta_step'], su
+00016ac0: 6273 616d 706c 653d 7061 7261 6d73 5b27  bsample=params['
+00016ad0: 7375 6273 616d 706c 6527 5d2c 2072 616e  subsample'], ran
+00016ae0: 646f 6d5f 7374 6174 653d 3139 3039 2923  dom_state=1909)#
+00016af0: 2c20 7472 6565 5f6d 6574 686f 643d 2768  , tree_method='h
+00016b00: 6973 7427 290a 2020 2020 2020 2020 2020  ist').          
+00016b10: 2020 0a20 2020 2020 2020 2069 6620 7365    .        if se
+00016b20: 6c66 2e6f 7074 5f63 7620 3c20 313a 0a20  lf.opt_cv < 1:. 
+00016b30: 2020 2020 2020 2020 2020 2062 7374 203d             bst =
+00016b40: 2074 7261 696e 2870 6172 616d 732c 2064   train(params, d
+00016b50: 7472 6169 6e2c 2065 7661 6c73 3d5b 2864  train, evals=[(d
+00016b60: 7661 6c69 642c 2022 7661 6c69 6461 7469  valid, "validati
+00016b70: 6f6e 2229 5d2c 2063 616c 6c62 6163 6b73  on")], callbacks
+00016b80: 3d5b 7072 756e 696e 675f 6361 6c6c 6261  =[pruning_callba
+00016b90: 636b 5d29 0a20 2020 2020 2020 2020 2020  ck]).           
+00016ba0: 2070 7265 6473 203d 2062 7374 2e70 7265   preds = bst.pre
+00016bb0: 6469 6374 2864 7661 6c69 6429 0a20 2020  dict(dvalid).   
+00016bc0: 2020 2020 2020 2020 2070 7265 645f 6c61           pred_la
+00016bd0: 6265 6c73 203d 206e 702e 7269 6e74 2870  bels = np.rint(p
+00016be0: 7265 6473 290a 2020 2020 2020 2020 2020  reds).          
+00016bf0: 2020 6163 6375 7261 6379 203d 2061 6363    accuracy = acc
+00016c00: 7572 6163 795f 7363 6f72 6528 7661 6c69  uracy_score(vali
+00016c10: 645f 792c 2070 7265 645f 6c61 6265 6c73  d_y, pred_labels
+00016c20: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
+00016c30: 2020 2020 2020 2020 2020 2020 6376 203d              cv =
+00016c40: 2063 726f 7373 5f76 616c 6964 6174 6528   cross_validate(
+00016c50: 636c 662c 2073 656c 662e 6461 7461 5f78  clf, self.data_x
+00016c60: 2c20 7365 6c66 2e64 6174 615f 792c 2063  , self.data_y, c
+00016c70: 763d 7365 6c66 2e6f 7074 5f63 7629 0a20  v=self.opt_cv). 
+00016c80: 2020 2020 2020 2020 2020 2061 6363 7572             accur
+00016c90: 6163 7920 3d20 6e70 2e6d 6561 6e28 6376  acy = np.mean(cv
+00016ca0: 5b27 7465 7374 5f73 636f 7265 275d 290a  ['test_score']).
+00016cb0: 2020 2020 2020 2020 0a20 2020 2020 2020          .       
+00016cc0: 2072 6574 7572 6e20 6163 6375 7261 6379   return accuracy
+00016cd0: 0a0a 636c 6173 7320 6f62 6a65 6374 6976  ..class objectiv
+00016ce0: 655f 6e6e 286f 626a 6563 7429 3a0a 2020  e_nn(object):.  
+00016cf0: 2020 2222 220a 2020 2020 4f70 7469 6d69    """.    Optimi
+00016d00: 7a61 7469 6f6e 206f 626a 6563 7469 7665  zation objective
+00016d10: 2066 756e 6374 696f 6e20 666f 7220 7468   function for th
+00016d20: 6520 7363 696b 6974 2d6c 6561 726e 2069  e scikit-learn i
+00016d30: 6d70 6c65 6d65 6e74 6174 696e 206f 6620  mplementatin of 
+00016d40: 7468 650a 2020 2020 4d4c 5020 636c 6173  the.    MLP clas
+00016d50: 7369 6669 6572 2e20 5468 6520 4f70 7475  sifier. The Optu
+00016d60: 6e61 2073 6f66 7477 6172 6520 666f 7220  na software for 
+00016d70: 6879 7065 7270 6172 616d 6574 6572 206f  hyperparameter o
+00016d80: 7074 696d 697a 6174 696f 6e0a 2020 2020  ptimization.    
+00016d90: 7761 7320 7075 626c 6973 6865 6420 696e  was published in
+00016da0: 2032 3031 3920 6279 2041 6b69 6261 2065   2019 by Akiba e
+00016db0: 7420 616c 2e20 5061 7065 723a 2068 7474  t al. Paper: htt
+00016dc0: 7073 3a2f 2f61 7278 6976 2e6f 7267 2f61  ps://arxiv.org/a
+00016dd0: 6273 2f31 3930 372e 3130 3930 322e 0a0a  bs/1907.10902...
+00016de0: 2020 2020 5468 6520 746f 7461 6c20 6e75      The total nu
+00016df0: 6d62 6572 206f 6620 6869 6464 656e 206c  mber of hidden l
+00016e00: 6179 6572 7320 746f 2074 6573 7420 6973  ayers to test is
+00016e10: 206c 696d 6974 6564 2074 6f20 3130 2c20   limited to 10, 
+00016e20: 7769 7468 2031 3030 2d35 3030 3020 706f  with 100-5000 po
+00016e30: 7373 6962 6c65 200a 2020 2020 6e75 6d62  ssible .    numb
+00016e40: 6572 206f 6620 6e65 7572 6f6e 7320 696e  er of neurons in
+00016e50: 2065 6163 682e 0a0a 2020 2020 4172 6773   each...    Args
+00016e60: 3a0a 2020 2020 2020 2020 6461 7461 5f78  :.        data_x
+00016e70: 2028 6e64 6172 7261 7929 3a20 3244 2061   (ndarray): 2D a
+00016e80: 7272 6179 206f 6620 7369 7a65 2028 6e20  rray of size (n 
+00016e90: 7820 6d29 2c20 7768 6572 6520 6e20 6973  x m), where n is
+00016ea0: 2074 6865 0a20 2020 2020 2020 2020 2020   the.           
+00016eb0: 206e 756d 6265 7220 6f66 2073 616d 706c   number of sampl
+00016ec0: 6573 2c20 616e 6420 6d20 7468 6520 6e75  es, and m the nu
+00016ed0: 6d62 6572 206f 6620 6665 6174 7572 6573  mber of features
+00016ee0: 2e0a 2020 2020 2020 2020 6461 7461 5f79  ..        data_y
+00016ef0: 2028 6e64 6172 7261 792c 2073 7472 293a   (ndarray, str):
+00016f00: 2031 4420 6172 7261 7920 636f 6e74 6169   1D array contai
+00016f10: 6e69 6e67 2074 6865 2063 6f72 7265 7370  ning the corresp
+00016f20: 6f6e 696e 6720 6c61 6265 6c73 2e20 0a20  oning labels. . 
+00016f30: 2020 2020 2020 206f 7074 5f63 7620 2869         opt_cv (i
+00016f40: 6e74 293a 2043 726f 7373 2d76 616c 6964  nt): Cross-valid
+00016f50: 6174 696f 6e73 2074 6f20 7065 7266 6f72  ations to perfor
+00016f60: 6d20 7768 656e 2061 7373 6573 696e 6720  m when assesing 
+00016f70: 7468 6520 7065 7266 6f72 6d61 6e63 6520  the performance 
+00016f80: 6174 2065 6163 680a 2020 2020 2020 2020  at each.        
+00016f90: 2020 2020 6879 7065 7270 6172 616d 6574      hyperparamet
+00016fa0: 6572 206f 7074 696d 697a 6174 696f 6e20  er optimization 
+00016fb0: 7472 6961 6c2e 2046 6f72 2065 7861 6d70  trial. For examp
+00016fc0: 6c65 2c20 6966 2063 763d 332c 2074 6865  le, if cv=3, the
+00016fd0: 6e20 6561 6368 206f 7074 696d 697a 6174  n each optimizat
+00016fe0: 696f 6e20 7472 6961 6c0a 2020 2020 2020  ion trial.      
+00016ff0: 2020 2020 2020 7769 6c6c 2062 6520 6173        will be as
+00017000: 7365 7373 6564 2061 6363 6f72 6469 6e67  sessed according
+00017010: 2074 6f20 7468 6520 332d 666f 6c64 2063   to the 3-fold c
+00017020: 726f 7373 2076 616c 6964 6174 696f 6e20  ross validation 
+00017030: 6163 6375 7261 6379 2e20 0a0a 2020 2020  accuracy. ..    
+00017040: 5265 7475 726e 733a 0a20 2020 2020 2020  Returns:.       
+00017050: 2054 6865 2070 6572 666f 726d 616e 6365   The performance
+00017060: 206d 6574 7269 632c 2064 6574 6572 6d69   metric, determi
+00017070: 6e65 6420 7573 696e 6720 7468 6520 6372  ned using the cr
+00017080: 6f73 732d 666f 6c64 2076 616c 6964 6174  oss-fold validat
+00017090: 696f 6e20 6d65 7468 6f64 2e0a 2020 2020  ion method..    
+000170a0: 2222 220a 0a20 2020 2064 6566 205f 5f69  """..    def __i
+000170b0: 6e69 745f 5f28 7365 6c66 2c20 6461 7461  nit__(self, data
+000170c0: 5f78 2c20 6461 7461 5f79 2c20 6f70 745f  _x, data_y, opt_
+000170d0: 6376 293a 0a20 2020 2020 2020 2073 656c  cv):.        sel
+000170e0: 662e 6461 7461 5f78 203d 2064 6174 615f  f.data_x = data_
+000170f0: 780a 2020 2020 2020 2020 7365 6c66 2e64  x.        self.d
+00017100: 6174 615f 7920 3d20 6461 7461 5f79 0a20  ata_y = data_y. 
+00017110: 2020 2020 2020 2073 656c 662e 6f70 745f         self.opt_
+00017120: 6376 203d 206f 7074 5f63 760a 0a20 2020  cv = opt_cv..   
+00017130: 2064 6566 205f 5f63 616c 6c5f 5f28 7365   def __call__(se
+00017140: 6c66 2c20 7472 6961 6c29 3a0a 2020 2020  lf, trial):.    
+00017150: 2020 2020 6c65 6172 6e69 6e67 5f72 6174      learning_rat
+00017160: 655f 696e 6974 203d 2074 7269 616c 2e73  e_init = trial.s
+00017170: 7567 6765 7374 5f66 6c6f 6174 2827 6c65  uggest_float('le
+00017180: 6172 6e69 6e67 5f72 6174 655f 696e 6974  arning_rate_init
+00017190: 272c 2031 652d 352c 2030 2e31 2c20 7374  ', 1e-5, 0.1, st
+000171a0: 6570 3d31 652d 3529 0a20 2020 2020 2020  ep=1e-5).       
+000171b0: 2073 6f6c 7665 7220 3d20 7472 6961 6c2e   solver = trial.
+000171c0: 7375 6767 6573 745f 6361 7465 676f 7269  suggest_categori
+000171d0: 6361 6c28 2273 6f6c 7665 7222 2c20 5b22  cal("solver", ["
+000171e0: 7367 6422 2c20 2261 6461 6d22 5d29 2023  sgd", "adam"]) #
+000171f0: 226c 6266 6773 220a 2020 2020 2020 2020  "lbfgs".        
+00017200: 6163 7469 7661 7469 6f6e 203d 2074 7269  activation = tri
+00017210: 616c 2e73 7567 6765 7374 5f63 6174 6567  al.suggest_categ
+00017220: 6f72 6963 616c 2822 6163 7469 7661 7469  orical("activati
+00017230: 6f6e 222c 205b 226c 6f67 6973 7469 6322  on", ["logistic"
+00017240: 2c20 2274 616e 6822 2c20 2272 656c 7522  , "tanh", "relu"
+00017250: 5d29 0a20 2020 2020 2020 206c 6561 726e  ]).        learn
+00017260: 696e 675f 7261 7465 203d 2074 7269 616c  ing_rate = trial
+00017270: 2e73 7567 6765 7374 5f63 6174 6567 6f72  .suggest_categor
+00017280: 6963 616c 2822 6c65 6172 6e69 6e67 5f72  ical("learning_r
+00017290: 6174 6522 2c20 5b22 636f 6e73 7461 6e74  ate", ["constant
+000172a0: 222c 2022 696e 7673 6361 6c69 6e67 222c  ", "invscaling",
+000172b0: 2022 6164 6170 7469 7665 225d 290a 2020   "adaptive"]).  
+000172c0: 2020 2020 2020 616c 7068 6120 3d20 7472        alpha = tr
+000172d0: 6961 6c2e 7375 6767 6573 745f 666c 6f61  ial.suggest_floa
+000172e0: 7428 2261 6c70 6861 222c 2031 652d 372c  t("alpha", 1e-7,
+000172f0: 2031 2c20 7374 6570 3d31 652d 3629 0a20   1, step=1e-6). 
+00017300: 2020 2020 2020 2062 6174 6368 5f73 697a         batch_siz
+00017310: 6520 3d20 7472 6961 6c2e 7375 6767 6573  e = trial.sugges
+00017320: 745f 696e 7428 2762 6174 6368 5f73 697a  t_int('batch_siz
+00017330: 6527 2c20 312c 2031 3030 3029 0a20 2020  e', 1, 1000).   
+00017340: 2020 2020 206e 5f6c 6179 6572 7320 3d20       n_layers = 
+00017350: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
+00017360: 7428 2768 6964 6465 6e5f 6c61 7965 725f  t('hidden_layer_
+00017370: 7369 7a65 7327 2c20 312c 2031 3029 0a0a  sizes', 1, 10)..
+00017380: 2020 2020 2020 2020 6c61 7965 7273 203d          layers =
+00017390: 205b 5d0a 2020 2020 2020 2020 666f 7220   [].        for 
+000173a0: 6920 696e 2072 616e 6765 286e 5f6c 6179  i in range(n_lay
+000173b0: 6572 7329 3a0a 2020 2020 2020 2020 2020  ers):.          
+000173c0: 2020 6c61 7965 7273 2e61 7070 656e 6428    layers.append(
+000173d0: 7472 6961 6c2e 7375 6767 6573 745f 696e  trial.suggest_in
+000173e0: 7428 6627 6e5f 756e 6974 735f 7b69 7d27  t(f'n_units_{i}'
+000173f0: 2c20 3130 302c 2035 3030 3029 290a 0a20  , 100, 5000)).. 
+00017400: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
+00017410: 2020 2020 2020 2020 636c 6620 3d20 4d4c          clf = ML
+00017420: 5043 6c61 7373 6966 6965 7228 6869 6464  PClassifier(hidd
+00017430: 656e 5f6c 6179 6572 5f73 697a 6573 3d74  en_layer_sizes=t
+00017440: 7570 6c65 286c 6179 6572 7329 2c6c 6561  uple(layers),lea
+00017450: 726e 696e 675f 7261 7465 5f69 6e69 743d  rning_rate_init=
+00017460: 6c65 6172 6e69 6e67 5f72 6174 655f 696e  learning_rate_in
+00017470: 6974 2c20 0a20 2020 2020 2020 2020 2020  it, .           
+00017480: 2020 2020 2073 6f6c 7665 723d 736f 6c76       solver=solv
+00017490: 6572 2c20 6163 7469 7661 7469 6f6e 3d61  er, activation=a
+000174a0: 6374 6976 6174 696f 6e2c 2061 6c70 6861  ctivation, alpha
+000174b0: 3d61 6c70 6861 2c20 6261 7463 685f 7369  =alpha, batch_si
+000174c0: 7a65 3d62 6174 6368 5f73 697a 652c 206d  ze=batch_size, m
+000174d0: 6178 5f69 7465 723d 3235 3030 2c20 7261  ax_iter=2500, ra
+000174e0: 6e64 6f6d 5f73 7461 7465 3d31 3930 3929  ndom_state=1909)
+000174f0: 0a20 2020 2020 2020 2065 7863 6570 743a  .        except:
+00017500: 0a20 2020 2020 2020 2020 2020 2070 7269  .            pri
+00017510: 6e74 2822 496e 7661 6c69 6420 6879 7065  nt("Invalid hype
+00017520: 7270 6172 616d 6574 6572 2063 6f6d 6269  rparameter combi
+00017530: 6e61 7469 6f6e 2c20 736b 6970 7069 6e67  nation, skipping
+00017540: 2074 7269 616c 2229 0a20 2020 2020 2020   trial").       
+00017550: 2020 2020 2072 6574 7572 6e20 302e 300a       return 0.0.
+00017560: 0a20 2020 2020 2020 2063 7620 3d20 6372  .        cv = cr
+00017570: 6f73 735f 7661 6c69 6461 7465 2863 6c66  oss_validate(clf
+00017580: 2c20 7365 6c66 2e64 6174 615f 782c 2073  , self.data_x, s
+00017590: 656c 662e 6461 7461 5f79 2c20 6376 3d73  elf.data_y, cv=s
+000175a0: 656c 662e 6f70 745f 6376 290a 2020 2020  elf.opt_cv).    
+000175b0: 2020 2020 6669 6e61 6c5f 7363 6f72 6520      final_score 
+000175c0: 3d20 6e70 2e6d 6561 6e28 6376 5b27 7465  = np.mean(cv['te
+000175d0: 7374 5f73 636f 7265 275d 290a 0a20 2020  st_score'])..   
+000175e0: 2020 2020 2072 6574 7572 6e20 6669 6e61       return fina
+000175f0: 6c5f 7363 6f72 650a 0a63 6c61 7373 206f  l_score..class o
+00017600: 626a 6563 7469 7665 5f72 6628 6f62 6a65  bjective_rf(obje
+00017610: 6374 293a 0a20 2020 2022 2222 0a20 2020  ct):.    """.   
+00017620: 204f 7074 696d 697a 6174 696f 6e20 6f62   Optimization ob
+00017630: 6a65 6374 6976 6520 6675 6e63 7469 6f6e  jective function
+00017640: 2066 6f72 2074 6865 2073 6369 6b69 742d   for the scikit-
+00017650: 6c65 6172 6e20 696d 706c 656d 656e 7461  learn implementa
+00017660: 7469 6e20 6f66 2074 6865 0a20 2020 2052  tin of the.    R
+00017670: 616e 646f 6d20 466f 7265 7374 2063 6c61  andom Forest cla
+00017680: 7373 6966 6965 722e 2054 6865 204f 7074  ssifier. The Opt
+00017690: 756e 6120 736f 6674 7761 7265 2066 6f72  una software for
+000176a0: 2068 7970 6572 7061 7261 6d65 7465 7220   hyperparameter 
+000176b0: 6f70 7469 6d69 7a61 7469 6f6e 0a20 2020  optimization.   
+000176c0: 2077 6173 2070 7562 6c69 7368 6564 2069   was published i
+000176d0: 6e20 3230 3139 2062 7920 416b 6962 6120  n 2019 by Akiba 
+000176e0: 6574 2061 6c2e 2050 6170 6572 3a20 6874  et al. Paper: ht
+000176f0: 7470 733a 2f2f 6172 7869 762e 6f72 672f  tps://arxiv.org/
+00017700: 6162 732f 3139 3037 2e31 3039 3032 0a0a  abs/1907.10902..
+00017710: 2020 2020 4172 6773 3a0a 2020 2020 2020      Args:.      
+00017720: 2020 6461 7461 5f78 2028 6e64 6172 7261    data_x (ndarra
+00017730: 7929 3a20 3244 2061 7272 6179 206f 6620  y): 2D array of 
+00017740: 7369 7a65 2028 6e20 7820 6d29 2c20 7768  size (n x m), wh
+00017750: 6572 6520 6e20 6973 2074 6865 0a20 2020  ere n is the.   
+00017760: 2020 2020 2020 2020 206e 756d 6265 7220           number 
+00017770: 6f66 2073 616d 706c 6573 2c20 616e 6420  of samples, and 
+00017780: 6d20 7468 6520 6e75 6d62 6572 206f 6620  m the number of 
+00017790: 6665 6174 7572 6573 2e0a 2020 2020 2020  features..      
+000177a0: 2020 6461 7461 5f79 2028 6e64 6172 7261    data_y (ndarra
+000177b0: 792c 2073 7472 293a 2031 4420 6172 7261  y, str): 1D arra
+000177c0: 7920 636f 6e74 6169 6e69 6e67 2074 6865  y containing the
+000177d0: 2063 6f72 7265 7370 6f6e 696e 6720 6c61   corresponing la
+000177e0: 6265 6c73 2e20 0a20 2020 2020 2020 206f  bels. .        o
+000177f0: 7074 5f63 7620 2869 6e74 293a 2043 726f  pt_cv (int): Cro
+00017800: 7373 2d76 616c 6964 6174 696f 6e73 2074  ss-validations t
+00017810: 6f20 7065 7266 6f72 6d20 7768 656e 2061  o perform when a
+00017820: 7373 6573 696e 6720 7468 6520 7065 7266  ssesing the perf
+00017830: 6f72 6d61 6e63 6520 6174 2065 6163 680a  ormance at each.
+00017840: 2020 2020 2020 2020 2020 2020 6879 7065              hype
+00017850: 7270 6172 616d 6574 6572 206f 7074 696d  rparameter optim
+00017860: 697a 6174 696f 6e20 7472 6961 6c2e 2046  ization trial. F
+00017870: 6f72 2065 7861 6d70 6c65 2c20 6966 2063  or example, if c
+00017880: 763d 332c 2074 6865 6e20 6561 6368 206f  v=3, then each o
+00017890: 7074 696d 697a 6174 696f 6e20 7472 6961  ptimization tria
+000178a0: 6c0a 2020 2020 2020 2020 2020 2020 7769  l.            wi
+000178b0: 6c6c 2062 6520 6173 7365 7373 6564 2061  ll be assessed a
+000178c0: 6363 6f72 6469 6e67 2074 6f20 7468 6520  ccording to the 
+000178d0: 332d 666f 6c64 2063 726f 7373 2076 616c  3-fold cross val
+000178e0: 6964 6174 696f 6e20 6163 6375 7261 6379  idation accuracy
+000178f0: 2e20 0a0a 2020 2020 5265 7475 726e 733a  . ..    Returns:
+00017900: 0a20 2020 2020 2020 2054 6865 2070 6572  .        The per
+00017910: 666f 726d 616e 6365 206d 6574 7269 632c  formance metric,
+00017920: 2064 6574 6572 6d69 6e65 6420 7573 696e   determined usin
+00017930: 6720 7468 6520 6372 6f73 732d 666f 6c64  g the cross-fold
+00017940: 2076 616c 6964 6174 696f 6e20 6d65 7468   validation meth
+00017950: 6f64 2e0a 2020 2020 2222 220a 2020 2020  od..    """.    
+00017960: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+00017970: 5f28 7365 6c66 2c20 6461 7461 5f78 2c20  _(self, data_x, 
+00017980: 6461 7461 5f79 2c20 6f70 745f 6376 293a  data_y, opt_cv):
+00017990: 0a0a 2020 2020 2020 2020 7365 6c66 2e64  ..        self.d
+000179a0: 6174 615f 7820 3d20 6461 7461 5f78 0a20  ata_x = data_x. 
+000179b0: 2020 2020 2020 2073 656c 662e 6461 7461         self.data
+000179c0: 5f79 203d 2064 6174 615f 790a 2020 2020  _y = data_y.    
+000179d0: 2020 2020 7365 6c66 2e6f 7074 5f63 7620      self.opt_cv 
+000179e0: 3d20 6f70 745f 6376 0a0a 2020 2020 6465  = opt_cv..    de
+000179f0: 6620 5f5f 6361 6c6c 5f5f 2873 656c 662c  f __call__(self,
+00017a00: 2074 7269 616c 293a 0a0a 2020 2020 2020   trial):..      
+00017a10: 2020 6e5f 6573 7469 6d61 746f 7273 203d    n_estimators =
+00017a20: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+00017a30: 6e74 2827 6e5f 6573 7469 6d61 746f 7273  nt('n_estimators
+00017a40: 272c 2031 3030 2c20 3330 3030 290a 2020  ', 100, 3000).  
+00017a50: 2020 2020 2020 6372 6974 6572 696f 6e20        criterion 
+00017a60: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+00017a70: 6361 7465 676f 7269 6361 6c28 2763 7269  categorical('cri
+00017a80: 7465 7269 6f6e 272c 205b 2767 696e 6927  terion', ['gini'
+00017a90: 2c20 2765 6e74 726f 7079 275d 290a 2020  , 'entropy']).  
+00017aa0: 2020 2020 2020 6d61 785f 6465 7074 6820        max_depth 
+00017ab0: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+00017ac0: 696e 7428 276d 6178 5f64 6570 7468 272c  int('max_depth',
+00017ad0: 2032 2c20 3235 290a 2020 2020 2020 2020   2, 25).        
+00017ae0: 6d69 6e5f 7361 6d70 6c65 735f 7370 6c69  min_samples_spli
+00017af0: 7420 3d20 7472 6961 6c2e 7375 6767 6573  t = trial.sugges
+00017b00: 745f 696e 7428 276d 696e 5f73 616d 706c  t_int('min_sampl
+00017b10: 6573 5f73 706c 6974 272c 2032 2c20 3235  es_split', 2, 25
+00017b20: 290a 2020 2020 2020 2020 6d69 6e5f 7361  ).        min_sa
+00017b30: 6d70 6c65 735f 6c65 6166 203d 2074 7269  mples_leaf = tri
+00017b40: 616c 2e73 7567 6765 7374 5f69 6e74 2827  al.suggest_int('
+00017b50: 6d69 6e5f 7361 6d70 6c65 735f 6c65 6166  min_samples_leaf
+00017b60: 272c 2031 2c20 3135 290a 2020 2020 2020  ', 1, 15).      
+00017b70: 2020 6d61 785f 6665 6174 7572 6573 203d    max_features =
+00017b80: 2074 7269 616c 2e73 7567 6765 7374 5f69   trial.suggest_i
+00017b90: 6e74 2827 6d61 785f 6665 6174 7572 6573  nt('max_features
+00017ba0: 272c 2031 2c20 7365 6c66 2e64 6174 615f  ', 1, self.data_
+00017bb0: 782e 7368 6170 655b 315d 290a 2020 2020  x.shape[1]).    
+00017bc0: 2020 2020 626f 6f74 7374 7261 7020 3d20      bootstrap = 
+00017bd0: 7472 6961 6c2e 7375 6767 6573 745f 6361  trial.suggest_ca
+00017be0: 7465 676f 7269 6361 6c28 2762 6f6f 7473  tegorical('boots
+00017bf0: 7472 6170 272c 205b 5472 7565 2c20 4661  trap', [True, Fa
+00017c00: 6c73 655d 290a 2020 2020 2020 2020 0a20  lse]).        . 
+00017c10: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
+00017c20: 2020 2020 2020 2020 636c 6620 3d20 5261          clf = Ra
+00017c30: 6e64 6f6d 466f 7265 7374 436c 6173 7369  ndomForestClassi
+00017c40: 6669 6572 286e 5f65 7374 696d 6174 6f72  fier(n_estimator
+00017c50: 733d 6e5f 6573 7469 6d61 746f 7273 2c20  s=n_estimators, 
+00017c60: 6372 6974 6572 696f 6e3d 6372 6974 6572  criterion=criter
+00017c70: 696f 6e2c 206d 6178 5f64 6570 7468 3d6d  ion, max_depth=m
+00017c80: 6178 5f64 6570 7468 2c0a 2020 2020 2020  ax_depth,.      
+00017c90: 2020 2020 2020 2020 2020 6d69 6e5f 7361            min_sa
+00017ca0: 6d70 6c65 735f 7370 6c69 743d 6d69 6e5f  mples_split=min_
+00017cb0: 7361 6d70 6c65 735f 7370 6c69 742c 206d  samples_split, m
+00017cc0: 696e 5f73 616d 706c 6573 5f6c 6561 663d  in_samples_leaf=
+00017cd0: 6d69 6e5f 7361 6d70 6c65 735f 6c65 6166  min_samples_leaf
+00017ce0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00017cf0: 2020 6d61 785f 6665 6174 7572 6573 3d6d    max_features=m
+00017d00: 6178 5f66 6561 7475 7265 732c 2062 6f6f  ax_features, boo
+00017d10: 7473 7472 6170 3d62 6f6f 7473 7472 6170  tstrap=bootstrap
+00017d20: 2c20 7261 6e64 6f6d 5f73 7461 7465 3d31  , random_state=1
+00017d30: 3930 3929 0a20 2020 2020 2020 2065 7863  909).        exc
+00017d40: 6570 743a 0a20 2020 2020 2020 2020 2020  ept:.           
+00017d50: 2070 7269 6e74 2822 496e 7661 6c69 6420   print("Invalid 
+00017d60: 6879 7065 7270 6172 616d 6574 6572 2063  hyperparameter c
+00017d70: 6f6d 6269 6e61 7469 6f6e 2c20 736b 6970  ombination, skip
+00017d80: 7069 6e67 2074 7269 616c 2229 0a20 2020  ping trial").   
+00017d90: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00017da0: 302e 300a 0a20 2020 2020 2020 2063 7620  0.0..        cv 
+00017db0: 3d20 6372 6f73 735f 7661 6c69 6461 7465  = cross_validate
+00017dc0: 2863 6c66 2c20 7365 6c66 2e64 6174 615f  (clf, self.data_
+00017dd0: 782c 2073 656c 662e 6461 7461 5f79 2c20  x, self.data_y, 
+00017de0: 6376 3d73 656c 662e 6f70 745f 6376 290a  cv=self.opt_cv).
+00017df0: 2020 2020 2020 2020 6669 6e61 6c5f 7363          final_sc
+00017e00: 6f72 6520 3d20 6e70 2e6d 6561 6e28 6376  ore = np.mean(cv
+00017e10: 5b27 7465 7374 5f73 636f 7265 275d 290a  ['test_score']).
+00017e20: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00017e30: 6669 6e61 6c5f 7363 6f72 650a 0a63 6c61  final_score..cla
+00017e40: 7373 204f 626a 6563 7469 7665 4f6e 6543  ss ObjectiveOneC
+00017e50: 6c61 7373 5356 4d28 6f62 6a65 6374 293a  lassSVM(object):
+00017e60: 0a20 2020 2022 2222 0a20 2020 204f 7074  .    """.    Opt
+00017e70: 696d 697a 6174 696f 6e20 6f62 6a65 6374  imization object
+00017e80: 6976 6520 6675 6e63 7469 6f6e 2066 6f72  ive function for
+00017e90: 2074 6865 2073 6369 6b69 742d 6c65 6172   the scikit-lear
+00017ea0: 6e20 696d 706c 656d 656e 7461 7469 6f6e  n implementation
+00017eb0: 206f 6620 7468 650a 2020 2020 4f6e 652d   of the.    One-
+00017ec0: 436c 6173 7320 5356 4d2e 2054 6865 204f  Class SVM. The O
+00017ed0: 7074 756e 6120 736f 6674 7761 7265 2066  ptuna software f
+00017ee0: 6f72 2068 7970 6572 7061 7261 6d65 7465  or hyperparamete
+00017ef0: 7220 6f70 7469 6d69 7a61 7469 6f6e 0a20  r optimization. 
+00017f00: 2020 2077 6173 2070 7562 6c69 7368 6564     was published
+00017f10: 2069 6e20 3230 3139 2062 7920 416b 6962   in 2019 by Akib
+00017f20: 6120 6574 2061 6c2e 2050 6170 6572 3a20  a et al. Paper: 
+00017f30: 6874 7470 733a 2f2f 6172 7869 762e 6f72  https://arxiv.or
+00017f40: 672f 6162 732f 3139 3037 2e31 3039 3032  g/abs/1907.10902
+00017f50: 0a0a 2020 2020 4172 6773 3a0a 2020 2020  ..    Args:.    
+00017f60: 2020 2020 6461 7461 5f78 2028 6e64 6172      data_x (ndar
+00017f70: 7261 7929 3a20 3244 2061 7272 6179 206f  ray): 2D array o
+00017f80: 6620 7369 7a65 2028 6e20 7820 6d29 2c20  f size (n x m), 
+00017f90: 7768 6572 6520 6e20 6973 2074 6865 206e  where n is the n
+00017fa0: 756d 6265 7220 6f66 2073 616d 706c 6573  umber of samples
+00017fb0: 2c0a 2020 2020 2020 2020 2020 2020 616e  ,.            an
+00017fc0: 6420 6d20 6973 2074 6865 206e 756d 6265  d m is the numbe
+00017fd0: 7220 6f66 2066 6561 7475 7265 732e 0a20  r of features.. 
+00017fe0: 2020 2020 2020 2064 6174 615f 7920 286e         data_y (n
+00017ff0: 6461 7272 6179 2c20 7374 7229 3a20 3144  darray, str): 1D
+00018000: 2061 7272 6179 2063 6f6e 7461 696e 696e   array containin
+00018010: 6720 7468 6520 636f 7272 6573 706f 6e64  g the correspond
+00018020: 696e 6720 6c61 6265 6c73 2e0a 2020 2020  ing labels..    
+00018030: 2020 2020 6f70 745f 6376 2028 696e 7429      opt_cv (int)
+00018040: 3a20 4372 6f73 732d 7661 6c69 6461 7469  : Cross-validati
+00018050: 6f6e 7320 746f 2070 6572 666f 726d 2077  ons to perform w
+00018060: 6865 6e20 6173 7365 7373 696e 6720 7468  hen assessing th
+00018070: 6520 7065 7266 6f72 6d61 6e63 6520 6174  e performance at
+00018080: 2065 6163 680a 2020 2020 2020 2020 2020   each.          
+00018090: 2020 6879 7065 7270 6172 616d 6574 6572    hyperparameter
+000180a0: 206f 7074 696d 697a 6174 696f 6e20 7472   optimization tr
+000180b0: 6961 6c2e 2046 6f72 2065 7861 6d70 6c65  ial. For example
+000180c0: 2c20 6966 2063 763d 332c 2074 6865 6e20  , if cv=3, then 
+000180d0: 6561 6368 206f 7074 696d 697a 6174 696f  each optimizatio
+000180e0: 6e20 7472 6961 6c0a 2020 2020 2020 2020  n trial.        
+000180f0: 2020 2020 7769 6c6c 2062 6520 6173 7365      will be asse
+00018100: 7373 6564 2061 6363 6f72 6469 6e67 2074  ssed according t
+00018110: 6f20 7468 6520 332d 666f 6c64 2063 726f  o the 3-fold cro
+00018120: 7373 2d76 616c 6964 6174 696f 6e20 6163  ss-validation ac
+00018130: 6375 7261 6379 2e0a 0a20 2020 2052 6574  curacy...    Ret
+00018140: 7572 6e73 3a0a 2020 2020 2020 2020 5468  urns:.        Th
+00018150: 6520 7065 7266 6f72 6d61 6e63 6520 6d65  e performance me
+00018160: 7472 6963 2c20 6465 7465 726d 696e 6564  tric, determined
+00018170: 2075 7369 6e67 2074 6865 2063 726f 7373   using the cross
+00018180: 2d66 6f6c 6420 7661 6c69 6461 7469 6f6e  -fold validation
+00018190: 206d 6574 686f 642e 0a20 2020 2022 2222   method..    """
+000181a0: 0a0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
+000181b0: 5f5f 2873 656c 662c 2064 6174 615f 782c  __(self, data_x,
+000181c0: 2064 6174 615f 792c 206f 7074 5f63 7629   data_y, opt_cv)
+000181d0: 3a0a 2020 2020 2020 2020 7365 6c66 2e64  :.        self.d
+000181e0: 6174 615f 7820 3d20 6461 7461 5f78 0a20  ata_x = data_x. 
+000181f0: 2020 2020 2020 2073 656c 662e 6461 7461         self.data
+00018200: 5f79 203d 2064 6174 615f 790a 2020 2020  _y = data_y.    
+00018210: 2020 2020 7365 6c66 2e6f 7074 5f63 7620      self.opt_cv 
+00018220: 3d20 6f70 745f 6376 0a0a 2020 2020 6465  = opt_cv..    de
+00018230: 6620 5f5f 6361 6c6c 5f5f 2873 656c 662c  f __call__(self,
+00018240: 2074 7269 616c 293a 0a20 2020 2020 2020   trial):.       
+00018250: 2022 2222 0a20 2020 2020 2020 2044 6566   """.        Def
+00018260: 696e 6520 7468 6520 6f70 7469 6d69 7a61  ine the optimiza
+00018270: 7469 6f6e 206f 626a 6563 7469 7665 2066  tion objective f
+00018280: 756e 6374 696f 6e20 666f 7220 7468 6520  unction for the 
+00018290: 4f6e 652d 436c 6173 7320 5356 4d2e 0a0a  One-Class SVM...
+000182a0: 2020 2020 2020 2020 4172 6773 3a0a 2020          Args:.  
+000182b0: 2020 2020 2020 2020 2020 7472 6961 6c20            trial 
+000182c0: 286f 7074 756e 612e 7472 6961 6c2e 5472  (optuna.trial.Tr
+000182d0: 6961 6c29 3a20 4120 5472 6961 6c20 6f62  ial): A Trial ob
+000182e0: 6a65 6374 2063 6f6e 7461 696e 696e 6720  ject containing 
+000182f0: 7468 6520 6375 7272 656e 7420 7374 6174  the current stat
+00018300: 6520 6f66 2074 6865 206f 7074 696d 697a  e of the optimiz
+00018310: 6174 696f 6e2e 0a0a 2020 2020 2020 2020  ation...        
+00018320: 5265 7475 726e 733a 0a20 2020 2020 2020  Returns:.       
+00018330: 2020 2020 2066 6c6f 6174 3a20 5468 6520       float: The 
+00018340: 7065 7266 6f72 6d61 6e63 6520 6d65 7472  performance metr
+00018350: 6963 2c20 6465 7465 726d 696e 6564 2075  ic, determined u
+00018360: 7369 6e67 2063 726f 7373 2d76 616c 6964  sing cross-valid
+00018370: 6174 696f 6e2e 0a20 2020 2020 2020 2022  ation..        "
+00018380: 2222 0a0a 2020 2020 2020 2020 6b65 726e  ""..        kern
+00018390: 656c 203d 2074 7269 616c 2e73 7567 6765  el = trial.sugge
+000183a0: 7374 5f63 6174 6567 6f72 6963 616c 2827  st_categorical('
+000183b0: 6b65 726e 656c 272c 205b 276c 696e 6561  kernel', ['linea
+000183c0: 7227 2c20 2770 6f6c 7927 2c20 2772 6266  r', 'poly', 'rbf
+000183d0: 272c 2027 7369 676d 6f69 6427 2c20 2770  ', 'sigmoid', 'p
+000183e0: 7265 636f 6d70 7574 6564 275d 290a 2020  recomputed']).  
+000183f0: 2020 2020 2020 6465 6772 6565 203d 2074        degree = t
+00018400: 7269 616c 2e73 7567 6765 7374 5f69 6e74  rial.suggest_int
+00018410: 2827 6465 6772 6565 272c 2030 2c20 3130  ('degree', 0, 10
+00018420: 290a 2020 2020 2020 2020 6761 6d6d 6120  ).        gamma 
+00018430: 3d20 7472 6961 6c2e 7375 6767 6573 745f  = trial.suggest_
+00018440: 6361 7465 676f 7269 6361 6c28 2767 616d  categorical('gam
+00018450: 6d61 272c 205b 2773 6361 6c65 272c 2027  ma', ['scale', '
+00018460: 6175 746f 275d 290a 2020 2020 2020 2020  auto']).        
+00018470: 636f 6566 3020 3d20 7472 6961 6c2e 7375  coef0 = trial.su
+00018480: 6767 6573 745f 666c 6f61 7428 2763 6f65  ggest_float('coe
+00018490: 6630 272c 2030 2e30 2c20 312e 3029 0a20  f0', 0.0, 1.0). 
+000184a0: 2020 2020 2020 2074 6f6c 203d 2074 7269         tol = tri
+000184b0: 616c 2e73 7567 6765 7374 5f66 6c6f 6174  al.suggest_float
+000184c0: 2827 746f 6c27 2c20 3165 2d36 2c20 3165  ('tol', 1e-6, 1e
+000184d0: 2d32 2c20 6c6f 673d 5472 7565 290a 2020  -2, log=True).  
+000184e0: 2020 2020 2020 6e75 203d 2074 7269 616c        nu = trial
+000184f0: 2e73 7567 6765 7374 5f66 6c6f 6174 2827  .suggest_float('
+00018500: 6e75 272c 2030 2e31 2c20 312e 3029 0a20  nu', 0.1, 1.0). 
+00018510: 2020 2020 2020 2073 6872 696e 6b69 6e67         shrinking
+00018520: 203d 2074 7269 616c 2e73 7567 6765 7374   = trial.suggest
+00018530: 5f63 6174 6567 6f72 6963 616c 2827 7368  _categorical('sh
+00018540: 7269 6e6b 696e 6727 2c20 5b54 7275 652c  rinking', [True,
+00018550: 2046 616c 7365 5d29 0a20 2020 2020 2020   False]).       
+00018560: 2063 6163 6865 5f73 697a 6520 3d20 7472   cache_size = tr
+00018570: 6961 6c2e 7375 6767 6573 745f 666c 6f61  ial.suggest_floa
+00018580: 7428 2763 6163 6865 5f73 697a 6527 2c20  t('cache_size', 
+00018590: 3130 302c 2031 3030 3029 0a0a 2020 2020  100, 1000)..    
+000185a0: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
+000185b0: 2020 2020 2063 6c66 203d 204f 6e65 436c       clf = OneCl
+000185c0: 6173 7353 564d 286b 6572 6e65 6c3d 6b65  assSVM(kernel=ke
+000185d0: 726e 656c 2c20 6465 6772 6565 3d64 6567  rnel, degree=deg
+000185e0: 7265 652c 2067 616d 6d61 3d67 616d 6d61  ree, gamma=gamma
+000185f0: 2c20 636f 6566 303d 636f 6566 302c 2074  , coef0=coef0, t
+00018600: 6f6c 3d74 6f6c 2c0a 2020 2020 2020 2020  ol=tol,.        
+00018610: 2020 2020 2020 2020 6e75 3d6e 752c 2073          nu=nu, s
+00018620: 6872 696e 6b69 6e67 3d73 6872 696e 6b69  hrinking=shrinki
+00018630: 6e67 2c20 6361 6368 655f 7369 7a65 3d63  ng, cache_size=c
+00018640: 6163 6865 5f73 697a 6529 0a20 2020 2020  ache_size).     
+00018650: 2020 2065 7863 6570 743a 0a20 2020 2020     except:.     
+00018660: 2020 2020 2020 2070 7269 6e74 2822 496e         print("In
+00018670: 7661 6c69 6420 6879 7065 7270 6172 616d  valid hyperparam
+00018680: 6574 6572 2063 6f6d 6269 6e61 7469 6f6e  eter combination
+00018690: 2c20 736b 6970 7069 6e67 2074 7269 616c  , skipping trial
+000186a0: 2229 0a20 2020 2020 2020 2020 2020 2072  ").            r
+000186b0: 6574 7572 6e20 302e 300a 0a20 2020 2020  eturn 0.0..     
+000186c0: 2020 2063 7620 3d20 6372 6f73 735f 7661     cv = cross_va
+000186d0: 6c69 6461 7465 2863 6c66 2c20 7365 6c66  lidate(clf, self
+000186e0: 2e64 6174 615f 782c 2073 656c 662e 6461  .data_x, self.da
+000186f0: 7461 5f79 2c20 6376 3d73 656c 662e 6f70  ta_y, cv=self.op
+00018700: 745f 6376 290a 2020 2020 2020 2020 6669  t_cv).        fi
+00018710: 6e61 6c5f 7363 6f72 6520 3d20 6e70 2e6d  nal_score = np.m
+00018720: 6561 6e28 6376 5b27 7465 7374 5f73 636f  ean(cv['test_sco
+00018730: 7265 275d 290a 0a20 2020 2020 2020 2072  re'])..        r
+00018740: 6574 7572 6e20 6669 6e61 6c5f 7363 6f72  eturn final_scor
+00018750: 650a 0a63 6c61 7373 204d 6f6e 6974 6f72  e..class Monitor
+00018760: 5f54 7261 636b 6572 2843 616c 6c62 6163  _Tracker(Callbac
+00018770: 6b29 3a0a 2020 2020 2222 220a 2020 2020  k):.    """.    
+00018780: 4375 7374 6f6d 2063 616c 6c62 6163 6b20  Custom callback 
+00018790: 7468 6174 2061 6c6c 6f77 7320 666f 7220  that allows for 
+000187a0: 7477 6f20 6469 6666 6572 656e 7420 6d6f  two different mo
+000187b0: 6e69 746f 7273 2e0a 2020 2020 5468 6973  nitors..    This
+000187c0: 2063 6c61 7373 2069 7320 7573 6564 2062   class is used b
+000187d0: 7920 7468 6520 606f 626a 6563 7469 7665  y the `objective
+000187e0: 5f63 6e6e 6020 726f 7574 696e 6520 6173  _cnn` routine as
+000187f0: 2069 7420 696e 6865 7269 7473 2074 6865   it inherits the
+00018800: 2060 6d6f 6e69 746f 7231 6020 0a20 2020   `monitor1` .   
+00018810: 2061 6e64 2060 6d6f 6e69 746f 7232 6020   and `monitor2` 
+00018820: 6174 7472 6962 7574 6573 2c20 6173 2077  attributes, as w
+00018830: 656c 6c20 6173 2074 6865 6972 2063 6f72  ell as their cor
+00018840: 7265 7370 6f6e 6469 6e67 2074 6872 6573  responding thres
+00018850: 686f 6c64 732e 2054 6869 7320 6561 726c  holds. This earl
+00018860: 7920 7374 6f70 7069 6e67 0a20 2020 2063  y stopping.    c
+00018870: 7573 746f 6d20 6361 6c6c 6261 636b 2077  ustom callback w
+00018880: 696c 6c20 7465 726d 696e 6174 6520 7468  ill terminate th
+00018890: 6520 7472 6169 6e69 6e67 2065 6172 6c79  e training early
+000188a0: 2069 6620 6569 7468 6572 206d 6f6e 6974   if either monit
+000188b0: 6f72 7320 6372 6f73 7320 7468 6569 7220  ors cross their 
+000188c0: 7265 7370 6563 7469 7665 0a20 2020 2074  respective.    t
+000188d0: 6872 6573 686f 6c64 2c20 7468 6572 6566  hreshold, theref
+000188e0: 6f72 6520 7468 6520 7061 7469 656e 6365  ore the patience
+000188f0: 2069 6e70 7574 2069 7320 6e6f 7420 7573   input is not us
+00018900: 6564 2e20 5768 6574 6865 7220 7468 6520  ed. Whether the 
+00018910: 7468 7265 7368 6f6c 6420 7368 6f75 6c64  threshold should
+00018920: 2062 6520 6120 6365 696c 696e 670a 2020   be a ceiling.  
+00018930: 2020 6f72 2066 6c6f 6f72 2076 616c 7565    or floor value
+00018940: 2077 696c 6c20 6265 2064 6574 6572 6d69   will be determi
+00018950: 6e65 6420 6163 636f 7264 696e 6720 746f  ned according to
+00018960: 2074 6865 206d 6574 7269 632c 2062 7920   the metric, by 
+00018970: 6368 6563 6b69 6e67 2077 6865 7468 6572  checking whether
+00018980: 2074 6865 206d 6f6e 6974 6f72 206e 616d   the monitor nam
+00018990: 650a 2020 2020 636f 6e74 6169 6e73 2074  e.    contains t
+000189a0: 6865 2077 6f72 6420 276c 6f73 7327 2e0a  he word 'loss'..
+000189b0: 0a20 2020 2041 7267 733a 0a20 2020 2020  .    Args:.     
+000189c0: 2020 206d 6f6e 6974 6f72 3120 2873 7472     monitor1 (str
+000189d0: 293a 204e 616d 6520 6f66 2074 6865 206d  ): Name of the m
+000189e0: 6574 7269 6320 746f 206d 6f6e 6974 6f72  etric to monitor
+000189f0: 2e20 4966 2060 4e6f 6e65 602c 2074 6869  . If `None`, thi
+00018a00: 7320 6d6f 6e69 746f 7220 7769 6c6c 206e  s monitor will n
+00018a10: 6f74 2062 6520 7573 6564 2e0a 2020 2020  ot be used..    
+00018a20: 2020 2020 6d6f 6e69 746f 7232 2028 7374      monitor2 (st
+00018a30: 7229 3a20 4e61 6d65 206f 6620 7468 6520  r): Name of the 
+00018a40: 6d65 7472 6963 2074 6f20 6d6f 6e69 746f  metric to monito
+00018a50: 722e 2049 6620 604e 6f6e 6560 2c20 7468  r. If `None`, th
+00018a60: 6973 206d 6f6e 6974 6f72 2077 696c 6c20  is monitor will 
+00018a70: 6e6f 7420 6265 2075 7365 642e 0a20 2020  not be used..   
+00018a80: 2020 2020 206d 6f6e 6974 6f72 315f 7468       monitor1_th
+00018a90: 7265 7368 2028 666c 6f61 7429 3a20 5468  resh (float): Th
+00018aa0: 7265 7368 6f6c 6420 7661 6c75 6520 666f  reshold value fo
+00018ab0: 7220 606d 6f6e 6974 6f72 3160 2e0a 2020  r `monitor1`..  
+00018ac0: 2020 2020 2020 6d6f 6e69 746f 7232 5f74        monitor2_t
+00018ad0: 6872 6573 6820 2866 6c6f 6174 293a 2054  hresh (float): T
+00018ae0: 6872 6573 686f 6c64 2076 616c 7565 2066  hreshold value f
+00018af0: 6f72 2060 6d6f 6e69 746f 7232 602e 0a0a  or `monitor2`...
+00018b00: 2020 2020 4174 7472 6962 7574 6573 3a0a      Attributes:.
+00018b10: 2020 2020 2020 2020 7374 6f70 7065 645f          stopped_
+00018b20: 6570 6f63 6820 2869 6e74 293a 2054 6865  epoch (int): The
+00018b30: 2065 706f 6368 2061 7420 7768 6963 6820   epoch at which 
+00018b40: 7468 6520 7472 6169 6e69 6e67 2077 6173  the training was
+00018b50: 2073 746f 7070 6564 2e0a 2020 2020 2020   stopped..      
+00018b60: 2020 6265 7374 5f6d 6574 7269 6320 2866    best_metric (f
+00018b70: 6c6f 6174 293a 2054 6865 2062 6573 7420  loat): The best 
+00018b80: 6d65 7472 6963 2076 616c 7565 2061 6368  metric value ach
+00018b90: 6965 7665 6420 6475 7269 6e67 2074 6865  ieved during the
+00018ba0: 2074 7261 696e 696e 672e 0a20 2020 2020   training..     
+00018bb0: 2020 2062 6573 745f 7765 6967 6874 7320     best_weights 
+00018bc0: 286e 6461 7272 6179 293a 2054 6865 2077  (ndarray): The w
+00018bd0: 6569 6768 7473 206f 6620 7468 6520 6d6f  eights of the mo
+00018be0: 6465 6c20 6174 2074 6865 2065 706f 6368  del at the epoch
+00018bf0: 2077 6974 6820 7468 6520 6265 7374 206d   with the best m
+00018c00: 6574 7269 6320 7661 6c75 652e 0a0a 2020  etric value...  
+00018c10: 2020 5265 7475 726e 733a 0a20 2020 2020    Returns:.     
+00018c20: 2020 204e 6f6e 650a 2020 2020 2222 220a     None.    """.
+00018c30: 2020 2020 0a20 2020 2064 6566 205f 5f69      .    def __i
+00018c40: 6e69 745f 5f28 7365 6c66 2c20 6d6f 6e69  nit__(self, moni
+00018c50: 746f 7231 3d4e 6f6e 652c 206d 6f6e 6974  tor1=None, monit
+00018c60: 6f72 323d 4e6f 6e65 2c20 6d6f 6e69 746f  or2=None, monito
+00018c70: 7231 5f74 6872 6573 683d 4e6f 6e65 2c20  r1_thresh=None, 
+00018c80: 6d6f 6e69 746f 7232 5f74 6872 6573 683d  monitor2_thresh=
+00018c90: 4e6f 6e65 293a 0a20 2020 2020 2020 2073  None):.        s
+00018ca0: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
+00018cb0: 2920 2323 496e 6974 6961 6c69 7a65 7320  ) ##Initializes 
+00018cc0: 7468 6520 696e 6865 7269 7465 6420 6174  the inherited at
+00018cd0: 7472 6962 7574 6573 2061 6e64 206d 6574  tributes and met
+00018ce0: 686f 6473 2066 726f 6d20 7468 6520 7061  hods from the pa
+00018cf0: 7265 6e74 2063 6c61 7373 2061 7320 6974  rent class as it
+00018d00: 2077 696c 6c20 696e 6865 7269 7420 6672   will inherit fr
+00018d10: 6f6d 2043 616c 6c62 6163 6b0a 2020 2020  om Callback.    
+00018d20: 2020 2020 7365 6c66 2e6d 6f6e 6974 6f72      self.monitor
+00018d30: 3120 3d20 6d6f 6e69 746f 7231 0a20 2020  1 = monitor1.   
+00018d40: 2020 2020 2073 656c 662e 6d6f 6e69 746f       self.monito
+00018d50: 7232 203d 206d 6f6e 6974 6f72 320a 2020  r2 = monitor2.  
+00018d60: 2020 2020 2020 7365 6c66 2e6d 6f6e 6974        self.monit
+00018d70: 6f72 315f 7468 7265 7368 203d 206d 6f6e  or1_thresh = mon
+00018d80: 6974 6f72 315f 7468 7265 7368 0a20 2020  itor1_thresh.   
+00018d90: 2020 2020 2073 656c 662e 6d6f 6e69 746f       self.monito
+00018da0: 7232 5f74 6872 6573 6820 3d20 6d6f 6e69  r2_thresh = moni
+00018db0: 746f 7232 5f74 6872 6573 680a 2020 2020  tor2_thresh.    
+00018dc0: 2020 2020 7365 6c66 2e73 746f 7070 6564      self.stopped
+00018dd0: 5f65 706f 6368 203d 2030 0a20 2020 2020  _epoch = 0.     
+00018de0: 2020 2073 656c 662e 6265 7374 5f6d 6574     self.best_met
+00018df0: 7269 6320 3d20 666c 6f61 7428 2769 6e66  ric = float('inf
+00018e00: 2729 200a 2020 2020 2020 2020 7365 6c66  ') .        self
+00018e10: 2e62 6573 745f 7765 6967 6874 7320 3d20  .best_weights = 
+00018e20: 4e6f 6e65 2023 5769 6c6c 2075 7365 2074  None #Will use t
+00018e30: 6869 7320 746f 2073 746f 7265 2074 6865  his to store the
+00018e40: 2077 6569 6768 7473 2077 6974 6820 7468   weights with th
+00018e50: 6520 6265 7374 206d 6574 7269 6320 7661  e best metric va
+00018e60: 6c75 6520 6275 7420 6e6f 7420 6375 7272  lue but not curr
+00018e70: 656e 746c 7920 6361 6c6c 6564 2069 6e20  ently called in 
+00018e80: 7468 6520 726f 7574 696e 650a 0a20 2020  the routine..   
+00018e90: 2064 6566 206f 6e5f 6570 6f63 685f 656e   def on_epoch_en
+00018ea0: 6428 7365 6c66 2c20 6570 6f63 682c 206c  d(self, epoch, l
+00018eb0: 6f67 733d 7b7d 293a 0a20 2020 2020 2020  ogs={}):.       
+00018ec0: 2022 2222 0a20 2020 2020 2020 2054 6869   """.        Thi
+00018ed0: 7320 6d65 7468 6f64 2077 696c 6c20 6265  s method will be
+00018ee0: 2063 616c 6c65 6420 6174 2074 6865 2065   called at the e
+00018ef0: 6e64 206f 6620 6561 6368 2065 706f 6368  nd of each epoch
+00018f00: 2064 7572 696e 6720 7472 6169 6e69 6e67   during training
+00018f10: 2e0a 0a20 2020 2020 2020 2041 7267 733a  ...        Args:
+00018f20: 0a20 2020 2020 2020 2020 2020 2065 706f  .            epo
+00018f30: 6368 2028 696e 7429 3a20 4375 7272 656e  ch (int): Curren
+00018f40: 7420 6570 6f63 6820 6e75 6d62 6572 2e0a  t epoch number..
+00018f50: 2020 2020 2020 2020 2020 2020 6c6f 6773              logs
+00018f60: 2028 6469 6374 293a 2044 6963 7469 6f6e   (dict): Diction
+00018f70: 6172 7920 636f 6e74 6169 6e69 6e67 2074  ary containing t
+00018f80: 6865 206d 6574 7269 6373 2066 6f72 2074  he metrics for t
+00018f90: 6865 2063 7572 7265 6e74 2065 706f 6368  he current epoch
+00018fa0: 2e0a 0a20 2020 2020 2020 2052 6574 7572  ...        Retur
+00018fb0: 6e73 3a0a 2020 2020 2020 2020 2020 2020  ns:.            
+00018fc0: 4e6f 6e65 0a20 2020 2020 2020 2022 2222  None.        """
+00018fd0: 0a0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
+00018fe0: 662e 6d6f 6e69 746f 7231 2069 7320 6e6f  f.monitor1 is no
+00018ff0: 7420 4e6f 6e65 2061 6e64 2073 656c 662e  t None and self.
+00019000: 6d6f 6e69 746f 7232 2069 7320 6e6f 7420  monitor2 is not 
+00019010: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+00019020: 2020 6375 7272 656e 745f 3120 3d20 6c6f    current_1 = lo
+00019030: 6773 2e67 6574 2873 656c 662e 6d6f 6e69  gs.get(self.moni
+00019040: 746f 7231 290a 2020 2020 2020 2020 2020  tor1).          
+00019050: 2020 6375 7272 656e 745f 3220 3d20 6c6f    current_2 = lo
+00019060: 6773 2e67 6574 2873 656c 662e 6d6f 6e69  gs.get(self.moni
+00019070: 746f 7232 290a 2020 2020 2020 2020 2020  tor2).          
+00019080: 2020 6966 2027 6c6f 7373 2720 6e6f 7420    if 'loss' not 
+00019090: 696e 2073 656c 662e 6d6f 6e69 746f 7231  in self.monitor1
+000190a0: 2061 6e64 2027 6c6f 7373 2720 696e 2073   and 'loss' in s
+000190b0: 656c 662e 6d6f 6e69 746f 7232 3a0a 2020  elf.monitor2:.  
+000190c0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+000190d0: 206e 702e 6772 6561 7465 7228 6375 7272   np.greater(curr
+000190e0: 656e 745f 312c 2073 656c 662e 6d6f 6e69  ent_1, self.moni
+000190f0: 746f 7231 5f74 6872 6573 6829 206f 7220  tor1_thresh) or 
+00019100: 6e70 2e6c 6573 735f 6571 7561 6c28 6375  np.less_equal(cu
+00019110: 7272 656e 745f 322c 2073 656c 662e 6d6f  rrent_2, self.mo
+00019120: 6e69 746f 7232 5f74 6872 6573 6829 3a0a  nitor2_thresh):.
+00019130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019140: 2020 2020 7365 6c66 2e73 746f 7070 6564      self.stopped
+00019150: 5f65 706f 6368 203d 2065 706f 6368 0a20  _epoch = epoch. 
+00019160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019170: 2020 2073 656c 662e 6d6f 6465 6c2e 7374     self.model.st
+00019180: 6f70 5f74 7261 696e 696e 6720 3d20 5472  op_training = Tr
+00019190: 7565 0a20 2020 2020 2020 2020 2020 2020  ue.             
+000191a0: 2020 2063 7572 7265 6e74 5f6d 6574 7269     current_metri
+000191b0: 6320 3d20 6375 7272 656e 745f 310a 2020  c = current_1.  
+000191c0: 2020 2020 2020 2020 2020 656c 6966 2027            elif '
+000191d0: 6c6f 7373 2720 6e6f 7420 696e 2073 656c  loss' not in sel
+000191e0: 662e 6d6f 6e69 746f 7231 2061 6e64 2027  f.monitor1 and '
+000191f0: 6c6f 7373 2720 6e6f 7420 696e 2073 656c  loss' not in sel
+00019200: 662e 6d6f 6e69 746f 7232 3a0a 2020 2020  f.monitor2:.    
+00019210: 2020 2020 2020 2020 2020 2020 6966 206e              if n
+00019220: 702e 6772 6561 7465 7228 6375 7272 656e  p.greater(curren
+00019230: 745f 312c 2073 656c 662e 6d6f 6e69 746f  t_1, self.monito
+00019240: 7231 5f74 6872 6573 6829 206f 7220 6e70  r1_thresh) or np
+00019250: 2e67 7265 6174 6572 2863 7572 7265 6e74  .greater(current
+00019260: 5f32 2c20 7365 6c66 2e6d 6f6e 6974 6f72  _2, self.monitor
+00019270: 325f 7468 7265 7368 293a 0a20 2020 2020  2_thresh):.     
+00019280: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00019290: 656c 662e 7374 6f70 7065 645f 6570 6f63  elf.stopped_epoc
+000192a0: 6820 3d20 6570 6f63 680a 2020 2020 2020  h = epoch.      
+000192b0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+000192c0: 6c66 2e6d 6f64 656c 2e73 746f 705f 7472  lf.model.stop_tr
+000192d0: 6169 6e69 6e67 203d 2054 7275 650a 2020  aining = True.  
+000192e0: 2020 2020 2020 2020 2020 2020 2020 6375                cu
+000192f0: 7272 656e 745f 6d65 7472 6963 203d 2063  rrent_metric = c
+00019300: 7572 7265 6e74 5f31 0a20 2020 2020 2020  urrent_1.       
+00019310: 2020 2020 2065 6c69 6620 276c 6f73 7327       elif 'loss'
+00019320: 2069 6e20 7365 6c66 2e6d 6f6e 6974 6f72   in self.monitor
+00019330: 3120 616e 6420 276c 6f73 7327 2069 6e20  1 and 'loss' in 
+00019340: 7365 6c66 2e6d 6f6e 6974 6f72 323a 0a20  self.monitor2:. 
+00019350: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00019360: 6620 6e70 2e6c 6573 735f 6571 7561 6c28  f np.less_equal(
+00019370: 6375 7272 656e 745f 312c 2073 656c 662e  current_1, self.
+00019380: 6d6f 6e69 746f 7231 5f74 6872 6573 6829  monitor1_thresh)
+00019390: 206f 7220 6e70 2e6c 6573 735f 6571 7561   or np.less_equa
+000193a0: 6c28 6375 7272 656e 745f 322c 2073 656c  l(current_2, sel
+000193b0: 662e 6d6f 6e69 746f 7232 5f74 6872 6573  f.monitor2_thres
+000193c0: 6829 3a0a 2020 2020 2020 2020 2020 2020  h):.            
+000193d0: 2020 2020 2020 2020 7365 6c66 2e73 746f          self.sto
+000193e0: 7070 6564 5f65 706f 6368 203d 2065 706f  pped_epoch = epo
+000193f0: 6368 0a20 2020 2020 2020 2020 2020 2020  ch.             
+00019400: 2020 2020 2020 2073 656c 662e 6d6f 6465         self.mode
+00019410: 6c2e 7374 6f70 5f74 7261 696e 696e 6720  l.stop_training 
+00019420: 3d20 5472 7565 0a20 2020 2020 2020 2020  = True.         
+00019430: 2020 2020 2020 2063 7572 7265 6e74 5f6d         current_m
+00019440: 6574 7269 6320 3d20 6375 7272 656e 745f  etric = current_
+00019450: 310a 2020 2020 2020 2020 2020 2020 656c  1.            el
+00019460: 6966 2027 6c6f 7373 2720 696e 2073 656c  if 'loss' in sel
+00019470: 662e 6d6f 6e69 746f 7231 2061 6e64 2027  f.monitor1 and '
+00019480: 6c6f 7373 2720 6e6f 7420 696e 2073 656c  loss' not in sel
+00019490: 662e 6d6f 6e69 746f 7232 3a0a 2020 2020  f.monitor2:.    
+000194a0: 2020 2020 2020 2020 2020 2020 6966 206e              if n
+000194b0: 702e 6c65 7373 5f65 7175 616c 2863 7572  p.less_equal(cur
+000194c0: 7265 6e74 5f31 2c20 7365 6c66 2e6d 6f6e  rent_1, self.mon
+000194d0: 6974 6f72 315f 7468 7265 7368 2920 6f72  itor1_thresh) or
+000194e0: 206e 702e 6772 6561 7465 7228 6375 7272   np.greater(curr
+000194f0: 656e 745f 322c 2073 656c 662e 6d6f 6e69  ent_2, self.moni
+00019500: 746f 7232 5f74 6872 6573 6829 3a0a 2020  tor2_thresh):.  
+00019510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019520: 2020 7365 6c66 2e73 746f 7070 6564 5f65    self.stopped_e
+00019530: 706f 6368 203d 2065 706f 6368 0a20 2020  poch = epoch.   
+00019540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019550: 2073 656c 662e 6d6f 6465 6c2e 7374 6f70   self.model.stop
+00019560: 5f74 7261 696e 696e 6720 3d20 5472 7565  _training = True
+00019570: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00019580: 2063 7572 7265 6e74 5f6d 6574 7269 6320   current_metric 
+00019590: 3d20 6375 7272 656e 745f 310a 2020 2020  = current_1.    
+000195a0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+000195b0: 2020 2020 2020 2020 2020 2020 2020 7261                ra
+000195c0: 6973 6520 5661 6c75 6545 7272 6f72 2827  ise ValueError('
+000195d0: 496e 7661 6c69 6420 6d6f 6e69 746f 7220  Invalid monitor 
+000195e0: 696e 7075 742e 2729 0a20 2020 2020 2020  input.').       
+000195f0: 2020 2020 200a 2020 2020 2020 2020 2020       .          
+00019600: 2020 6966 2063 7572 7265 6e74 5f6d 6574    if current_met
+00019610: 7269 6320 3c20 7365 6c66 2e62 6573 745f  ric < self.best_
+00019620: 6d65 7472 6963 3a0a 2020 2020 2020 2020  metric:.        
+00019630: 2020 2020 2020 2020 7365 6c66 2e62 6573          self.bes
+00019640: 745f 6d65 7472 6963 203d 2063 7572 7265  t_metric = curre
+00019650: 6e74 5f6d 6574 7269 630a 2020 2020 2020  nt_metric.      
+00019660: 2020 2020 2020 2020 2020 7365 6c66 2e62            self.b
+00019670: 6573 745f 7765 6967 6874 7320 3d20 7365  est_weights = se
+00019680: 6c66 2e6d 6f64 656c 2e67 6574 5f77 6569  lf.model.get_wei
+00019690: 6768 7473 2829 0a20 2020 2020 2020 2020  ghts().         
+000196a0: 2020 2020 2020 200a 2020 2020 2020 2020         .        
+000196b0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+000196c0: 2020 6375 7272 656e 745f 6d65 7472 6963    current_metric
+000196d0: 203d 206c 6f67 732e 6765 7428 7365 6c66   = logs.get(self
+000196e0: 2e6d 6f6e 6974 6f72 3129 0a20 2020 2020  .monitor1).     
+000196f0: 2020 2020 2020 2069 6620 276c 6f73 7327         if 'loss'
+00019700: 206e 6f74 2069 6e20 7365 6c66 2e6d 6f6e   not in self.mon
+00019710: 6974 6f72 313a 0a20 2020 2020 2020 2020  itor1:.         
+00019720: 2020 2020 2020 2069 6620 6e70 2e67 7265         if np.gre
+00019730: 6174 6572 2863 7572 7265 6e74 5f6d 6574  ater(current_met
+00019740: 7269 632c 2073 656c 662e 6d6f 6e69 746f  ric, self.monito
+00019750: 7231 5f74 6872 6573 6829 3a0a 2020 2020  r1_thresh):.    
+00019760: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019770: 7365 6c66 2e73 746f 7070 6564 5f65 706f  self.stopped_epo
+00019780: 6368 203d 2065 706f 6368 0a20 2020 2020  ch = epoch.     
+00019790: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+000197a0: 656c 662e 6d6f 6465 6c2e 7374 6f70 5f74  elf.model.stop_t
+000197b0: 7261 696e 696e 6720 3d20 5472 7565 0a20  raining = True. 
+000197c0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+000197d0: 6620 6375 7272 656e 745f 6d65 7472 6963  f current_metric
+000197e0: 203c 2073 656c 662e 6265 7374 5f6d 6574   < self.best_met
+000197f0: 7269 633a 0a20 2020 2020 2020 2020 2020  ric:.           
+00019800: 2020 2020 2020 2020 2073 656c 662e 6265           self.be
+00019810: 7374 5f6d 6574 7269 6320 3d20 6375 7272  st_metric = curr
+00019820: 656e 745f 6d65 7472 6963 0a20 2020 2020  ent_metric.     
+00019830: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00019840: 656c 662e 6265 7374 5f77 6569 6768 7473  elf.best_weights
+00019850: 203d 2073 656c 662e 6d6f 6465 6c2e 6765   = self.model.ge
+00019860: 745f 7765 6967 6874 7328 290a 2020 2020  t_weights().    
+00019870: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00019880: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00019890: 206e 702e 6c65 7373 5f65 7175 616c 2863   np.less_equal(c
+000198a0: 7572 7265 6e74 5f6d 6574 7269 632c 2073  urrent_metric, s
+000198b0: 656c 662e 6d6f 6e69 746f 7231 5f74 6872  elf.monitor1_thr
+000198c0: 6573 6829 3a0a 2020 2020 2020 2020 2020  esh):.          
+000198d0: 2020 2020 2020 2020 2020 7365 6c66 2e73            self.s
+000198e0: 746f 7070 6564 5f65 706f 6368 203d 2065  topped_epoch = e
+000198f0: 706f 6368 0a20 2020 2020 2020 2020 2020  poch.           
+00019900: 2020 2020 2020 2020 2073 656c 662e 6d6f           self.mo
+00019910: 6465 6c2e 7374 6f70 5f74 7261 696e 696e  del.stop_trainin
+00019920: 6720 3d20 5472 7565 0a20 2020 2020 2020  g = True.       
+00019930: 2020 2020 2020 2020 2069 6620 6375 7272           if curr
+00019940: 656e 745f 6d65 7472 6963 203c 2073 656c  ent_metric < sel
+00019950: 662e 6265 7374 5f6d 6574 7269 633a 0a20  f.best_metric:. 
+00019960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019970: 2020 2073 656c 662e 6265 7374 5f6d 6574     self.best_met
+00019980: 7269 6320 3d20 6375 7272 656e 745f 6d65  ric = current_me
+00019990: 7472 6963 0a20 2020 2020 2020 2020 2020  tric.           
+000199a0: 2020 2020 2020 2020 2073 656c 662e 6265           self.be
+000199b0: 7374 5f77 6569 6768 7473 203d 2073 656c  st_weights = sel
+000199c0: 662e 6d6f 6465 6c2e 6765 745f 7765 6967  f.model.get_weig
+000199d0: 6874 7328 290a 0a64 6566 2068 7970 6572  hts()..def hyper
+000199e0: 5f6f 7074 2864 6174 615f 783d 4e6f 6e65  _opt(data_x=None
+000199f0: 2c20 6461 7461 5f79 3d4e 6f6e 652c 2076  , data_y=None, v
+00019a00: 616c 5f58 3d4e 6f6e 652c 2076 616c 5f59  al_X=None, val_Y
+00019a10: 3d4e 6f6e 652c 2069 6d67 5f6e 756d 5f63  =None, img_num_c
+00019a20: 6861 6e6e 656c 733d 312c 2063 6c66 3d27  hannels=1, clf='
+00019a30: 616c 6578 6e65 7427 2c20 0a20 2020 206e  alexnet', .    n
+00019a40: 6f72 6d61 6c69 7a65 3d54 7275 652c 206d  ormalize=True, m
+00019a50: 696e 5f70 6978 656c 3d30 2c20 6d61 785f  in_pixel=0, max_
+00019a60: 7069 7865 6c3d 3130 3030 2c20 6e5f 6974  pixel=1000, n_it
+00019a70: 6572 3d32 352c 2070 6174 6965 6e63 653d  er=25, patience=
+00019a80: 352c 206d 6574 7269 633d 276c 6f73 7327  5, metric='loss'
+00019a90: 2c20 6d65 7472 6963 323d 4e6f 6e65 2c20  , metric2=None, 
+00019aa0: 6d65 7472 6963 333d 4e6f 6e65 2c20 6176  metric3=None, av
+00019ab0: 6572 6167 653d 5472 7565 2c20 0a20 2020  erage=True, .   
+00019ac0: 2074 6573 745f 706f 7369 7469 7665 3d4e   test_positive=N
+00019ad0: 6f6e 652c 2074 6573 745f 6e65 6761 7469  one, test_negati
+00019ae0: 7665 3d4e 6f6e 652c 2074 6573 745f 6163  ve=None, test_ac
+00019af0: 635f 7468 7265 7368 6f6c 643d 4e6f 6e65  c_threshold=None
+00019b00: 2c20 706f 7374 5f6d 6574 7269 633d 5472  , post_metric=Tr
+00019b10: 7565 2c20 6f70 745f 6d6f 6465 6c3d 5472  ue, opt_model=Tr
+00019b20: 7565 2c20 6261 7463 685f 7369 7a65 5f6d  ue, batch_size_m
+00019b30: 696e 3d31 362c 2062 6174 6368 5f73 697a  in=16, batch_siz
+00019b40: 655f 6d61 783d 3634 2c20 7472 6169 6e5f  e_max=64, train_
+00019b50: 6570 6f63 6873 3d32 352c 206f 7074 5f63  epochs=25, opt_c
+00019b60: 763d 4e6f 6e65 2c0a 2020 2020 6f70 745f  v=None,.    opt_
+00019b70: 6175 673d 4661 6c73 652c 2062 6174 6368  aug=False, batch
+00019b80: 5f6d 696e 3d32 2c20 6261 7463 685f 6d61  _min=2, batch_ma
+00019b90: 783d 3235 2c20 6261 7463 685f 6f74 6865  x=25, batch_othe
+00019ba0: 723d 312c 2062 616c 616e 6365 3d54 7275  r=1, balance=Tru
+00019bb0: 652c 2069 6d61 6765 5f73 697a 655f 6d69  e, image_size_mi
+00019bc0: 6e3d 3530 2c20 696d 6167 655f 7369 7a65  n=50, image_size
+00019bd0: 5f6d 6178 3d31 3030 2c20 7368 6966 743d  _max=100, shift=
+00019be0: 3130 2c20 6f70 745f 6d61 785f 6d69 6e5f  10, opt_max_min_
+00019bf0: 7069 783d 4e6f 6e65 2c20 6f70 745f 6d61  pix=None, opt_ma
+00019c00: 785f 6d61 785f 7069 783d 4e6f 6e65 2c20  x_max_pix=None, 
+00019c10: 0a20 2020 2072 6f74 6174 696f 6e3d 4661  .    rotation=Fa
+00019c20: 6c73 652c 2068 6f72 697a 6f6e 7461 6c3d  lse, horizontal=
+00019c30: 4661 6c73 652c 2076 6572 7469 6361 6c3d  False, vertical=
+00019c40: 4661 6c73 652c 206d 6173 6b5f 7369 7a65  False, mask_size
+00019c50: 3d4e 6f6e 652c 206e 756d 5f6d 6173 6b73  =None, num_masks
+00019c60: 3d4e 6f6e 652c 2073 6d6f 7465 5f73 616d  =None, smote_sam
+00019c70: 706c 696e 673d 302c 2062 6c65 6e64 5f6d  pling=0, blend_m
+00019c80: 6178 3d30 2c20 6e75 6d5f 696d 6167 6573  ax=0, num_images
+00019c90: 5f74 6f5f 626c 656e 643d 322c 2062 6c65  _to_blend=2, ble
+00019ca0: 6e64 696e 675f 6675 6e63 3d27 6d65 616e  nding_func='mean
+00019cb0: 272c 2062 6c65 6e64 5f6f 7468 6572 3d31  ', blend_other=1
+00019cc0: 2c20 0a20 2020 207a 6f6f 6d5f 7261 6e67  , .    zoom_rang
+00019cd0: 653d 4e6f 6e65 2c20 736b 6577 5f61 6e67  e=None, skew_ang
+00019ce0: 6c65 3d30 2c20 6c69 6d69 745f 7365 6172  le=0, limit_sear
+00019cf0: 6368 3d54 7275 652c 206d 6f6e 6974 6f72  ch=True, monitor
+00019d00: 313d 4e6f 6e65 2c20 6d6f 6e69 746f 7232  1=None, monitor2
+00019d10: 3d4e 6f6e 652c 206d 6f6e 6974 6f72 315f  =None, monitor1_
+00019d20: 7468 7265 7368 3d4e 6f6e 652c 206d 6f6e  thresh=None, mon
+00019d30: 6974 6f72 325f 7468 7265 7368 3d4e 6f6e  itor2_thresh=Non
+00019d40: 652c 2076 6572 626f 7365 3d30 2c20 7265  e, verbose=0, re
+00019d50: 7475 726e 5f73 7475 6479 3d54 7275 6529  turn_study=True)
+00019d60: 3a20 0a20 2020 2022 2222 0a20 2020 204f  : .    """.    O
+00019d70: 7074 696d 697a 6573 2068 7970 6572 7061  ptimizes hyperpa
+00019d80: 7261 6d65 7465 7273 2075 7369 6e67 2061  rameters using a
+00019d90: 206b 2d66 6f6c 6420 6372 6f73 7320 7661   k-fold cross va
+00019da0: 6c69 6461 7469 6f6e 2073 706c 6974 7469  lidation splitti
+00019db0: 6e67 2073 7472 6174 6567 792e 0a0a 2020  ng strategy...  
+00019dc0: 2020 2a2a 494d 504f 5254 414e 542a 2a20    **IMPORTANT** 
+00019dd0: 496e 2074 6865 2063 6173 6520 6f66 2043  In the case of C
+00019de0: 4e4e 206f 7074 696d 697a 6174 696f 6e2c  NN optimization,
+00019df0: 2064 6174 615f 7820 616e 6420 6461 7461   data_x and data
+00019e00: 5f79 2061 7265 206e 6f74 2074 6865 2073  _y are not the s
+00019e10: 7461 6e64 6172 640a 2020 2020 6461 7461  tandard.    data
+00019e20: 2070 6c75 7320 6c61 6265 6c73 202d 2d20   plus labels -- 
+00019e30: 4d69 6372 6f4c 4941 2061 7373 756d 6573  MicroLIA assumes
+00019e40: 2062 696e 6172 7920 636c 6173 7369 6669   binary classifi
+00019e50: 6361 7469 6f6e 2061 6c77 6179 7320 7468  cation always th
+00019e60: 6572 6566 6f72 6520 6966 206f 7074 696d  erefore if optim
+00019e70: 697a 696e 6720 6120 0a20 2020 2043 4e4e  izing a .    CNN
+00019e80: 2074 6865 2073 616d 706c 6573 2066 6f72   the samples for
+00019e90: 2074 6865 2066 6972 7374 2063 6c61 7373   the first class
+00019ea0: 2073 686f 756c 6420 6265 2070 6173 7365   should be passe
+00019eb0: 6420 7468 726f 7567 6820 7468 6520 6461  d through the da
+00019ec0: 7461 5f78 2070 6172 616d 6574 6572 2c20  ta_x parameter, 
+00019ed0: 616e 6420 7468 6520 0a20 2020 2073 616d  and the .    sam
+00019ee0: 706c 6573 2066 6f72 2074 6865 2073 6563  ples for the sec
+00019ef0: 6f6e 6420 636c 6173 7320 7368 6f75 6c64  ond class should
+00019f00: 2062 6520 6769 7665 6e20 6173 2064 6174   be given as dat
+00019f10: 615f 792e 2054 6865 7365 2074 776f 2063  a_y. These two c
+00019f20: 6c61 7373 6573 2077 696c 6c20 6175 746f  lasses will auto
+00019f30: 6d61 7469 6361 6c6c 7920 0a20 2020 2062  matically .    b
+00019f40: 6520 6173 7369 676e 6564 2074 6865 2070  e assigned the p
+00019f50: 6f73 6974 6976 6520 616e 6420 6e65 6761  ositive and nega
+00019f60: 7469 7665 206c 6162 656c 7320 3120 616e  tive labels 1 an
+00019f70: 6420 302c 2072 6573 7065 6374 6976 656c  d 0, respectivel
+00019f80: 792e 204c 696b 6577 6973 652c 2069 6620  y. Likewise, if 
+00019f90: 6f70 7469 6d69 7a69 6e67 2061 200a 2020  optimizing a .  
+00019fa0: 2020 434e 4e20 6d6f 6465 6c2c 2076 616c    CNN model, val
+00019fb0: 5f58 2063 6f72 7265 7370 6f6e 6473 2074  _X corresponds t
+00019fc0: 6f20 7468 6520 696d 6167 6573 206f 6620  o the images of 
+00019fd0: 7468 6520 6669 7273 7420 636c 6173 732c  the first class,
+00019fe0: 2061 6e64 2076 616c 5f59 2074 6865 2069   and val_Y the i
+00019ff0: 6d61 6765 7320 6f66 2074 6865 2073 6563  mages of the sec
+0001a000: 6f6e 6420 636c 6173 732e 200a 2020 2020  ond class. .    
+0001a010: 0a20 2020 2049 6620 7361 7665 5f73 7475  .    If save_stu
+0001a020: 6479 3d54 7275 652c 2074 6865 204f 7074  dy=True, the Opt
+0001a030: 756e 6120 7374 7564 7920 6f62 6a65 6374  una study object
+0001a040: 2077 696c 6c20 6265 2074 6865 2074 6869   will be the thi
+0001a050: 7264 206f 7574 7075 742e 2054 6869 730a  rd output. This.
+0001a060: 2020 2020 6f62 6a65 6374 2063 616e 2062      object can b
+0001a070: 6520 7573 6564 2066 6f72 2076 6172 696f  e used for vario
+0001a080: 7573 2061 6e61 6c79 7369 732c 2069 6e63  us analysis, inc
+0001a090: 6c75 6469 6e67 206f 7074 696d 697a 6174  luding optimizat
+0001a0a0: 696f 6e20 7669 7375 616c 697a 6174 696f  ion visualizatio
+0001a0b0: 6e73 2e0a 2020 2020 5365 653a 2068 7474  ns..    See: htt
+0001a0c0: 7073 3a2f 2f6f 7074 756e 612e 7265 6164  ps://optuna.read
+0001a0d0: 7468 6564 6f63 732e 696f 2f65 6e2f 7374  thedocs.io/en/st
+0001a0e0: 6162 6c65 2f72 6566 6572 656e 6365 2f67  able/reference/g
+0001a0f0: 656e 6572 6174 6564 2f6f 7074 756e 612e  enerated/optuna.
+0001a100: 7374 7564 792e 5374 7564 792e 6874 6d6c  study.Study.html
+0001a110: 0a0a 2020 2020 4578 616d 706c 653a 0a20  ..    Example:. 
+0001a120: 2020 2020 2020 2054 6865 2066 756e 6374         The funct
+0001a130: 696f 6e20 7769 6c6c 2063 7265 6174 6520  ion will create 
+0001a140: 7468 6520 636c 6173 7369 6669 6361 7469  the classificati
+0001a150: 6f6e 2065 6e67 696e 6520 616e 6420 6f70  on engine and op
+0001a160: 7469 6d69 7a65 2074 6865 2068 7970 6572  timize the hyper
+0001a170: 7061 7261 6d65 7465 7273 0a20 2020 2020  parameters.     
+0001a180: 2020 2075 7369 6e67 2061 6e20 6974 6572     using an iter
+0001a190: 6174 6976 6520 6170 7072 6f61 6368 3a0a  ative approach:.
+0001a1a0: 0a20 2020 2020 2020 203e 3e3e 206d 6f64  .        >>> mod
+0001a1b0: 656c 2c20 7061 7261 6d73 203d 2068 7970  el, params = hyp
+0001a1c0: 6572 5f6f 7074 2864 6174 615f 782c 2064  er_opt(data_x, d
+0001a1d0: 6174 615f 792c 2063 6c66 3d27 7266 2729  ata_y, clf='rf')
+0001a1e0: 200a 2020 2020 2020 2020 0a20 2020 2020   .        .     
+0001a1f0: 2020 2054 6865 2066 6972 7374 206f 7574     The first out
+0001a200: 7075 7420 6973 206f 7572 206f 7074 696d  put is our optim
+0001a210: 616c 2063 6c61 7373 6966 6965 722c 2061  al classifier, a
+0001a220: 6e64 2077 696c 6c20 6265 2075 7365 6420  nd will be used 
+0001a230: 746f 206d 616b 6520 7072 6564 6963 7469  to make predicti
+0001a240: 6f6e 733a 0a20 2020 2020 2020 200a 2020  ons:.        .  
+0001a250: 2020 2020 2020 3e3e 3e20 7072 6564 6963        >>> predic
+0001a260: 7469 6f6e 203d 206d 6f64 656c 2e70 7265  tion = model.pre
+0001a270: 6469 6374 286e 6577 5f64 6174 6129 0a20  dict(new_data). 
+0001a280: 2020 2020 2020 200a 2020 2020 2020 2020         .        
+0001a290: 5468 6520 7365 636f 6e64 206f 7574 7075  The second outpu
+0001a2a0: 7420 6f66 2074 6865 206f 7074 696d 697a  t of the optimiz
+0001a2b0: 6520 6675 6e63 7469 6f6e 2069 7320 7468  e function is th
+0001a2c0: 6520 6469 6374 696f 6e61 7279 2063 6f6e  e dictionary con
+0001a2d0: 7461 696e 696e 670a 2020 2020 2020 2020  taining.        
+0001a2e0: 7468 6520 6879 7065 7270 6172 616d 6574  the hyperparamet
+0001a2f0: 6572 2063 6f6d 6269 6e61 7469 6f6e 2074  er combination t
+0001a300: 6861 7420 7969 656c 6465 6420 7468 6520  hat yielded the 
+0001a310: 6869 6768 6573 7420 6d65 616e 2061 6363  highest mean acc
+0001a320: 7572 6163 792e 0a0a 2020 2020 2020 2020  uracy...        
+0001a330: 4966 2073 6176 655f 7374 7564 7920 3d20  If save_study = 
+0001a340: 5472 7565 2c20 7468 6520 4f70 7475 6e61  True, the Optuna
+0001a350: 2073 7475 6479 206f 626a 6563 7420 7769   study object wi
+0001a360: 6c6c 2061 6c73 6f20 6265 2072 6574 7572  ll also be retur
+0001a370: 6e65 6420 6173 2074 6865 2074 6869 7264  ned as the third
+0001a380: 206f 7574 7075 742e 0a20 2020 2020 2020   output..       
+0001a390: 2054 6869 7320 6361 6e20 6265 2075 7365   This can be use
+0001a3a0: 6420 746f 2070 6c6f 7420 7468 6520 6f70  d to plot the op
+0001a3b0: 7469 6d69 7a61 7469 6f6e 2072 6573 756c  timization resul
+0001a3c0: 7473 2c20 7365 653a 2068 7474 7073 3a2f  ts, see: https:/
+0001a3d0: 2f6f 7074 756e 612e 7265 6164 7468 6564  /optuna.readthed
+0001a3e0: 6f63 732e 696f 2f65 6e2f 6c61 7465 7374  ocs.io/en/latest
+0001a3f0: 2f74 7574 6f72 6961 6c2f 3130 5f6b 6579  /tutorial/10_key
+0001a400: 5f66 6561 7475 7265 732f 3030 355f 7669  _features/005_vi
+0001a410: 7375 616c 697a 6174 696f 6e2e 6874 6d6c  sualization.html
+0001a420: 2373 7068 782d 676c 722d 7475 746f 7269  #sphx-glr-tutori
+0001a430: 616c 2d31 302d 6b65 792d 6665 6174 7572  al-10-key-featur
+0001a440: 6573 2d30 3035 2d76 6973 7561 6c69 7a61  es-005-visualiza
+0001a450: 7469 6f6e 2d70 790a 0a20 2020 2020 2020  tion-py..       
+0001a460: 203e 3e3e 2066 726f 6d20 6f70 7475 6e61   >>> from optuna
+0001a470: 2e76 6973 7561 6c69 7a61 7469 6f6e 2e6d  .visualization.m
+0001a480: 6174 706c 6f74 6c69 6220 696d 706f 7274  atplotlib import
+0001a490: 2070 6c6f 745f 636f 6e74 6f75 720a 2020   plot_contour.  
+0001a4a0: 2020 2020 2020 3e3e 3e20 0a20 2020 2020        >>> .     
+0001a4b0: 2020 203e 3e3e 206d 6f64 656c 2c20 7061     >>> model, pa
+0001a4c0: 7261 6d73 2c20 7374 7564 7920 3d20 6879  rams, study = hy
+0001a4d0: 7065 725f 6f70 7428 6461 7461 5f78 2c20  per_opt(data_x, 
+0001a4e0: 6461 7461 5f79 2c20 636c 663d 2772 6627  data_y, clf='rf'
+0001a4f0: 2c20 7361 7665 5f73 7475 6479 3d54 7275  , save_study=Tru
+0001a500: 6529 200a 2020 2020 2020 2020 3e3e 3e20  e) .        >>> 
+0001a510: 706c 6f74 5f63 6f6e 746f 7572 2873 7475  plot_contour(stu
+0001a520: 6479 290a 0a20 2020 2020 2020 2049 6620  dy)..        If 
+0001a530: 636c 663d 2761 6c65 786e 6574 2720 6f72  clf='alexnet' or
+0001a540: 2061 6e79 206f 6620 7468 6520 434e 4e20   any of the CNN 
+0001a550: 6f70 7469 6f6e 732c 2074 6865 206d 6f64  options, the mod
+0001a560: 656c 2069 7320 6e6f 7420 7265 7475 726e  el is not return
+0001a570: 6564 2e0a 2020 2020 2020 2020 0a20 2020  ed..        .   
+0001a580: 2041 7267 733a 0a20 2020 2020 2020 2064   Args:.        d
+0001a590: 6174 615f 7820 286e 6461 7272 6179 293a  ata_x (ndarray):
+0001a5a0: 2032 4420 6172 7261 7920 6f66 2073 697a   2D array of siz
+0001a5b0: 6520 286e 2078 206d 292c 2077 6865 7265  e (n x m), where
+0001a5c0: 206e 2069 7320 7468 650a 2020 2020 2020   n is the.      
+0001a5d0: 2020 2020 2020 6e75 6d62 6572 206f 6620        number of 
+0001a5e0: 7361 6d70 6c65 732c 2061 6e64 206d 2074  samples, and m t
+0001a5f0: 6865 206e 756d 6265 7220 6f66 2066 6561  he number of fea
+0001a600: 7475 7265 732e 2049 6620 636c 663d 2761  tures. If clf='a
+0001a610: 6c65 786e 6574 2720 6f72 2061 6e79 206f  lexnet' or any o
+0001a620: 6620 7468 6520 434e 4e20 6f70 7469 6f6e  f the CNN option
+0001a630: 732c 200a 2020 2020 2020 2020 2020 2020  s, .            
+0001a640: 7468 6520 7361 6d70 6c65 7320 666f 7220  the samples for 
+0001a650: 7468 6520 6669 7273 7420 636c 6173 7320  the first class 
+0001a660: 7368 6f75 6c64 2062 6520 7061 7373 6564  should be passed
+0001a670: 2c20 7768 6963 6820 7769 6c6c 2061 7574  , which will aut
+0001a680: 6f6d 6174 6963 616c 6c79 200a 2020 2020  omatically .    
+0001a690: 2020 2020 2020 2020 6265 2061 7373 6967          be assig
+0001a6a0: 6e65 6420 7468 6520 706f 7369 7469 7665  ned the positive
+0001a6b0: 206c 6162 656c 2027 3127 2e0a 2020 2020   label '1'..    
+0001a6c0: 2020 2020 6461 7461 5f79 2028 6e64 6172      data_y (ndar
+0001a6d0: 7261 792c 2073 7472 293a 2031 4420 6172  ray, str): 1D ar
+0001a6e0: 7261 7920 636f 6e74 6169 6e69 6e67 2074  ray containing t
+0001a6f0: 6865 2063 6f72 7265 7370 6f6e 696e 6720  he corresponing 
+0001a700: 6c61 6265 6c73 2e20 4966 2063 6c66 3d27  labels. If clf='
+0001a710: 616c 6578 6e65 7427 206f 7220 616e 7920  alexnet' or any 
+0001a720: 6f66 2074 6865 2043 4e4e 206f 7074 696f  of the CNN optio
+0001a730: 6e73 2c20 0a20 2020 2020 2020 2020 2020  ns, .           
+0001a740: 2074 6865 2073 616d 706c 6573 2066 6f72   the samples for
+0001a750: 2074 6865 2073 6563 6f6e 6420 636c 6173   the second clas
+0001a760: 7320 7368 6f75 6c64 2062 6520 7061 7373  s should be pass
+0001a770: 6564 2c20 7768 6963 6820 7769 6c6c 2061  ed, which will a
+0001a780: 7574 6f6d 6174 6963 616c 6c79 0a20 2020  utomatically.   
+0001a790: 2020 2020 2020 2020 2062 6520 6173 7369           be assi
+0001a7a0: 676e 6564 2074 6865 206e 6567 6174 6976  gned the negativ
+0001a7b0: 6520 6c61 6265 6c20 2730 272e 0a20 2020  e label '0'..   
+0001a7c0: 2020 2020 2063 6c66 2028 7374 7229 3a20       clf (str): 
+0001a7d0: 5468 6520 6d61 6368 696e 6520 6c65 6172  The machine lear
+0001a7e0: 6e69 6e67 2063 6c61 7373 6966 6965 7220  ning classifier 
+0001a7f0: 746f 206f 7074 696d 697a 652e 2043 616e  to optimize. Can
+0001a800: 2065 6974 6865 7220 6265 0a20 2020 2020   either be.     
+0001a810: 2020 2020 2020 2027 7266 2720 666f 7220         'rf' for 
+0001a820: 5261 6e64 6f6d 2046 6f72 6573 742c 2027  Random Forest, '
+0001a830: 6e6e 2720 666f 7220 4e65 7572 616c 204e  nn' for Neural N
+0001a840: 6574 776f 726b 2c20 2778 6762 2720 666f  etwork, 'xgb' fo
+0001a850: 7220 6558 7472 656d 6520 4772 6164 6965  r eXtreme Gradie
+0001a860: 6e74 2042 6f6f 7374 696e 672c 0a20 2020  nt Boosting,.   
+0001a870: 2020 2020 2020 2020 206f 7220 2761 6c65           or 'ale
+0001a880: 786e 6574 2720 6f72 2061 6e79 206f 6620  xnet' or any of 
+0001a890: 7468 6520 434e 4e20 6f70 7469 6f6e 732c  the CNN options,
+0001a8a0: 2066 6f72 2043 6f6e 766f 6c75 7469 6f6e   for Convolution
+0001a8b0: 616c 204e 6575 7261 6c20 4e65 7477 6f72  al Neural Networ
+0001a8c0: 6b2e 2044 6566 6175 6c74 7320 746f 2027  k. Defaults to '
+0001a8d0: 7266 272e 0a20 2020 2020 2020 206e 5f69  rf'..        n_i
+0001a8e0: 7465 7220 2869 6e74 2c20 6f70 7469 6f6e  ter (int, option
+0001a8f0: 616c 293a 2054 6865 206d 6178 696d 756d  al): The maximum
+0001a900: 206e 756d 6265 7220 6f66 2069 7465 7261   number of itera
+0001a910: 7469 6f6e 7320 746f 2070 6572 666f 726d  tions to perform
+0001a920: 2064 7572 696e 6720 0a20 2020 2020 2020   during .       
+0001a930: 2020 2020 2074 6865 2068 7970 6572 7061       the hyperpa
+0001a940: 7261 6d65 7465 7220 7365 6172 6368 2e20  rameter search. 
+0001a950: 4465 6661 756c 7473 2074 6f20 3235 2e0a  Defaults to 25..
+0001a960: 2020 2020 2020 2020 6f70 745f 6376 2028          opt_cv (
+0001a970: 696e 7429 3a20 4372 6f73 732d 7661 6c69  int): Cross-vali
+0001a980: 6461 7469 6f6e 7320 746f 2070 6572 666f  dations to perfo
+0001a990: 726d 2077 6865 6e20 6173 7365 7369 6e67  rm when assesing
+0001a9a0: 2074 6865 2070 6572 666f 726d 616e 6365   the performance
+0001a9b0: 2061 7420 6561 6368 0a20 2020 2020 2020   at each.       
+0001a9c0: 2020 2020 2068 7970 6572 7061 7261 6d65       hyperparame
+0001a9d0: 7465 7220 6f70 7469 6d69 7a61 7469 6f6e  ter optimization
+0001a9e0: 2074 7269 616c 2e20 466f 7220 6578 616d   trial. For exam
+0001a9f0: 706c 652c 2069 6620 6376 3d33 2c20 7468  ple, if cv=3, th
+0001aa00: 656e 2065 6163 6820 6f70 7469 6d69 7a61  en each optimiza
+0001aa10: 7469 6f6e 2074 7269 616c 0a20 2020 2020  tion trial.     
+0001aa20: 2020 2020 2020 2077 696c 6c20 6265 2061         will be a
+0001aa30: 7373 6573 7365 6420 6163 636f 7264 696e  ssessed accordin
+0001aa40: 6720 746f 2074 6865 2033 2d66 6f6c 6420  g to the 3-fold 
+0001aa50: 6372 6f73 7320 7661 6c69 6461 7469 6f6e  cross validation
+0001aa60: 2061 6363 7572 6163 792e 200a 2020 2020   accuracy. .    
+0001aa70: 2020 2020 2020 2020 4966 2063 6c66 3d27          If clf='
+0001aa80: 7867 6227 2061 6e64 2074 6869 7320 7661  xgb' and this va
+0001aa90: 6c75 6520 6973 2073 6574 2062 6574 7765  lue is set betwe
+0001aaa0: 656e 2030 2061 6e64 2031 2c20 7468 6973  en 0 and 1, this
+0001aab0: 2073 6574 7320 7468 6520 7369 7a65 206f   sets the size o
+0001aac0: 6620 7468 6520 7661 6c69 6461 7469 6f6e  f the validation
+0001aad0: 2064 6174 612c 200a 2020 2020 2020 2020   data, .        
+0001aae0: 2020 2020 7768 6963 6820 7769 6c6c 2062      which will b
+0001aaf0: 6520 6368 6f73 656e 2072 616e 646f 6d6c  e chosen randoml
+0001ab00: 7920 6561 6368 2074 7269 616c 2e20 5468  y each trial. Th
+0001ab10: 6973 2069 7320 7573 6564 2074 6f20 656e  is is used to en
+0001ab20: 6162 6c65 2061 6e20 6561 726c 7920 7374  able an early st
+0001ab30: 6f70 7069 6e67 2063 616c 6c62 6163 6b20  opping callback 
+0001ab40: 7768 6963 6820 0a20 2020 2020 2020 2020  which .         
+0001ab50: 2020 2069 7320 6e6f 7420 706f 7373 6962     is not possib
+0001ab60: 6c65 2077 6974 6820 7468 6520 6372 6f73  le with the cros
+0001ab70: 732d 7661 6c69 6461 7469 6f6e 206d 6574  s-validation met
+0001ab80: 686f 642e 2044 6566 6175 6c74 7320 746f  hod. Defaults to
+0001ab90: 2031 302e 200a 2020 2020 2020 2020 6c69   10. .        li
+0001aba0: 6d69 745f 7365 6172 6368 2028 626f 6f6c  mit_search (bool
+0001abb0: 293a 2049 6620 5472 7565 2074 6865 206f  ): If True the o
+0001abc0: 7074 696d 697a 6174 696f 6e20 7365 6172  ptimization sear
+0001abd0: 6368 2073 7061 6365 7320 7769 6c6c 2062  ch spaces will b
+0001abe0: 6520 6c69 6d69 7465 642c 2066 6f72 2063  e limited, for c
+0001abf0: 6f6d 7075 7461 7469 6f6e 616c 2061 6e64  omputational and
+0001ac00: 2074 696d 6520 7075 7270 6f73 6573 2e20   time purposes. 
+0001ac10: 0a20 2020 2020 2020 2020 2020 2054 6869  .            Thi
+0001ac20: 7320 6973 2065 7370 6563 6961 6c6c 7920  s is especially 
+0001ac30: 696d 706f 7274 616e 7420 6966 2074 756e  important if tun
+0001ac40: 696e 6720 6120 434e 4e20 6d6f 6465 6c2c  ing a CNN model,
+0001ac50: 2061 7320 6d65 6d6f 7279 2065 7272 6f72   as memory error
+0001ac60: 7320 6361 6e20 6265 2065 6e63 6f75 6e74  s can be encount
+0001ac70: 6572 6564 2e20 4465 6661 756c 7473 2074  ered. Defaults t
+0001ac80: 6f20 5472 7565 2e0a 2020 2020 2020 2020  o True..        
+0001ac90: 6261 6c61 6e63 6520 2862 6f6f 6c2c 206f  balance (bool, o
+0001aca0: 7074 696f 6e61 6c29 3a20 4966 2054 7275  ptional): If Tru
+0001acb0: 652c 2061 2077 6569 6768 7473 2061 7272  e, a weights arr
+0001acc0: 6179 2077 696c 6c20 6265 2063 616c 6375  ay will be calcu
+0001acd0: 6c61 7465 6420 616e 6420 7573 6564 0a20  lated and used. 
+0001ace0: 2020 2020 2020 2020 2020 2077 6865 6e20             when 
+0001acf0: 6669 7474 696e 6720 7468 6520 636c 6173  fitting the clas
+0001ad00: 7369 6669 6572 2e20 5468 6973 2063 616e  sifier. This can
+0001ad10: 2069 6d70 726f 7665 2063 6c61 7373 6966   improve classif
+0001ad20: 6963 6174 696f 6e20 7768 656e 2063 6c61  ication when cla
+0001ad30: 7373 6573 0a20 2020 2020 2020 2020 2020  sses.           
+0001ad40: 2061 7265 2069 6d62 616c 616e 6365 642e   are imbalanced.
+0001ad50: 2054 6869 7320 6973 206f 6e6c 7920 6170   This is only ap
+0001ad60: 706c 6965 6420 6966 2074 6865 2063 6c61  plied if the cla
+0001ad70: 7373 6966 6963 6174 696f 6e20 6973 2061  ssification is a
+0001ad80: 2062 696e 6172 7920 7461 736b 2e20 0a20   binary task. . 
+0001ad90: 2020 2020 2020 2020 2020 2044 6566 6175             Defau
+0001ada0: 6c74 7320 746f 2054 7275 652e 2049 6620  lts to True. If 
+0001adb0: 636c 663d 2761 6c65 786e 6574 2720 6f72  clf='alexnet' or
+0001adc0: 2061 6e79 206f 6620 7468 6520 434e 4e20   any of the CNN 
+0001add0: 6f70 7469 6f6e 732c 2074 6869 7320 7769  options, this wi
+0001ade0: 6c6c 2064 6574 6572 6d69 6e65 2077 6865  ll determine whe
+0001adf0: 7468 6572 2074 6865 2074 776f 2063 6c61  ther the two cla
+0001ae00: 7373 6573 0a20 2020 2020 2020 2020 2020  sses.           
+0001ae10: 2061 7265 206b 6570 7420 7468 6520 7361   are kept the sa
+0001ae20: 6d65 2073 697a 6520 6475 7269 6e67 206f  me size during o
+0001ae30: 7074 696d 697a 6174 696f 6e2c 2061 7070  ptimization, app
+0001ae40: 6c69 6361 626c 6520 6966 2074 756e 696e  licable if tunin
+0001ae50: 6720 7468 6520 6175 676d 656e 7461 7469  g the augmentati
+0001ae60: 6f6e 0a20 2020 2020 2020 2020 2020 2070  on.            p
+0001ae70: 6172 616d 6574 6572 732e 2044 6566 6175  arameters. Defau
+0001ae80: 6c74 7320 746f 2054 7275 652e 0a20 2020  lts to True..   
+0001ae90: 2020 2020 2072 6574 7572 6e5f 7374 7564       return_stud
+0001aea0: 7920 2862 6f6f 6c2c 206f 7074 696f 6e61  y (bool, optiona
+0001aeb0: 6c29 3a20 4966 2054 7275 6520 7468 6520  l): If True the 
+0001aec0: 4f70 7475 6e61 2073 7475 6479 206f 626a  Optuna study obj
+0001aed0: 6563 7420 7769 6c6c 2062 6520 7265 7475  ect will be retu
+0001aee0: 726e 6564 2e20 5468 6973 0a20 2020 2020  rned. This.     
+0001aef0: 2020 2020 2020 2063 616e 2062 6520 7573         can be us
+0001af00: 6564 2074 6f20 7265 7669 6577 2074 6865  ed to review the
+0001af10: 206d 6574 686f 6420 6174 7472 6962 7574   method attribut
+0001af20: 6573 2c20 7375 6368 2061 7320 6f70 7469  es, such as opti
+0001af30: 6d69 7a61 7469 6f6e 2070 6c6f 7473 2e20  mization plots. 
+0001af40: 4465 6661 756c 7473 2074 6f20 5472 7565  Defaults to True
+0001af50: 2e0a 0a20 2020 2054 6865 2066 6f6c 6c6c  ...    The folll
+0001af60: 6f77 696e 6720 6172 6775 6d65 6e74 7320  owing arguments 
+0001af70: 6172 6520 6f6e 6c79 2075 7365 6420 7768  are only used wh
+0001af80: 656e 206f 7074 696d 697a 696e 6720 7468  en optimizing th
+0001af90: 6520 434e 4e20 6e65 7477 6f72 6b3a 0a0a  e CNN network:..
+0001afa0: 2020 2020 4172 6773 3a0a 2020 2020 2020      Args:.      
+0001afb0: 2020 696d 675f 6e75 6d5f 6368 616e 6e65    img_num_channe
+0001afc0: 6c73 2028 696e 7429 3a20 5468 6520 6e75  ls (int): The nu
+0001afd0: 6d62 6572 206f 6620 6669 6c74 6572 732e  mber of filters.
+0001afe0: 2044 6566 6175 6c74 7320 746f 2031 2e0a   Defaults to 1..
+0001aff0: 2020 2020 2020 2020 6e6f 726d 616c 697a          normaliz
+0001b000: 6520 2862 6f6f 6c2c 206f 7074 696f 6e61  e (bool, optiona
+0001b010: 6c29 3a20 4966 2054 7275 6520 7468 6520  l): If True the 
+0001b020: 6461 7461 2077 696c 6c20 6265 206d 696e  data will be min
+0001b030: 2d6d 6178 206e 6f72 6d61 6c69 7a65 6420  -max normalized 
+0001b040: 7573 696e 6720 7468 6520 0a20 2020 2020  using the .     
+0001b050: 2020 2020 2020 2069 6e70 7574 206d 696e         input min
+0001b060: 2061 6e64 206d 6178 2070 6978 656c 732e   and max pixels.
+0001b070: 2044 6566 6175 6c74 7320 746f 2054 7275   Defaults to Tru
+0001b080: 652e 0a20 2020 2020 2020 206d 696e 5f70  e..        min_p
+0001b090: 6978 656c 2028 696e 742c 206f 7074 696f  ixel (int, optio
+0001b0a0: 6e61 6c29 3a20 5468 6520 6d69 6e69 6d75  nal): The minimu
+0001b0b0: 6d20 7069 7865 6c20 636f 756e 742c 2070  m pixel count, p
+0001b0c0: 6978 656c 7320 7769 7468 2063 6f75 6e74  ixels with count
+0001b0d0: 7320 0a20 2020 2020 2020 2020 2020 2062  s .            b
+0001b0e0: 656c 6f77 2074 6869 7320 7468 7265 7368  elow this thresh
+0001b0f0: 6f6c 6420 7769 6c6c 2062 6520 7365 7420  old will be set 
+0001b100: 746f 2074 6869 7320 6c69 6d69 742e 2044  to this limit. D
+0001b110: 6566 6175 6c74 7320 746f 2030 2e0a 2020  efaults to 0..  
+0001b120: 2020 2020 2020 6d61 785f 7069 7865 6c20        max_pixel 
+0001b130: 2869 6e74 2c20 6c69 7374 2c20 6f70 7469  (int, list, opti
+0001b140: 6f6e 616c 293a 2054 6865 206d 6178 696d  onal): The maxim
+0001b150: 756d 2070 6978 656c 2063 6f75 6e74 2c20  um pixel count, 
+0001b160: 7069 7865 6c73 2077 6974 6820 636f 756e  pixels with coun
+0001b170: 7473 200a 2020 2020 2020 2020 2020 2020  ts .            
+0001b180: 6162 6f76 6520 7468 6973 2074 6872 6573  above this thres
+0001b190: 686f 6c64 2077 696c 6c20 6265 2073 6574  hold will be set
+0001b1a0: 2074 6f20 7468 6973 206c 696d 6974 2e20   to this limit. 
+0001b1b0: 4465 6661 756c 7473 2074 6f20 3130 302e  Defaults to 100.
+0001b1c0: 2049 6620 696d 675f 6e75 6d5f 6368 616e   If img_num_chan
+0001b1d0: 6e65 6c73 0a20 2020 2020 2020 2020 2020  nels.           
+0001b1e0: 2069 7320 6e6f 7420 312c 2074 6865 206d   is not 1, the m
+0001b1f0: 6178 5f70 6978 656c 2073 686f 756c 6420  ax_pixel should 
+0001b200: 6265 2061 206c 6973 7420 636f 6e74 6169  be a list contai
+0001b210: 6e69 6e67 2074 776f 2076 616c 7565 732c  ning two values,
+0001b220: 206f 6e65 2066 6f72 2065 6163 6820 6261   one for each ba
+0001b230: 6e64 2e0a 2020 2020 2020 2020 7661 6c5f  nd..        val_
+0001b240: 706f 7369 7469 7665 2028 6e64 6172 7261  positive (ndarra
+0001b250: 792c 206f 7074 696f 6e61 6c29 3a20 506f  y, optional): Po
+0001b260: 7369 7469 7665 2063 6c61 7373 2064 6174  sitive class dat
+0001b270: 6120 746f 2062 6520 7573 6564 2066 6f72  a to be used for
+0001b280: 2076 616c 6964 6174 696f 6e2e 2044 6566   validation. Def
+0001b290: 6175 6c74 7320 746f 204e 6f6e 652e 0a20  aults to None.. 
+0001b2a0: 2020 2020 2020 2076 616c 5f6e 6567 6174         val_negat
+0001b2b0: 6976 6520 286e 6461 7272 6179 2c20 6f70  ive (ndarray, op
+0001b2c0: 7469 6f6e 616c 293a 204e 6567 6174 6976  tional): Negativ
+0001b2d0: 6520 636c 6173 7320 6461 7461 2074 6f20  e class data to 
+0001b2e0: 6265 2075 7365 6420 666f 7220 7661 6c69  be used for vali
+0001b2f0: 6461 7469 6f6e 2e20 4465 6661 756c 7473  dation. Defaults
+0001b300: 2074 6f20 4e6f 6e65 2e0a 2020 2020 2020   to None..      
+0001b310: 2020 7465 7374 5f70 6f73 6974 6976 6520    test_positive 
+0001b320: 286e 6461 7272 6179 2c20 6f70 7469 6f6e  (ndarray, option
+0001b330: 616c 293a 2050 6f73 6974 6976 6520 636c  al): Positive cl
+0001b340: 6173 7320 6461 7461 2074 6f20 6265 2075  ass data to be u
+0001b350: 7365 6420 666f 7220 706f 7374 2d74 7269  sed for post-tri
+0001b360: 616c 2074 6573 7469 6e67 2e20 4465 6661  al testing. Defa
+0001b370: 756c 7473 2074 6f20 4e6f 6e65 2e0a 2020  ults to None..  
+0001b380: 2020 2020 2020 7465 7374 5f6e 6567 6174        test_negat
+0001b390: 6976 6520 286e 6461 7272 6179 2c20 6f70  ive (ndarray, op
+0001b3a0: 7469 6f6e 616c 293a 204e 6567 6174 6976  tional): Negativ
+0001b3b0: 6520 636c 6173 7320 6461 7461 2074 6f20  e class data to 
+0001b3c0: 6265 2075 7365 6420 666f 7220 706f 7374  be used for post
+0001b3d0: 2d74 7269 616c 2074 6573 7469 6e67 2e20  -trial testing. 
+0001b3e0: 4465 6661 756c 7473 2074 6f20 4e6f 6e65  Defaults to None
+0001b3f0: 2e0a 2020 2020 2020 2020 7465 7374 5f61  ..        test_a
+0001b400: 6363 5f74 6872 6573 686f 6c64 2028 666c  cc_threshold (fl
+0001b410: 6f61 742c 206f 7074 696f 6e61 6c29 3a20  oat, optional): 
+0001b420: 4966 2069 6e70 7574 2c20 6d6f 6465 6c73  If input, models
+0001b430: 2074 6861 7420 7969 656c 6420 7465 7374   that yield test
+0001b440: 2061 6363 7572 6163 6965 7320 6c6f 7765   accuracies lowe
+0001b450: 7220 7468 616e 2074 6865 2074 6872 6573  r than the thres
+0001b460: 686f 6c64 2077 696c 6c0a 2020 2020 2020  hold will.      
+0001b470: 2020 2020 2020 6265 2072 656a 6563 7465        be rejecte
+0001b480: 6420 6279 2074 6865 206f 7074 696d 697a  d by the optimiz
+0001b490: 6572 2e20 5468 6520 6163 6375 7261 6379  er. The accuracy
+0001b4a0: 206f 6620 626f 7468 2074 6865 2074 6573   of both the tes
+0001b4b0: 745f 706f 7369 7469 7665 2061 6e64 2074  t_positive and t
+0001b4c0: 6573 745f 6e65 6761 7469 7665 2069 7320  est_negative is 
+0001b4d0: 6173 6573 7365 642c 2069 6620 696e 7075  asessed, if inpu
+0001b4e0: 742e 0a20 2020 2020 2020 2020 2020 2054  t..            T
+0001b4f0: 6869 7320 6973 2075 7365 6420 746f 2072  his is used to r
+0001b500: 656a 6563 7420 6d6f 6465 6c73 2074 6861  eject models tha
+0001b510: 7420 6861 7665 206f 7665 7220 6f72 2075  t have over or u
+0001b520: 6e64 6572 2066 6974 2074 6865 2074 7261  nder fit the tra
+0001b530: 696e 696e 6720 6461 7461 2e20 4465 6661  ining data. Defa
+0001b540: 756c 7473 2074 6f20 4e6f 6e65 2e0a 2020  ults to None..  
+0001b550: 2020 2020 2020 706f 7374 5f6d 6574 7269        post_metri
+0001b560: 6320 2862 6f6f 6c29 3a20 4966 2054 7275  c (bool): If Tru
+0001b570: 652c 2074 6865 2074 6573 745f 706f 7369  e, the test_posi
+0001b580: 7469 7665 2061 6e64 2f6f 7220 7465 7374  tive and/or test
+0001b590: 5f6e 6567 6174 6976 6520 696e 7075 7473  _negative inputs
+0001b5a0: 2077 696c 6c20 6265 2069 6e63 6c75 6465   will be include
+0001b5b0: 6420 696e 2074 6865 2066 696e 616c 206f  d in the final o
+0001b5c0: 7074 696d 697a 6174 696f 6e20 7363 6f72  ptimization scor
+0001b5d0: 652e 0a20 2020 2020 2020 2020 2020 2054  e..            T
+0001b5e0: 6869 7320 7769 6c6c 2062 6520 7468 6520  his will be the 
+0001b5f0: 6176 6572 6167 6564 206f 7574 206d 6574  averaged out met
+0001b600: 7269 632e 2044 6566 6175 6c74 7320 746f  ric. Defaults to
+0001b610: 2054 7275 652e 2043 616e 2062 6520 7365   True. Can be se
+0001b620: 7420 746f 2046 616c 7365 2074 6f20 6f6e  t to False to on
+0001b630: 6c79 2061 7070 6c79 2074 6865 2074 6573  ly apply the tes
+0001b640: 745f 6163 635f 7468 7265 7368 6f6c 642e  t_acc_threshold.
+0001b650: 0a20 2020 2020 2020 2074 7261 696e 5f65  .        train_e
+0001b660: 706f 6368 7320 2869 6e74 293a 204e 756d  pochs (int): Num
+0001b670: 6265 7220 6f66 2065 706f 6368 7320 746f  ber of epochs to
+0001b680: 2074 6865 2074 7261 696e 2074 6865 2043   the train the C
+0001b690: 4e4e 2074 6f20 6475 7269 6e67 2074 6865  NN to during the
+0001b6a0: 206f 7074 696d 697a 6174 696f 6e20 7472   optimization tr
+0001b6b0: 6961 6c73 2e20 4465 6661 756c 7473 2074  ials. Defaults t
+0001b6c0: 6f20 3235 2e0a 2020 2020 2020 2020 6d65  o 25..        me
+0001b6d0: 7472 6963 2028 7374 7229 3a20 4173 7365  tric (str): Asse
+0001b6e0: 736d 656e 7420 6d65 7472 6963 2074 6f20  sment metric to 
+0001b6f0: 7573 6520 7768 656e 2062 6f74 6820 7072  use when both pr
+0001b700: 756e 696e 6720 616e 6420 7363 6f72 696e  uning and scorin
+0001b710: 6720 7468 6520 6879 7065 7270 6172 616d  g the hyperparam
+0001b720: 6574 6572 206f 7074 696d 697a 6174 696f  eter optimizatio
+0001b730: 6e20 7472 6961 6c2e 0a20 2020 2020 2020  n trial..       
+0001b740: 2020 2020 2044 6566 6175 6c74 7320 746f       Defaults to
+0001b750: 2027 6c6f 7373 272e 204f 7074 696f 6e73   'loss'. Options
+0001b760: 2069 6e63 6c75 6465 3a20 276c 6f73 7327   include: 'loss'
+0001b770: 2027 6269 6e61 7279 5f61 6363 7572 6163   'binary_accurac
+0001b780: 7927 2c20 2766 315f 7363 6f72 6527 2027  y', 'f1_score' '
+0001b790: 616c 6c27 206f 7220 7468 6520 7661 6c69  all' or the vali
+0001b7a0: 6461 7469 6f6e 2065 7175 6976 616c 656e  dation equivalen
+0001b7b0: 7473 2028 652e 672e 2027 7661 6c5f 6c6f  ts (e.g. 'val_lo
+0001b7c0: 7373 2729 2e0a 2020 2020 2020 2020 7061  ss')..        pa
+0001b7d0: 7469 656e 6365 2028 696e 7429 3a20 4e75  tience (int): Nu
+0001b7e0: 6d62 6572 206f 6620 6570 6f63 6873 2077  mber of epochs w
+0001b7f0: 6974 686f 7574 2069 6d70 726f 7665 6d65  ithout improveme
+0001b800: 6e74 2062 6566 6f72 6520 7468 6520 6f70  nt before the op
+0001b810: 7469 6d69 7a61 7469 6f6e 2074 7269 616c  timization trial
+0001b820: 2069 7320 7465 726d 696e 6174 6564 2e20   is terminated. 
+0001b830: 4465 6661 756c 7473 2074 6f20 302c 2077  Defaults to 0, w
+0001b840: 6869 6368 0a20 2020 2020 2020 2020 2020  hich.           
+0001b850: 2064 6973 6162 6c65 7320 7468 6973 2066   disables this f
+0001b860: 6561 7475 7265 2e0a 2020 2020 2020 2020  eature..        
+0001b870: 6176 6572 6167 6520 2862 6f6f 6c29 3a20  average (bool): 
+0001b880: 4966 2046 616c 7365 2c20 7468 6520 6465  If False, the de
+0001b890: 7369 676e 6174 6564 206d 6574 7269 6320  signated metric 
+0001b8a0: 7769 6c6c 2062 6520 6361 6c63 756c 6174  will be calculat
+0001b8b0: 6564 2061 6363 6f72 6469 6e67 2074 6f20  ed according to 
+0001b8c0: 6974 7320 7661 6c75 6520 6174 2074 6865  its value at the
+0001b8d0: 2065 6e64 206f 6620 7468 6520 7472 6169   end of the trai
+0001b8e0: 6e5f 6570 6f63 6873 2e20 0a20 2020 2020  n_epochs. .     
+0001b8f0: 2020 2020 2020 2049 6620 5472 7565 2c20         If True, 
+0001b900: 7468 6520 6d65 7472 6963 2077 696c 6c20  the metric will 
+0001b910: 6265 2061 7665 7261 6765 6420 6f75 7420  be averaged out 
+0001b920: 6163 726f 7373 2061 6c6c 2074 7261 696e  across all train
+0001b930: 5f65 706f 6368 732e 2044 6566 6175 6c74  _epochs. Default
+0001b940: 7320 746f 2054 7275 652e 0a20 2020 2020  s to True..     
+0001b950: 2020 206f 7074 5f6d 6f64 656c 2028 626f     opt_model (bo
+0001b960: 6f6c 293a 2049 6620 5472 7565 2c20 7468  ol): If True, th
+0001b970: 6520 6172 6368 6974 6563 7475 7265 2070  e architecture p
+0001b980: 6172 616d 6574 6572 7320 7769 6c6c 2062  arameters will b
+0001b990: 6520 6f70 7469 6d69 7a65 642e 2044 6566  e optimized. Def
+0001b9a0: 6175 6c74 7320 746f 2054 7275 652e 0a20  aults to True.. 
+0001b9b0: 2020 2020 2020 206f 7074 5f61 7567 2028         opt_aug (
+0001b9c0: 626f 6f6c 293a 2049 6620 5472 7565 2c20  bool): If True, 
+0001b9d0: 7468 6520 6175 676d 656e 7461 7469 6f6e  the augmentation
+0001b9e0: 2070 726f 6365 6475 7265 2077 696c 6c20   procedure will 
+0001b9f0: 6265 206f 7074 696d 697a 6564 2e20 4465  be optimized. De
+0001ba00: 6661 756c 7473 2074 6f20 4661 6c73 652e  faults to False.
+0001ba10: 0a20 2020 2020 2020 2062 6174 6368 5f6d  .        batch_m
+0001ba20: 696e 2028 696e 7429 3a20 5468 6520 6d69  in (int): The mi
+0001ba30: 6e69 6d75 6d20 6e75 6d62 6572 206f 6620  nimum number of 
+0001ba40: 6175 676d 656e 7461 7469 6f6e 7320 746f  augmentations to
+0001ba50: 2070 6572 666f 726d 2070 6572 2069 6d61   perform per ima
+0001ba60: 6765 206f 6e20 7468 6520 706f 7369 7469  ge on the positi
+0001ba70: 7665 2063 6c61 7373 2c20 6f6e 6c79 2061  ve class, only a
+0001ba80: 7070 6c69 6361 626c 6520 0a20 2020 2020  pplicable .     
+0001ba90: 2020 2020 2020 2069 6620 6f70 745f 6175         if opt_au
+0001baa0: 673d 5472 7565 2e20 4465 6661 756c 7473  g=True. Defaults
+0001bab0: 2074 6f20 322e 0a20 2020 2020 2020 2062   to 2..        b
+0001bac0: 6174 6368 5f6d 6178 2028 696e 7429 3a20  atch_max (int): 
+0001bad0: 5468 6520 6d61 7869 6d75 6d20 6e75 6d62  The maximum numb
+0001bae0: 6572 206f 6620 6175 676d 656e 7461 7469  er of augmentati
+0001baf0: 6f6e 7320 746f 2070 6572 666f 726d 2070  ons to perform p
+0001bb00: 6572 2069 6d61 6765 206f 6e20 7468 6520  er image on the 
+0001bb10: 706f 7369 7469 7665 2063 6c61 7373 2c20  positive class, 
+0001bb20: 6f6e 6c79 2061 7070 6c69 6361 626c 6520  only applicable 
+0001bb30: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+0001bb40: 6f70 745f 6175 673d 5472 7565 2e20 4465  opt_aug=True. De
+0001bb50: 6661 756c 7473 2074 6f20 3235 2e0a 2020  faults to 25..  
+0001bb60: 2020 2020 2020 6261 7463 685f 6f74 6865        batch_othe
+0001bb70: 7220 2869 6e74 293a 2054 6865 206e 756d  r (int): The num
+0001bb80: 6265 7220 6f66 2061 7567 6d65 6e74 6174  ber of augmentat
+0001bb90: 696f 6e73 2074 6f20 7065 7266 6f72 6d20  ions to perform 
+0001bba0: 746f 2074 6865 206f 7468 6572 2063 6c61  to the other cla
+0001bbb0: 7373 2c20 7072 6573 756d 6564 2074 6f20  ss, presumed to 
+0001bbc0: 6265 2074 6865 206d 616a 6f72 6974 7920  be the majority 
+0001bbd0: 636c 6173 732e 0a20 2020 2020 2020 2020  class..         
+0001bbe0: 2020 2044 6566 6175 6c74 7320 746f 2031     Defaults to 1
+0001bbf0: 2e20 5468 6973 2069 7320 646f 6e65 2074  . This is done t
+0001bc00: 6f20 656e 7375 7265 2061 7567 6d65 6e74  o ensure augment
+0001bc10: 6174 696f 6e20 7465 6368 6e69 7175 6573  ation techniques
+0001bc20: 2061 7265 2061 7070 6c69 6564 2063 6f6e   are applied con
+0001bc30: 7369 7374 656e 746c 7920 6163 726f 7373  sistently across
+0001bc40: 2062 6f74 6820 636c 6173 7365 732e 2020   both classes.  
+0001bc50: 2020 2020 2020 0a20 2020 2020 2020 2069        .        i
+0001bc60: 6d61 6765 5f73 697a 655f 6d69 6e20 2869  mage_size_min (i
+0001bc70: 6e74 293a 2054 6865 206d 696e 696d 756d  nt): The minimum
+0001bc80: 2069 6d61 6765 2073 697a 6520 746f 2061   image size to a
+0001bc90: 7373 6573 732c 206f 6e6c 7920 6170 706c  ssess, only appl
+0001bca0: 6963 6162 6c65 2069 6620 6f70 745f 6175  icable if opt_au
+0001bcb0: 673d 5472 7565 2e20 4465 6661 756c 7473  g=True. Defaults
+0001bcc0: 2074 6f20 3530 2e0a 2020 2020 2020 2020   to 50..        
+0001bcd0: 696d 6167 655f 7369 7a65 5f6d 6178 2028  image_size_max (
+0001bce0: 696e 7429 3a20 5468 6520 6d61 7869 6d75  int): The maximu
+0001bcf0: 6d20 696d 6167 6520 7369 7a65 2074 6f20  m image size to 
+0001bd00: 6173 7365 7373 2c20 6f6e 6c79 2061 7070  assess, only app
+0001bd10: 6c69 6361 626c 6520 6966 206f 7074 5f61  licable if opt_a
+0001bd20: 7567 3d54 7275 652e 2044 6566 6175 6c74  ug=True. Default
+0001bd30: 7320 746f 2031 3030 2e0a 2020 2020 2020  s to 100..      
+0001bd40: 2020 6f70 745f 6d61 785f 6d69 6e5f 7069    opt_max_min_pi
+0001bd50: 7820 2869 6e74 2c20 6f70 7469 6f6e 616c  x (int, optional
+0001bd60: 293a 2054 6865 206d 696e 696d 756d 206d  ): The minimum m
+0001bd70: 6178 2070 6978 656c 2076 616c 7565 2074  ax pixel value t
+0001bd80: 6f20 7573 6520 7768 656e 2074 756e 696e  o use when tunin
+0001bd90: 6720 7468 6520 6e6f 726d 616c 697a 6174  g the normalizat
+0001bda0: 696f 6e20 7072 6f63 6564 7572 652c 200a  ion procedure, .
+0001bdb0: 2020 2020 2020 2020 2020 2020 6f6e 6c79              only
+0001bdc0: 2061 7070 6c69 6361 626c 6520 6966 206f   applicable if o
+0001bdd0: 7074 5f61 7567 3d54 7275 652e 2044 6566  pt_aug=True. Def
+0001bde0: 6175 6c74 7320 746f 204e 6f6e 652e 0a20  aults to None.. 
+0001bdf0: 2020 2020 2020 206f 7074 5f6d 6178 5f6d         opt_max_m
+0001be00: 6178 5f70 6978 2028 696e 742c 206f 7074  ax_pix (int, opt
+0001be10: 696f 6e61 6c29 3a20 5468 6520 6d61 7869  ional): The maxi
+0001be20: 6d75 6d20 6d61 7820 7069 7865 6c20 7661  mum max pixel va
+0001be30: 6c75 6520 746f 2075 7365 2077 6865 6e20  lue to use when 
+0001be40: 7475 6e69 6e67 2074 6865 206e 6f72 6d61  tuning the norma
+0001be50: 6c69 7a61 7469 6f6e 2070 726f 6365 6475  lization procedu
+0001be60: 7265 2c20 0a20 2020 2020 2020 2020 2020  re, .           
+0001be70: 206f 6e6c 7920 6170 706c 6963 6162 6c65   only applicable
+0001be80: 2069 6620 6f70 745f 6175 673d 5472 7565   if opt_aug=True
+0001be90: 2e20 4465 6661 756c 7473 2074 6f20 4e6f  . Defaults to No
+0001bea0: 6e65 2e0a 2020 2020 2020 2020 7368 6966  ne..        shif
+0001beb0: 7420 2869 6e74 293a 2054 6865 206d 6178  t (int): The max
+0001bec0: 2061 6c6c 6f77 6564 2076 6572 7469 6361   allowed vertica
+0001bed0: 6c2f 686f 7269 7a6f 6e74 616c 2073 6869  l/horizontal shi
+0001bee0: 6674 7320 746f 2075 7365 2064 7572 696e  fts to use durin
+0001bef0: 6720 7468 6520 6461 7461 2061 7567 6d65  g the data augme
+0001bf00: 6e74 6174 696f 6e20 726f 7574 696e 652c  ntation routine,
+0001bf10: 206f 6e6c 7920 6170 706c 6963 6162 6c65   only applicable
+0001bf20: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+0001bf30: 6f70 745f 6175 673d 5472 7565 2e20 4465  opt_aug=True. De
+0001bf40: 6661 756c 7473 2074 6f20 3130 2070 6978  faults to 10 pix
+0001bf50: 656c 732e 0a20 2020 2020 2020 206d 6173  els..        mas
+0001bf60: 6b5f 7369 7a65 2028 696e 742c 206f 7074  k_size (int, opt
+0001bf70: 696f 6e61 6c29 3a20 4966 2065 6e61 626c  ional): If enabl
+0001bf80: 6564 2c20 7468 6973 2077 696c 6c20 7365  ed, this will se
+0001bf90: 7420 7468 6520 7069 7865 6c20 6c65 6e67  t the pixel leng
+0001bfa0: 7468 206f 6620 6120 7371 7561 7265 2063  th of a square c
+0001bfb0: 7574 6f75 742c 2074 6f20 6265 2072 616e  utout, to be ran
+0001bfc0: 646f 6d6c 7920 706c 6163 6564 0a20 2020  domly placed.   
+0001bfd0: 2020 2020 2020 2020 2073 6f6d 6577 6865           somewhe
+0001bfe0: 7265 2069 6e20 7468 6520 6175 676d 656e  re in the augmen
+0001bff0: 7465 6420 696d 6167 652e 2054 6869 7320  ted image. This 
+0001c000: 6375 746f 7574 2077 696c 6c20 7265 706c  cutout will repl
+0001c010: 6163 6520 7468 6520 696d 6167 6520 7661  ace the image va
+0001c020: 6c75 6573 2077 6974 6820 302c 2074 6865  lues with 0, the
+0001c030: 7265 666f 7265 2073 6572 7669 6e67 2061  refore serving a
+0001c040: 7320 6120 0a20 2020 2020 2020 2020 2020  s a .           
+0001c050: 2072 6567 756c 6172 697a 6572 2e20 4f6e   regularizer. On
+0001c060: 6c79 2061 7070 6c69 6361 626c 6520 6966  ly applicable if
+0001c070: 206f 7074 5f61 7567 3d54 7275 652e 2054   opt_aug=True. T
+0001c080: 6869 7320 7661 6c75 6520 6361 6e20 6569  his value can ei
+0001c090: 7468 6572 2062 6520 616e 2069 6e74 6567  ther be an integ
+0001c0a0: 6572 2074 6f20 6861 7264 2d73 6574 2074  er to hard-set t
+0001c0b0: 6865 206d 6173 6b20 7369 7a65 2065 7665  he mask size eve
+0001c0c0: 7279 7469 6d65 2c0a 2020 2020 2020 2020  rytime,.        
+0001c0d0: 2020 2020 6f72 2063 616e 2062 6520 6120      or can be a 
+0001c0e0: 7475 706c 6520 7265 7072 6573 656e 7469  tuple representi
+0001c0f0: 6e67 2074 6865 206c 6f77 6572 2061 6e64  ng the lower and
+0001c100: 2075 7070 6572 2062 6f75 6e64 732c 2072   upper bounds, r
+0001c110: 6573 7065 6374 6976 656c 792c 2069 6e20  espectively, in 
+0001c120: 7768 6963 6820 6361 7365 2074 6865 206d  which case the m
+0001c130: 6173 6b20 7369 7a65 2077 696c 6c20 6265  ask size will be
+0001c140: 206f 7074 696d 697a 6564 2e20 0a20 2020   optimized. .   
+0001c150: 2020 2020 2020 2020 2044 6566 6175 6c74           Default
+0001c160: 7320 746f 204e 6f6e 652e 0a20 2020 2020  s to None..     
+0001c170: 2020 206e 756d 5f6d 6173 6b73 2028 696e     num_masks (in
+0001c180: 742c 206f 7074 696f 6e61 6c29 3a20 5468  t, optional): Th
+0001c190: 6520 6e75 6d62 6572 206f 6620 6d61 736b  e number of mask
+0001c1a0: 7320 746f 2063 7265 6174 652c 2074 6f20  s to create, to 
+0001c1b0: 6265 2075 7365 6420 616c 6f6e 6773 6964  be used alongsid
+0001c1c0: 6520 7468 6520 6d61 736b 5f73 697a 6520  e the mask_size 
+0001c1d0: 7061 7261 6d65 7465 722e 204e 6f74 6520  parameter. Note 
+0001c1e0: 7468 6174 2069 6620 0a20 2020 2020 2020  that if .       
+0001c1f0: 2020 2020 2074 6869 7320 6973 2073 6574       this is set
+0001c200: 2074 6f20 6120 7661 6c75 6520 6772 6561   to a value grea
+0001c210: 7465 7220 7468 616e 206f 6e65 2c20 6f76  ter than one, ov
+0001c220: 6572 6c61 7020 6d61 7920 6f63 6375 722e  erlap may occur.
+0001c230: 2054 6869 7320 7661 6c75 6520 6361 6e20   This value can 
+0001c240: 6569 7468 6572 2062 6520 616e 2069 6e74  either be an int
+0001c250: 6567 6572 2074 6f20 6861 7264 2d73 6574  eger to hard-set
+0001c260: 2074 6865 206e 756d 6265 720a 2020 2020   the number.    
+0001c270: 2020 2020 2020 2020 6f66 206d 6173 6b73          of masks
+0001c280: 2065 7665 7279 7469 6d65 2c20 6f72 2069   everytime, or i
+0001c290: 7420 6361 6e20 6265 2061 2074 7570 6c65  t can be a tuple
+0001c2a0: 2072 6570 7265 7365 6e74 696e 6720 7468   representing th
+0001c2b0: 6520 6c6f 7765 7220 616e 6420 7570 7065  e lower and uppe
+0001c2c0: 7220 626f 756e 6473 2c20 7265 7370 6563  r bounds, respec
+0001c2d0: 7469 7665 6c79 2c20 696e 2077 6869 6368  tively, in which
+0001c2e0: 2063 6173 6520 7468 6520 6e75 6d62 6572   case the number
+0001c2f0: 0a20 2020 2020 2020 2020 2020 206f 6620  .            of 
+0001c300: 6d61 736b 7320 7769 6c6c 2062 6520 6f70  masks will be op
+0001c310: 7469 6d69 7a65 642e 2044 6566 6175 6c74  timized. Default
+0001c320: 7320 746f 204e 6f6e 652e 0a20 2020 2020  s to None..     
+0001c330: 2020 2076 6572 626f 7365 2028 696e 7429     verbose (int)
+0001c340: 3a20 436f 6e74 726f 6c73 2074 6865 2061  : Controls the a
+0001c350: 6d6f 756e 7420 6f66 206f 7574 7075 7420  mount of output 
+0001c360: 7072 696e 7465 6420 6475 7269 6e67 2074  printed during t
+0001c370: 6865 2074 7261 696e 696e 6720 7072 6f63  he training proc
+0001c380: 6573 732e 2041 2076 616c 7565 206f 6620  ess. A value of 
+0001c390: 3020 6973 2066 6f72 2073 696c 656e 7420  0 is for silent 
+0001c3a0: 6d6f 6465 2c20 0a20 2020 2020 2020 2020  mode, .         
+0001c3b0: 2020 2061 2076 616c 7565 206f 6620 3120     a value of 1 
+0001c3c0: 6973 2075 7365 6420 666f 7220 7072 6f67  is used for prog
+0001c3d0: 7265 7373 2062 6172 206d 6f64 652c 2061  ress bar mode, a
+0001c3e0: 6e64 2032 2066 6f72 206f 6e65 206c 696e  nd 2 for one lin
+0001c3f0: 6520 7065 7220 6570 6f63 6820 6d6f 6465  e per epoch mode
+0001c400: 2e20 4465 6661 756c 7473 2074 6f20 312e  . Defaults to 1.
+0001c410: 0a20 2020 2020 2020 2073 6d6f 7465 5f73  .        smote_s
+0001c420: 616d 706c 696e 6720 2866 6c6f 6174 293a  ampling (float):
+0001c430: 2054 6865 2073 6d6f 7465 5f73 616d 706c   The smote_sampl
+0001c440: 696e 6720 7061 7261 6d65 7465 7220 6973  ing parameter is
+0001c450: 2075 7365 6420 696e 2074 6865 2053 4d4f   used in the SMO
+0001c460: 5445 2061 6c67 6f72 6974 686d 2074 6f20  TE algorithm to 
+0001c470: 7370 6563 6966 7920 7468 6520 6465 7369  specify the desi
+0001c480: 7265 6420 0a20 2020 2020 2020 2020 2020  red .           
+0001c490: 2072 6174 696f 206f 6620 7468 6520 6d69   ratio of the mi
+0001c4a0: 6e6f 7269 7479 2063 6c61 7373 2074 6f20  nority class to 
+0001c4b0: 7468 6520 6d61 6a6f 7269 7479 2063 6c61  the majority cla
+0001c4c0: 7373 2e20 4465 6661 756c 7473 2074 6f20  ss. Defaults to 
+0001c4d0: 3020 7768 6963 6820 6469 7361 626c 6573  0 which disables
+0001c4e0: 2074 6865 2070 726f 6365 6475 7265 2e0a   the procedure..
+0001c4f0: 2020 2020 2020 2020 0a20 2020 2054 6865          .    The
+0001c500: 2066 6f6c 6c6c 6f77 696e 6720 6172 6775   folllowing argu
+0001c510: 6d65 6e74 7320 6361 6e20 6265 2075 7365  ments can be use
+0001c520: 6420 746f 2073 6574 2065 6172 6c79 2d73  d to set early-s
+0001c530: 746f 7070 696e 6720 6361 6c6c 6261 636b  topping callback
+0001c540: 732e 2054 6865 7365 2063 616e 2062 6520  s. These can be 
+0001c550: 7573 6564 2074 6f20 7465 726d 696e 6174  used to terminat
+0001c560: 6520 7472 6961 6c73 2074 6861 7420 6578  e trials that ex
+0001c570: 6365 6564 0a20 2020 2070 7265 2d64 6574  ceed.    pre-det
+0001c580: 6572 6d69 6e65 6420 7468 7265 7368 6f6c  ermined threshol
+0001c590: 6473 2c20 7768 6963 6820 6d61 7920 6265  ds, which may be
+0001c5a0: 2069 6e64 6963 6174 6976 6520 6f66 2061   indicative of a
+0001c5b0: 6e20 6f76 6572 6669 7420 6d6f 6465 6c2e  n overfit model.
+0001c5c0: 0a0a 2020 2020 4172 6773 3a0a 2020 2020  ..    Args:.    
+0001c5d0: 2020 2020 6d6f 6e69 746f 7231 2028 7374      monitor1 (st
+0001c5e0: 722c 206f 7074 696f 6e61 6c29 3a20 5468  r, optional): Th
+0001c5f0: 6520 6669 7273 7420 6d65 7472 6963 2074  e first metric t
+0001c600: 6f20 6d6f 6e69 746f 722c 2063 616e 2074  o monitor, can t
+0001c610: 616b 6520 7468 6520 7361 6d65 2076 616c  ake the same val
+0001c620: 7565 7320 6173 2074 6865 206d 6574 7269  ues as the metri
+0001c630: 6320 6172 6775 6d65 6e74 2e20 4465 6661  c argument. Defa
+0001c640: 756c 7473 2074 6f20 4e6f 6e65 2e0a 2020  ults to None..  
+0001c650: 2020 2020 2020 6d6f 6e69 746f 7232 2028        monitor2 (
+0001c660: 7374 722c 206f 7074 696f 6e61 6c29 3a20  str, optional): 
+0001c670: 5468 6520 7365 636f 6e64 206d 6574 7269  The second metri
+0001c680: 6320 746f 206d 6f6e 6974 6f72 2c20 6361  c to monitor, ca
+0001c690: 6e20 7461 6b65 2074 6865 2073 616d 6520  n take the same 
+0001c6a0: 7661 6c75 6573 2061 7320 7468 6520 6d65  values as the me
+0001c6b0: 7472 6963 2061 7267 756d 656e 742e 2044  tric argument. D
+0001c6c0: 6566 6175 6c74 7320 746f 204e 6f6e 652e  efaults to None.
+0001c6d0: 0a20 2020 2020 2020 206d 6f6e 6974 6f72  .        monitor
+0001c6e0: 315f 7468 7265 7368 2028 666c 6f61 742c  1_thresh (float,
+0001c6f0: 206f 7074 696f 6e61 6c29 3a20 5468 6520   optional): The 
+0001c700: 7468 7265 7368 6f6c 6420 7661 6c75 6520  threshold value 
+0001c710: 6f66 2074 6865 2066 6972 7374 206d 6f6e  of the first mon
+0001c720: 6974 6f72 206d 6574 7269 632e 2049 6620  itor metric. If 
+0001c730: 7468 6520 6d65 7472 6963 2069 7320 6c6f  the metric is lo
+0001c740: 7373 2d72 656c 6174 6564 0a20 2020 2020  ss-related.     
+0001c750: 2020 2020 2020 2074 6865 2074 7261 696e         the train
+0001c760: 696e 6720 7769 6c6c 2073 746f 7020 6561  ing will stop ea
+0001c770: 726c 7920 6966 2074 6865 2076 616c 7565  rly if the value
+0001c780: 2066 616c 6c73 2062 656c 6f77 2074 6869   falls below thi
+0001c790: 7320 7468 7265 7368 6f6c 642e 2053 696d  s threshold. Sim
+0001c7a0: 696c 6172 6c79 2c20 6966 2074 6865 206d  ilarly, if the m
+0001c7b0: 6574 7269 6320 6973 2061 6363 7572 6163  etric is accurac
+0001c7c0: 792d 7265 6c61 7465 642c 0a20 2020 2020  y-related,.     
+0001c7d0: 2020 2020 2020 2074 6865 6e20 7468 6520         then the 
+0001c7e0: 7472 6169 6e69 6e67 2077 696c 6c20 7374  training will st
+0001c7f0: 6f70 2065 6172 6c79 2069 6620 7468 6520  op early if the 
+0001c800: 7661 6c75 6520 6661 6c6c 7320 6162 6f76  value falls abov
+0001c810: 6520 7468 6973 2074 6872 6573 686f 6c64  e this threshold
+0001c820: 2e20 4465 6661 756c 7473 2074 6f20 4e6f  . Defaults to No
+0001c830: 6e65 2e0a 2020 2020 2020 2020 6d6f 6e69  ne..        moni
+0001c840: 746f 7232 5f74 6872 6573 6820 2866 6c6f  tor2_thresh (flo
+0001c850: 6174 2c20 6f70 7469 6f6e 616c 293a 2054  at, optional): T
+0001c860: 6865 2074 6872 6573 686f 6c64 2076 616c  he threshold val
+0001c870: 7565 206f 6620 7468 6520 7365 636f 6e64  ue of the second
+0001c880: 206d 6f6e 6974 6f72 206d 6574 7269 632e   monitor metric.
+0001c890: 2049 6620 7468 6520 6d65 7472 6963 2069   If the metric i
+0001c8a0: 7320 6c6f 7373 2d72 656c 6174 6564 0a20  s loss-related. 
+0001c8b0: 2020 2020 2020 2020 2020 2074 6865 2074             the t
+0001c8c0: 7261 696e 696e 6720 7769 6c6c 2073 746f  raining will sto
+0001c8d0: 7020 6561 726c 7920 6966 2074 6865 2076  p early if the v
+0001c8e0: 616c 7565 2066 616c 6c73 2062 656c 6f77  alue falls below
+0001c8f0: 2074 6869 7320 7468 7265 7368 6f6c 642e   this threshold.
+0001c900: 2053 696d 696c 6172 6c79 2c20 6966 2074   Similarly, if t
+0001c910: 6865 206d 6574 7269 6320 6973 2061 6363  he metric is acc
+0001c920: 7572 6163 792d 7265 6c61 7465 642c 0a20  uracy-related,. 
+0001c930: 2020 2020 2020 2020 2020 2074 6865 6e20             then 
+0001c940: 7468 6520 7472 6169 6e69 6e67 2077 696c  the training wil
+0001c950: 6c20 7374 6f70 2065 6172 6c79 2069 6620  l stop early if 
+0001c960: 7468 6520 7661 6c75 6520 6661 6c6c 7320  the value falls 
+0001c970: 6162 6f76 6520 7468 6973 2074 6872 6573  above this thres
+0001c980: 686f 6c64 2e20 4465 6661 756c 7473 2074  hold. Defaults t
+0001c990: 6f20 4e6f 6e65 2e0a 2020 2020 2020 2020  o None..        
+0001c9a0: 0a20 2020 2052 6574 7572 6e73 3a0a 2020  .    Returns:.  
+0001c9b0: 2020 2020 2020 5468 6520 6669 7273 7420        The first 
+0001c9c0: 6f75 7470 7574 2069 7320 7468 6520 636c  output is the cl
+0001c9d0: 6173 7369 6669 6572 2077 6974 6820 7468  assifier with th
+0001c9e0: 6520 6f70 7469 6d61 6c20 6879 7065 7270  e optimal hyperp
+0001c9f0: 6172 616d 6574 6572 732e 0a20 2020 2020  arameters..     
+0001ca00: 2020 2053 6563 6f6e 6420 6f75 7470 7574     Second output
+0001ca10: 2069 7320 6120 6469 6374 696f 6e61 7279   is a dictionary
+0001ca20: 2063 6f6e 7461 696e 696e 6720 7468 6520   containing the 
+0001ca30: 6f70 7469 6d61 6c20 6879 7065 7270 6172  optimal hyperpar
+0001ca40: 616d 6574 6572 732e 0a20 2020 2020 2020  ameters..       
+0001ca50: 2049 6620 7361 7665 5f73 7475 6479 3d54   If save_study=T
+0001ca60: 7275 652c 2074 6865 204f 7074 756e 6120  rue, the Optuna 
+0001ca70: 7374 7564 7920 6f62 6a65 6374 2077 696c  study object wil
+0001ca80: 6c20 6265 2074 6865 2074 6869 7264 206f  l be the third o
+0001ca90: 7574 7075 742e 0a20 2020 2022 2222 0a0a  utput..    """..
+0001caa0: 2020 2020 6966 2063 6c66 203d 3d20 2772      if clf == 'r
+0001cab0: 6627 3a0a 2020 2020 2020 2020 6d6f 6465  f':.        mode
+0001cac0: 6c5f 3020 3d20 5261 6e64 6f6d 466f 7265  l_0 = RandomFore
+0001cad0: 7374 436c 6173 7369 6669 6572 2872 616e  stClassifier(ran
+0001cae0: 646f 6d5f 7374 6174 653d 3139 3039 290a  dom_state=1909).
+0001caf0: 2020 2020 656c 6966 2063 6c66 203d 3d20      elif clf == 
+0001cb00: 276e 6e27 3a0a 2020 2020 2020 2020 6d6f  'nn':.        mo
+0001cb10: 6465 6c5f 3020 3d20 4d4c 5043 6c61 7373  del_0 = MLPClass
+0001cb20: 6966 6965 7228 7261 6e64 6f6d 5f73 7461  ifier(random_sta
+0001cb30: 7465 3d31 3930 3929 0a20 2020 2065 6c69  te=1909).    eli
+0001cb40: 6620 636c 6620 3d3d 2027 7867 6227 3a0a  f clf == 'xgb':.
+0001cb50: 2020 2020 2020 2020 6d6f 6465 6c5f 3020          model_0 
+0001cb60: 3d20 5847 4243 6c61 7373 6966 6965 7228  = XGBClassifier(
+0001cb70: 7261 6e64 6f6d 5f73 7461 7465 3d31 3930  random_state=190
+0001cb80: 3929 0a20 2020 2020 2020 2069 6620 616c  9).        if al
+0001cb90: 6c28 6973 696e 7374 616e 6365 2876 616c  l(isinstance(val
+0001cba0: 2c20 2869 6e74 2c20 7374 7229 2920 666f  , (int, str)) fo
+0001cbb0: 7220 7661 6c20 696e 2064 6174 615f 7929  r val in data_y)
+0001cbc0: 3a0a 2020 2020 2020 2020 2020 2020 7072  :.            pr
+0001cbd0: 696e 7428 2758 4742 6f6f 7374 2063 6c61  int('XGBoost cla
+0001cbe0: 7373 6966 6965 7220 7265 7175 6972 6573  ssifier requires
+0001cbf0: 206e 756d 6572 6963 616c 2063 6c61 7373   numerical class
+0001cc00: 206c 6162 656c 7321 2043 6f6e 7665 7274   labels! Convert
+0001cc10: 696e 6720 636c 6173 7320 6c61 6265 6c73  ing class labels
+0001cc20: 2061 7320 666f 6c6c 6f77 733a 2729 0a20   as follows:'). 
+0001cc30: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+0001cc40: 2827 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f  ('______________
+0001cc50: 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f 5f5f  ________________
+0001cc60: 5f5f 5f5f 5f5f 2729 0a20 2020 2020 2020  ______').       
+0001cc70: 2020 2020 2079 203d 206e 702e 7a65 726f       y = np.zero
+0001cc80: 7328 6c65 6e28 6461 7461 5f79 2929 0a20  s(len(data_y)). 
+0001cc90: 2020 2020 2020 2020 2020 2066 6f72 2069             for i
+0001cca0: 2069 6e20 7261 6e67 6528 6c65 6e28 6e70   in range(len(np
+0001ccb0: 2e75 6e69 7175 6528 6461 7461 5f79 2929  .unique(data_y))
+0001ccc0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+0001ccd0: 2020 2070 7269 6e74 2873 7472 286e 702e     print(str(np.
+0001cce0: 756e 6971 7565 2864 6174 615f 7929 5b69  unique(data_y)[i
+0001ccf0: 5d29 2e6c 6a75 7374 2831 3029 2b27 2020  ]).ljust(10)+'  
+0001cd00: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d3e 2020  ------------->  
+0001cd10: 2020 2027 2b73 7472 2869 2929 0a20 2020     '+str(i)).   
+0001cd20: 2020 2020 2020 2020 2020 2020 2069 6e64               ind
+0001cd30: 6578 203d 206e 702e 7768 6572 6528 6461  ex = np.where(da
+0001cd40: 7461 5f79 203d 3d20 6e70 2e75 6e69 7175  ta_y == np.uniqu
+0001cd50: 6528 6461 7461 5f79 295b 695d 295b 305d  e(data_y)[i])[0]
+0001cd60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001cd70: 2079 5b69 6e64 6578 5d20 3d20 690a 2020   y[index] = i.  
+0001cd80: 2020 2020 2020 2020 2020 6461 7461 5f79            data_y
+0001cd90: 203d 2079 200a 2020 2020 2020 2020 2020   = y .          
+0001cda0: 2020 7072 696e 7428 272d 2d2d 2d2d 2d2d    print('-------
+0001cdb0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+0001cdc0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d27 290a  -------------').
+0001cdd0: 2020 2020 656c 6966 2063 6c66 203d 3d20      elif clf == 
+0001cde0: 2761 6c65 786e 6574 2720 6f72 2063 6c66  'alexnet' or clf
+0001cdf0: 203d 3d20 2776 6767 3136 2720 6f72 2063   == 'vgg16' or c
+0001ce00: 6c66 203d 3d20 2772 6573 6e65 7431 3827  lf == 'resnet18'
+0001ce10: 206f 7220 636c 6620 3d3d 2027 6375 7374   or clf == 'cust
+0001ce20: 6f6d 5f63 6e6e 273a 0a20 2020 2020 2020  om_cnn':.       
+0001ce30: 2070 6173 730a 2020 2020 656c 7365 3a0a   pass.    else:.
+0001ce40: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+0001ce50: 6c75 6545 7272 6f72 2827 636c 6620 6172  lueError('clf ar
+0001ce60: 6775 6d65 6e74 206d 7573 7420 6569 7468  gument must eith
+0001ce70: 6572 2062 6520 2272 6622 2c20 2278 6762  er be "rf", "xgb
+0001ce80: 222c 2022 6e6e 222c 206f 7220 2261 6c65  ", "nn", or "ale
+0001ce90: 786e 6574 222c 2022 7667 6731 3622 2c20  xnet", "vgg16", 
+0001cea0: 2272 6573 6e65 7431 3822 2c20 2263 7573  "resnet18", "cus
+0001ceb0: 746f 6d5f 636e 6e22 2e27 290a 0a20 2020  tom_cnn".')..   
+0001cec0: 2069 6620 6e5f 6974 6572 203d 3d20 303a   if n_iter == 0:
+0001ced0: 0a20 2020 2020 2020 2069 6620 636c 6620  .        if clf 
+0001cee0: 3d3d 2027 7266 2720 6f72 2063 6c66 203d  == 'rf' or clf =
+0001cef0: 3d20 2778 6762 2720 6f72 2063 6c66 203d  = 'xgb' or clf =
+0001cf00: 3d20 276e 6e27 3a0a 2020 2020 2020 2020  = 'nn':.        
+0001cf10: 2020 2020 7072 696e 7428 274e 6f20 6f70      print('No op
+0001cf20: 7469 6d69 7a61 7469 6f6e 2074 7269 616c  timization trial
+0001cf30: 7320 636f 6e66 6967 7572 6564 2028 6e5f  s configured (n_
+0001cf40: 6974 6572 3d30 292c 2072 6574 7572 6e69  iter=0), returni
+0001cf50: 6e67 2062 6173 6520 7b7d 206d 6f64 656c  ng base {} model
+0001cf60: 2e2e 2e27 2e66 6f72 6d61 7428 636c 6629  ...'.format(clf)
+0001cf70: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
+0001cf80: 7475 726e 206d 6f64 656c 5f30 200a 2020  turn model_0 .  
+0001cf90: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+0001cfa0: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+0001cfb0: 6c75 6545 7272 6f72 2827 4e6f 206f 7074  lueError('No opt
+0001cfc0: 696d 697a 6174 696f 6e20 7472 6961 6c73  imization trials
+0001cfd0: 2063 6f6e 6669 6775 7265 642c 2073 6574   configured, set
+0001cfe0: 206e 5f69 7465 7220 3e20 3021 2729 0a0a   n_iter > 0!')..
+0001cff0: 2020 2020 6966 2063 6c66 203d 3d20 2772      if clf == 'r
+0001d000: 6627 206f 7220 636c 6620 3d3d 2027 7867  f' or clf == 'xg
+0001d010: 6227 206f 7220 636c 6620 3d3d 2027 6e6e  b' or clf == 'nn
+0001d020: 273a 0a20 2020 2020 2020 2063 7620 3d20  ':.        cv = 
+0001d030: 6372 6f73 735f 7661 6c69 6461 7465 286d  cross_validate(m
+0001d040: 6f64 656c 5f30 2c20 6461 7461 5f78 2c20  odel_0, data_x, 
+0001d050: 6461 7461 5f79 2c20 6376 3d6f 7074 5f63  data_y, cv=opt_c
+0001d060: 7629 0a20 2020 2020 2020 2069 6e69 7469  v).        initi
+0001d070: 616c 5f73 636f 7265 203d 206e 702e 6d65  al_score = np.me
+0001d080: 616e 2863 765b 2774 6573 745f 7363 6f72  an(cv['test_scor
+0001d090: 6527 5d29 0a0a 2020 2020 7361 6d70 6c65  e'])..    sample
+0001d0a0: 7220 3d20 6f70 7475 6e61 2e73 616d 706c  r = optuna.sampl
+0001d0b0: 6572 732e 5450 4553 616d 706c 6572 2873  ers.TPESampler(s
+0001d0c0: 6565 643d 3139 3039 290a 2020 2020 7374  eed=1909).    st
+0001d0d0: 7564 7920 3d20 6f70 7475 6e61 2e63 7265  udy = optuna.cre
+0001d0e0: 6174 655f 7374 7564 7928 6469 7265 6374  ate_study(direct
+0001d0f0: 696f 6e3d 276d 6178 696d 697a 6527 2c20  ion='maximize', 
+0001d100: 7361 6d70 6c65 723d 7361 6d70 6c65 7229  sampler=sampler)
+0001d110: 232c 2070 7275 6e65 723d 6f70 7475 6e61  #, pruner=optuna
+0001d120: 2e70 7275 6e65 7273 2e4d 6564 6961 6e50  .pruners.MedianP
+0001d130: 7275 6e65 7228 6e5f 7374 6172 7475 705f  runer(n_startup_
+0001d140: 7472 6961 6c73 3d35 2c20 6e5f 7761 726d  trials=5, n_warm
+0001d150: 7570 5f73 7465 7073 3d33 302c 2069 6e74  up_steps=30, int
+0001d160: 6572 7661 6c5f 7374 6570 733d 3130 2929  erval_steps=10))
+0001d170: 0a20 2020 2070 7269 6e74 2827 5374 6172  .    print('Star
+0001d180: 7469 6e67 2068 7970 6572 7061 7261 6d65  ting hyperparame
+0001d190: 7465 7220 6f70 7469 6d69 7a61 7469 6f6e  ter optimization
+0001d1a0: 2c20 7468 6973 2077 696c 6c20 7461 6b65  , this will take
+0001d1b0: 2061 2077 6869 6c65 2e2e 2e27 290a 0a20   a while...').. 
+0001d1c0: 2020 2023 4966 2062 696e 6172 7920 636c     #If binary cl
+0001d1d0: 6173 7369 6669 6361 7469 6f6e 2074 6173  assification tas
+0001d1e0: 6b2c 2063 616e 2064 6561 6c20 7769 7468  k, can deal with
+0001d1f0: 2069 6d62 616c 616e 6365 2063 6c61 7373   imbalance class
+0001d200: 6573 2077 6974 6820 7765 6967 6874 7320  es with weights 
+0001d210: 6879 7065 7270 6172 616d 6574 6572 0a20  hyperparameter. 
+0001d220: 2020 2069 6620 6c65 6e28 6e70 2e75 6e69     if len(np.uni
+0001d230: 7175 6528 6461 7461 5f79 2929 203d 3d20  que(data_y)) == 
+0001d240: 323a 0a20 2020 2020 2020 2069 6620 636c  2:.        if cl
+0001d250: 6620 3d3d 2027 7266 2720 6f72 2063 6c66  f == 'rf' or clf
+0001d260: 203d 3d20 2778 6762 2720 6f72 2063 6c66   == 'xgb' or clf
+0001d270: 203d 3d20 276e 6e27 3a0a 2020 2020 2020   == 'nn':.      
+0001d280: 2020 2020 2020 636f 756e 7465 7220 3d20        counter = 
+0001d290: 436f 756e 7465 7228 6461 7461 5f79 290a  Counter(data_y).
+0001d2a0: 2020 2020 2020 2020 2020 2020 6966 2063              if c
+0001d2b0: 6f75 6e74 6572 5b6e 702e 756e 6971 7565  ounter[np.unique
+0001d2c0: 2864 6174 615f 7929 5b30 5d5d 2021 3d20  (data_y)[0]] != 
+0001d2d0: 636f 756e 7465 725b 6e70 2e75 6e69 7175  counter[np.uniqu
+0001d2e0: 6528 6461 7461 5f79 295b 315d 5d3a 0a20  e(data_y)[1]]:. 
+0001d2f0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0001d300: 6620 6261 6c61 6e63 653a 0a20 2020 2020  f balance:.     
+0001d310: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0001d320: 7269 6e74 2827 556e 6261 6c61 6e63 6564  rint('Unbalanced
+0001d330: 2064 6174 6173 6574 2064 6574 6563 7465   dataset detecte
+0001d340: 642c 2077 696c 6c20 7472 6169 6e20 636c  d, will train cl
+0001d350: 6173 7369 6669 6572 2077 6974 6820 7765  assifier with we
+0001d360: 6967 6874 7321 2054 6f20 6469 7361 626c  ights! To disabl
+0001d370: 652c 2073 6574 2062 616c 616e 6365 3d46  e, set balance=F
+0001d380: 616c 7365 2729 0a20 2020 2020 2020 2020  alse').         
+0001d390: 2020 2020 2020 2020 2020 2069 6620 636c             if cl
+0001d3a0: 6620 3d3d 2027 7867 6227 3a0a 2020 2020  f == 'xgb':.    
+0001d3b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d3c0: 2020 2020 746f 7461 6c5f 6e65 6761 7469      total_negati
+0001d3d0: 7665 203d 206c 656e 286e 702e 7768 6572  ve = len(np.wher
+0001d3e0: 6528 6461 7461 5f79 203d 3d20 636f 756e  e(data_y == coun
+0001d3f0: 7465 722e 6d6f 7374 5f63 6f6d 6d6f 6e28  ter.most_common(
+0001d400: 3129 5b30 5d5b 305d 295b 305d 290a 2020  1)[0][0])[0]).  
+0001d410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d420: 2020 2020 2020 746f 7461 6c5f 706f 7369        total_posi
+0001d430: 7469 7665 203d 206c 656e 2864 6174 615f  tive = len(data_
+0001d440: 7929 202d 2074 6f74 616c 5f6e 6567 6174  y) - total_negat
+0001d450: 6976 650a 2020 2020 2020 2020 2020 2020  ive.            
+0001d460: 2020 2020 2020 2020 2020 2020 7361 6d70              samp
+0001d470: 6c65 5f77 6569 6768 7420 3d20 746f 7461  le_weight = tota
+0001d480: 6c5f 6e65 6761 7469 7665 202f 2074 6f74  l_negative / tot
+0001d490: 616c 5f70 6f73 6974 6976 650a 2020 2020  al_positive.    
+0001d4a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d4b0: 656c 6966 2063 6c66 203d 3d20 2772 6627  elif clf == 'rf'
+0001d4c0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0001d4d0: 2020 2020 2020 2020 2020 7361 6d70 6c65            sample
+0001d4e0: 5f77 6569 6768 7420 3d20 2762 616c 616e  _weight = 'balan
+0001d4f0: 6365 6427 0a20 2020 2020 2020 2020 2020  ced'.           
+0001d500: 2020 2020 2020 2020 2065 6c69 6620 636c           elif cl
+0001d510: 6620 3d3d 2027 6e6e 273a 0a20 2020 2020  f == 'nn':.     
+0001d520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d530: 2020 2070 7269 6e74 2827 5741 524e 494e     print('WARNIN
+0001d540: 473a 204d 4c50 436c 6173 7369 6669 6572  G: MLPClassifier
+0001d550: 2829 2064 6f65 7320 6e6f 7420 7375 7070  () does not supp
+0001d560: 6f72 7420 7361 6d70 6c65 2077 6569 6768  ort sample weigh
+0001d570: 7473 2e27 290a 2020 2020 2020 2020 2020  ts.').          
+0001d580: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+0001d590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d5a0: 7361 6d70 6c65 5f77 6569 6768 7420 3d20  sample_weight = 
+0001d5b0: 4e6f 6e65 0a20 2020 2020 2020 2020 2020  None.           
+0001d5c0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+0001d5d0: 2020 2020 2020 2073 616d 706c 655f 7765         sample_we
+0001d5e0: 6967 6874 203d 204e 6f6e 650a 2020 2020  ight = None.    
+0001d5f0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+0001d600: 2020 2020 2020 7072 696e 7428 2755 6e62        print('Unb
+0001d610: 616c 616e 6365 6420 6461 7461 7365 7420  alanced dataset 
+0001d620: 6465 7465 6374 6564 2062 7574 2074 6865  detected but the
+0001d630: 206f 7074 696d 697a 6174 696f 6e20 726f   optimization ro
+0001d640: 7574 696e 6520 646f 6573 206e 6f74 2063  utine does not c
+0001d650: 7572 7265 6e74 6c79 2073 7570 706f 7274  urrently support
+0001d660: 2077 6569 6768 7473 2e20 546f 2075 7365   weights. To use
+0001d670: 2074 6865 2077 6569 6768 7465 645f 6269   the weighted_bi
+0001d680: 6e61 7279 5f63 726f 7373 656e 7472 6f70  nary_crossentrop
+0001d690: 7920 6c6f 7373 2066 756e 6374 696f 6e2c  y loss function,
+0001d6a0: 206c 6f61 6420 7468 6520 6465 7369 7265   load the desire
+0001d6b0: 6420 6d6f 6465 6c20 6469 7265 6374 6c79  d model directly
+0001d6c0: 2061 6e64 2073 6574 206c 6f73 733d 2277   and set loss="w
+0001d6d0: 6569 6768 7465 645f 6269 6e61 7279 5f63  eighted_binary_c
+0001d6e0: 726f 7373 656e 7472 6f70 7922 2028 7265  rossentropy" (re
+0001d6f0: 6665 7220 746f 2074 6865 204d 6963 726f  fer to the Micro
+0001d700: 4c49 412e 636e 6e5f 6d6f 6465 6c20 4150  LIA.cnn_model AP
+0001d710: 4920 646f 6375 6d65 6e74 6174 696f 6e29  I documentation)
+0001d720: 2e27 290a 2020 2020 656c 7365 3a0a 2020  .').    else:.  
+0001d730: 2020 2020 2020 7361 6d70 6c65 5f77 6569        sample_wei
+0001d740: 6768 7420 3d20 4e6f 6e65 0a0a 2020 2020  ght = None..    
+0001d750: 6966 2063 6c66 203d 3d20 2772 6627 3a0a  if clf == 'rf':.
+0001d760: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+0001d770: 2020 2020 2020 2020 206f 626a 6563 7469           objecti
+0001d780: 7665 203d 206f 626a 6563 7469 7665 5f72  ve = objective_r
+0001d790: 6628 6461 7461 5f78 2c20 6461 7461 5f79  f(data_x, data_y
+0001d7a0: 2c20 6f70 745f 6376 3d6f 7074 5f63 7629  , opt_cv=opt_cv)
+0001d7b0: 0a20 2020 2020 2020 2020 2020 2073 7475  .            stu
+0001d7c0: 6479 2e6f 7074 696d 697a 6528 6f62 6a65  dy.optimize(obje
+0001d7d0: 6374 6976 652c 206e 5f74 7269 616c 733d  ctive, n_trials=
+0001d7e0: 6e5f 6974 6572 2c20 7368 6f77 5f70 726f  n_iter, show_pro
+0001d7f0: 6772 6573 735f 6261 723d 5472 7565 2923  gress_bar=True)#
+0001d800: 2c20 6763 5f61 6674 6572 5f74 7269 616c  , gc_after_trial
+0001d810: 3d54 7275 6529 0a20 2020 2020 2020 2020  =True).         
+0001d820: 2020 2070 6172 616d 7320 3d20 7374 7564     params = stud
+0001d830: 792e 6265 7374 5f74 7269 616c 2e70 6172  y.best_trial.par
+0001d840: 616d 730a 2020 2020 2020 2020 2020 2020  ams.            
+0001d850: 6d6f 6465 6c20 3d20 5261 6e64 6f6d 466f  model = RandomFo
+0001d860: 7265 7374 436c 6173 7369 6669 6572 286e  restClassifier(n
+0001d870: 5f65 7374 696d 6174 6f72 733d 7061 7261  _estimators=para
+0001d880: 6d73 5b27 6e5f 6573 7469 6d61 746f 7273  ms['n_estimators
+0001d890: 275d 2c20 6372 6974 6572 696f 6e3d 7061  '], criterion=pa
+0001d8a0: 7261 6d73 5b27 6372 6974 6572 696f 6e27  rams['criterion'
+0001d8b0: 5d2c 200a 2020 2020 2020 2020 2020 2020  ], .            
+0001d8c0: 2020 2020 6d61 785f 6465 7074 683d 7061      max_depth=pa
+0001d8d0: 7261 6d73 5b27 6d61 785f 6465 7074 6827  rams['max_depth'
+0001d8e0: 5d2c 206d 696e 5f73 616d 706c 6573 5f73  ], min_samples_s
+0001d8f0: 706c 6974 3d70 6172 616d 735b 276d 696e  plit=params['min
+0001d900: 5f73 616d 706c 6573 5f73 706c 6974 275d  _samples_split']
+0001d910: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+0001d920: 2020 206d 696e 5f73 616d 706c 6573 5f6c     min_samples_l
+0001d930: 6561 663d 7061 7261 6d73 5b27 6d69 6e5f  eaf=params['min_
+0001d940: 7361 6d70 6c65 735f 6c65 6166 275d 2c20  samples_leaf'], 
+0001d950: 6d61 785f 6665 6174 7572 6573 3d70 6172  max_features=par
+0001d960: 616d 735b 276d 6178 5f66 6561 7475 7265  ams['max_feature
+0001d970: 7327 5d2c 200a 2020 2020 2020 2020 2020  s'], .          
+0001d980: 2020 2020 2020 626f 6f74 7374 7261 703d        bootstrap=
+0001d990: 7061 7261 6d73 5b27 626f 6f74 7374 7261  params['bootstra
+0001d9a0: 7027 5d2c 2063 6c61 7373 5f77 6569 6768  p'], class_weigh
+0001d9b0: 743d 7361 6d70 6c65 5f77 6569 6768 742c  t=sample_weight,
+0001d9c0: 2072 616e 646f 6d5f 7374 6174 653d 3139   random_state=19
+0001d9d0: 3039 290a 2020 2020 2020 2020 6578 6365  09).        exce
+0001d9e0: 7074 3a0a 2020 2020 2020 2020 2020 2020  pt:.            
+0001d9f0: 7072 696e 7428 2746 6169 6c65 6420 746f  print('Failed to
+0001da00: 206f 7074 696d 697a 6520 7769 7468 204f   optimize with O
+0001da10: 7074 756e 612c 2073 7769 7463 6869 6e67  ptuna, switching
+0001da20: 206f 7665 7220 746f 2042 6179 6573 5365   over to BayesSe
+0001da30: 6172 6368 4356 2e2e 2e27 290a 2020 2020  archCV...').    
+0001da40: 2020 2020 2020 2020 7061 7261 6d73 203d          params =
+0001da50: 207b 0a20 2020 2020 2020 2020 2020 2020   {.             
+0001da60: 2020 2027 6372 6974 6572 696f 6e27 3a20     'criterion': 
+0001da70: 5b22 6769 6e69 222c 2022 656e 7472 6f70  ["gini", "entrop
+0001da80: 7922 5d2c 0a20 2020 2020 2020 2020 2020  y"],.           
+0001da90: 2020 2020 2027 6e5f 6573 7469 6d61 746f       'n_estimato
+0001daa0: 7273 273a 205b 696e 7428 7829 2066 6f72  rs': [int(x) for
+0001dab0: 2078 2069 6e20 6e70 2e6c 696e 7370 6163   x in np.linspac
+0001dac0: 6528 3530 2c31 3030 302c 206e 756d 3d32  e(50,1000, num=2
+0001dad0: 3029 5d2c 200a 2020 2020 2020 2020 2020  0)], .          
+0001dae0: 2020 2020 2020 276d 6178 5f66 6561 7475        'max_featu
+0001daf0: 7265 7327 3a20 5b64 6174 615f 782e 7368  res': [data_x.sh
+0001db00: 6170 655b 315d 2c20 2273 7172 7422 2c20  ape[1], "sqrt", 
+0001db10: 226c 6f67 3222 5d2c 0a20 2020 2020 2020  "log2"],.       
+0001db20: 2020 2020 2020 2020 2027 6d61 785f 6465           'max_de
+0001db30: 7074 6827 3a20 5b69 6e74 2878 2920 666f  pth': [int(x) fo
+0001db40: 7220 7820 696e 206e 702e 6c69 6e73 7061  r x in np.linspa
+0001db50: 6365 2835 2c35 302c 6e75 6d3d 3529 5d2c  ce(5,50,num=5)],
+0001db60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001db70: 2027 6d69 6e5f 7361 6d70 6c65 735f 7370   'min_samples_sp
+0001db80: 6c69 7427 3a20 5b33 2c34 2c36 2c37 2c38  lit': [3,4,6,7,8
+0001db90: 2c39 2c31 305d 2c0a 2020 2020 2020 2020  ,9,10],.        
+0001dba0: 2020 2020 2020 2020 276d 696e 5f73 616d          'min_sam
+0001dbb0: 706c 6573 5f6c 6561 6627 3a20 5b31 2c33  ples_leaf': [1,3
+0001dbc0: 2c35 2c37 2c39 2c31 305d 2c0a 2020 2020  ,5,7,9,10],.    
+0001dbd0: 2020 2020 2020 2020 2020 2020 276d 6178              'max
+0001dbe0: 5f6c 6561 665f 6e6f 6465 7327 3a20 5b69  _leaf_nodes': [i
+0001dbf0: 6e74 2878 2920 666f 7220 7820 696e 206e  nt(x) for x in n
+0001dc00: 702e 6c69 6e73 7061 6365 2832 2c32 3030  p.linspace(2,200
+0001dc10: 295d 2c0a 2020 2020 2020 2020 2020 2020  )],.            
+0001dc20: 2020 2020 2762 6f6f 7473 7472 6170 273a      'bootstrap':
+0001dc30: 205b 5472 7565 2c46 616c 7365 5d20 2020   [True,False]   
+0001dc40: 0a20 2020 2020 2020 2020 2020 207d 0a20  .            }. 
+0001dc50: 2020 2020 2020 2020 2020 2067 7320 3d20             gs = 
+0001dc60: 4261 7965 7353 6561 7263 6843 5628 6e5f  BayesSearchCV(n_
+0001dc70: 6974 6572 3d6e 5f69 7465 722c 2065 7374  iter=n_iter, est
+0001dc80: 696d 6174 6f72 3d6d 6f64 656c 5f30 2c20  imator=model_0, 
+0001dc90: 7365 6172 6368 5f73 7061 6365 733d 7061  search_spaces=pa
+0001dca0: 7261 6d73 2c20 0a20 2020 2020 2020 2020  rams, .         
+0001dcb0: 2020 2020 2020 206f 7074 696d 697a 6572         optimizer
+0001dcc0: 5f6b 7761 7267 733d 7b27 6261 7365 5f65  _kwargs={'base_e
+0001dcd0: 7374 696d 6174 6f72 273a 2027 5246 277d  stimator': 'RF'}
+0001dce0: 2c20 6376 3d6f 7074 5f63 7629 0a20 2020  , cv=opt_cv).   
+0001dcf0: 2020 2020 2020 2020 2067 732e 6669 7428           gs.fit(
+0001dd00: 6461 7461 5f78 2c20 6461 7461 5f79 290a  data_x, data_y).
+0001dd10: 2020 2020 2020 2020 2020 2020 6265 7374              best
+0001dd20: 5f65 7374 2c20 6265 7374 5f73 636f 7265  _est, best_score
+0001dd30: 203d 2067 732e 6265 7374 5f65 7374 696d   = gs.best_estim
+0001dd40: 6174 6f72 5f2c 206e 702e 726f 756e 6428  ator_, np.round(
+0001dd50: 6773 2e62 6573 745f 7363 6f72 655f 2c20  gs.best_score_, 
+0001dd60: 3429 0a20 2020 2020 2020 2020 2020 2070  4).            p
+0001dd70: 7269 6e74 2827 4869 6768 6573 7420 6d65  rint('Highest me
+0001dd80: 616e 2061 6363 7572 6163 793a 207b 7d27  an accuracy: {}'
+0001dd90: 2e66 6f72 6d61 7428 6265 7374 5f73 636f  .format(best_sco
+0001dda0: 7265 2929 0a20 2020 2020 2020 2020 2020  re)).           
+0001ddb0: 2072 6574 7572 6e20 6773 2e62 6573 745f   return gs.best_
+0001ddc0: 6573 7469 6d61 746f 725f 2c20 6773 2e62  estimator_, gs.b
+0001ddd0: 6573 745f 7061 7261 6d73 5f0a 0a20 2020  est_params_..   
+0001dde0: 2065 6c69 6620 636c 6620 3d3d 2027 6e6e   elif clf == 'nn
+0001ddf0: 273a 0a20 2020 2020 2020 2074 7279 3a0a  ':.        try:.
+0001de00: 2020 2020 2020 2020 2020 2020 6f62 6a65              obje
+0001de10: 6374 6976 6520 3d20 6f62 6a65 6374 6976  ctive = objectiv
+0001de20: 655f 6e6e 2864 6174 615f 782c 2064 6174  e_nn(data_x, dat
+0001de30: 615f 792c 206f 7074 5f63 763d 6f70 745f  a_y, opt_cv=opt_
+0001de40: 6376 290a 2020 2020 2020 2020 2020 2020  cv).            
+0001de50: 7374 7564 792e 6f70 7469 6d69 7a65 286f  study.optimize(o
+0001de60: 626a 6563 7469 7665 2c20 6e5f 7472 6961  bjective, n_tria
+0001de70: 6c73 3d6e 5f69 7465 722c 2073 686f 775f  ls=n_iter, show_
+0001de80: 7072 6f67 7265 7373 5f62 6172 3d54 7275  progress_bar=Tru
+0001de90: 6529 232c 2067 635f 6166 7465 725f 7472  e)#, gc_after_tr
+0001dea0: 6961 6c3d 5472 7565 290a 2020 2020 2020  ial=True).      
+0001deb0: 2020 2020 2020 7061 7261 6d73 203d 2073        params = s
+0001dec0: 7475 6479 2e62 6573 745f 7472 6961 6c2e  tudy.best_trial.
+0001ded0: 7061 7261 6d73 0a20 2020 2020 2020 2020  params.         
+0001dee0: 2020 206c 6179 6572 7320 3d20 5b70 6172     layers = [par
+0001def0: 616d 2066 6f72 2070 6172 616d 2069 6e20  am for param in 
+0001df00: 7061 7261 6d73 2069 6620 276e 5f75 6e69  params if 'n_uni
+0001df10: 7473 5f27 2069 6e20 7061 7261 6d5d 0a20  ts_' in param]. 
+0001df20: 2020 2020 2020 2020 2020 206c 6179 6572             layer
+0001df30: 7320 3d20 7475 706c 6528 7061 7261 6d73  s = tuple(params
+0001df40: 5b6c 6179 6572 5d20 666f 7220 6c61 7965  [layer] for laye
+0001df50: 7220 696e 206c 6179 6572 7329 0a20 2020  r in layers).   
+0001df60: 2020 2020 2020 2020 206d 6f64 656c 203d           model =
+0001df70: 204d 4c50 436c 6173 7369 6669 6572 2868   MLPClassifier(h
+0001df80: 6964 6465 6e5f 6c61 7965 725f 7369 7a65  idden_layer_size
+0001df90: 733d 7475 706c 6528 6c61 7965 7273 292c  s=tuple(layers),
+0001dfa0: 206c 6561 726e 696e 675f 7261 7465 5f69   learning_rate_i
+0001dfb0: 6e69 743d 7061 7261 6d73 5b27 6c65 6172  nit=params['lear
+0001dfc0: 6e69 6e67 5f72 6174 655f 696e 6974 275d  ning_rate_init']
+0001dfd0: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+0001dfe0: 2020 2061 6374 6976 6174 696f 6e3d 7061     activation=pa
+0001dff0: 7261 6d73 5b27 6163 7469 7661 7469 6f6e  rams['activation
+0001e000: 275d 2c20 6c65 6172 6e69 6e67 5f72 6174  '], learning_rat
+0001e010: 653d 7061 7261 6d73 5b27 6c65 6172 6e69  e=params['learni
+0001e020: 6e67 5f72 6174 6527 5d2c 2061 6c70 6861  ng_rate'], alpha
+0001e030: 3d70 6172 616d 735b 2761 6c70 6861 275d  =params['alpha']
+0001e040: 2c20 0a20 2020 2020 2020 2020 2020 2020  , .             
+0001e050: 2020 2062 6174 6368 5f73 697a 653d 7061     batch_size=pa
+0001e060: 7261 6d73 5b27 6261 7463 685f 7369 7a65  rams['batch_size
+0001e070: 275d 2c20 736f 6c76 6572 3d70 6172 616d  '], solver=param
+0001e080: 735b 2773 6f6c 7665 7227 5d2c 206d 6178  s['solver'], max
+0001e090: 5f69 7465 723d 3235 3030 2c20 7261 6e64  _iter=2500, rand
+0001e0a0: 6f6d 5f73 7461 7465 3d31 3930 3929 0a20  om_state=1909). 
+0001e0b0: 2020 2020 2020 2065 7863 6570 743a 0a20         except:. 
+0001e0c0: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+0001e0d0: 2827 4661 696c 6564 2074 6f20 6f70 7469  ('Failed to opti
+0001e0e0: 6d69 7a65 2077 6974 6820 4f70 7475 6e61  mize with Optuna
+0001e0f0: 2c20 7377 6974 6368 696e 6720 6f76 6572  , switching over
+0001e100: 2074 6f20 4261 7965 7353 6561 7263 6843   to BayesSearchC
+0001e110: 562e 2e2e 2729 0a20 2020 2020 2020 2020  V...').         
+0001e120: 2020 2070 6172 616d 7320 3d20 7b0a 2020     params = {.  
+0001e130: 2020 2020 2020 2020 2020 2020 2020 2768                'h
+0001e140: 6964 6465 6e5f 6c61 7965 725f 7369 7a65  idden_layer_size
+0001e150: 7327 3a20 5b28 3130 302c 292c 2835 302c  s': [(100,),(50,
+0001e160: 3130 302c 3530 292c 2837 352c 3530 2c32  100,50),(75,50,2
+0001e170: 3029 2c28 3135 302c 3130 302c 3530 292c  0),(150,100,50),
+0001e180: 2831 3230 2c38 302c 3430 292c 2831 3030  (120,80,40),(100
+0001e190: 2c35 302c 3330 295d 2c0a 2020 2020 2020  ,50,30)],.      
+0001e1a0: 2020 2020 2020 2020 2020 276c 6561 726e            'learn
+0001e1b0: 696e 675f 7261 7465 273a 205b 2763 6f6e  ing_rate': ['con
+0001e1c0: 7374 616e 7427 2c20 2769 6e76 7363 616c  stant', 'invscal
+0001e1d0: 696e 6727 2c20 2761 6461 7074 6976 6527  ing', 'adaptive'
+0001e1e0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+0001e1f0: 2020 2027 616c 7068 6127 3a20 5b30 2e30     'alpha': [0.0
+0001e200: 3030 3031 2c20 302e 355d 2c20 0a20 2020  0001, 0.5], .   
+0001e210: 2020 2020 2020 2020 2020 2020 2027 6163               'ac
+0001e220: 7469 7661 7469 6f6e 273a 205b 2774 616e  tivation': ['tan
+0001e230: 6827 2c20 276c 6f67 6973 7469 6327 2c20  h', 'logistic', 
+0001e240: 2772 656c 7527 5d2c 0a20 2020 2020 2020  'relu'],.       
+0001e250: 2020 2020 2020 2020 2027 736f 6c76 6572           'solver
+0001e260: 273a 205b 2773 6764 272c 2027 6164 616d  ': ['sgd', 'adam
+0001e270: 275d 2c0a 2020 2020 2020 2020 2020 2020  '],.            
+0001e280: 2020 2020 276d 6178 5f69 7465 7227 3a20      'max_iter': 
+0001e290: 5b31 3030 2c20 3135 302c 2032 3030 5d20  [100, 150, 200] 
+0001e2a0: 0a20 2020 2020 2020 2020 2020 207d 0a20  .            }. 
+0001e2b0: 2020 2020 2020 2020 2020 2067 7320 3d20             gs = 
+0001e2c0: 4261 7965 7353 6561 7263 6843 5628 6e5f  BayesSearchCV(n_
+0001e2d0: 6974 6572 3d6e 5f69 7465 722c 2065 7374  iter=n_iter, est
+0001e2e0: 696d 6174 6f72 3d6d 6f64 656c 5f30 2c20  imator=model_0, 
+0001e2f0: 7365 6172 6368 5f73 7061 6365 733d 7061  search_spaces=pa
+0001e300: 7261 6d73 2c20 6376 3d6f 7074 5f63 7629  rams, cv=opt_cv)
+0001e310: 0a20 2020 2020 2020 2020 2020 2067 732e  .            gs.
+0001e320: 6669 7428 6461 7461 5f78 2c20 6461 7461  fit(data_x, data
+0001e330: 5f79 290a 2020 2020 2020 2020 2020 2020  _y).            
+0001e340: 6265 7374 5f65 7374 2c20 6265 7374 5f73  best_est, best_s
+0001e350: 636f 7265 203d 2067 732e 6265 7374 5f65  core = gs.best_e
+0001e360: 7374 696d 6174 6f72 5f2c 206e 702e 726f  stimator_, np.ro
+0001e370: 756e 6428 6773 2e62 6573 745f 7363 6f72  und(gs.best_scor
+0001e380: 655f 2c20 3429 0a20 2020 2020 2020 2020  e_, 4).         
+0001e390: 2020 2070 7269 6e74 2827 4869 6768 6573     print('Highes
+0001e3a0: 7420 6d65 616e 2061 6363 7572 6163 793a  t mean accuracy:
+0001e3b0: 207b 7d27 2e66 6f72 6d61 7428 6265 7374   {}'.format(best
+0001e3c0: 5f73 636f 7265 2929 0a20 2020 2020 2020  _score)).       
+0001e3d0: 2020 2020 2072 6574 7572 6e20 6773 2e62       return gs.b
+0001e3e0: 6573 745f 6573 7469 6d61 746f 725f 2c20  est_estimator_, 
+0001e3f0: 6773 2e62 6573 745f 7061 7261 6d73 5f0a  gs.best_params_.
+0001e400: 2020 2020 2020 2020 2020 0a20 2020 2065            .    e
+0001e410: 6c69 6620 636c 6620 3d3d 2027 7867 6227  lif clf == 'xgb'
+0001e420: 3a0a 2020 2020 2020 2020 6f62 6a65 6374  :.        object
+0001e430: 6976 6520 3d20 6f62 6a65 6374 6976 655f  ive = objective_
+0001e440: 7867 6228 6461 7461 5f78 2c20 6461 7461  xgb(data_x, data
+0001e450: 5f79 2c20 6c69 6d69 745f 7365 6172 6368  _y, limit_search
+0001e460: 3d6c 696d 6974 5f73 6561 7263 682c 206f  =limit_search, o
+0001e470: 7074 5f63 763d 6f70 745f 6376 290a 2020  pt_cv=opt_cv).  
+0001e480: 2020 2020 2020 6966 206c 696d 6974 5f73        if limit_s
+0001e490: 6561 7263 683a 0a20 2020 2020 2020 2020  earch:.         
+0001e4a0: 2020 2070 7269 6e74 2827 4e4f 5445 3a20     print('NOTE: 
+0001e4b0: 546f 2065 7870 616e 6420 6879 7065 7270  To expand hyperp
+0001e4c0: 6172 616d 6574 6572 2073 6561 7263 6820  arameter search 
+0001e4d0: 7370 6163 652c 2073 6574 206c 696d 6974  space, set limit
+0001e4e0: 5f73 6561 7263 683d 4661 6c73 652c 2061  _search=False, a
+0001e4f0: 6c74 686f 7567 6820 7468 6973 2077 696c  lthough this wil
+0001e500: 6c20 696e 6372 6561 7365 2074 6865 206f  l increase the o
+0001e510: 7074 696d 697a 6174 696f 6e20 7469 6d65  ptimization time
+0001e520: 2073 6967 6e69 6669 6361 6e74 6c79 2e27   significantly.'
+0001e530: 290a 2020 2020 2020 2020 7374 7564 792e  ).        study.
+0001e540: 6f70 7469 6d69 7a65 286f 626a 6563 7469  optimize(objecti
+0001e550: 7665 2c20 6e5f 7472 6961 6c73 3d6e 5f69  ve, n_trials=n_i
+0001e560: 7465 722c 2073 686f 775f 7072 6f67 7265  ter, show_progre
+0001e570: 7373 5f62 6172 3d54 7275 6529 232c 2067  ss_bar=True)#, g
+0001e580: 635f 6166 7465 725f 7472 6961 6c3d 5472  c_after_trial=Tr
+0001e590: 7565 290a 2020 2020 2020 2020 7061 7261  ue).        para
+0001e5a0: 6d73 203d 2073 7475 6479 2e62 6573 745f  ms = study.best_
+0001e5b0: 7472 6961 6c2e 7061 7261 6d73 0a20 2020  trial.params.   
+0001e5c0: 2020 2020 2069 6620 6c69 6d69 745f 7365       if limit_se
+0001e5d0: 6172 6368 3a0a 2020 2020 2020 2020 2020  arch:.          
+0001e5e0: 2020 6966 2070 6172 616d 735b 2762 6f6f    if params['boo
+0001e5f0: 7374 6572 275d 203d 3d20 2764 6172 7427  ster'] == 'dart'
+0001e600: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0001e610: 2020 6d6f 6465 6c20 3d20 5847 4243 6c61    model = XGBCla
+0001e620: 7373 6966 6965 7228 626f 6f73 7465 723d  ssifier(booster=
+0001e630: 7061 7261 6d73 5b27 626f 6f73 7465 7227  params['booster'
+0001e640: 5d2c 2020 6e5f 6573 7469 6d61 746f 7273  ],  n_estimators
+0001e650: 3d70 6172 616d 735b 276e 5f65 7374 696d  =params['n_estim
+0001e660: 6174 6f72 7327 5d2c 2072 6567 5f6c 616d  ators'], reg_lam
+0001e670: 6264 613d 7061 7261 6d73 5b27 7265 675f  bda=params['reg_
+0001e680: 6c61 6d62 6461 275d 2c20 0a20 2020 2020  lambda'], .     
+0001e690: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+0001e6a0: 6567 5f61 6c70 6861 3d70 6172 616d 735b  eg_alpha=params[
+0001e6b0: 2772 6567 5f61 6c70 6861 275d 2c20 6d61  'reg_alpha'], ma
+0001e6c0: 785f 6465 7074 683d 7061 7261 6d73 5b27  x_depth=params['
+0001e6d0: 6d61 785f 6465 7074 6827 5d2c 2065 7461  max_depth'], eta
+0001e6e0: 3d70 6172 616d 735b 2765 7461 275d 2c20  =params['eta'], 
+0001e6f0: 6761 6d6d 613d 7061 7261 6d73 5b27 6761  gamma=params['ga
+0001e700: 6d6d 6127 5d2c 200a 2020 2020 2020 2020  mma'], .        
+0001e710: 2020 2020 2020 2020 2020 2020 6772 6f77              grow
+0001e720: 5f70 6f6c 6963 793d 7061 7261 6d73 5b27  _policy=params['
+0001e730: 6772 6f77 5f70 6f6c 6963 7927 5d2c 2073  grow_policy'], s
+0001e740: 616d 706c 655f 7479 7065 3d70 6172 616d  ample_type=param
+0001e750: 735b 2773 616d 706c 655f 7479 7065 275d  s['sample_type']
+0001e760: 2c20 6e6f 726d 616c 697a 655f 7479 7065  , normalize_type
+0001e770: 3d70 6172 616d 735b 276e 6f72 6d61 6c69  =params['normali
+0001e780: 7a65 5f74 7970 6527 5d2c 0a20 2020 2020  ze_type'],.     
+0001e790: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+0001e7a0: 6174 655f 6472 6f70 3d70 6172 616d 735b  ate_drop=params[
+0001e7b0: 2772 6174 655f 6472 6f70 275d 2c20 736b  'rate_drop'], sk
+0001e7c0: 6970 5f64 726f 703d 7061 7261 6d73 5b27  ip_drop=params['
+0001e7d0: 736b 6970 5f64 726f 7027 5d2c 2073 6361  skip_drop'], sca
+0001e7e0: 6c65 5f70 6f73 5f77 6569 6768 743d 7361  le_pos_weight=sa
+0001e7f0: 6d70 6c65 5f77 6569 6768 742c 2072 616e  mple_weight, ran
+0001e800: 646f 6d5f 7374 6174 653d 3139 3039 290a  dom_state=1909).
+0001e810: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+0001e820: 2070 6172 616d 735b 2762 6f6f 7374 6572   params['booster
+0001e830: 275d 203d 3d20 2767 6274 7265 6527 3a0a  '] == 'gbtree':.
+0001e840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e850: 6d6f 6465 6c20 3d20 5847 4243 6c61 7373  model = XGBClass
+0001e860: 6966 6965 7228 626f 6f73 7465 723d 7061  ifier(booster=pa
+0001e870: 7261 6d73 5b27 626f 6f73 7465 7227 5d2c  rams['booster'],
+0001e880: 2020 6e5f 6573 7469 6d61 746f 7273 3d70    n_estimators=p
+0001e890: 6172 616d 735b 276e 5f65 7374 696d 6174  arams['n_estimat
+0001e8a0: 6f72 7327 5d2c 2072 6567 5f6c 616d 6264  ors'], reg_lambd
+0001e8b0: 613d 7061 7261 6d73 5b27 7265 675f 6c61  a=params['reg_la
+0001e8c0: 6d62 6461 275d 2c20 0a20 2020 2020 2020  mbda'], .       
+0001e8d0: 2020 2020 2020 2020 2020 2020 2072 6567               reg
+0001e8e0: 5f61 6c70 6861 3d70 6172 616d 735b 2772  _alpha=params['r
+0001e8f0: 6567 5f61 6c70 6861 275d 2c20 6d61 785f  eg_alpha'], max_
+0001e900: 6465 7074 683d 7061 7261 6d73 5b27 6d61  depth=params['ma
+0001e910: 785f 6465 7074 6827 5d2c 2065 7461 3d70  x_depth'], eta=p
+0001e920: 6172 616d 735b 2765 7461 275d 2c20 6761  arams['eta'], ga
+0001e930: 6d6d 613d 7061 7261 6d73 5b27 6761 6d6d  mma=params['gamm
+0001e940: 6127 5d2c 200a 2020 2020 2020 2020 2020  a'], .          
+0001e950: 2020 2020 2020 2020 2020 6772 6f77 5f70            grow_p
+0001e960: 6f6c 6963 793d 7061 7261 6d73 5b27 6772  olicy=params['gr
+0001e970: 6f77 5f70 6f6c 6963 7927 5d2c 2073 7562  ow_policy'], sub
+0001e980: 7361 6d70 6c65 3d70 6172 616d 735b 2773  sample=params['s
+0001e990: 7562 7361 6d70 6c65 275d 2c20 7363 616c  ubsample'], scal
+0001e9a0: 655f 706f 735f 7765 6967 6874 3d73 616d  e_pos_weight=sam
+0001e9b0: 706c 655f 7765 6967 6874 2c20 7261 6e64  ple_weight, rand
+0001e9c0: 6f6d 5f73 7461 7465 3d31 3930 3929 0a20  om_state=1909). 
+0001e9d0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+0001e9e0: 2020 2020 2020 2020 2069 6620 7061 7261           if para
+0001e9f0: 6d73 5b27 626f 6f73 7465 7227 5d20 3d3d  ms['booster'] ==
+0001ea00: 2027 6461 7274 273a 0a20 2020 2020 2020   'dart':.       
+0001ea10: 2020 2020 2020 2020 206d 6f64 656c 203d           model =
+0001ea20: 2058 4742 436c 6173 7369 6669 6572 2862   XGBClassifier(b
+0001ea30: 6f6f 7374 6572 3d70 6172 616d 735b 2762  ooster=params['b
+0001ea40: 6f6f 7374 6572 275d 2c20 6e5f 6573 7469  ooster'], n_esti
+0001ea50: 6d61 746f 7273 3d70 6172 616d 735b 276e  mators=params['n
+0001ea60: 5f65 7374 696d 6174 6f72 7327 5d2c 2063  _estimators'], c
+0001ea70: 6f6c 7361 6d70 6c65 5f62 7974 7265 653d  olsample_bytree=
+0001ea80: 7061 7261 6d73 5b27 636f 6c73 616d 706c  params['colsampl
+0001ea90: 655f 6279 7472 6565 275d 2c20 0a20 2020  e_bytree'], .   
+0001eaa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eab0: 2072 6567 5f6c 616d 6264 613d 7061 7261   reg_lambda=para
+0001eac0: 6d73 5b27 7265 675f 6c61 6d62 6461 275d  ms['reg_lambda']
+0001ead0: 2c20 7265 675f 616c 7068 613d 7061 7261  , reg_alpha=para
+0001eae0: 6d73 5b27 7265 675f 616c 7068 6127 5d2c  ms['reg_alpha'],
+0001eaf0: 206d 6178 5f64 6570 7468 3d70 6172 616d   max_depth=param
+0001eb00: 735b 276d 6178 5f64 6570 7468 275d 2c20  s['max_depth'], 
+0001eb10: 6574 613d 7061 7261 6d73 5b27 6574 6127  eta=params['eta'
+0001eb20: 5d2c 2067 616d 6d61 3d70 6172 616d 735b  ], gamma=params[
+0001eb30: 2767 616d 6d61 275d 2c20 0a20 2020 2020  'gamma'], .     
+0001eb40: 2020 2020 2020 2020 2020 2020 2020 2067                 g
+0001eb50: 726f 775f 706f 6c69 6379 3d70 6172 616d  row_policy=param
+0001eb60: 735b 2767 726f 775f 706f 6c69 6379 275d  s['grow_policy']
+0001eb70: 2c20 7361 6d70 6c65 5f74 7970 653d 7061  , sample_type=pa
+0001eb80: 7261 6d73 5b27 7361 6d70 6c65 5f74 7970  rams['sample_typ
+0001eb90: 6527 5d2c 206e 6f72 6d61 6c69 7a65 5f74  e'], normalize_t
+0001eba0: 7970 653d 7061 7261 6d73 5b27 6e6f 726d  ype=params['norm
+0001ebb0: 616c 697a 655f 7479 7065 275d 2c72 6174  alize_type'],rat
+0001ebc0: 655f 6472 6f70 3d70 6172 616d 735b 2772  e_drop=params['r
+0001ebd0: 6174 655f 6472 6f70 275d 2c20 0a20 2020  ate_drop'], .   
+0001ebe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ebf0: 2073 6b69 705f 6472 6f70 3d70 6172 616d   skip_drop=param
+0001ec00: 735b 2773 6b69 705f 6472 6f70 275d 2c20  s['skip_drop'], 
+0001ec10: 6d69 6e5f 6368 696c 645f 7765 6967 6874  min_child_weight
+0001ec20: 3d70 6172 616d 735b 276d 696e 5f63 6869  =params['min_chi
+0001ec30: 6c64 5f77 6569 6768 7427 5d2c 206d 6178  ld_weight'], max
+0001ec40: 5f64 656c 7461 5f73 7465 703d 7061 7261  _delta_step=para
+0001ec50: 6d73 5b27 6d61 785f 6465 6c74 615f 7374  ms['max_delta_st
+0001ec60: 6570 275d 2c20 7375 6273 616d 706c 653d  ep'], subsample=
+0001ec70: 7061 7261 6d73 5b27 7375 6273 616d 706c  params['subsampl
+0001ec80: 6527 5d2c 0a20 2020 2020 2020 2020 2020  e'],.           
+0001ec90: 2020 2020 2020 2020 2073 6361 6c65 5f70           scale_p
+0001eca0: 6f73 5f77 6569 6768 743d 7361 6d70 6c65  os_weight=sample
+0001ecb0: 5f77 6569 6768 742c 2072 616e 646f 6d5f  _weight, random_
+0001ecc0: 7374 6174 653d 3139 3039 290a 2020 2020  state=1909).    
+0001ecd0: 2020 2020 2020 2020 656c 6966 2070 6172          elif par
+0001ece0: 616d 735b 2762 6f6f 7374 6572 275d 203d  ams['booster'] =
+0001ecf0: 3d20 2767 6274 7265 6527 3a0a 2020 2020  = 'gbtree':.    
+0001ed00: 2020 2020 2020 2020 2020 2020 6d6f 6465              mode
+0001ed10: 6c20 3d20 5847 4243 6c61 7373 6966 6965  l = XGBClassifie
+0001ed20: 7228 626f 6f73 7465 723d 7061 7261 6d73  r(booster=params
+0001ed30: 5b27 626f 6f73 7465 7227 5d2c 206e 5f65  ['booster'], n_e
+0001ed40: 7374 696d 6174 6f72 733d 7061 7261 6d73  stimators=params
+0001ed50: 5b27 6e5f 6573 7469 6d61 746f 7273 275d  ['n_estimators']
+0001ed60: 2c20 636f 6c73 616d 706c 655f 6279 7472  , colsample_bytr
+0001ed70: 6565 3d70 6172 616d 735b 2763 6f6c 7361  ee=params['colsa
+0001ed80: 6d70 6c65 5f62 7974 7265 6527 5d2c 200a  mple_bytree'], .
+0001ed90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eda0: 2020 2020 7265 675f 6c61 6d62 6461 3d70      reg_lambda=p
+0001edb0: 6172 616d 735b 2772 6567 5f6c 616d 6264  arams['reg_lambd
+0001edc0: 6127 5d2c 2072 6567 5f61 6c70 6861 3d70  a'], reg_alpha=p
+0001edd0: 6172 616d 735b 2772 6567 5f61 6c70 6861  arams['reg_alpha
+0001ede0: 275d 2c20 6d61 785f 6465 7074 683d 7061  '], max_depth=pa
+0001edf0: 7261 6d73 5b27 6d61 785f 6465 7074 6827  rams['max_depth'
+0001ee00: 5d2c 2065 7461 3d70 6172 616d 735b 2765  ], eta=params['e
+0001ee10: 7461 275d 2c20 6761 6d6d 613d 7061 7261  ta'], gamma=para
+0001ee20: 6d73 5b27 6761 6d6d 6127 5d2c 200a 2020  ms['gamma'], .  
+0001ee30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ee40: 2020 6772 6f77 5f70 6f6c 6963 793d 7061    grow_policy=pa
+0001ee50: 7261 6d73 5b27 6772 6f77 5f70 6f6c 6963  rams['grow_polic
+0001ee60: 7927 5d2c 2073 7562 7361 6d70 6c65 3d70  y'], subsample=p
+0001ee70: 6172 616d 735b 2773 7562 7361 6d70 6c65  arams['subsample
+0001ee80: 275d 2c20 6d69 6e5f 6368 696c 645f 7765  '], min_child_we
+0001ee90: 6967 6874 3d70 6172 616d 735b 276d 696e  ight=params['min
+0001eea0: 5f63 6869 6c64 5f77 6569 6768 7427 5d2c  _child_weight'],
+0001eeb0: 206d 6178 5f64 656c 7461 5f73 7465 703d   max_delta_step=
+0001eec0: 7061 7261 6d73 5b27 6d61 785f 6465 6c74  params['max_delt
+0001eed0: 615f 7374 6570 275d 2c0a 2020 2020 2020  a_step'],.      
+0001eee0: 2020 2020 2020 2020 2020 2020 2020 7363                sc
+0001eef0: 616c 655f 706f 735f 7765 6967 6874 3d73  ale_pos_weight=s
+0001ef00: 616d 706c 655f 7765 6967 6874 2c20 7261  ample_weight, ra
+0001ef10: 6e64 6f6d 5f73 7461 7465 3d31 3930 3929  ndom_state=1909)
+0001ef20: 0a20 2020 2020 2020 0a20 2020 2065 6c73  .       .    els
+0001ef30: 653a 0a20 2020 2020 2020 206f 626a 6563  e:.        objec
+0001ef40: 7469 7665 203d 206f 626a 6563 7469 7665  tive = objective
+0001ef50: 5f63 6e6e 2864 6174 615f 782c 2064 6174  _cnn(data_x, dat
+0001ef60: 615f 792c 2076 616c 5f70 6f73 6974 6976  a_y, val_positiv
+0001ef70: 653d 7661 6c5f 582c 2076 616c 5f6e 6567  e=val_X, val_neg
+0001ef80: 6174 6976 653d 7661 6c5f 592c 2069 6d67  ative=val_Y, img
+0001ef90: 5f6e 756d 5f63 6861 6e6e 656c 733d 696d  _num_channels=im
+0001efa0: 675f 6e75 6d5f 6368 616e 6e65 6c73 2c20  g_num_channels, 
+0001efb0: 636c 663d 636c 662c 200a 2020 2020 2020  clf=clf, .      
+0001efc0: 2020 2020 2020 6e6f 726d 616c 697a 653d        normalize=
+0001efd0: 6e6f 726d 616c 697a 652c 206d 696e 5f70  normalize, min_p
+0001efe0: 6978 656c 3d6d 696e 5f70 6978 656c 2c20  ixel=min_pixel, 
+0001eff0: 6d61 785f 7069 7865 6c3d 6d61 785f 7069  max_pixel=max_pi
+0001f000: 7865 6c2c 2070 6174 6965 6e63 653d 7061  xel, patience=pa
+0001f010: 7469 656e 6365 2c20 6d65 7472 6963 3d6d  tience, metric=m
+0001f020: 6574 7269 632c 206d 6574 7269 6332 3d6d  etric, metric2=m
+0001f030: 6574 7269 6332 2c20 6d65 7472 6963 333d  etric2, metric3=
+0001f040: 6d65 7472 6963 332c 2061 7665 7261 6765  metric3, average
+0001f050: 3d61 7665 7261 6765 2c20 200a 2020 2020  =average,  .    
+0001f060: 2020 2020 2020 2020 7465 7374 5f70 6f73          test_pos
+0001f070: 6974 6976 653d 7465 7374 5f70 6f73 6974  itive=test_posit
+0001f080: 6976 652c 2074 6573 745f 6e65 6761 7469  ive, test_negati
+0001f090: 7665 3d74 6573 745f 6e65 6761 7469 7665  ve=test_negative
+0001f0a0: 2c20 7465 7374 5f61 6363 5f74 6872 6573  , test_acc_thres
+0001f0b0: 686f 6c64 3d74 6573 745f 6163 635f 7468  hold=test_acc_th
+0001f0c0: 7265 7368 6f6c 642c 2070 6f73 745f 6d65  reshold, post_me
+0001f0d0: 7472 6963 3d70 6f73 745f 6d65 7472 6963  tric=post_metric
+0001f0e0: 2c20 6f70 745f 6d6f 6465 6c3d 6f70 745f  , opt_model=opt_
+0001f0f0: 6d6f 6465 6c2c 2062 6174 6368 5f73 697a  model, batch_siz
+0001f100: 655f 6d69 6e3d 6261 7463 685f 7369 7a65  e_min=batch_size
+0001f110: 5f6d 696e 2c20 6261 7463 685f 7369 7a65  _min, batch_size
+0001f120: 5f6d 6178 3d62 6174 6368 5f73 697a 655f  _max=batch_size_
+0001f130: 6d61 782c 200a 2020 2020 2020 2020 2020  max, .          
+0001f140: 2020 7472 6169 6e5f 6570 6f63 6873 3d74    train_epochs=t
+0001f150: 7261 696e 5f65 706f 6368 732c 206f 7074  rain_epochs, opt
+0001f160: 5f63 763d 6f70 745f 6376 2c20 6f70 745f  _cv=opt_cv, opt_
+0001f170: 6175 673d 6f70 745f 6175 672c 2062 6174  aug=opt_aug, bat
+0001f180: 6368 5f6d 696e 3d62 6174 6368 5f6d 696e  ch_min=batch_min
+0001f190: 2c20 6261 7463 685f 6d61 783d 6261 7463  , batch_max=batc
+0001f1a0: 685f 6d61 782c 2062 6174 6368 5f6f 7468  h_max, batch_oth
+0001f1b0: 6572 3d62 6174 6368 5f6f 7468 6572 2c20  er=batch_other, 
+0001f1c0: 6261 6c61 6e63 653d 6261 6c61 6e63 652c  balance=balance,
+0001f1d0: 2069 6d61 6765 5f73 697a 655f 6d69 6e3d   image_size_min=
+0001f1e0: 696d 6167 655f 7369 7a65 5f6d 696e 2c20  image_size_min, 
+0001f1f0: 696d 6167 655f 7369 7a65 5f6d 6178 3d69  image_size_max=i
+0001f200: 6d61 6765 5f73 697a 655f 6d61 782c 200a  mage_size_max, .
+0001f210: 2020 2020 2020 2020 2020 2020 7368 6966              shif
+0001f220: 743d 7368 6966 742c 206f 7074 5f6d 6178  t=shift, opt_max
+0001f230: 5f6d 696e 5f70 6978 3d6f 7074 5f6d 6178  _min_pix=opt_max
+0001f240: 5f6d 696e 5f70 6978 2c20 6f70 745f 6d61  _min_pix, opt_ma
+0001f250: 785f 6d61 785f 7069 783d 6f70 745f 6d61  x_max_pix=opt_ma
+0001f260: 785f 6d61 785f 7069 782c 2072 6f74 6174  x_max_pix, rotat
+0001f270: 696f 6e3d 726f 7461 7469 6f6e 2c20 686f  ion=rotation, ho
+0001f280: 7269 7a6f 6e74 616c 3d68 6f72 697a 6f6e  rizontal=horizon
+0001f290: 7461 6c2c 2076 6572 7469 6361 6c3d 7665  tal, vertical=ve
+0001f2a0: 7274 6963 616c 2c20 6d61 736b 5f73 697a  rtical, mask_siz
+0001f2b0: 653d 6d61 736b 5f73 697a 652c 206e 756d  e=mask_size, num
+0001f2c0: 5f6d 6173 6b73 3d6e 756d 5f6d 6173 6b73  _masks=num_masks
+0001f2d0: 2c20 736d 6f74 655f 7361 6d70 6c69 6e67  , smote_sampling
+0001f2e0: 3d73 6d6f 7465 5f73 616d 706c 696e 672c  =smote_sampling,
+0001f2f0: 200a 2020 2020 2020 2020 2020 2020 626c   .            bl
+0001f300: 656e 645f 6d61 783d 626c 656e 645f 6d61  end_max=blend_ma
+0001f310: 782c 206e 756d 5f69 6d61 6765 735f 746f  x, num_images_to
+0001f320: 5f62 6c65 6e64 3d6e 756d 5f69 6d61 6765  _blend=num_image
+0001f330: 735f 746f 5f62 6c65 6e64 2c20 626c 656e  s_to_blend, blen
+0001f340: 6469 6e67 5f66 756e 633d 626c 656e 6469  ding_func=blendi
+0001f350: 6e67 5f66 756e 632c 2062 6c65 6e64 5f6f  ng_func, blend_o
+0001f360: 7468 6572 3d62 6c65 6e64 5f6f 7468 6572  ther=blend_other
+0001f370: 2c20 7a6f 6f6d 5f72 616e 6765 3d7a 6f6f  , zoom_range=zoo
+0001f380: 6d5f 7261 6e67 652c 2073 6b65 775f 616e  m_range, skew_an
+0001f390: 676c 653d 736b 6577 5f61 6e67 6c65 2c0a  gle=skew_angle,.
+0001f3a0: 2020 2020 2020 2020 2020 2020 6c69 6d69              limi
+0001f3b0: 745f 7365 6172 6368 3d6c 696d 6974 5f73  t_search=limit_s
+0001f3c0: 6561 7263 682c 206d 6f6e 6974 6f72 313d  earch, monitor1=
+0001f3d0: 6d6f 6e69 746f 7231 2c20 6d6f 6e69 746f  monitor1, monito
+0001f3e0: 7232 3d6d 6f6e 6974 6f72 322c 206d 6f6e  r2=monitor2, mon
+0001f3f0: 6974 6f72 315f 7468 7265 7368 3d6d 6f6e  itor1_thresh=mon
+0001f400: 6974 6f72 315f 7468 7265 7368 2c20 6d6f  itor1_thresh, mo
+0001f410: 6e69 746f 7232 5f74 6872 6573 683d 6d6f  nitor2_thresh=mo
+0001f420: 6e69 746f 7232 5f74 6872 6573 682c 2076  nitor2_thresh, v
+0001f430: 6572 626f 7365 3d76 6572 626f 7365 2920  erbose=verbose) 
+0001f440: 2020 2020 200a 2020 2020 2020 2020 2373       .        #s
+0001f450: 7475 6479 5f73 746f 705f 6362 203d 2053  tudy_stop_cb = S
+0001f460: 746f 7057 6865 6e54 7269 616c 4b65 6570  topWhenTrialKeep
+0001f470: 4265 696e 6750 7275 6e65 6443 616c 6c62  BeingPrunedCallb
+0001f480: 6163 6b28 7072 756e 655f 7468 7265 7368  ack(prune_thresh
+0001f490: 6f6c 6429 0a20 2020 2020 2020 2073 7475  old).        stu
+0001f4a0: 6479 2e6f 7074 696d 697a 6528 6f62 6a65  dy.optimize(obje
+0001f4b0: 6374 6976 652c 206e 5f74 7269 616c 733d  ctive, n_trials=
+0001f4c0: 6e5f 6974 6572 2c20 7368 6f77 5f70 726f  n_iter, show_pro
+0001f4d0: 6772 6573 735f 6261 723d 5472 7565 2c20  gress_bar=True, 
+0001f4e0: 6763 5f61 6674 6572 5f74 7269 616c 3d54  gc_after_trial=T
+0001f4f0: 7275 6529 2320 6361 6c6c 6261 636b 733d  rue)# callbacks=
+0001f500: 5b73 7475 6479 5f73 746f 705f 6362 5d29  [study_stop_cb])
+0001f510: 2c20 6e5f 6a6f 6273 3d31 290a 2020 2020  , n_jobs=1).    
+0001f520: 2020 2020 7061 7261 6d73 203d 2073 7475      params = stu
+0001f530: 6479 2e62 6573 745f 7472 6961 6c2e 7061  dy.best_trial.pa
+0001f540: 7261 6d73 0a0a 2020 2020 6669 6e61 6c5f  rams..    final_
+0001f550: 7363 6f72 6520 3d20 7374 7564 792e 6265  score = study.be
+0001f560: 7374 5f76 616c 7565 0a0a 2020 2020 6966  st_value..    if
+0001f570: 2063 6c66 203d 3d20 2772 6627 206f 7220   clf == 'rf' or 
+0001f580: 636c 6620 3d3d 2027 7867 6227 206f 7220  clf == 'xgb' or 
+0001f590: 636c 6620 3d3d 2027 6e6e 273a 0a20 2020  clf == 'nn':.   
+0001f5a0: 2020 2020 2069 6620 696e 6974 6961 6c5f       if initial_
+0001f5b0: 7363 6f72 6520 3e20 6669 6e61 6c5f 7363  score > final_sc
+0001f5c0: 6f72 653a 0a20 2020 2020 2020 2020 2020  ore:.           
+0001f5d0: 2070 7269 6e74 2827 4879 7065 7270 6172   print('Hyperpar
+0001f5e0: 616d 6574 6572 206f 7074 696d 697a 6174  ameter optimizat
+0001f5f0: 696f 6e20 636f 6d70 6c65 7465 2120 4f70  ion complete! Op
+0001f600: 7469 6d61 6c20 7065 7266 6f72 6d61 6e63  timal performanc
+0001f610: 6520 6f66 207b 7d20 6973 204c 4f57 4552  e of {} is LOWER
+0001f620: 2074 6861 6e20 7468 6520 6261 7365 2070   than the base p
+0001f630: 6572 666f 726d 616e 6365 206f 6620 7b7d  erformance of {}
+0001f640: 2c20 7472 7920 696e 6372 6561 7369 6e67  , try increasing
+0001f650: 2074 6865 2076 616c 7565 206f 6620 6e5f   the value of n_
+0001f660: 6974 6572 2061 6e64 2072 756e 2061 6761  iter and run aga
+0001f670: 696e 2e27 2e66 6f72 6d61 7428 6e70 2e72  in.'.format(np.r
+0001f680: 6f75 6e64 2866 696e 616c 5f73 636f 7265  ound(final_score
+0001f690: 2c20 3829 2c20 6e70 2e72 6f75 6e64 2869  , 8), np.round(i
+0001f6a0: 6e69 7469 616c 5f73 636f 7265 2c20 3829  nitial_score, 8)
+0001f6b0: 2929 0a20 2020 2020 2020 2065 6c73 653a  )).        else:
+0001f6c0: 0a20 2020 2020 2020 2020 2020 2070 7269  .            pri
+0001f6d0: 6e74 2827 4879 7065 7270 6172 616d 6574  nt('Hyperparamet
+0001f6e0: 6572 206f 7074 696d 697a 6174 696f 6e20  er optimization 
+0001f6f0: 636f 6d70 6c65 7465 2120 4f70 7469 6d61  complete! Optima
+0001f700: 6c20 7065 7266 6f72 6d61 6e63 6520 6f66  l performance of
+0001f710: 207b 7d20 6973 2048 4947 4845 5220 7468   {} is HIGHER th
+0001f720: 616e 2074 6865 2062 6173 6520 7065 7266  an the base perf
+0001f730: 6f72 6d61 6e63 6520 6f66 207b 7d2e 272e  ormance of {}.'.
+0001f740: 666f 726d 6174 286e 702e 726f 756e 6428  format(np.round(
+0001f750: 6669 6e61 6c5f 7363 6f72 652c 2038 292c  final_score, 8),
+0001f760: 206e 702e 726f 756e 6428 696e 6974 6961   np.round(initia
+0001f770: 6c5f 7363 6f72 652c 2038 2929 290a 2020  l_score, 8))).  
+0001f780: 2020 2020 2020 6966 2072 6574 7572 6e5f        if return_
+0001f790: 7374 7564 793a 0a20 2020 2020 2020 2020  study:.         
+0001f7a0: 2020 2072 6574 7572 6e20 6d6f 6465 6c2c     return model,
+0001f7b0: 2070 6172 616d 732c 2073 7475 6479 0a20   params, study. 
+0001f7c0: 2020 2020 2020 2072 6574 7572 6e20 6d6f         return mo
+0001f7d0: 6465 6c2c 2070 6172 616d 730a 2020 2020  del, params.    
+0001f7e0: 656c 7365 3a0a 2020 2020 2020 2020 7072  else:.        pr
+0001f7f0: 696e 7428 2748 7970 6572 7061 7261 6d65  int('Hyperparame
+0001f800: 7465 7220 6f70 7469 6d69 7a61 7469 6f6e  ter optimization
+0001f810: 2063 6f6d 706c 6574 6521 204f 7074 696d   complete! Optim
+0001f820: 616c 2070 6572 666f 726d 616e 6365 3a20  al performance: 
+0001f830: 7b7d 272e 666f 726d 6174 286e 702e 726f  {}'.format(np.ro
+0001f840: 756e 6428 6669 6e61 6c5f 7363 6f72 652c  und(final_score,
+0001f850: 2038 2929 290a 2020 2020 2020 2020 6966   8))).        if
+0001f860: 2072 6574 7572 6e5f 7374 7564 793a 0a20   return_study:. 
+0001f870: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+0001f880: 6e20 7061 7261 6d73 2c20 7374 7564 790a  n params, study.
+0001f890: 2020 2020 2020 2020 7265 7475 726e 2070          return p
+0001f8a0: 6172 616d 730a 0a64 6566 2062 6f72 7574  arams..def borut
+0001f8b0: 6173 6861 705f 6f70 7428 6461 7461 5f78  ashap_opt(data_x
+0001f8c0: 2c20 6461 7461 5f79 2c20 626f 7275 7461  , data_y, boruta
+0001f8d0: 5f74 7269 616c 733d 3530 2c20 6d6f 6465  _trials=50, mode
+0001f8e0: 6c3d 2772 6627 2c20 696d 706f 7274 616e  l='rf', importan
+0001f8f0: 6365 5f74 7970 653d 2767 6169 6e27 293a  ce_type='gain'):
+0001f900: 0a20 2020 2022 2222 0a20 2020 2041 7070  .    """.    App
+0001f910: 6c69 6573 2061 2063 6f6d 6269 6e61 7469  lies a combinati
+0001f920: 6f6e 206f 6620 7468 6520 426f 7275 7461  on of the Boruta
+0001f930: 2061 6c67 6f72 6974 686d 2061 6e64 0a20   algorithm and. 
+0001f940: 2020 2053 6861 706c 6579 2076 616c 7565     Shapley value
+0001f950: 732c 2061 206d 6574 686f 6420 6465 7665  s, a method deve
+0001f960: 6c6f 7065 6420 6279 2045 6f67 6861 6e20  loped by Eoghan 
+0001f970: 4b65 616e 7920 2832 3032 3029 2e0a 0a20  Keany (2020)... 
+0001f980: 2020 2053 6565 3a20 6874 7470 733a 2f2f     See: https://
+0001f990: 646f 692e 6f72 672f 3130 2e35 3238 312f  doi.org/10.5281/
+0001f9a0: 7a65 6e6f 646f 2e34 3234 3736 3138 0a0a  zenodo.4247618..
+0001f9b0: 2020 2020 4172 6773 3a0a 2020 2020 2020      Args:.      
+0001f9c0: 2020 6461 7461 5f78 2028 6e64 6172 7261    data_x (ndarra
+0001f9d0: 7929 3a20 3244 2061 7272 6179 206f 6620  y): 2D array of 
+0001f9e0: 7369 7a65 2028 6e20 7820 6d29 2c20 7768  size (n x m), wh
+0001f9f0: 6572 6520 6e20 6973 2074 6865 0a20 2020  ere n is the.   
+0001fa00: 2020 2020 2020 2020 206e 756d 6265 7220           number 
+0001fa10: 6f66 2073 616d 706c 6573 2c20 616e 6420  of samples, and 
+0001fa20: 6d20 7468 6520 6e75 6d62 6572 206f 6620  m the number of 
+0001fa30: 6665 6174 7572 6573 2e0a 2020 2020 2020  features..      
+0001fa40: 2020 6461 7461 5f79 2028 6e64 6172 7261    data_y (ndarra
+0001fa50: 792c 2073 7472 293a 2031 4420 6172 7261  y, str): 1D arra
+0001fa60: 7920 636f 6e74 6169 6e69 6e67 2074 6865  y containing the
+0001fa70: 2063 6f72 7265 7370 6f6e 696e 6720 6c61   corresponing la
+0001fa80: 6265 6c73 2e0a 2020 2020 2020 2020 626f  bels..        bo
+0001fa90: 7275 7461 5f74 7269 616c 7320 2869 6e74  ruta_trials (int
+0001faa0: 293a 2054 6865 206e 756d 6265 7220 6f66  ): The number of
+0001fab0: 2074 7269 616c 7320 746f 2072 756e 2e20   trials to run. 
+0001fac0: 4120 6c61 7267 6572 206e 756d 6265 7220  A larger number 
+0001fad0: 6973 0a20 2020 2020 2020 2020 2020 2062  is.            b
+0001fae0: 6574 7465 7220 6173 2074 6865 2064 6973  etter as the dis
+0001faf0: 7472 6962 7574 696f 6e20 7769 6c6c 2062  tribution will b
+0001fb00: 6520 6d6f 7265 2072 6f62 7573 7420 746f  e more robust to
+0001fb10: 2072 616e 646f 6d20 666c 7563 7475 6174   random fluctuat
+0001fb20: 696f 6e73 2e20 0a20 2020 2020 2020 2020  ions. .         
+0001fb30: 2020 2044 6566 6175 6c74 7320 746f 2035     Defaults to 5
+0001fb40: 302e 0a20 2020 2020 2020 206d 6f64 656c  0..        model
+0001fb50: 2028 7374 7229 3a20 5468 6520 656e 7365   (str): The ense
+0001fb60: 6d62 6c65 206d 6574 686f 6420 746f 2075  mble method to u
+0001fb70: 7365 2077 6865 6e20 6669 7474 696e 6720  se when fitting 
+0001fb80: 616e 6420 6361 6c63 756c 6174 696e 670a  and calculating.
+0001fb90: 2020 2020 2020 2020 2020 2020 7468 6520              the 
+0001fba0: 6665 6174 7572 6520 696d 706f 7274 616e  feature importan
+0001fbb0: 6365 206d 6574 7269 632e 204f 6e6c 7920  ce metric. Only 
+0001fbc0: 7477 6f20 6f70 7469 6f6e 7320 6172 6520  two options are 
+0001fbd0: 6375 7272 656e 746c 790a 2020 2020 2020  currently.      
+0001fbe0: 2020 2020 2020 7375 7070 6f72 7465 642c        supported,
+0001fbf0: 2027 7266 2720 666f 7220 5261 6e64 6f6d   'rf' for Random
+0001fc00: 2046 6f72 6573 7420 616e 6420 2778 6762   Forest and 'xgb
+0001fc10: 2720 666f 7220 4578 7472 656d 6520 4772  ' for Extreme Gr
+0001fc20: 6164 6965 6e74 2042 6f6f 7374 696e 672e  adient Boosting.
+0001fc30: 0a20 2020 2020 2020 2020 2020 2044 6566  .            Def
+0001fc40: 6175 6c74 7320 746f 2027 7266 272e 0a20  aults to 'rf'.. 
+0001fc50: 2020 2020 2020 2069 6d70 6f72 7461 6e63         importanc
+0001fc60: 655f 7479 7065 2028 7374 7229 3a20 5468  e_type (str): Th
+0001fc70: 6520 6665 6174 7572 6520 696d 706f 7274  e feature import
+0001fc80: 616e 6365 2074 7970 6520 746f 2075 7365  ance type to use
+0001fc90: 2c20 6f6e 6c79 2061 7070 6c69 6361 626c  , only applicabl
+0001fca0: 650a 2020 2020 2020 2020 2020 2020 7768  e.            wh
+0001fcb0: 656e 2075 7369 6e67 2063 6c66 3d27 7867  en using clf='xg
+0001fcc0: 6227 2e20 5468 6520 6f70 7469 6f6e 7320  b'. The options 
+0001fcd0: 696e 636c 7564 6520 e280 9c67 6169 6ee2  include ...gain.
+0001fce0: 809d 2c20 e280 9c77 6569 6768 74e2 809d  .., ...weight...
+0001fcf0: 2c20 e280 9c63 6f76 6572 e280 9d2c 0a20  , ...cover...,. 
+0001fd00: 2020 2020 2020 2020 2020 20e2 809c 746f             ...to
+0001fd10: 7461 6c5f 6761 696e e280 9d20 6f72 20e2  tal_gain... or .
+0001fd20: 809c 746f 7461 6c5f 636f 7665 72e2 809d  ..total_cover...
+0001fd30: 2e20 4465 6661 756c 7473 2074 6f20 2767  . Defaults to 'g
+0001fd40: 6169 6e27 2e0a 0a20 2020 2052 6574 7572  ain'...    Retur
+0001fd50: 6e73 3a0a 2020 2020 2020 2020 4669 7273  ns:.        Firs
+0001fd60: 7420 6f75 7470 7574 2069 7320 6120 3144  t output is a 1D
+0001fd70: 2061 7272 6179 2063 6f6e 7461 696e 696e   array containin
+0001fd80: 6720 7468 6520 696e 6469 6365 7320 6f66  g the indices of
+0001fd90: 2074 6865 2073 656c 6563 7465 6420 6665   the selected fe
+0001fda0: 6174 7572 6573 2e20 0a20 2020 2020 2020  atures. .       
+0001fdb0: 2054 6865 7365 2069 6e64 6963 6573 2063   These indices c
+0001fdc0: 616e 2074 6865 6e20 6265 2075 7365 6420  an then be used 
+0001fdd0: 746f 2073 656c 6563 7420 7468 6520 636f  to select the co
+0001fde0: 6c75 6d6e 7320 696e 2074 6865 2064 6174  lumns in the dat
+0001fdf0: 615f 7820 6172 7261 792e 0a20 2020 2020  a_x array..     
+0001fe00: 2020 2053 6563 6f6e 6420 6f75 7470 7574     Second output
+0001fe10: 2069 7320 7468 6520 6665 6174 7572 6520   is the feature 
+0001fe20: 7365 6c65 6374 696f 6e20 6f62 6a65 6374  selection object
+0001fe30: 2c20 7768 6963 6820 636f 6e74 6169 6e73  , which contains
+0001fe40: 2066 6561 7475 7265 2073 656c 6563 7469   feature selecti
+0001fe50: 6f6e 0a20 2020 2020 2020 2068 6973 746f  on.        histo
+0001fe60: 7279 2069 6e66 6f72 6d61 7469 6f6e 2061  ry information a
+0001fe70: 6e64 2076 6973 7561 6c69 7a61 7469 6f6e  nd visualization
+0001fe80: 206f 7074 696f 6e73 2e0a 2020 2020 2222   options..    ""
+0001fe90: 220a 2020 2020 0a20 2020 2069 6620 626f  ".    .    if bo
+0001fea0: 7275 7461 5f74 7269 616c 7320 3d3d 2030  ruta_trials == 0
+0001feb0: 3a20 2354 6869 7320 6973 2074 6865 2066  : #This is the f
+0001fec0: 6c61 6720 7468 6174 2074 6865 2065 6e73  lag that the ens
+0001fed0: 656d 626c 655f 6d6f 6465 6c2e 436c 6173  emble_model.Clas
+0001fee0: 7369 6669 6572 2063 6c61 7373 2075 7365  sifier class use
+0001fef0: 7320 746f 2064 6973 6162 6c65 2066 6561  s to disable fea
+0001ff00: 7475 7265 2073 656c 6563 7469 6f6e 0a20  ture selection. 
+0001ff10: 2020 2020 2020 2072 6574 7572 6e20 6e70         return np
+0001ff20: 2e61 7261 6e67 6528 6461 7461 5f78 2e73  .arange(data_x.s
+0001ff30: 6861 7065 5b31 5d29 2c20 4e6f 6e65 0a0a  hape[1]), None..
+0001ff40: 2020 2020 6966 2062 6f72 7574 615f 7472      if boruta_tr
+0001ff50: 6961 6c73 203c 2032 303a 0a20 2020 2020  ials < 20:.     
+0001ff60: 2020 2070 7269 6e74 2827 5741 524e 494e     print('WARNIN
+0001ff70: 473a 2052 6573 756c 7473 2061 7265 2075  G: Results are u
+0001ff80: 6e73 7461 626c 6520 6966 2062 6f72 7574  nstable if borut
+0001ff90: 615f 7472 6961 6c73 2069 7320 746f 6f20  a_trials is too 
+0001ffa0: 6c6f 7721 2729 0a20 2020 2069 6620 6e70  low!').    if np
+0001ffb0: 2e61 6e79 286e 702e 6973 6e61 6e28 6461  .any(np.isnan(da
+0001ffc0: 7461 5f78 2929 3a0a 2020 2020 2020 2020  ta_x)):.        
+0001ffd0: 2370 7269 6e74 2827 4e61 4e20 7661 6c75  #print('NaN valu
+0001ffe0: 6573 2064 6574 6563 7465 642c 2061 7070  es detected, app
+0001fff0: 6c79 696e 6720 5374 7261 776d 616e 2069  lying Strawman i
+00020000: 6d70 7574 6174 696f 6e2e 2e2e 2729 0a20  mputation...'). 
+00020010: 2020 2020 2020 2064 6174 615f 7820 3d20         data_x = 
+00020020: 5374 7261 776d 616e 5f69 6d70 7574 6174  Strawman_imputat
+00020030: 696f 6e28 6461 7461 5f78 290a 0a20 2020  ion(data_x)..   
+00020040: 2069 6620 6d6f 6465 6c20 3d3d 2027 7266   if model == 'rf
+00020050: 273a 0a20 2020 2020 2020 2063 6c61 7373  ':.        class
+00020060: 6966 6965 7220 3d20 5261 6e64 6f6d 466f  ifier = RandomFo
+00020070: 7265 7374 436c 6173 7369 6669 6572 2872  restClassifier(r
+00020080: 616e 646f 6d5f 7374 6174 653d 3139 3039  andom_state=1909
+00020090: 290a 2020 2020 656c 6966 206d 6f64 656c  ).    elif model
+000200a0: 203d 3d20 2778 6762 273a 0a20 2020 2020   == 'xgb':.     
+000200b0: 2020 2063 6c61 7373 6966 6965 7220 3d20     classifier = 
+000200c0: 5847 4243 6c61 7373 6966 6965 7228 7472  XGBClassifier(tr
+000200d0: 6565 5f6d 6574 686f 643d 2765 7861 6374  ee_method='exact
+000200e0: 272c 206d 6178 5f64 6570 7468 3d32 302c  ', max_depth=20,
+000200f0: 2069 6d70 6f72 7461 6e63 655f 7479 7065   importance_type
+00020100: 3d69 6d70 6f72 7461 6e63 655f 7479 7065  =importance_type
+00020110: 2c20 7261 6e64 6f6d 5f73 7461 7465 3d31  , random_state=1
+00020120: 3930 3929 0a20 2020 2065 6c73 653a 0a20  909).    else:. 
+00020130: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+00020140: 7565 4572 726f 7228 274d 6f64 656c 2061  ueError('Model a
+00020150: 7267 756d 656e 7420 6d75 7374 2065 6974  rgument must eit
+00020160: 6865 7220 6265 2022 7266 2220 6f72 2022  her be "rf" or "
+00020170: 7867 6222 2e27 290a 2020 2020 0a20 2020  xgb".').    .   
+00020180: 2074 7279 3a0a 2020 2020 2020 2020 2342   try:.        #B
+00020190: 6f72 7574 6153 6861 7020 7072 6f67 7261  orutaShap progra
+000201a0: 6d20 7265 7175 6972 6573 2069 6e70 7574  m requires input
+000201b0: 2074 6f20 6861 7665 2074 6865 2063 6f6c   to have the col
+000201c0: 756d 6e73 2061 7474 7269 6275 7465 0a20  umns attribute. 
+000201d0: 2020 2020 2020 2023 436f 6e76 6572 7469         #Converti
+000201e0: 6e67 2074 6f20 5061 6e64 6173 2064 6174  ng to Pandas dat
+000201f0: 6166 7261 6d65 0a20 2020 2020 2020 2063  aframe.        c
+00020200: 6f6c 7320 3d20 5b73 7472 2869 2920 666f  ols = [str(i) fo
+00020210: 7220 6920 696e 206e 702e 6172 616e 6765  r i in np.arange
+00020220: 2864 6174 615f 782e 7368 6170 655b 315d  (data_x.shape[1]
+00020230: 295d 0a20 2020 2020 2020 2058 203d 2044  )].        X = D
+00020240: 6174 6146 7261 6d65 2864 6174 615f 782c  ataFrame(data_x,
+00020250: 2063 6f6c 756d 6e73 3d63 6f6c 7329 0a20   columns=cols). 
+00020260: 2020 2020 2020 2079 203d 206e 702e 7a65         y = np.ze
+00020270: 726f 7328 6c65 6e28 6461 7461 5f79 2929  ros(len(data_y))
+00020280: 0a0a 2020 2020 2020 2020 2342 656c 6f77  ..        #Below
+00020290: 2069 7320 746f 2063 6f6e 7665 7274 2063   is to convert c
+000202a0: 6174 6567 6f72 6963 616c 206c 6162 656c  ategorical label
+000202b0: 7320 746f 206e 756d 6572 6963 616c 2c20  s to numerical, 
+000202c0: 6173 2070 6572 2042 6f72 7574 6153 6861  as per BorutaSha
+000202d0: 7020 7265 7175 6972 656d 656e 7473 0a20  p requirements. 
+000202e0: 2020 2020 2020 2066 6f72 2069 2c20 6c61         for i, la
+000202f0: 6265 6c20 696e 2065 6e75 6d65 7261 7465  bel in enumerate
+00020300: 286e 702e 756e 6971 7565 2864 6174 615f  (np.unique(data_
+00020310: 7929 293a 0a20 2020 2020 2020 2020 2020  y)):.           
+00020320: 206d 6173 6b20 3d20 6e70 2e77 6865 7265   mask = np.where
+00020330: 2864 6174 615f 7920 3d3d 206c 6162 656c  (data_y == label
+00020340: 295b 305d 0a20 2020 2020 2020 2020 2020  )[0].           
+00020350: 2079 5b6d 6173 6b5d 203d 2069 0a0a 2020   y[mask] = i..  
+00020360: 2020 2020 2020 6665 6174 5f73 656c 6563        feat_selec
+00020370: 746f 7220 3d20 426f 7275 7461 5368 6170  tor = BorutaShap
+00020380: 286d 6f64 656c 3d63 6c61 7373 6966 6965  (model=classifie
+00020390: 722c 2069 6d70 6f72 7461 6e63 655f 6d65  r, importance_me
+000203a0: 6173 7572 653d 2773 6861 7027 2c20 636c  asure='shap', cl
+000203b0: 6173 7369 6669 6361 7469 6f6e 3d54 7275  assification=Tru
+000203c0: 6529 0a20 2020 2020 2020 2070 7269 6e74  e).        print
+000203d0: 2827 5275 6e6e 696e 6720 6665 6174 7572  ('Running featur
+000203e0: 6520 7365 6c65 6374 696f 6e2e 2e2e 2729  e selection...')
+000203f0: 0a20 2020 2020 2020 2066 6561 745f 7365  .        feat_se
+00020400: 6c65 6374 6f72 2e66 6974 2858 3d58 2c20  lector.fit(X=X, 
+00020410: 793d 792c 206e 5f74 7269 616c 733d 626f  y=y, n_trials=bo
+00020420: 7275 7461 5f74 7269 616c 732c 2076 6572  ruta_trials, ver
+00020430: 626f 7365 3d46 616c 7365 2c20 7261 6e64  bose=False, rand
+00020440: 6f6d 5f73 7461 7465 3d31 3930 3929 0a0a  om_state=1909)..
+00020450: 2020 2020 2020 2020 696e 6465 7820 3d20          index = 
+00020460: 6e70 2e61 7272 6179 285b 696e 7428 6665  np.array([int(fe
+00020470: 6174 2920 666f 7220 6665 6174 2069 6e20  at) for feat in 
+00020480: 6665 6174 5f73 656c 6563 746f 722e 6163  feat_selector.ac
+00020490: 6365 7074 6564 5d29 0a20 2020 2020 2020  cepted]).       
+000204a0: 2069 6e64 6578 2e73 6f72 7428 290a 2020   index.sort().  
+000204b0: 2020 2020 2020 7072 696e 7428 2746 6561        print('Fea
+000204c0: 7475 7265 2073 656c 6563 7469 6f6e 2063  ture selection c
+000204d0: 6f6d 706c 6574 652c 207b 7d20 7365 6c65  omplete, {} sele
+000204e0: 6374 6564 206f 7574 206f 6620 7b7d 2127  cted out of {}!'
+000204f0: 2e66 6f72 6d61 7428 6c65 6e28 696e 6465  .format(len(inde
+00020500: 7829 2c20 6461 7461 5f78 2e73 6861 7065  x), data_x.shape
+00020510: 5b31 5d29 290a 2020 2020 6578 6365 7074  [1])).    except
+00020520: 3a0a 2020 2020 2020 2020 7072 696e 7428  :.        print(
+00020530: 2742 6f72 7574 6120 7769 7468 2053 6861  'Boruta with Sha
+00020540: 706c 6579 2076 616c 7565 7320 6661 696c  pley values fail
+00020550: 6564 2c20 7377 6974 6368 696e 6720 746f  ed, switching to
+00020560: 206f 7269 6769 6e61 6c20 426f 7275 7461   original Boruta
+00020570: 2e2e 2e27 290a 2020 2020 2020 2020 696e  ...').        in
+00020580: 6465 7820 3d20 626f 7275 7461 5f6f 7074  dex = boruta_opt
+00020590: 2864 6174 615f 782c 2064 6174 615f 7929  (data_x, data_y)
+000205a0: 0a0a 2020 2020 7265 7475 726e 2069 6e64  ..    return ind
+000205b0: 6578 2c20 6665 6174 5f73 656c 6563 746f  ex, feat_selecto
+000205c0: 720a 0a64 6566 2062 6f72 7574 615f 6f70  r..def boruta_op
+000205d0: 7428 6461 7461 5f78 2c20 6461 7461 5f79  t(data_x, data_y
+000205e0: 293a 0a20 2020 2022 2222 0a20 2020 2041  ):.    """.    A
+000205f0: 7070 6c69 6573 2074 6865 2042 6f72 7574  pplies the Borut
+00020600: 6120 616c 676f 7269 7468 6d20 284b 7572  a algorithm (Kur
+00020610: 7361 2026 2052 7564 6e69 636b 6920 3230  sa & Rudnicki 20
+00020620: 3131 2920 746f 2069 6465 6e74 6966 7920  11) to identify 
+00020630: 6665 6174 7572 6573 0a20 2020 2074 6861  features.    tha
+00020640: 7420 7065 7266 6f72 6d20 776f 7273 6520  t perform worse 
+00020650: 7468 616e 2072 616e 646f 6d2e 0a0a 2020  than random...  
+00020660: 2020 5365 653a 2068 7474 7073 3a2f 2f61    See: https://a
+00020670: 7278 6976 2e6f 7267 2f70 6466 2f31 3130  rxiv.org/pdf/110
+00020680: 362e 3531 3132 2e70 6466 0a0a 2020 2020  6.5112.pdf..    
+00020690: 4172 6773 3a0a 2020 2020 2020 2020 6461  Args:.        da
+000206a0: 7461 5f78 2028 6e64 6172 7261 7929 3a20  ta_x (ndarray): 
+000206b0: 3244 2061 7272 6179 206f 6620 7369 7a65  2D array of size
+000206c0: 2028 6e20 7820 6d29 2c20 7768 6572 6520   (n x m), where 
+000206d0: 6e20 6973 2074 6865 0a20 2020 2020 2020  n is the.       
+000206e0: 2020 2020 206e 756d 6265 7220 6f66 2073       number of s
+000206f0: 616d 706c 6573 2c20 616e 6420 6d20 7468  amples, and m th
+00020700: 6520 6e75 6d62 6572 206f 6620 6665 6174  e number of feat
+00020710: 7572 6573 2e0a 2020 2020 2020 2020 6461  ures..        da
+00020720: 7461 5f79 2028 6e64 6172 7261 792c 2073  ta_y (ndarray, s
+00020730: 7472 293a 2031 4420 6172 7261 7920 636f  tr): 1D array co
+00020740: 6e74 6169 6e69 6e67 2074 6865 2063 6f72  ntaining the cor
+00020750: 7265 7370 6f6e 696e 6720 6c61 6265 6c73  responing labels
+00020760: 2e0a 2020 2020 2020 2020 2020 2020 0a20  ..            . 
+00020770: 2020 2052 6574 7572 6e73 3a0a 2020 2020     Returns:.    
+00020780: 2020 2020 3144 2061 7272 6179 2063 6f6e      1D array con
+00020790: 7461 696e 696e 6720 7468 6520 696e 6469  taining the indi
+000207a0: 6365 7320 6f66 2074 6865 2073 656c 6563  ces of the selec
+000207b0: 7465 6420 6665 6174 7572 6573 2e20 5468  ted features. Th
+000207c0: 6973 2063 616e 2074 6865 6e0a 2020 2020  is can then.    
+000207d0: 2020 2020 6265 2075 7365 6420 746f 2069      be used to i
+000207e0: 6e64 6578 2074 6865 2063 6f6c 756d 6e73  ndex the columns
+000207f0: 2069 6e20 7468 6520 6461 7461 5f78 2061   in the data_x a
+00020800: 7272 6179 2e0a 2020 2020 2222 220a 0a20  rray..    """.. 
+00020810: 2020 2063 6c61 7373 6966 6965 7220 3d20     classifier = 
+00020820: 5261 6e64 6f6d 466f 7265 7374 436c 6173  RandomForestClas
+00020830: 7369 6669 6572 2872 616e 646f 6d5f 7374  sifier(random_st
+00020840: 6174 653d 3139 3039 290a 0a20 2020 2066  ate=1909)..    f
+00020850: 6561 745f 7365 6c65 6374 6f72 203d 2042  eat_selector = B
+00020860: 6f72 7574 6150 7928 636c 6173 7369 6669  orutaPy(classifi
+00020870: 6572 2c20 6e5f 6573 7469 6d61 746f 7273  er, n_estimators
+00020880: 3d27 6175 746f 272c 2072 616e 646f 6d5f  ='auto', random_
+00020890: 7374 6174 653d 3139 3039 290a 2020 2020  state=1909).    
+000208a0: 7072 696e 7428 2752 756e 6e69 6e67 2066  print('Running f
+000208b0: 6561 7475 7265 2073 656c 6563 7469 6f6e  eature selection
+000208c0: 2e2e 2e27 290a 2020 2020 6665 6174 5f73  ...').    feat_s
+000208d0: 656c 6563 746f 722e 6669 7428 6461 7461  elector.fit(data
+000208e0: 5f78 2c20 6461 7461 5f79 290a 0a20 2020  _x, data_y)..   
+000208f0: 2066 6561 7473 203d 206e 702e 6172 7261   feats = np.arra
+00020900: 7928 5b73 7472 2866 6561 7429 2066 6f72  y([str(feat) for
+00020910: 2066 6561 7420 696e 2066 6561 745f 7365   feat in feat_se
+00020920: 6c65 6374 6f72 2e73 7570 706f 7274 5f5d  lector.support_]
+00020930: 290a 2020 2020 696e 6465 7820 3d20 6e70  ).    index = np
+00020940: 2e77 6865 7265 2866 6561 7473 203d 3d20  .where(feats == 
+00020950: 2754 7275 6527 295b 305d 0a0a 2020 2020  'True')[0]..    
+00020960: 7072 696e 7428 2746 6561 7475 7265 2073  print('Feature s
+00020970: 656c 6563 7469 6f6e 2063 6f6d 706c 6574  election complet
+00020980: 652c 207b 7d20 7365 6c65 6374 6564 206f  e, {} selected o
+00020990: 7574 206f 6620 7b7d 2127 2e66 6f72 6d61  ut of {}!'.forma
+000209a0: 7428 6c65 6e28 696e 6465 7829 2c6c 656e  t(len(index),len
+000209b0: 2866 6561 745f 7365 6c65 6374 6f72 2e73  (feat_selector.s
+000209c0: 7570 706f 7274 2929 290a 0a20 2020 2072  upport)))..    r
+000209d0: 6574 7572 6e20 696e 6465 780a 0a64 6566  eturn index..def
+000209e0: 2069 6d70 7574 655f 6d69 7373 696e 675f   impute_missing_
+000209f0: 7661 6c75 6573 2864 6174 612c 2069 6d70  values(data, imp
+00020a00: 7574 6572 3d4e 6f6e 652c 2073 7472 6174  uter=None, strat
+00020a10: 6567 793d 276b 6e6e 272c 206b 3d33 2c20  egy='knn', k=3, 
+00020a20: 636f 6e73 7461 6e74 5f76 616c 7565 3d30  constant_value=0
+00020a30: 293a 0a20 2020 2022 2222 0a20 2020 2049  ):.    """.    I
+00020a40: 6d70 7574 6520 6d69 7373 696e 6720 7661  mpute missing va
+00020a50: 6c75 6573 2069 6e20 7468 6520 696e 7075  lues in the inpu
+00020a60: 7420 6461 7461 2061 7272 6179 2075 7369  t data array usi
+00020a70: 6e67 2076 6172 696f 7573 2069 6d70 7574  ng various imput
+00020a80: 6174 696f 6e20 7374 7261 7465 6769 6573  ation strategies
+00020a90: 2e0a 2020 2020 4279 2064 6566 6175 6c74  ..    By default
+00020aa0: 2074 6865 2069 6d70 7574 6572 2077 696c   the imputer wil
+00020ab0: 6c20 6265 2063 7265 6174 6564 2061 6e64  l be created and
+00020ac0: 2072 6574 7572 6e65 642c 2075 6e6c 6573   returned, unles
+00020ad0: 730a 2020 2020 7468 6520 696d 7075 7465  s.    the impute
+00020ae0: 7220 6172 6775 6d65 6e74 2069 7320 7365  r argument is se
+00020af0: 742c 2069 6e20 7768 6963 6820 6361 7365  t, in which case
+00020b00: 206f 6e6c 7920 7468 6520 7472 616e 7366   only the transf
+00020b10: 6f72 6d65 640a 2020 2020 6461 7461 2069  ormed.    data i
+00020b20: 7320 6f75 7470 7574 2e20 0a0a 2020 2020  s output. ..    
+00020b30: 5468 6520 6675 6e63 7469 6f6e 2066 6972  The function fir
+00020b40: 7374 2069 6465 6e74 6966 6965 7320 7468  st identifies th
+00020b50: 6520 636f 6c75 6d6e 7320 7769 7468 206d  e columns with m
+00020b60: 6f73 746c 7920 6d69 7373 696e 6720 7661  ostly missing va
+00020b70: 6c75 6573 2062 6173 6564 206f 6e20 7468  lues based on th
+00020b80: 6520 6e61 6e5f 7468 7265 7368 6f6c 6420  e nan_threshold 
+00020b90: 7061 7261 6d65 7465 722e 200a 2020 2020  parameter. .    
+00020ba0: 4974 2072 6570 6c61 6365 7320 7468 6520  It replaces the 
+00020bb0: 7661 6c75 6573 2069 6e20 7468 6f73 6520  values in those 
+00020bc0: 636f 6c75 6d6e 7320 7769 7468 207a 6572  columns with zer
+00020bd0: 6f73 2062 6566 6f72 6520 7065 7266 6f72  os before perfor
+00020be0: 6d69 6e67 2074 6865 2069 6d70 7574 6174  ming the imputat
+00020bf0: 696f 6e20 7374 6570 2075 7369 6e67 2074  ion step using t
+00020c00: 6865 2073 656c 6563 7465 6420 0a20 2020  he selected .   
+00020c10: 2069 6d70 7574 6174 696f 6e20 7374 7261   imputation stra
+00020c20: 7465 6779 2e20 5468 6973 2077 6179 2c20  tegy. This way, 
+00020c30: 7468 6520 6967 6e6f 7265 6420 636f 6c75  the ignored colu
+00020c40: 6d6e 7320 7769 6c6c 2068 6176 6520 7a65  mns will have ze
+00020c50: 726f 7320 616e 6420 776f 6e27 7420 6265  ros and won't be
+00020c60: 2074 616b 656e 2069 6e74 6f20 6163 636f   taken into acco
+00020c70: 756e 7420 6475 7269 6e67 2069 6d70 7574  unt during imput
+00020c80: 6174 696f 6e2e 200a 2020 2020 5468 6520  ation. .    The 
+00020c90: 7265 7375 6c74 696e 6720 696d 7075 7465  resulting impute
+00020ca0: 645f 6461 7461 2077 696c 6c20 6861 7665  d_data will have
+00020cb0: 2061 6c6c 2063 6f6c 756d 6e73 2070 7265   all columns pre
+00020cc0: 7365 7276 6564 2c20 7769 7468 206d 6973  served, with mis
+00020cd0: 7369 6e67 2076 616c 7565 7320 6669 6c6c  sing values fill
+00020ce0: 6564 2061 6363 6f72 6469 6e67 2074 6f20  ed according to 
+00020cf0: 7468 6520 6368 6f73 656e 2069 6d70 7574  the chosen imput
+00020d00: 6174 696f 6e20 7374 7261 7465 6779 2e0a  ation strategy..
+00020d10: 2020 2020 5468 6973 2069 7320 7265 7175      This is requ
+00020d20: 6972 6564 2062 6563 6175 7365 2074 6865  ired because the
+00020d30: 2069 6d70 7574 6174 696f 6e20 7465 6368   imputation tech
+00020d40: 6e69 7175 6573 2065 6d70 6c6f 7965 6420  niques employed 
+00020d50: 7265 6d6f 7665 2063 6f6c 756d 6e73 2074  remove columns t
+00020d60: 6861 7420 6861 7665 2074 6f6f 206d 616e  hat have too man
+00020d70: 7920 6e61 6e73 210a 2020 2020 0a20 2020  y nans!.    .   
+00020d80: 204e 6f74 653a 0a20 2020 2020 2020 2041   Note:.        A
+00020d90: 7320 7468 6520 4b4e 4e20 696d 7075 7461  s the KNN imputa
+00020da0: 7469 6f6e 206d 6574 686f 6420 6275 6e64  tion method bund
+00020db0: 6c65 7320 6e65 6967 6862 6f72 7320 6163  les neighbors ac
+00020dc0: 636f 7264 696e 6720 746f 2074 6865 6972  cording to their
+00020dd0: 2065 7563 6c65 6469 616e 2064 6973 7461   eucledian dista
+00020de0: 6e63 652c 0a20 2020 2020 2020 2069 7420  nce,.        it 
+00020df0: 6973 2073 656e 7369 7469 7665 2074 6f20  is sensitive to 
+00020e00: 6f75 746c 6965 7273 2e20 4675 7274 6865  outliers. Furthe
+00020e10: 726d 6f72 652c 2069 7420 6361 6e20 616c  rmore, it can al
+00020e20: 736f 2079 6965 6c64 2077 6561 6b20 7072  so yield weak pr
+00020e30: 6564 6963 7469 6f6e 7320 6966 2074 6865  edictions if the
+00020e40: 0a20 2020 2020 2020 2074 7261 696e 696e  .        trainin
+00020e50: 6720 6665 6174 7572 6573 2061 7265 2068  g features are h
+00020e60: 6561 7669 6c69 7920 636f 7272 656c 6174  eaviliy correlat
+00020e70: 6564 2e20 5461 6e67 2026 2049 7368 7761  ed. Tang & Ishwa
+00020e80: 7261 6e20 3230 3137 2072 6570 6f72 7465  ran 2017 reporte
+00020e90: 6420 7468 6174 2069 6620 7468 6572 6520  d that if there 
+00020ea0: 6973 200a 2020 2020 2020 2020 6c6f 7720  is .        low 
+00020eb0: 746f 206d 6564 6975 6d20 636f 7272 656c  to medium correl
+00020ec0: 6174 696f 6e20 696e 2074 6865 2064 6174  ation in the dat
+00020ed0: 6173 6574 2c20 5261 6e64 6f6d 2046 6f72  aset, Random For
+00020ee0: 6573 7420 696d 7075 7461 7469 6f6e 2061  est imputation a
+00020ef0: 6c67 6f72 6974 686d 7320 7065 7266 6f72  lgorithms perfor
+00020f00: 6d20 0a20 2020 2020 2020 2062 6574 7465  m .        bette
+00020f10: 7220 7468 616e 204b 4e4e 2069 6d70 7574  r than KNN imput
+00020f20: 6174 696f 6e0a 0a20 2020 2041 7267 733a  ation..    Args:
+00020f30: 0a20 2020 2020 2020 2064 6174 6120 286e  .        data (n
+00020f40: 6461 7272 6179 293a 2049 6e70 7574 2064  darray): Input d
+00020f50: 6174 6120 6172 7261 7920 7769 7468 206d  ata array with m
+00020f60: 6973 7369 6e67 2076 616c 7565 732e 0a20  issing values.. 
+00020f70: 2020 2020 2020 2069 6d70 7574 6572 2028         imputer (
+00020f80: 6f70 7469 6f6e 616c 293a 2041 204b 4e4e  optional): A KNN
+00020f90: 496d 7075 7465 7220 636c 6173 7320 696e  Imputer class in
+00020fa0: 7374 616e 6365 2c20 636f 6e66 6967 7572  stance, configur
+00020fb0: 6564 2075 7369 6e67 2073 6b6c 6561 726e  ed using sklearn
+00020fc0: 2e69 6d70 7574 652e 4b4e 4e49 6d70 7574  .impute.KNNImput
+00020fd0: 6572 2e0a 2020 2020 2020 2020 2020 2020  er..            
+00020fe0: 4465 6661 756c 7473 2074 6f20 4e6f 6e65  Defaults to None
+00020ff0: 2c20 696e 2077 6869 6368 2063 6173 6520  , in which case 
+00021000: 7468 6520 7472 616e 7366 6f72 6d61 7469  the transformati
+00021010: 6f6e 2069 7320 6372 6561 7465 6420 7573  on is created us
+00021020: 696e 670a 2020 2020 2020 2020 2020 2020  ing.            
+00021030: 7468 6520 6461 7461 2069 7473 656c 662e  the data itself.
+00021040: 200a 2020 2020 2020 2020 7374 7261 7465   .        strate
+00021050: 6779 2028 7374 722c 206f 7074 696f 6e61  gy (str, optiona
+00021060: 6c29 3a20 496d 7075 7461 7469 6f6e 2073  l): Imputation s
+00021070: 7472 6174 6567 7920 746f 2075 7365 2e20  trategy to use. 
+00021080: 4465 6661 756c 7473 2074 6f20 276b 6e6e  Defaults to 'knn
+00021090: 272e 0a20 2020 2020 2020 2020 2020 202d  '..            -
+000210a0: 2027 6d65 616e 273a 2046 696c 6c20 6d69   'mean': Fill mi
+000210b0: 7373 696e 6720 7661 6c75 6573 2077 6974  ssing values wit
+000210c0: 6820 7468 6520 6d65 616e 206f 6620 7468  h the mean of th
+000210d0: 6520 6e6f 6e2d 6d69 7373 696e 6720 7661  e non-missing va
+000210e0: 6c75 6573 2069 6e20 7468 6520 7361 6d65  lues in the same
+000210f0: 2063 6f6c 756d 6e2e 0a20 2020 2020 2020   column..       
+00021100: 2020 2020 202d 2027 6d65 6469 616e 273a       - 'median':
+00021110: 2046 696c 6c20 6d69 7373 696e 6720 7661   Fill missing va
+00021120: 6c75 6573 2077 6974 6820 7468 6520 6d65  lues with the me
+00021130: 6469 616e 206f 6620 7468 6520 6e6f 6e2d  dian of the non-
+00021140: 6d69 7373 696e 6720 7661 6c75 6573 2069  missing values i
+00021150: 6e20 7468 6520 7361 6d65 2063 6f6c 756d  n the same colum
+00021160: 6e2e 0a20 2020 2020 2020 2020 2020 202d  n..            -
+00021170: 2027 6d6f 6465 273a 2046 696c 6c20 6d69   'mode': Fill mi
+00021180: 7373 696e 6720 7661 6c75 6573 2077 6974  ssing values wit
+00021190: 6820 7468 6520 6d6f 6465 2028 6d6f 7374  h the mode (most
+000211a0: 2066 7265 7175 656e 7420 7661 6c75 6529   frequent value)
+000211b0: 206f 6620 7468 6520 6e6f 6e2d 6d69 7373   of the non-miss
+000211c0: 696e 6720 7661 6c75 6573 2069 6e20 7468  ing values in th
+000211d0: 6520 7361 6d65 2063 6f6c 756d 6e2e 0a20  e same column.. 
+000211e0: 2020 2020 2020 2020 2020 202d 2027 636f             - 'co
+000211f0: 6e73 7461 6e74 273a 2046 696c 6c20 6d69  nstant': Fill mi
+00021200: 7373 696e 6720 7661 6c75 6573 2077 6974  ssing values wit
+00021210: 6820 6120 636f 6e73 7461 6e74 2076 616c  h a constant val
+00021220: 7565 2070 726f 7669 6465 6420 6279 2074  ue provided by t
+00021230: 6865 2075 7365 722e 0a20 2020 2020 2020  he user..       
+00021240: 2020 2020 202d 2027 6b6e 6e27 3a20 4669       - 'knn': Fi
+00021250: 6c6c 206d 6973 7369 6e67 2076 616c 7565  ll missing value
+00021260: 7320 7573 696e 6720 6b2d 4e65 6172 6573  s using k-Neares
+00021270: 7420 4e65 6967 6862 6f72 2069 6d70 7574  t Neighbor imput
+00021280: 6174 696f 6e2e 0a20 2020 2020 2020 206b  ation..        k
+00021290: 2028 696e 742c 206f 7074 696f 6e61 6c29   (int, optional)
+000212a0: 3a20 4e75 6d62 6572 206f 6620 6e65 6172  : Number of near
+000212b0: 6573 7420 6e65 6967 6862 6f72 7320 746f  est neighbors to
+000212c0: 2063 6f6e 7369 6465 7220 666f 7220 6b2d   consider for k-
+000212d0: 4e65 6172 6573 7420 4e65 6967 6862 6f72  Nearest Neighbor
+000212e0: 2069 6d70 7574 6174 696f 6e2e 0a20 2020   imputation..   
+000212f0: 2020 2020 2020 2020 204f 6e6c 7920 6170           Only ap
+00021300: 706c 6963 6162 6c65 2069 6620 7468 6520  plicable if the 
+00021310: 696d 7075 7461 7469 6f6e 2073 7472 6174  imputation strat
+00021320: 6567 7920 6973 2073 6574 2074 6f20 276b  egy is set to 'k
+00021330: 6e6e 272e 2044 6566 6175 6c74 7320 746f  nn'. Defaults to
+00021340: 2033 2e0a 2020 2020 2020 2020 636f 6e73   3..        cons
+00021350: 7461 6e74 5f76 616c 7565 2028 666c 6f61  tant_value (floa
+00021360: 7420 6f72 2069 6e74 2c20 6f70 7469 6f6e  t or int, option
+00021370: 616c 293a 2043 6f6e 7374 616e 7420 7661  al): Constant va
+00021380: 6c75 6520 746f 2075 7365 2066 6f72 2063  lue to use for c
+00021390: 6f6e 7374 616e 7420 696d 7075 7461 7469  onstant imputati
+000213a0: 6f6e 2e0a 2020 2020 2020 2020 2020 2020  on..            
+000213b0: 4f6e 6c79 2061 7070 6c69 6361 626c 6520  Only applicable 
+000213c0: 6966 2074 6865 2069 6d70 7574 6174 696f  if the imputatio
+000213d0: 6e20 7374 7261 7465 6779 2069 7320 7365  n strategy is se
+000213e0: 7420 746f 2027 636f 6e73 7461 6e74 272e  t to 'constant'.
+000213f0: 2044 6566 6175 6c74 7320 746f 2030 2e0a   Defaults to 0..
+00021400: 0a20 2020 2052 6574 7572 6e73 3a0a 2020  .    Returns:.  
+00021410: 2020 2020 2020 5468 6520 6669 7273 7420        The first 
+00021420: 6f75 7470 7574 2069 7320 7468 6520 6461  output is the da
+00021430: 7461 2061 7272 6179 2077 6974 6820 7769  ta array with wi
+00021440: 7468 2074 6865 206d 6973 7369 6e67 2076  th the missing v
+00021450: 616c 7565 7320 6669 6c6c 6564 2069 6e2e  alues filled in.
+00021460: 200a 2020 2020 2020 2020 5468 6520 7365   .        The se
+00021470: 636f 6e64 206f 7574 7075 7420 6973 2074  cond output is t
+00021480: 6865 204b 4e4e 2049 6d70 7574 6572 2074  he KNN Imputer t
+00021490: 6861 7420 7368 6f75 6c64 2062 6520 7573  hat should be us
+000214a0: 6564 2074 6f20 7472 616e 7366 6f72 6d0a  ed to transform.
+000214b0: 2020 2020 2020 2020 6e65 7720 6461 7461          new data
+000214c0: 2c20 7072 696f 7220 746f 2070 7265 6469  , prior to predi
+000214d0: 6374 696f 6e73 2e20 0a20 2020 2022 2222  ctions. .    """
+000214e0: 0a0a 2020 2020 636f 6c75 6d6e 5f6d 6973  ..    column_mis
+000214f0: 7369 6e67 5f72 6174 696f 7320 3d20 6e70  sing_ratios = np
+00021500: 2e6d 6561 6e28 6e70 2e69 736e 616e 2864  .mean(np.isnan(d
+00021510: 6174 6129 2c20 6178 6973 3d30 290a 2020  ata), axis=0).  
+00021520: 2020 636f 6c75 6d6e 735f 746f 5f69 676e    columns_to_ign
+00021530: 6f72 6520 3d20 6e70 2e77 6865 7265 2863  ore = np.where(c
+00021540: 6f6c 756d 6e5f 6d69 7373 696e 675f 7261  olumn_missing_ra
+00021550: 7469 6f73 203e 206e 616e 5f74 6872 6573  tios > nan_thres
+00021560: 686f 6c64 295b 305d 0a20 2020 2069 6620  hold)[0].    if 
+00021570: 6c65 6e28 636f 6c75 6d6e 735f 746f 5f69  len(columns_to_i
+00021580: 676e 6f72 6529 203e 2030 3a0a 2020 2020  gnore) > 0:.    
+00021590: 2020 2020 7072 696e 7428 6622 5741 524e      print(f"WARN
+000215a0: 494e 473a 2041 7420 6c65 6173 7420 6f6e  ING: At least on
+000215b0: 6520 6461 7461 2063 6f6c 756d 6e20 6861  e data column ha
+000215c0: 7320 746f 6f20 6d61 6e79 206e 616e 2076  s too many nan v
+000215d0: 616c 7565 7320 6163 636f 7264 696e 6720  alues according 
+000215e0: 746f 2074 6865 2066 6f6c 6c6f 7769 6e67  to the following
+000215f0: 2074 6872 6573 686f 6c64 3a20 7b6e 616e   threshold: {nan
+00021600: 5f74 6872 6573 686f 6c64 7d2e 2054 6865  _threshold}. The
+00021610: 7365 2063 6f6c 756d 6e73 2068 6176 6520  se columns have 
+00021620: 6265 656e 207a 6572 6f65 6420 6f75 7420  been zeroed out 
+00021630: 636f 6d70 6c65 7465 6c79 3a20 7b63 6f6c  completely: {col
+00021640: 756d 6e73 5f74 6f5f 6967 6e6f 7265 7d22  umns_to_ignore}"
+00021650: 290a 2020 2020 2020 2020 6461 7461 5b3a  ).        data[:
+00021660: 2c63 6f6c 756d 6e73 5f74 6f5f 6967 6e6f  ,columns_to_igno
+00021670: 7265 5d20 3d20 300a 0a20 2020 2069 6620  re] = 0..    if 
+00021680: 696d 7075 7465 7220 6973 204e 6f6e 653a  imputer is None:
+00021690: 0a20 2020 2020 2020 2069 6620 7374 7261  .        if stra
+000216a0: 7465 6779 203d 3d20 276d 6561 6e27 3a0a  tegy == 'mean':.
+000216b0: 2020 2020 2020 2020 2020 2020 696d 7075              impu
+000216c0: 7465 7220 3d20 5369 6d70 6c65 496d 7075  ter = SimpleImpu
+000216d0: 7465 7228 7374 7261 7465 6779 3d27 6d65  ter(strategy='me
+000216e0: 616e 2729 0a20 2020 2020 2020 2065 6c69  an').        eli
+000216f0: 6620 7374 7261 7465 6779 203d 3d20 276d  f strategy == 'm
+00021700: 6564 6961 6e27 3a0a 2020 2020 2020 2020  edian':.        
+00021710: 2020 2020 696d 7075 7465 7220 3d20 5369      imputer = Si
+00021720: 6d70 6c65 496d 7075 7465 7228 7374 7261  mpleImputer(stra
+00021730: 7465 6779 3d27 6d65 6469 616e 2729 0a20  tegy='median'). 
+00021740: 2020 2020 2020 2065 6c69 6620 7374 7261         elif stra
+00021750: 7465 6779 203d 3d20 276d 6f64 6527 3a0a  tegy == 'mode':.
+00021760: 2020 2020 2020 2020 2020 2020 696d 7075              impu
+00021770: 7465 7220 3d20 5369 6d70 6c65 496d 7075  ter = SimpleImpu
+00021780: 7465 7228 7374 7261 7465 6779 3d27 6d6f  ter(strategy='mo
+00021790: 7374 5f66 7265 7175 656e 7427 290a 2020  st_frequent').  
+000217a0: 2020 2020 2020 656c 6966 2073 7472 6174        elif strat
+000217b0: 6567 7920 3d3d 2027 636f 6e73 7461 6e74  egy == 'constant
+000217c0: 273a 0a20 2020 2020 2020 2020 2020 2069  ':.            i
+000217d0: 6620 636f 6e73 7461 6e74 5f76 616c 7565  f constant_value
+000217e0: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+000217f0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00021800: 5661 6c75 6545 7272 6f72 2822 5468 6520  ValueError("The 
+00021810: 636f 6e73 7461 6e74 5f76 616c 7565 2070  constant_value p
+00021820: 6172 616d 6574 6572 206d 7573 7420 6265  arameter must be
+00021830: 2070 726f 7669 6465 6420 6966 2073 7472   provided if str
+00021840: 6174 6567 793d 2763 6f6e 7374 616e 7427  ategy='constant'
+00021850: 2e22 290a 2020 2020 2020 2020 2020 2020  .").            
+00021860: 696d 7075 7465 7220 3d20 5369 6d70 6c65  imputer = Simple
+00021870: 496d 7075 7465 7228 7374 7261 7465 6779  Imputer(strategy
+00021880: 3d27 636f 6e73 7461 6e74 272c 2066 696c  ='constant', fil
+00021890: 6c5f 7661 6c75 653d 636f 6e73 7461 6e74  l_value=constant
+000218a0: 5f76 616c 7565 290a 2020 2020 2020 2020  _value).        
+000218b0: 656c 6966 2073 7472 6174 6567 7920 3d3d  elif strategy ==
+000218c0: 2027 6b6e 6e27 3a0a 2020 2020 2020 2020   'knn':.        
+000218d0: 2020 2020 696d 7075 7465 7220 3d20 4b4e      imputer = KN
+000218e0: 4e49 6d70 7574 6572 286e 5f6e 6569 6768  NImputer(n_neigh
+000218f0: 626f 7273 3d6b 290a 2020 2020 2020 2020  bors=k).        
+00021900: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+00021910: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+00021920: 6f72 2822 496e 7661 6c69 6420 696d 7075  or("Invalid impu
+00021930: 7461 7469 6f6e 2073 7472 6174 6567 792e  tation strategy.
+00021940: 2050 6c65 6173 6520 6368 6f6f 7365 2066   Please choose f
+00021950: 726f 6d20 276d 6561 6e27 2c20 276d 6564  rom 'mean', 'med
+00021960: 6961 6e27 2c20 276d 6f64 6527 2c20 2763  ian', 'mode', 'c
+00021970: 6f6e 7374 616e 7427 2c20 6f72 2027 6b6e  onstant', or 'kn
+00021980: 6e27 2e22 290a 0a20 2020 2020 2020 2069  n'.")..        i
+00021990: 6d70 7574 6572 2e66 6974 2864 6174 6129  mputer.fit(data)
+000219a0: 0a20 2020 2020 2020 2069 6d70 7574 6564  .        imputed
+000219b0: 5f64 6174 6120 3d20 696d 7075 7465 722e  _data = imputer.
+000219c0: 7472 616e 7366 6f72 6d28 6461 7461 290a  transform(data).
+000219d0: 2020 2020 2020 2020 7265 7475 726e 2069          return i
+000219e0: 6d70 7574 6564 5f64 6174 612c 2069 6d70  mputed_data, imp
+000219f0: 7574 6572 0a0a 2020 2020 7265 7475 726e  uter..    return
+00021a00: 2069 6d70 7574 6572 2e74 7261 6e73 666f   imputer.transfo
+00021a10: 726d 2864 6174 6129 200a 0a64 6566 2053  rm(data) ..def S
+00021a20: 7472 6177 6d61 6e5f 696d 7075 7461 7469  trawman_imputati
+00021a30: 6f6e 2864 6174 6129 3a0a 2020 2020 2222  on(data):.    ""
+00021a40: 220a 2020 2020 5065 7266 6f72 6d20 5374  ".    Perform St
+00021a50: 7261 776d 616e 2069 6d70 7574 6174 696f  rawman imputatio
+00021a60: 6e2c 2061 2074 696d 652d 6566 6669 6369  n, a time-effici
+00021a70: 656e 7420 616c 676f 7269 7468 6d0a 2020  ent algorithm.  
+00021a80: 2020 696e 2077 6869 6368 206d 6973 7369    in which missi
+00021a90: 6e67 2064 6174 6120 7661 6c75 6573 2061  ng data values a
+00021aa0: 7265 2072 6570 6c61 6365 6420 7769 7468  re replaced with
+00021ab0: 2074 6865 206d 6564 6961 6e0a 2020 2020   the median.    
+00021ac0: 7661 6c75 6520 6f66 2074 6865 2065 6e74  value of the ent
+00021ad0: 6972 652c 206e 6f6e 2d4e 614e 2073 616d  ire, non-NaN sam
+00021ae0: 706c 652e 2049 6620 7468 6520 6461 7461  ple. If the data
+00021af0: 2069 7320 6120 686f 742d 656e 636f 6465   is a hot-encode
+00021b00: 640a 2020 2020 626f 6f6c 6561 6e20 2861  d.    boolean (a
+00021b10: 7320 7468 6520 5246 2064 6f65 7320 6e6f  s the RF does no
+00021b20: 7420 616c 6c6f 7720 5472 7565 206f 7220  t allow True or 
+00021b30: 4661 6c73 6529 2c20 7468 656e 2074 6865  False), then the
+00021b40: 200a 2020 2020 696e 7374 616e 6365 2074   .    instance t
+00021b50: 6861 7420 6973 2075 7365 6420 7468 6520  hat is used the 
+00021b60: 6d6f 7374 2077 696c 6c20 6265 2063 6f6d  most will be com
+00021b70: 7075 7465 6420 6173 2074 6865 206d 6564  puted as the med
+00021b80: 6961 6e2e 200a 0a20 2020 2054 6869 7320  ian. ..    This 
+00021b90: 6973 2074 6865 2062 6173 656c 696e 6520  is the baseline 
+00021ba0: 616c 676f 7269 7468 6d20 7573 6564 2062  algorithm used b
+00021bb0: 7920 2854 616e 6720 2620 4973 6877 6172  y (Tang & Ishwar
+00021bc0: 616e 2032 3031 3729 2e0a 2020 2020 5365  an 2017)..    Se
+00021bd0: 653a 2068 7474 7073 3a2f 2f61 7278 6976  e: https://arxiv
+00021be0: 2e6f 7267 2f70 6466 2f31 3730 312e 3035  .org/pdf/1701.05
+00021bf0: 3330 352e 7064 660a 0a20 2020 204e 6f74  305.pdf..    Not
+00021c00: 653a 0a20 2020 2020 2020 2054 6869 7320  e:.        This 
+00021c10: 6675 6e63 7469 6f6e 2061 7373 756d 6573  function assumes
+00021c20: 2065 6163 6820 726f 7720 636f 7272 6573   each row corres
+00021c30: 706f 6e64 7320 746f 206f 6e65 2073 616d  ponds to one sam
+00021c40: 706c 652c 2061 6e64 200a 2020 2020 2020  ple, and .      
+00021c50: 2020 7468 6174 206d 6973 7369 6e67 2076    that missing v
+00021c60: 616c 7565 7320 6172 6520 6d61 736b 6564  alues are masked
+00021c70: 2061 7320 6569 7468 6572 204e 614e 206f   as either NaN o
+00021c80: 7220 696e 662e 200a 0a20 2020 2041 7267  r inf. ..    Arg
+00021c90: 733a 0a20 2020 2020 2020 2064 6174 6120  s:.        data 
+00021ca0: 286e 6461 7272 6179 293a 2031 4420 6172  (ndarray): 1D ar
+00021cb0: 7261 7920 6966 2073 696e 676c 6520 7061  ray if single pa
+00021cc0: 7261 6d65 7465 7220 6973 2069 6e70 7574  rameter is input
+00021cd0: 2e20 4966 0a20 2020 2020 2020 2020 2020  . If.           
+00021ce0: 2064 6174 6120 6973 2032 2d64 696d 656e   data is 2-dimen
+00021cf0: 7369 6f6e 616c 2c20 7468 6520 6d65 6469  sional, the medi
+00021d00: 616e 7320 7769 6c6c 2062 6520 6361 6c63  ans will be calc
+00021d10: 756c 6174 6564 0a20 2020 2020 2020 2020  ulated.         
+00021d20: 2020 2075 7369 6e67 2074 6865 206e 6f6e     using the non
+00021d30: 2d6d 6973 7369 6e67 2076 616c 7565 7320  -missing values 
+00021d40: 696e 2065 6163 6820 636f 7272 6573 706f  in each correspo
+00021d50: 6e64 696e 6720 636f 6c75 6d6e 2e0a 0a20  nding column... 
+00021d60: 2020 2052 6574 7572 6e73 3a0a 2020 2020     Returns:.    
+00021d70: 2020 2020 5468 6520 6461 7461 2061 7272      The data arr
+00021d80: 6179 2077 6974 6820 7468 6520 6d69 7373  ay with the miss
+00021d90: 696e 6720 7661 6c75 6573 2066 696c 6c65  ing values fille
+00021da0: 6420 696e 2e20 0a20 2020 2022 2222 0a0a  d in. .    """..
+00021db0: 2020 2020 6966 206e 702e 616c 6c28 6e70      if np.all(np
+00021dc0: 2e69 7366 696e 6974 6528 6461 7461 2929  .isfinite(data))
+00021dd0: 3a0a 2020 2020 2020 2020 7072 696e 7428  :.        print(
+00021de0: 274e 6f20 6d69 7373 696e 6720 7661 6c75  'No missing valu
+00021df0: 6573 2069 6e20 6461 7461 2c20 7265 7475  es in data, retu
+00021e00: 726e 696e 6720 6f72 6967 696e 616c 2061  rning original a
+00021e10: 7272 6179 2e27 290a 2020 2020 2020 2020  rray.').        
+00021e20: 7265 7475 726e 2064 6174 6120 0a0a 2020  return data ..  
+00021e30: 2020 6966 206c 656e 2864 6174 612e 7368    if len(data.sh
+00021e40: 6170 6529 203d 3d20 313a 0a20 2020 2020  ape) == 1:.     
+00021e50: 2020 206d 6173 6b20 3d20 6e70 2e77 6865     mask = np.whe
+00021e60: 7265 286e 702e 6973 6669 6e69 7465 2864  re(np.isfinite(d
+00021e70: 6174 6129 295b 305d 0a20 2020 2020 2020  ata))[0].       
+00021e80: 206d 6564 6961 6e20 3d20 6e70 2e6d 6564   median = np.med
+00021e90: 6961 6e28 6461 7461 5b6d 6173 6b5d 290a  ian(data[mask]).
+00021ea0: 2020 2020 2020 2020 6461 7461 5b6e 702e          data[np.
+00021eb0: 6973 6e61 6e28 6461 7461 295d 203d 206d  isnan(data)] = m
+00021ec0: 6564 6961 6e20 0a0a 2020 2020 2020 2020  edian ..        
+00021ed0: 7265 7475 726e 2064 6174 610a 0a20 2020  return data..   
+00021ee0: 204e 792c 204e 7820 3d20 6461 7461 2e73   Ny, Nx = data.s
+00021ef0: 6861 7065 0a20 2020 2069 6d70 7574 6564  hape.    imputed
+00021f00: 5f64 6174 6120 3d20 6e70 2e7a 6572 6f73  _data = np.zeros
+00021f10: 2828 4e79 2c4e 7829 290a 0a20 2020 2066  ((Ny,Nx))..    f
+00021f20: 6f72 2069 2069 6e20 7261 6e67 6528 4e78  or i in range(Nx
+00021f30: 293a 0a20 2020 2020 2020 206d 6173 6b20  ):.        mask 
+00021f40: 3d20 6e70 2e77 6865 7265 286e 702e 6973  = np.where(np.is
+00021f50: 6669 6e69 7465 2864 6174 615b 3a2c 695d  finite(data[:,i]
+00021f60: 2929 5b30 5d0a 2020 2020 2020 2020 6d65  ))[0].        me
+00021f70: 6469 616e 203d 206e 702e 6d65 6469 616e  dian = np.median
+00021f80: 2864 6174 615b 3a2c 695d 5b6d 6173 6b5d  (data[:,i][mask]
+00021f90: 290a 0a20 2020 2020 2020 2066 6f72 206a  )..        for j
+00021fa0: 2069 6e20 7261 6e67 6528 4e79 293a 0a20   in range(Ny):. 
+00021fb0: 2020 2020 2020 2020 2020 2069 6620 6e70             if np
+00021fc0: 2e69 736e 616e 2864 6174 615b 6a2c 695d  .isnan(data[j,i]
+00021fd0: 2920 3d3d 2054 7275 6520 6f72 206e 702e  ) == True or np.
+00021fe0: 6973 696e 6628 6461 7461 5b6a 2c69 5d29  isinf(data[j,i])
+00021ff0: 203d 3d20 5472 7565 3a0a 2020 2020 2020   == True:.      
+00022000: 2020 2020 2020 2020 2020 696d 7075 7465            impute
+00022010: 645f 6461 7461 5b6a 2c69 5d20 3d20 6d65  d_data[j,i] = me
+00022020: 6469 616e 0a20 2020 2020 2020 2020 2020  dian.           
+00022030: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00022040: 2020 2020 2020 2069 6d70 7574 6564 5f64         imputed_d
+00022050: 6174 615b 6a2c 695d 203d 2064 6174 615b  ata[j,i] = data[
+00022060: 6a2c 695d 0a0a 2020 2020 7265 7475 726e  j,i]..    return
+00022070: 2069 6d70 7574 6564 5f64 6174 6120 0a0a   imputed_data ..
+00022080: 636c 6173 7320 5374 6f70 5768 656e 5472  class StopWhenTr
+00022090: 6961 6c4b 6565 7042 6569 6e67 5072 756e  ialKeepBeingPrun
+000220a0: 6564 4361 6c6c 6261 636b 3a0a 2020 2020  edCallback:.    
+000220b0: 2222 220a 2020 2020 436c 6173 7320 746f  """.    Class to
+000220c0: 2063 7265 6174 6520 6120 6375 7374 6f6d   create a custom
+000220d0: 2063 616c 6c62 6163 6b20 7468 6174 2077   callback that w
+000220e0: 696c 6c20 7374 6f70 0a20 2020 2074 6865  ill stop.    the
+000220f0: 204f 7074 756e 6120 6f70 7469 6d69 7a61   Optuna optimiza
+00022100: 7469 6f6e 2072 6f75 7469 6e65 2069 6620  tion routine if 
+00022110: 6120 6769 7665 6e20 6e75 6d62 6572 206f  a given number o
+00022120: 660a 2020 2020 7472 6961 6c73 2061 7265  f.    trials are
+00022130: 2070 7275 6e65 6420 696e 2061 2072 6f77   pruned in a row
+00022140: 2e20 5468 6973 2076 616c 7565 2069 7320  . This value is 
+00022150: 636f 6e74 726f 6c6c 6564 0a20 2020 2062  controlled.    b
+00022160: 7920 7468 6520 7468 7265 7368 6f6c 6420  y the threshold 
+00022170: 7061 7261 6d65 7465 722e 204e 6f74 2063  parameter. Not c
+00022180: 7572 7265 6e74 6c79 2065 6d70 6c6f 7965  urrently employe
+00022190: 6421 0a20 2020 2022 2222 0a20 2020 200a  d!.    """.    .
+000221a0: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
+000221b0: 2873 656c 662c 2074 6872 6573 686f 6c64  (self, threshold
+000221c0: 3a20 696e 7429 3a0a 2020 2020 2020 2020  : int):.        
+000221d0: 7365 6c66 2e74 6872 6573 686f 6c64 203d  self.threshold =
+000221e0: 2074 6872 6573 686f 6c64 0a20 2020 2020   threshold.     
+000221f0: 2020 2073 656c 662e 5f63 6f6e 7365 7175     self._consequ
+00022200: 7469 7665 5f70 7275 6e65 645f 636f 756e  tive_pruned_coun
+00022210: 7420 3d20 300a 0a20 2020 2064 6566 205f  t = 0..    def _
+00022220: 5f63 616c 6c5f 5f28 7365 6c66 2c20 7374  _call__(self, st
+00022230: 7564 793a 206f 7074 756e 612e 7374 7564  udy: optuna.stud
+00022240: 792e 5374 7564 792c 2074 7269 616c 3a20  y.Study, trial: 
+00022250: 6f70 7475 6e61 2e74 7269 616c 2e46 726f  optuna.trial.Fro
+00022260: 7a65 6e54 7269 616c 2920 2d3e 204e 6f6e  zenTrial) -> Non
+00022270: 653a 0a20 2020 2020 2020 2069 6620 7472  e:.        if tr
+00022280: 6961 6c2e 7374 6174 6520 3d3d 206f 7074  ial.state == opt
+00022290: 756e 612e 7472 6961 6c2e 5472 6961 6c53  una.trial.TrialS
+000222a0: 7461 7465 2e50 5255 4e45 443a 0a20 2020  tate.PRUNED:.   
+000222b0: 2020 2020 2020 2020 2073 656c 662e 5f63           self._c
+000222c0: 6f6e 7365 7175 7469 7665 5f70 7275 6e65  onsequtive_prune
+000222d0: 645f 636f 756e 7420 2b3d 2031 0a20 2020  d_count += 1.   
+000222e0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+000222f0: 2020 2020 2020 2073 656c 662e 5f63 6f6e         self._con
+00022300: 7365 7175 7469 7665 5f70 7275 6e65 645f  sequtive_pruned_
+00022310: 636f 756e 7420 3d20 300a 0a20 2020 2020  count = 0..     
+00022320: 2020 2069 6620 7365 6c66 2e5f 636f 6e73     if self._cons
+00022330: 6571 7574 6976 655f 7072 756e 6564 5f63  equtive_pruned_c
+00022340: 6f75 6e74 203e 3d20 7365 6c66 2e74 6872  ount >= self.thr
+00022350: 6573 686f 6c64 3a0a 2020 2020 2020 2020  eshold:.        
+00022360: 2020 2020 7374 7564 792e 7374 6f70 2829      study.stop()
+00022370: 0a0a 636c 6173 7320 496e 7075 7454 696d  ..class InputTim
+00022380: 656f 7574 3a0a 2020 2020 2222 220a 2020  eout:.    """.  
+00022390: 2020 4120 636c 6173 7320 666f 7220 7265    A class for re
+000223a0: 6164 696e 6720 7573 6572 2069 6e70 7574  ading user input
+000223b0: 2077 6974 6820 6120 7469 6d65 6f75 7420   with a timeout 
+000223c0: 6f6e 204c 696e 7578 2c20 7573 6564 2069  on Linux, used i
+000223d0: 6e20 7468 6520 434e 4e20 6f70 7469 6d69  n the CNN optimi
+000223e0: 7a61 7469 6f6e 2072 6f75 7469 6e65 2e20  zation routine. 
+000223f0: 0a20 2020 204e 6f74 2063 7572 7265 6e74  .    Not current
+00022400: 6c79 2075 7365 6420 6279 2074 6865 2070  ly used by the p
+00022410: 726f 6772 616d 210a 0a20 2020 2045 7861  rogram!..    Exa
+00022420: 6d70 6c65 3a0a 2020 2020 2020 2020 696e  mple:.        in
+00022430: 7075 745f 7469 6d65 6f75 7420 3d20 496e  put_timeout = In
+00022440: 7075 7454 696d 656f 7574 2822 456e 7465  putTimeout("Ente
+00022450: 7220 796f 7572 2069 6e70 7574 3a20 222c  r your input: ",
+00022460: 2035 290a 2020 2020 2020 2020 7472 793a   5).        try:
+00022470: 0a20 2020 2020 2020 2020 2020 2075 7365  .            use
+00022480: 725f 696e 7075 7420 3d20 696e 7075 745f  r_input = input_
+00022490: 7469 6d65 6f75 742e 696e 7075 7469 6d65  timeout.inputime
+000224a0: 6f75 7428 290a 2020 2020 2020 2020 2020  out().          
+000224b0: 2020 7072 696e 7428 2255 7365 7220 696e    print("User in
+000224c0: 7075 743a 222c 2075 7365 725f 696e 7075  put:", user_inpu
+000224d0: 7429 0a20 2020 2020 2020 2065 7863 6570  t).        excep
+000224e0: 7420 496e 7075 7454 696d 656f 7574 2e54  t InputTimeout.T
+000224f0: 696d 656f 7574 4f63 6375 7272 6564 3a0a  imeoutOccurred:.
+00022500: 2020 2020 2020 2020 2020 2020 7072 696e              prin
+00022510: 7428 2254 696d 656f 7574 206f 6363 7572  t("Timeout occur
+00022520: 7265 642e 204e 6f20 696e 7075 7420 7265  red. No input re
+00022530: 6365 6976 6564 2e22 290a 0a20 2020 2041  ceived.")..    A
+00022540: 7474 7269 6275 7465 733a 0a20 2020 2020  ttributes:.     
+00022550: 2020 2070 726f 6d70 7420 2873 7472 293a     prompt (str):
+00022560: 2054 6865 2070 726f 6d70 7420 6d65 7373   The prompt mess
+00022570: 6167 6520 746f 2064 6973 706c 6179 2074  age to display t
+00022580: 6f20 7468 6520 7573 6572 2e0a 2020 2020  o the user..    
+00022590: 2020 2020 7469 6d65 6f75 7420 2866 6c6f      timeout (flo
+000225a0: 6174 293a 2054 6865 206e 756d 6265 7220  at): The number 
+000225b0: 6f66 2073 6563 6f6e 6473 2074 6f20 7761  of seconds to wa
+000225c0: 6974 2066 6f72 2069 6e70 7574 2062 6566  it for input bef
+000225d0: 6f72 6520 7469 6d69 6e67 206f 7574 2e0a  ore timing out..
+000225e0: 2020 2020 0a20 2020 204d 6574 686f 6473      .    Methods
+000225f0: 3a0a 2020 2020 2020 2020 696e 7075 7469  :.        inputi
+00022600: 6d65 6f75 7428 293a 2052 6561 6473 2075  meout(): Reads u
+00022610: 7365 7220 696e 7075 7420 6672 6f6d 2074  ser input from t
+00022620: 6865 2063 6f6d 6d61 6e64 206c 696e 6520  he command line 
+00022630: 7769 7468 2061 2074 696d 656f 7574 2e20  with a timeout. 
+00022640: 4966 206e 6f20 696e 7075 7420 6973 0a20  If no input is. 
+00022650: 2020 2020 2020 2020 2020 2072 6563 6569             recei
+00022660: 7665 6420 7769 7468 696e 2074 6865 2073  ved within the s
+00022670: 7065 6369 6669 6564 2074 696d 656f 7574  pecified timeout
+00022680: 2c20 6120 5469 6d65 6f75 744f 6363 7572  , a TimeoutOccur
+00022690: 7265 6420 6578 6365 7074 696f 6e20 6973  red exception is
+000226a0: 2072 6169 7365 642e 0a20 2020 2022 2222   raised..    """
+000226b0: 0a0a 2020 2020 636c 6173 7320 5469 6d65  ..    class Time
+000226c0: 6f75 744f 6363 7572 7265 6428 4578 6365  outOccurred(Exce
+000226d0: 7074 696f 6e29 3a0a 2020 2020 2020 2020  ption):.        
+000226e0: 7061 7373 0a20 2020 200a 2020 2020 6465  pass.    .    de
+000226f0: 6620 5f5f 696e 6974 5f5f 2873 656c 662c  f __init__(self,
+00022700: 2070 726f 6d70 743d 2727 2c20 7469 6d65   prompt='', time
+00022710: 6f75 743d 3330 293a 0a20 2020 2020 2020  out=30):.       
+00022720: 2073 656c 662e 7072 6f6d 7074 203d 2070   self.prompt = p
+00022730: 726f 6d70 740a 2020 2020 2020 2020 7365  rompt.        se
+00022740: 6c66 2e74 696d 656f 7574 203d 2074 696d  lf.timeout = tim
+00022750: 656f 7574 0a20 2020 2020 2020 2073 656c  eout.        sel
+00022760: 662e 6563 686f 203d 2073 656c 662e 5f65  f.echo = self._e
+00022770: 6368 6f5f 706f 7369 780a 2020 2020 2020  cho_posix.      
+00022780: 2020 7365 6c66 2e69 6e70 7574 696d 656f    self.inputimeo
+00022790: 7574 203d 2073 656c 662e 5f69 6e70 7574  ut = self._input
+000227a0: 696d 656f 7574 5f70 6f73 6978 0a20 2020  imeout_posix.   
+000227b0: 200a 2020 2020 6465 6620 5f65 6368 6f5f   .    def _echo_
+000227c0: 706f 7369 7828 7365 6c66 2c20 7374 7269  posix(self, stri
+000227d0: 6e67 293a 0a20 2020 2020 2020 2073 7973  ng):.        sys
+000227e0: 2e73 7464 6f75 742e 7772 6974 6528 7374  .stdout.write(st
+000227f0: 7269 6e67 290a 2020 2020 2020 2020 7379  ring).        sy
+00022800: 732e 7374 646f 7574 2e66 6c75 7368 2829  s.stdout.flush()
+00022810: 0a20 2020 2020 2020 200a 2020 2020 6465  .        .    de
+00022820: 6620 5f69 6e70 7574 696d 656f 7574 5f70  f _inputimeout_p
+00022830: 6f73 6978 2873 656c 6629 3a0a 2020 2020  osix(self):.    
+00022840: 2020 2020 7365 6c66 2e65 6368 6f28 7365      self.echo(se
+00022850: 6c66 2e70 726f 6d70 7429 0a20 2020 2020  lf.prompt).     
+00022860: 2020 2073 656c 203d 2073 656c 6563 746f     sel = selecto
+00022870: 7273 2e44 6566 6175 6c74 5365 6c65 6374  rs.DefaultSelect
+00022880: 6f72 2829 0a20 2020 2020 2020 2073 656c  or().        sel
+00022890: 2e72 6567 6973 7465 7228 7379 732e 7374  .register(sys.st
+000228a0: 6469 6e2c 2073 656c 6563 746f 7273 2e45  din, selectors.E
+000228b0: 5645 4e54 5f52 4541 4429 0a20 2020 2020  VENT_READ).     
+000228c0: 2020 2065 7665 6e74 7320 3d20 7365 6c2e     events = sel.
+000228d0: 7365 6c65 6374 2873 656c 662e 7469 6d65  select(self.time
+000228e0: 6f75 7429 0a0a 2020 2020 2020 2020 6966  out)..        if
+000228f0: 2065 7665 6e74 733a 0a20 2020 2020 2020   events:.       
+00022900: 2020 2020 206b 6579 2c20 5f20 3d20 6576       key, _ = ev
+00022910: 656e 7473 5b30 5d0a 2020 2020 2020 2020  ents[0].        
+00022920: 2020 2020 7265 7475 726e 206b 6579 2e66      return key.f
+00022930: 696c 656f 626a 2e72 6561 646c 696e 6528  ileobj.readline(
+00022940: 292e 7273 7472 6970 2827 5c6e 2729 0a20  ).rstrip('\n'). 
+00022950: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00022960: 2020 2020 2020 2020 2073 656c 662e 6563           self.ec
+00022970: 686f 2827 5c6e 2729 0a20 2020 2020 2020  ho('\n').       
+00022980: 2020 2020 2074 6572 6d69 6f73 2e74 6366       termios.tcf
+00022990: 6c75 7368 2873 7973 2e73 7464 696e 2c20  lush(sys.stdin, 
+000229a0: 7465 726d 696f 732e 5443 4946 4c55 5348  termios.TCIFLUSH
+000229b0: 290a 2020 2020 2020 2020 2020 2020 7261  ).            ra
+000229c0: 6973 6520 7365 6c66 2e54 696d 656f 7574  ise self.Timeout
+000229d0: 4f63 6375 7272 6564 0a                   Occurred.
```

### Comparing `MicroLIA-2.2.6/MicroLIA/quality_check.py` & `MicroLIA-2.2.7/MicroLIA/quality_check.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,39 +17,39 @@
 def test_microlensing(timestamps, microlensing_mag, magerr, baseline, u_0, t_0, t_e, blend_ratio, n=7):
     """
     Test to ensure proper microlensing signal.
     This requires 7 measurements with a magnification of at least 1.34, imposing
     additional magnification thresholds to ensure the microlensing signal doesn't 
     mimic a noisy constant.
 
-    Parameters
+    Parameters:
     ----------
-    timestamps : array
-        Times at which to simulate the lightcurve.
-    microlensing_mag : array
-        Microlensing simulated magnitudes given the timestamps. 
-    magerr : array
-        Photometric error for each mag measurement.
-    baseline : float
-        Baseline magnitude of the event. 
-    u_0 : float
-        The source minimum impact parameter.
-    t_0 : float
-        The time of maximum magnification.
-    t_E : float
-        The timescale of the event in days.
-    blend_ratio : float
-        The blending coefficient.
-    n : int, optional
-        The mininum number of measurements that should be within the 
-        microlensing signal when simulating the lightcurves. 
+        timestamps : array
+            Times at which to simulate the lightcurve.
+        microlensing_mag : array
+            Microlensing simulated magnitudes given the timestamps. 
+        magerr : array
+            Photometric error for each mag measurement.
+        baseline : float
+            Baseline magnitude of the event. 
+        u_0 : float
+            The source minimum impact parameter.
+        t_0 : float
+            The time of maximum magnification.
+        t_E : float
+            The timescale of the event in days.
+        blend_ratio : float
+            The blending coefficient.
+        n : int, optional
+            The mininum number of measurements that should be within the 
+            microlensing signal when simulating the lightcurves. 
 
-    Returns
+    Returns:
     -------
-    condition : boolean
+    bool
         Returns True if microlensing passes the quality test. 
     """
 
     mag = simulate.constant(timestamps, baseline)
     condition = False
     signal_indices = np.argwhere((timestamps >= (t_0 - t_e)) & (timestamps <= (t_0 + t_e))) 
     if len(signal_indices) >= n:
@@ -72,36 +72,36 @@
 
 def test_cv(timestamps, outburst_start_times, outburst_end_times, end_rise_times, end_high_times, n1=7, n2=1):
     """
     Test to ensure proper CV signal.
     This requires 7 measurements within ANY outburst, with at least one 
     occurring within the rise or fall.
 
-    Parameters
+    Parameters:
     ----------
-    timestamps : array
-        Times at which to simulate the lightcurve.
-    outburst_start_times : array
-        The start time of each outburst.
-    outburst_end_times : array
-        The end time of each outburst.
-    end_rise_times : array
-        The end time of each rise (start time of max amplitude).
-    end_high_times : array
-        The end time of each peak (end time of max amplitude).
-    n1 : int, optional
-        The mininum number of measurements that should be within 
-        at least one outburst, defaults to 7.
-    n2 : int, optional
-        The mininum number of measurements that should be within the 
-        rise or drop of at least one outburst, defaults to 1.
+        timestamps : array
+            Times at which to simulate the lightcurve.
+        outburst_start_times : array
+            The start time of each outburst.
+        outburst_end_times : array
+            The end time of each outburst.
+        end_rise_times : array
+            The end time of each rise (start time of max amplitude).
+        end_high_times : array
+            The end time of each peak (end time of max amplitude).
+        n1 : int, optional
+            The mininum number of measurements that should be within 
+            at least one outburst, defaults to 7.
+        n2 : int, optional
+            The mininum number of measurements that should be within the 
+            rise or drop of at least one outburst, defaults to 1.
         
-    Returns
+    Returns:
     -------
-    condition : boolean
+    bool
         Returns True if CV passes the quality test. 
     """
 
     signal_measurements = []
     rise_measurements = []
     fall_measurements = []
     condition = False
```

### Comparing `MicroLIA-2.2.6/MicroLIA/simulate.py` & `MicroLIA-2.2.7/MicroLIA/simulate.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,118 +18,118 @@
 def microlensing(timestamps, baseline, t0_dist=None, u0_dist=None, tE_dist=None):
     """Simulates a microlensing event.  
     The microlensing parameter space is determined using data from an 
     analysis of the OGLE III microlensing survey from Y. Tsapras et al (2016).
     See: The OGLE-III planet detection efficiency from six years of microlensing observations (2003 to 2008).
     (https://arxiv.org/abs/1602.02519)
 
-    Parameters
+    Parameters:
     ----------
-    timestamps : array
-        Timestamps of the lightcurve.
-    baseline : float
-        Baseline magnitude of the lightcurve.
-    t0_dist: array, optional
-        An array containing the minumum and maximum t0 value to be 
-        considered during the microlensing simulations. The indivial
-        t0 per simulation will be selected from a uniform distribution
-        between these two values.
-    u0_dist: array, optional
-        An array containing the minumum and maximum u0 value to be 
-        considered during the microlensing simulations. The indivial
-        u0 per simulation will be selected from a uniform distribution
-        between these two values.
-    te_dist: array, optional
-        An array containing the minumum and maximum tE value to be 
-        considered during the microlensing simulations. The indivial
-        tE per simulation will be selected from a uniform distribution
-        between these two values.
+        timestamps : array
+            Timestamps of the lightcurve.
+        baseline : float
+            Baseline magnitude of the lightcurve.
+        t0_dist: array, tuple, optional
+            An array or tuple containing two values, the minimum and maximum value (in that order) to 
+            consider when simulating the microlensing events (in days), as this t0 parameter will be selected
+            using a random uniform distribution according to these bounds. Defaults to None, which will 
+            compute an appropriate t0 according to the range of the input timestamps.
+        u0_dist: array, tuple, optional
+            An array or tuple containing two values, the minimum and maximum value (in that order) to 
+            consider when simulating the microlensing events, as this u0 parameter will be selected
+            using a random uniform distribution according to these bounds. Defaults to None, which will 
+            set these bounds to (0, 1).
+        te_dist: array, tuple, optional
+            An array or tuple containing the mean and standard deviation (in that order) to consider for this tE parameter
+            during the microlensing simulations, as this value will be selected from a random normal distribution
+            using the specified mean and standard deviation. Defaults to None which will apply a mean of 30 with
+            a spread of 10 days.
 
-    Returns
+    Returns:
     -------
-    mag : array
-        Simulated magnitude given the timestamps.
-    u_0 : float
-        The source minimum impact parameter.
-    t_0 : float
-        The time of maximum magnification.
-    t_E : float
-        The timescale of the event in days.
-    blend_ratio : float
-        The blending coefficient chosen between 0 and 10.     
+        mag : array
+            Simulated magnitude given the timestamps.
+        u_0 : float
+            The source minimum impact parameter.
+        t_0 : float
+            The time of maximum magnification.
+        t_E : float
+            The timescale of the event in days.
+        blend_ratio : float
+            The blending coefficient chosen between 0 and 10.     
     """   
 
     if u0_dist:
-       lower_bound = u0_dist[0]
-       upper_bound = u0_dist[1]
-       u_0 = np.random.uniform(lower_bound, upper_bound) 
+       lower_bound, upper_bound = u0_dist[0], u0_dist[1]
     else:
-       u_0 = np.random.uniform(0, 1.0)
+        lower_bound, upper_bound = 0.0, 1.0
+
+    u_0 = np.random.uniform(lower_bound, upper_bound) 
 
     if tE_dist:
-       lower_bound = tE_dist[0]
-       upper_bound = tE_dist[1]
-       t_e = np.random.normal(lower_bound, upper_bound) 
+       tE_mean, tE_std = tE_dist[0], tE_dist[1]
     else:
-       t_e = np.random.normal(30, 10.0)
+       tE_mean, tE_std = 30.0, 10.0
+
+    t_e = np.random.normal(tE_mean, tE_std) 
 
     if t0_dist:
-        lower_bound = t0_dist[0]
-        upper_bound = t0_dist[1]
+        lower_bound, upper_bound = t0_dist[0], t0_dist[1]
     else:
         # Set bounds to ensure enough measurements are available near t_0 
         lower_bound = np.percentile(timestamps, 1)-0.5*t_e
         upper_bound = np.percentile(timestamps, 99)+0.5*t_e
 
     t_0 = np.random.uniform(lower_bound, upper_bound)  
 
-    blend_ratio = np.random.uniform(0,1)
+    blend_ratio = np.random.uniform(0, 1)
 
     u_t = np.sqrt(u_0**2 + ((timestamps - t_0) / t_e)**2)
     magnification = (u_t**2 + 2.) / (u_t * np.sqrt(u_t**2 + 4.))
 
-    flux = 10**((baseline) / -2.5)
+    mag = constant(timestamps, baseline)
+    flux = 10**((mag) / -2.5)
 
     flux_base = np.median(flux)
 
     f_s = flux_base / (1 + blend_ratio)
     f_b = blend_ratio * f_s
 
     flux_obs = f_s*magnification + f_b
     microlensing_mag = -2.5*np.log10(flux_obs)
 
-    return np.array(microlensing_mag), [baseline]*len(flux_obs), u_0, t_0, t_e, blend_ratio
+    return np.array(microlensing_mag), u_0, t_0, t_e, blend_ratio
     
 def cv(timestamps, baseline):
     """Simulates Cataclysmic Variable event.
     The outburst can be reasonably well represented as three linear phases: a steeply 
     positive gradient in the rising phase, a flat phase at maximum brightness followed by a declining 
     phase of somewhat shallower negative gradient. The period is selected from a normal distribution
     centered about 100 days with a standard deviation of 200 days. The outburtst amplitude ranges from
     0.5 to 5.0 mag, selected from a uniform random function. 
 
-    Parameters
+    Parameters:
     ----------
-    timestamps : array
-        Times at which to simulate the lightcurve.
-    baseline : float
-        Baseline magnitude at which to simulate the lightcurve.
+        timestamps : array
+            Times at which to simulate the lightcurve.
+        baseline : float
+            Baseline magnitude at which to simulate the lightcurve.
 
-    Returns
+    Returns:
     -------
-    mag : array
-        Simulated magnitudes given the timestamps and baseline. 
-    outburst_start_times : array
-        The start time of each outburst.
-    outburst_end_times : array
-        The end time of each outburst.
-    end_rise_times : array
-        The end time of each rise (start time of max amplitude).
-    end_high_times : array
-        The end time of each peak (end time of max amplitude).
+        mag : array
+            Simulated magnitudes given the timestamps and baseline. 
+        outburst_start_times : array
+            The start time of each outburst.
+        outburst_end_times : array
+            The end time of each outburst.
+        end_rise_times : array
+            The end time of each rise (start time of max amplitude).
+        end_high_times : array
+            The end time of each peak (end time of max amplitude).
     """
 
     period = abs(np.random.normal(100, 200))
     amplitude = np.random.uniform(0.5, 5.0)
     lc = np.zeros(len(timestamps))
     # First generate the times when outbursts start. Note that the
     # duration of outbursts can vary for a single object, so the t_end_outbursts will be added later.
@@ -181,58 +181,58 @@
     lc = lc + baseline 
 
     return np.array(lc), np.array(start_times), np.array(outburst_end_times), np.array(end_rise_times), np.array(end_high_times)
 
 def constant(timestamps, baseline):
     """Simulates a constant source displaying no variability.  
 
-    Parameters
+    Parameters:
     ----------
-    timestamps : array
-        Times at which to simulate the lightcurve.
-    baseline : float
-        Baseline magnitude of the lightcurve.
+        timestamps : array
+            Times at which to simulate the lightcurve.
+        baseline : float
+            Baseline magnitude of the lightcurve.
 
-    Returns
+    Returns:
     -------
-    mag : array
+    array
         Simulated magnitudes given the timestamps.
     """
 
     mag = [baseline] * len(timestamps)
 
     return np.array(mag)
 
 def variable(timestamps, baseline, bailey=None):       
     """Simulates a variable star. Theory from McGill et al. (2018).
     
     This function is outdated! Replaced with rrlyr_variable which employs the use
     of templates, thus more representative of true RRLyrae stars.
 
-    Parameters
+    Parameters:
     ----------
-    timestamps : array
-        Times at which to simulate the lightcurve.
-    baseline : float
-        Baseline magnitude at which to simulate the lightcurve.
-    bailey : int, optional 
-        The type of variable to simulate. A bailey
-        value of 1 simulaes RR Lyrae type ab, a value
-        of 2 simulates RR Lyrae type c, and a value of 
-        3 simulates a Cepheid variable. If not provided
-        it defaults to a random choice between the three. 
+        timestamps : array
+            Times at which to simulate the lightcurve.
+        baseline : float
+            Baseline magnitude at which to simulate the lightcurve.
+        bailey : int, optional 
+            The type of variable to simulate. A bailey
+            value of 1 simulaes RR Lyrae type ab, a value
+            of 2 simulates RR Lyrae type c, and a value of 
+            3 simulates a Cepheid variable. If not provided
+            it defaults to a random choice between the three. 
 
-    Returns
+    Returns:
     -------
-    mag : array
-        Simulated magnitudes given the timestamps.
-    amplitude : float
-        Amplitude of the signal in mag. 
-    bailey : float
-        Period of the signal in days.   
+        mag : array
+            Simulated magnitudes given the timestamps.
+        amplitude : float
+            Amplitude of the signal in mag. 
+        bailey : float
+            Period of the signal in days.   
     """
 
     time, ampl_k, phase_k, period = setup_parameters(timestamps, bailey)
     lightcurve = np.array(baseline)
 
     for idx in range(len(ampl_k)):
         lightcurve = lightcurve + ampl_k[idx] * np.cos(((2*np.pi*(idx+1))/period)*time+phase_k[idx])
@@ -241,36 +241,36 @@
 
     return np.array(lightcurve), amplitude, period 
 
 def simulate_mira_lightcurve(timestamps, baseline, primary_period, amplitude_pp, secondary_period, amplitude_sp, tertiary_period, amplitude_tp):
     """
     Simulates a Mira long-period variable (LPV) lightcurve.
 
-    Parameters
+    Parameters:
     ----------
-    timestamps : array-like
-        Times at which to simulate the lightcurve.
-    baseline : float
-        Baseline magnitude at which to simulate the lightcurve.
-    primary_period : float
-        Primary period of the Mira.
-    amplitude_pp : float
-        Amplitude of the primary period.
-    secondary_period : float
-        Secondary period of the Mira.
-    amplitude_sp : float
-        Amplitude of the secondary period.
-    tertiary_period : float
-        Tertiary period of the Mira.
-    amplitude_tp : float
-        Amplitude of the tertiary period.
+        timestamps : array-like
+            Times at which to simulate the lightcurve.
+        baseline : float
+            Baseline magnitude at which to simulate the lightcurve.
+        primary_period : float
+            Primary period of the Mira.
+        amplitude_pp : float
+            Amplitude of the primary period.
+        secondary_period : float
+            Secondary period of the Mira.
+        amplitude_sp : float
+            Amplitude of the secondary period.
+        tertiary_period : float
+            Tertiary period of the Mira.
+        amplitude_tp : float
+            Amplitude of the tertiary period.
 
-    Returns
+    Returns:
     -------
-    mag : array
+    array
         Simulated magnitudes given the timestamps.
     """
 
     amplitudes, periods = random_mira_parameters(primary_period, amplitude_pp, secondary_period, amplitude_sp, tertiary_period, amplitude_tp)
     lc = np.array(baseline)
 
     for idx in range(len(amplitudes)):
@@ -293,30 +293,30 @@
     In the context of the Mira lightcurve simulation, these parameters determine the contribution of the secondary 
     and tertiary periods to the overall variability of the lightcurve. By adjusting the values of f1, f2, and f3, you 
     can control the relative strengths of these additional periodic variations.
 
     These parameters are specific to the simulation model and are chosen based on the desired characteristics of the 
     simulated Mira lightcurve. They are typically determined based on observational data or theoretical considerations.
 
-    Returns
+    Returns:
     -------
-    a1 : float
-        Parameter a1.
-    ratio12 : float
-        Ratio between parameter 1 and parameter 2.
-    ratio13 : float
-        Ratio between parameter 1 and parameter 3.
-    ratio14 : float
-        Ratio between parameter 1 and parameter 4.
-    f1 : float
-        Parameter f1.
-    f2 : float
-        Parameter f2.
-    f3 : float
-        Parameter f3.
+        a1 : float
+            Parameter a1.
+        ratio12 : float
+            Ratio between parameter 1 and parameter 2.
+        ratio13 : float
+            Ratio between parameter 1 and parameter 3.
+        ratio14 : float
+            Ratio between parameter 1 and parameter 4.
+        f1 : float
+            Parameter f1.
+        f2 : float
+            Parameter f2.
+        f3 : float
+            Parameter f3.
     """
 
     a1=  0.31932222222222223
     ratio12 = 0.4231184105222867 
     ratio13 = 0.3079439089738683 
     ratio14 = 0.19454399944326523
     f1 =  3.9621766666666667
@@ -327,28 +327,28 @@
 
 def parametersRR1():
     """
     Returns the physical parameters for RR1 type variable stars.
 
     Returns
     -------
-    a1 : float
-        Parameter a1.
-    ratio12 : float
-        Ratio between parameter 1 and parameter 2.
-    ratio13 : float
-        Ratio between parameter 1 and parameter 3.
-    ratio14 : float
-        Ratio between parameter 1 and parameter 4.
-    f1 : float
-        Parameter f1.
-    f2 : float
-        Parameter f2.
-    f3 : float
-        Parameter f3.
+        a1 : float
+            Parameter a1.
+        ratio12 : float
+            Ratio between parameter 1 and parameter 2.
+        ratio13 : float
+            Ratio between parameter 1 and parameter 3.
+        ratio14 : float
+            Ratio between parameter 1 and parameter 4.
+        f1 : float
+            Parameter f1.
+        f2 : float
+            Parameter f2.
+        f3 : float
+            Parameter f3.
     """
 
     a1 =  0.24711999999999998
     ratio12 = 0.1740045322110716 
     ratio13 = 0.08066256609474477 
     ratio14 = 0.033964605589727
     f1 =  4.597792666666666
@@ -357,26 +357,26 @@
 
     return a1, ratio12, ratio13, ratio14, f1, f2, f3
 
 def uncertainties(time, curve, uncertain_factor):       
     """
     Adds random uncertainties to a given curve.
 
-    Parameters
+    Parameters:
     ----------
-    time : array-like
-        Times at which the curve is defined.
-    curve : array-like
-        Curve values.
-    uncertain_factor : float
-        Uncertainty factor in percentage.
+        time : array-like
+            Times at which the curve is defined.
+        curve : array-like
+            Curve values.
+        uncertain_factor : float
+            Uncertainty factor in percentage.
 
-    Returns
+    Returns:
     -------
-    realcurve : array
+    array
         Curve with added uncertainties.
     """
 
     N = len(time)
     uncertainty = np.random.normal(0, uncertain_factor/100, N)
     realcurve = []   
     #curve with uncertainties
@@ -385,29 +385,29 @@
 
     return realcurve
 
 def setup_parameters(timestamps, bailey=None):   
     """
     Setup of random physical parameters
     
-    Parameters
+    Parameters:
     ----------
     timestamps : array
         Times at which to simulate the lightcurve.
     bailey : int, optional 
         The type of variable to simulate. A bailey
         value of 1 simulaes RR Lyrae type ab, a value
         of 2 simulates RR Lyrae type c, and a value of 
         3 simulates a Cepheid variable. If not provided
         it defaults to a random choice between the three. 
     
-    Returns
+    Returns:
     -------
-    time, amp, phase, period : array
-        Time, amplitude, phase, period.
+    array, float
+        Outputs four values: time (array), amplitude (float), phase (float), and period (float).
     """
 
     time = np.array(timestamps) 
     if bailey is None:
         bailey = np.random.randint(1,4)
     if bailey < 0 or bailey > 3:
         raise RuntimeError("Bailey out of range, must be between 1 and 3.")
@@ -431,35 +431,35 @@
     
     return time, ampl_k, phase_k, period
 
 def random_mira_parameters(primary_period, amplitude_pp, secondary_period, amplitude_sp, tertiary_period, amplitude_tp):
     """
     Sets up random physical parameters for simulating Mira lightcurves.
 
-    Parameters
+    Parameters:
     ----------
-    primary_period : array-like
-        Array of primary periods.
-    amplitude_pp : array-like
-        Array of amplitudes for the primary periods.
-    secondary_period : array-like
-        Array of secondary periods.
-    amplitude_sp : array-like
-        Array of amplitudes for the secondary periods.
-    tertiary_period : array-like
-        Array of tertiary periods.
-    amplitude_tp : array-like
-        Array of amplitudes for the tertiary periods.
+        primary_period : array-like
+            Array of primary periods.
+        amplitude_pp : array-like
+            Array of amplitudes for the primary periods.
+        secondary_period : array-like
+            Array of secondary periods.
+        amplitude_sp : array-like
+            Array of amplitudes for the secondary periods.
+        tertiary_period : array-like
+            Array of tertiary periods.
+        amplitude_tp : array-like
+            Array of amplitudes for the tertiary periods.
 
-    Returns
+    Returns:
     -------
-    amplitudes : list
-        List of amplitudes for the simulated lightcurve.
-    periods : list
-        List of periods for the simulated lightcurve.
+        amplitudes : list
+            List of amplitudes for the simulated lightcurve.
+        periods : list
+            List of periods for the simulated lightcurve.
     """
 
     len_miras = len(primary_period)
     rand_idx = np.random.randint(0,len_miras,1)
     amplitudes = [amplitude_pp[rand_idx], amplitude_sp[rand_idx], amplitude_tp[rand_idx]]
     periods = [primary_period[rand_idx], secondary_period[rand_idx], tertiary_period[rand_idx]]
 
@@ -478,36 +478,36 @@
     Cepheid Variables which have an average period of 10 days.
     
     See:
     Template-based Period Fitting: https://www.astroml.org/gatspy/periodic/template.html
     Period distribution for RR Lyrae from Sesar et al. 2010 (https://arxiv.org/abs/0910.4611).
     Period distribution for Cepheids from Becker et al. 1977 (http://adsabs.harvard.edu/abs/1977ApJ...218..633B)
 
-    Parameters
+    Parameters:
     ----------
-    timestamps : array
-        Times at which to simulate the lightcurve.
-    baseline : float
-        Baseline at which to simulate the lightcurve.
-    bailey : int, optional 
-        The type of variable to simulate. A bailey
-        value of 1 simulaes RR Lyrae type ab, a value
-        of 2 simulates RR Lyrae type c, and a value of 
-        3 simulates a Cepheid variable period, but note the amplitude
-        is still derived from the RRLyrae template. If not provided
-        it defaults to a random choice between 1 and 2. 
+        timestamps : array
+            Times at which to simulate the lightcurve.
+        baseline : float
+            Baseline at which to simulate the lightcurve.
+        bailey : int, optional 
+            The type of variable to simulate. A bailey
+            value of 1 simulaes RR Lyrae type ab, a value
+            of 2 simulates RR Lyrae type c, and a value of 
+            3 simulates a Cepheid variable period, but note the amplitude
+            is still derived from the RRLyrae template. If not provided
+            it defaults to a random choice between 1 and 2. 
 
-    Returns
+    Returns:
     -------
-    mag : array
-        Simulated magnitudes given the timestamps.
-    amplitude : float
-        Amplitude of the signal in mag. 
-    period : float
-        Period of the signal in days.
+        mag : array
+            Simulated magnitudes given the timestamps.
+        amplitude : float
+            Amplitude of the signal in mag. 
+        period : float
+            Period of the signal in days.
     """
 
     if bailey is None: 
         bailey = np.random.randint(1,3) #Removing Bailey=3 option
     if bailey < 0 or bailey > 3:
         raise RuntimeError("Bailey out of range, must be between 1 and 3.")
 
@@ -546,19 +546,18 @@
     return np.array(mag_fit), amplitude, period
 
 
 def get_rrlyr_data_path():
     """
     Retrieves the path to the RRLyrae template data directory within the MicroLIA package.
 
-    Args:
-        None
-
     Returns:
-        data_path (str): Path to the data directory.
+    --------
+    str
+        Path to the data directory.
     """
 
     resource_package = __name__
     resource_path = 'data'
     data_path = pkg_resources.resource_filename(resource_package, resource_path)
     
     return data_path
```

### Comparing `MicroLIA-2.2.6/MicroLIA/training_set.py` & `MicroLIA-2.2.7/MicroLIA/training_set.py`

 * *Files 8% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 from MicroLIA import simulate
 from MicroLIA import noise_models
 from MicroLIA import quality_check
 from MicroLIA import extract_features
 from MicroLIA import features
 
 def create(timestamps, load_microlensing=None, min_mag=14, max_mag=21, noise=None, zp=24, exptime=60, 
-    n_class=500, ml_n1=7, cv_n1=7, cv_n2=1, t0_dist=None, u0_dist=None, tE_dist=None, filename='', 
+    n_class=500, ml_n1=7, cv_n1=7, cv_n2=1, t0_dist=None, u0_dist=None, tE_dist=None, filename=None, 
     apply_weights=True, save_file=True):
     """
     Creates a training dataset using adaptive cadence.
     Simulates each class n_class times, adding errors from
     a noise model either defined using the create_noise
     function, or Gaussian by default.
 
@@ -38,209 +38,183 @@
         To input your own microlensing lightcurves, you can set the load_microlensing parameter, which
         takes the path to a directory containing the lightcurve text files (3 columns: time,mag,magerr).
 
         Instead of a path, another valid input is a 3-dimensional array or list. This will be parsed one 
         element at a time along the 0th axis. Example:
 
         >>> lightcurves = []
-        >>> lightcurve_1 = np.c_[time1,mag1,magerr1]
-        >>> lightcurve_2 = np.c_[time2,mag2,magerr2]
+        >>> lightcurve_1 = np.c_[time1, mag1, magerr1]
+        >>> lightcurve_2 = np.c_[time2, mag2, magerr2]
         >>>
         >>> lightcurves.append(lightcurve_1)
         >>> lightcurves.append(lightcurve_2)
         >>>
         >>> create(timestamps, load_microlensing=lightcurves)
         
-    Parameters
-    __________
-    timestamps : list of arrays
-        Times at which to simulate the different lightcurves.
-        Must be an array containing all possible timestamps combinations.
-    load_microlensing : str, list, optional
-        Either a 3-dimensional array containing the lightcurves, or the path to a folder containing
-        the lightcurve text files. Data is asummed to be in following columns: time, mag, magerr. 
-        Defaults to None, in which case the microlensing lightcurves are simulated.
-    min_mag : float, optional
-        Minimum baseline magnitude for simulating lightcurves.
-        Defaults to 14. 
-    max_mag : float, optional 
-        Maximum baseline magnitude for simulating lightcurves.
-        Defaults to 21.
-    noise : function, optional 
-        Noise model, can be created using the create_noise function.
-        If None it defaults to adding Gaussian noise. 
-    zp: float
-        The zero point of the observing instrument, will be used when generating
-        the noise model. Defaults to 24.
-    exptime: float
-        Exposure time, will be used to generate the noise model. Defaults to 60 seconds.
-    n_class : int, optional
-        The amount of lightcurve (per class) to simulate.
-        Defaults to 500. 
-    ml_n1 : int, optional
-        The mininum number of measurements that should be within the 
-        microlensing signal when simulating the lightcurves. 
-    cv_n1 : int, optional
-        The mininum number of measurements that should be within 
-        at least one CV outburst when simulating the lightcurves.
-    cv_n2 : int, optional
-        The mininum number of measurements that should be within the 
-        rise or drop of at least one CV outburst when simulating the lightcurves.
-    t0_dist: array, optional
-        An array containing the minumum and maximum t0 value to be 
-        considered during the microlensing simulations. The indivial
-        t0 per simulation will be selected from a uniform distribution
-        between these two values.
-    u0_dist: array, optional
-        An array containing the minumum and maximum u0 value to be 
-        considered during the microlensing simulations. The indivial
-        u0 per simulation will be selected from a uniform distribution
-        between these two values.
-    te_dist: array, optional
-        An array containing the minumum and maximum tE value to be 
-        considered during the microlensing simulations. The indivial
-        tE per simulation will be selected from a uniform distribution
-        between these two values.
-    filename: str, optional
-        The name to be appended to the lightcurves.fits and the all_features.txt
-        files, only relevant if save_file=True. If no argument is input the
-        files will be saved with the default names only.
-    apply_weights: bool 
-        Whether to apply the photometric errors when calculating the features. Defaults
-        to True. Note that this assumes that the erros are Gaussian and uncorrelated. 
-    save_file: bool
-        If True the lightcurve.fits and all_features.txt files will be
-        saved to the home directory. Defaults to True.
-
-    Outputs
-    _______
-    data_x : array
-        2D array containing the statistical metrics of all simulated lightcurves.
-    data_y : array
-        1D array containing the class label of all simulated lightcurves.
-    dataset : FITS
-        All simulated lightcurves in a FITS file, sorted by class and ID
-    all_features : txt file
-        A txt file containing all the features plus class label and ID.
+    Parameters:
+    ----------
+        timestamps : list
+            Times at which to simulate the different lightcurves.
+            Must be an array/list containing all possible timestamps combinations, stored as lists.
+        load_microlensing : str, list, optional
+            Either a 3-dimensional array containing the lightcurves, or the path to a folder containing
+            the lightcurve text files. Data is asummed to be in following columns: time, mag, magerr. 
+            Defaults to None, in which case the microlensing lightcurves are simulated.
+        min_mag : float, optional
+            Minimum baseline magnitude for simulating lightcurves. Defaults to 14. 
+        max_mag : float, optional 
+            Maximum baseline magnitude for simulating lightcurves. Defaults to 21.
+        noise : function, optional 
+            Noise model, must be a function of flux, can be created using the create_noise function.
+            If None it defaults to Gaussian noise. Defaults to None.
+        zp : float
+            The zero point of the observing instrument, will be used when generating
+            the noise model. Defaults to 24.
+        exptime : float
+            Exposure time in seconds, will be used to generate the noise model. Defaults to 60.
+        n_class : int, optional
+            The amount of lightcurve (per class) to simulate. Defaults to 500. 
+        ml_n1 : int, optional
+            The mininum number of measurements that should be within the microlensing 
+            signal when simulating the lightcurves. Defaults to 7.
+        cv_n1 : int, optional
+            The mininum number of measurements that should be within at least one CV outburst 
+            when simulating the lightcurves. Defaults to 7.
+        cv_n2 : int, optional
+            The mininum number of measurements that should be within the rise or drop of at least 
+            one CV outburst when simulating the lightcurves. Defaults to 1.
+        t0_dist: array, tuple, optional
+            An array or tuple containing two values, the minimum and maximum value (in that order) to 
+            consider when simulating the microlensing events (in days), as this t0 parameter will be selected
+            using a random uniform distribution according to these bounds. Defaults to None, which will 
+            compute an appropriate t0 according to the range of the input timestamps.
+        u0_dist: array, optional
+            An array or tuple containing two values, the minimum and maximum value (in that order) to 
+            consider when simulating the microlensing events, as this u0 parameter will be selected
+            using a random uniform distribution according to these bounds. Defaults to None, which will 
+            set these bounds to (0, 1).
+        te_dist: array, optional
+            An array containing the mean and standard deviation (in that order) to consider for this tE parameter
+            during the microlensing simulations, as this value will be selected from a random normal distribution
+            using the specified mean and standard deviation. Defaults to None which will apply a mean of 30 with
+            a spread of 10 days.
+        apply_weights: bool 
+            Whether to apply the photometric errors when calculating the features. Defaults
+            to True. Note that this assumes that the erros are Gaussian and uncorrelated. 
+        save_file: bool
+            If True the lightcurve.fits and all_features.txt files will be saved to the home directory. 
+            Defaults to True.
+        filename: str, optional
+            The name to be appended to the saved files, only applicable if save_file is set to True.
+            files, only relevant if save_file=True. If no argument is input the
+            files will be saved with the default names only. Defaults to None.
+
+    Returns:
+    -------
+        data_x : array
+            2D array containing the statistical metrics of all simulated lightcurves.
+        data_y : array
+            1D array containing the class label of all simulated lightcurves.
+        lightcurves : FITS
+            All simulated lightcurves in a FITS file, sorted by class label and unique ID. Only
+            saved if save_file=True.
+        all_features : text file
+            A txt file containing all the features sorted by class label and unique ID. Only
+            saved if save_file=True.
+        csv : CSV file
+            A CSV file containing the training data present in the saved text file, which contains
+            the feature names and can be input directly when creating the classifier. Only
+            saved if save_file=True.
     """
 
     if len(getmembers(features, isfunction))*2 > n_class*5:
-        print("WARNING: Parameter n_class must be at least "+str(int(1+len(getmembers(features, isfunction))*2//5))+" for principal components to be computed.")
+        print("WARNING: The n_class argument must be at least "+str(int(1+len(getmembers(features, isfunction))*2//5))+" for principal components to be computed.")
+
+    if not isinstance(timestamps, (list, np.ndarray)):
+        raise ValueError("Incorrect format -- timestamps should be stored in a list or array.")
+
+    if any(not isinstance(ts, (list, np.ndarray)) for ts in timestamps):
+        raise ValueError("Incorrect format -- each element in timestamps should be a list or array.")
 
-    while True:
-        try:
-            len(timestamps[0])
-            break
-        except TypeError:
-            raise ValueError("Incorrect format -- append the timestamps to a list and try again.")
-
-    times_list=[]
-    mag_list=[]
-    magerr_list=[]
-    id_list = []
-    source_class_list=[]
-    stats_list = []
+    times_list, mag_list, magerr_list, id_list, source_class_list, stats_list = [], [], [], [], [], []
 
     progess_bar = bar.FillingSquaresBar('Simulating variables......', max=n_class)
-    for k in range(1,n_class+1):
-        time = random.choice(timestamps)
-        baseline = np.random.uniform(min_mag,max_mag)
+    for k in range(1, n_class+1):
+        time, baseline = random.choice(timestamps), np.random.uniform(min_mag, max_mag)
         mag, amplitude, period = simulate.rrlyr_variable(time, baseline)
         
         #Incorrect template fitting yields negative mag! 
         if np.min(mag) < 0:
             while np.min(mag) < 0:
                 mag, amplitude, period = simulate.rrlyr_variable(time, baseline)
                 
         if noise is not None:
             mag, magerr = noise_models.add_noise(mag, noise, zp=zp, exptime=exptime)
         if noise is None:
            mag, magerr = noise_models.add_gaussian_noise(mag, zp=zp, exptime=exptime)
            
-        source_class = ['VARIABLE']*len(time)
-        source_class_list.append(source_class)
-
-        id_num = [k]*len(time)
-        id_list.append(id_num)
-
-        times_list.append(time)
-        mag_list.append(mag)
-        magerr_list.append(magerr)
+        source_class_list.append(['VARIABLE']*len(time)); id_list.append([k]*len(time))
+        times_list.append(time); mag_list.append(mag); magerr_list.append(magerr)
         
         stats, feature_names = extract_features.extract_all(time, mag, magerr, apply_weights=apply_weights, convert=True, zp=zp, return_names=True)
         stats = [i for i in stats]
         stats = ['VARIABLE'] + [k] + stats
         stats_list.append(stats)
         progess_bar.next()
     progess_bar.finish()
 
     progess_bar = bar.FillingSquaresBar('Simulating constants......', max=n_class)
     for k in range(1,n_class+1):
-        time = random.choice(timestamps)
-        baseline = np.random.uniform(min_mag,max_mag)
+        time, baseline = random.choice(timestamps), np.random.uniform(min_mag, max_mag)
         mag = simulate.constant(time, baseline)
         
         if noise is not None:
             mag, magerr = noise_models.add_noise(mag, noise, zp=zp, exptime=exptime)
         if noise is None:
            mag, magerr = noise_models.add_gaussian_noise(mag, zp=zp, exptime=exptime)
            
-        source_class = ['CONSTANT']*len(time)
-        source_class_list.append(source_class)
-
-        id_num = [1*n_class+k]*len(time)
-        id_list.append(id_num)
-
-        times_list.append(time)
-        mag_list.append(mag)
-        magerr_list.append(magerr)
+        source_class_list.append(['CONSTANT']*len(time)); id_list.append([1*n_class+k]*len(time))
+        times_list.append(time); mag_list.append(mag); magerr_list.append(magerr)
         
         stats = extract_features.extract_all(time, mag, magerr, apply_weights=apply_weights, convert=True, zp=zp)
         stats = [i for i in stats]
         stats = ['CONSTANT'] + [1*n_class+k] + stats
         stats_list.append(stats) 
         progess_bar.next()  
     progess_bar.finish()
 
     progess_bar = bar.FillingSquaresBar('Simulating CV.............', max=n_class)   
-    for k in range(1,n_class+1):
+    for k in range(1, n_class+1):
         for j in range(100):
             if j > 20:
                 warn('Taking longer than usual to simulate CV... this happens if the timestamps are too sparse \
                 as it takes longer to simulate lightcurves that pass the quality check. The process will break after \
                 one hundred attempts, if this happens you can try setting the outburst parameter cv_n1 to a value between 2 and 6.')
-            time = random.choice(timestamps)
-            baseline = np.random.uniform(min_mag,max_mag)
+            
+            time, baseline = random.choice(timestamps), np.random.uniform(min_mag, max_mag)
             mag, burst_start_times, burst_end_times, end_rise_times, end_high_times = simulate.cv(time, baseline)
             
             quality = quality_check.test_cv(time, burst_start_times, burst_end_times, end_rise_times, end_high_times, n1=cv_n1, n2=cv_n2)
-            if quality is True:
+            if quality:
                 try:
                     if noise is not None:
                         mag, magerr = noise_models.add_noise(mag, noise, zp=zp, exptime=exptime)
                     if noise is None:
                         mag, magerr = noise_models.add_gaussian_noise(mag, zp=zp, exptime=exptime)
                 except ValueError:
                     continue
                 
-                source_class = ['CV']*len(time)
-                source_class_list.append(source_class)
-                id_num = [2*n_class+k]*len(time)
-                id_list.append(id_num)
-            
-                times_list.append(time)
-                mag_list.append(mag)
-                magerr_list.append(magerr)
+                source_class_list.append(['CV']*len(time)); id_list.append([2*n_class+k]*len(time))
+                times_list.append(time); mag_list.append(mag); magerr_list.append(magerr)
                 
                 stats = extract_features.extract_all(time, mag, magerr, apply_weights=apply_weights, convert=True, zp=zp)
                 stats = [i for i in stats]
                 stats = ['CV'] + [2*n_class+k] + stats
                 stats_list.append(stats)
-                progess_bar.next()
-                break
+                progess_bar.next(); break
 
             if j == 99:
                 raise RuntimeError('Unable to simulate proper CV in 100 tries with current cadence -- inspect cadence and try again.')
     progess_bar.finish()
 
     progess_bar = bar.FillingSquaresBar('Simulating LPV............', max=n_class)  
     resource_package = __name__
@@ -251,224 +225,209 @@
     amplitude_pp = mira_table.array['col5'].data
     secondary_period = mira_table.array['col6'].data
     amplitude_sp = mira_table.array['col7'].data
     tertiary_period = mira_table.array['col8'].data
     amplitude_tp = mira_table.array['col9'].data
 
     for k in range(1,n_class+1):
-        time = random.choice(timestamps)
-        baseline = np.random.uniform(min_mag,max_mag)
-        mag = simulate.simulate_mira_lightcurve(time, baseline, primary_period, amplitude_pp, secondary_period, amplitude_sp, tertiary_period, amplitude_tp)
-    
-        try:
-            if noise is not None:
-                mag, magerr = noise_models.add_noise(mag, noise, zp=zp, exptime=exptime)
-            if noise is None:             
-                mag, magerr = noise_models.add_gaussian_noise(mag, zp=zp, exptime=exptime)
-        except ValueError:
-            continue
-                
-        source_class = ['LPV']*len(time)
-        source_class_list.append(source_class)
-
-        id_num = [4*n_class+k]*len(time)
-        id_list.append(id_num)
-
-        times_list.append(time)
-        mag_list.append(mag)
-        magerr_list.append(magerr)
-        
-        stats = extract_features.extract_all(time, mag, magerr, apply_weights=apply_weights, convert=True, zp=zp)
-        stats = [i for i in stats]
-        stats = ['LPV'] + [4*n_class+k] + stats
-        stats_list.append(stats)
-        progess_bar.next()
+        for j in range(100):
+            time, baseline = random.choice(timestamps), np.random.uniform(min_mag, max_mag)
+            mag = simulate.simulate_mira_lightcurve(time, baseline, primary_period, amplitude_pp, secondary_period, amplitude_sp, tertiary_period, amplitude_tp)
+            
+            try:
+                if noise is not None:
+                    mag, magerr = noise_models.add_noise(mag, noise, zp=zp, exptime=exptime)
+                if noise is None:             
+                    mag, magerr = noise_models.add_gaussian_noise(mag, zp=zp, exptime=exptime)
+            except ValueError:
+                if j == 99:
+                    raise RuntimeError('Unable to simulate proper LPV in 100 tries with current cadence -- inspect cadence and try again.')
+                continue
+                    
+            source_class_list.append(['LPV']*len(time)); id_list.append([4*n_class+k]*len(time))
+            times_list.append(time); mag_list.append(mag); magerr_list.append(magerr)
+            
+            stats = extract_features.extract_all(time, mag, magerr, apply_weights=apply_weights, convert=True, zp=zp)
+            stats = [i for i in stats]
+            stats = ['LPV'] + [4*n_class+k] + stats
+            stats_list.append(stats)
+            progess_bar.next(); break
     progess_bar.finish()
 
     if load_microlensing is None:
         progess_bar = bar.FillingSquaresBar('Simulating microlensing...', max=n_class)  
         for k in range(1,n_class+1):
             for j in range(100):
                 if j > 20:
                     warn('Taking longer than usual to simulate ML... this happens if the timestamps are too sparse \
                     as it takes longer to simulate lightcurves that pass the quality check. The process will break after \
                     one hundred attempts, if this happens you can try setting the event parameter ml_n1 to a value between 2 and 6.')
-                time = random.choice(timestamps)
-                baseline = np.random.uniform(min_mag,max_mag)
-                mag, baseline, u_0, t_0, t_e, blend_ratio = simulate.microlensing(time, baseline, t0_dist, u0_dist, tE_dist)
+                
+                time, baseline = random.choice(timestamps), np.random.uniform(min_mag, max_mag)
+                mag, u_0, t_0, t_e, blend_ratio = simulate.microlensing(time, baseline, t0_dist, u0_dist, tE_dist)
 
                 try:
                     if noise is not None:
                         mag, magerr = noise_models.add_noise(mag, noise, zp=zp, exptime=exptime)
-                    if noise is None:             
-                        mag, magerr= noise_models.add_gaussian_noise(mag, zp=zp, exptime=exptime)
+                    if noise is None:
+                        mag, magerr = noise_models.add_gaussian_noise(mag, zp=zp, exptime=exptime)
                 except ValueError:
                     continue
-                    
+            
                 quality = quality_check.test_microlensing(time, mag, magerr, baseline, u_0, t_0, t_e, blend_ratio, n=ml_n1)
-                if quality is True:          
-                    source_class = ['ML']*len(time)
-                    source_class_list.append(source_class)
-                    id_num = [3*n_class+k]*len(time)
-                    id_list.append(id_num)
-                
-                    times_list.append(time)
-                    mag_list.append(mag)
-                    magerr_list.append(magerr)
+                if quality:     
+                    source_class_list.append(['ML']*len(time)); id_list.append([3*n_class+k]*len(time)) 
+                    times_list.append(time); mag_list.append(mag); magerr_list.append(magerr)
                    
                     stats = extract_features.extract_all(time, mag, magerr, apply_weights=apply_weights, convert=True, zp=zp)
                     stats = [i for i in stats]
                     stats = ['ML'] + [3*n_class+k] + stats
                     stats_list.append(stats)
-                    progess_bar.next()
-                    break
+                    progess_bar.next(); break
 
                 if j == 99:
-                    raise RuntimeError('Unable to simulate proper ML in 100 tries with current cadence -- inspect cadence and/or noise model and try again.')
+                    raise RuntimeError('Unable to simulate proper microlensing in 100 tries with current cadence -- inspect cadence and/or noise model and try again.')
         progess_bar.finish()
+
     else:
-        try: #If load_microlensing is a list
+        try: #If load_microlensing is a list containing the lightcurves
             progess_bar = bar.FillingSquaresBar('Loading microlensing......', max=len(load_microlensing)) 
             for i in range(len(load_microlensing)):
                 time, mag, magerr = load_microlensing[i][:,0], load_microlensing[i][:,1], load_microlensing[i][:,2]
-                source_class = ['ML']*len(time)
-                source_class_list.append(source_class)
-
-                id_num = [1*n_class+k+i]*len(time)
-                id_list.append(id_num)
-
-                times_list.append(time)
-                mag_list.append(mag)
-                magerr_list.append(magerr)
+                
+                source_class_list.append(['ML']*len(time)); id_list.append([1*n_class+k+i]*len(time))
+                times_list.append(time); mag_list.append(mag); magerr_list.append(magerr)
                 
                 stats = extract_features.extract_all(time, mag, magerr, apply_weights=apply_weights, convert=True, zp=zp)
                 stats = [i for i in stats]
                 stats = ['ML'] + [1*n_class+k+i] + stats
                 stats_list.append(stats) 
                 progess_bar.next()  
             progess_bar.finish()
             
-        except: #If load_microlensing is a path 
-            if load_microlensing[-1] != '/':
-                load_microlensing+='/'
+        except: #If load_microlensing is a path to where the lightcurves are saved
+            load_microlensing += '/' if load_microlensing[-1] != '/' else load_microlensing
             filenames = [name for name in os.listdir(load_microlensing)]
             progess_bar = bar.FillingSquaresBar('Loading microlensing......', max=len(filenames)) 
             for i in range(len(load_microlensing)):
                 try:
                     lightcurve = np.loadtxt(load_microlensing+filenames[i])
                     time, mag, magerr = lightcurve[:,0], lightcurve[:,1], lightcurve[:,2]
                 except:
                     print('WARNING: File {} could not be loaded, skipping...'.format(filenames[i]))
                     continue
 
-                source_class = ['ML']*len(time)
-                source_class_list.append(source_class)
-
-                id_num = [1*n_class+k+i]*len(time)
-                id_list.append(id_num)
-
-                times_list.append(time)
-                mag_list.append(mag)
-                magerr_list.append(magerr)
+                source_class_list.append(['ML']*len(time)); id_list.append([1*n_class+k+i]*len(time))
+                times_list.append(time); mag_list.append(mag); magerr_list.append(magerr)
                 
                 stats = extract_features.extract_all(time, mag, magerr, apply_weights=apply_weights, convert=True, zp=zp)
                 stats = [i for i in stats]
                 stats = ['ML'] + [1*n_class+k+i] + stats
                 stats_list.append(stats) 
                 progess_bar.next()  
             progess_bar.finish()
 
     if save_file:
-        print('Writing files to home directory...')
+        print('Writing files to local home directory...')
         path = str(Path.home())+'/'
 
         col0 = fits.Column(name='Class', format='20A', array=np.hstack(source_class_list))
         col1 = fits.Column(name='ID', format='E', array=np.hstack(id_list))
         col2 = fits.Column(name='time', format='D', array=np.hstack(times_list))
         col3 = fits.Column(name='mag', format='E', array=np.hstack(mag_list))
         col4 = fits.Column(name='magerr', format='E', array=np.hstack(magerr_list))
         cols = fits.ColDefs([col0, col1, col2, col3, col4])
         hdu = fits.BinTableHDU.from_columns(cols)
 
-        fname = Path('lightcurves_'+filename+'_.fits')
+        fname = Path('lightcurves_'+filename+'.fits') if filename is not None else Path('lightcurves.fits')
+
         if fname.exists(): #To avoid error if file already exists
             fname.unlink()
         hdu.writeto(path+str(fname),overwrite=True)
 
-        np.savetxt(path+'temporary_feats.txt', np.array(stats_list).astype(str), fmt='%s')
-        with open(path+'temporary_feats.txt', 'r') as infile, open(path+'all_features_'+filename+'.txt', 'w') as outfile:    
+        np.savetxt(path+'__temporary_feats__.txt', np.array(stats_list).astype(str), fmt='%s')
+        _file_ = path+'all_features_'+filename+'.txt' if filename is not None else path+'all_features.txt'
+
+        with open(path+'__temporary_feats__.txt', 'r') as infile, open(_file_, 'w') as outfile:    
             outfile.write('# FEAT NAMES # || ' + ' || '.join(feature_names) + '\n')
             data = infile.read()
             data = data.replace("'", "")
             data = data.replace(",", "")
             data = data.replace("[", "")
             data = data.replace("]", "")
             outfile.write(data)
-        os.remove(path+'temporary_feats.txt')
+        os.remove(path+'__temporary_feats__.txt')
 
     data = np.array(stats_list)
-    data_x = data[:,2:].astype('float')
-    data_y = data[:,0].astype(str)
+    data_x, data_y= data[:,2:].astype('float'), data[:,0].astype(str)
+
+    if save_file:
+        df = DataFrame(data_x, columns=feature_names)
+        df['label'] = data_y
 
-    df = DataFrame(data_x, columns=feature_names)
-    df['label'] = data_y
-    df.to_csv(path+'MicroLIA_Training_Set_'+filename+'_.csv', index=False)
-    print("Complete! Files saved in: {}".format(path))
+        if filename is None:
+            df.to_csv(path+'MicroLIA_Training_Set.csv', index=False)
+        else:
+            df.to_csv(path+'MicroLIA_Training_Set_'+filename+'.csv', index=False)
+
+        print("Complete! Files saved in: {}".format(path))
 
     return data_x, data_y
 
-def load_all(path, convert=True, zp=24, filename='', extract_all=True, apply_weights=True, save_file=True):
+def load_all(path, convert=True, zp=24, filename=None, apply_weights=True, save_file=True):
     """
     Function to load already simulated lightcurves. The subdirectories in the path
     must contain the lightcurve text files for each class (columns: time,mag,magerr)
 
     Note:
         If a file cannot be loaded with the standard numpy.loadtxt() function
         it will be printed and skipped, therefore no strings allowed, only the columns with the float numbers (nan ok)
 
-    Args:
-        path: str
+    Parameters:
+    ----------
+        path : str
             Path to the root directory containing the lightcurve subdirectories
-        convert: bool
+        convert : bool
             If True the magnitudes will be converted to flux using the input zeropoint.
             If the lightcurves are already in flux, set convert=False. Defaults to True.
-        zp: float
+        zp : float
             The zero point of the observing instrument, will be used to calcualate 
             the features. This is ignored used if convert=False. Defaults to 24.
-        filename: str, optional
+        filename : str, optional
             The name to be appended to the lightcurves.fits and the all_features.txt
             files, only relevant if save_file=True. If no argument is input the
-            files will be saved with the default names only.
-        apply_weights: bool 
+            files will be saved with the default names only. Defaults to None.
+        apply_weights : bool 
             Whether to apply the photometric errors when calculating the features. Defaults
             to True. Note that this assumes that the erros are Gaussian and uncorrelated. 
-        save_file: bool
+        save_file : bool
             If True the lightcurve.fits and all_features.txt files will be
             saved to the home directory. Defaults to True.
-
-    Outputs
-    _______
-    data_x : array
-        2D array containing the statistical metrics of all simulated lightcurves.
-    data_y : array
-        1D array containing the class label of all simulated lightcurves.
-    dataset : FITS
-        All simulated lightcurves in a FITS file, sorted by class and ID
-    all_features : txt file
-        A txt file containing all the features plus class label and ID.
+    
+    Returns:
+    -------
+        data_x : array
+            2D array containing the statistical metrics of all simulated lightcurves.
+        data_y : array
+            1D array containing the class label of all simulated lightcurves.
+        lightcurves : FITS
+            All simulated lightcurves in a FITS file, sorted by class label and unique ID. Only
+            saved if save_file=True.
+        all_features : text file
+            A txt file containing all the features sorted by class label and unique ID. Only
+            saved if save_file=True.
+        csv : CSV file
+            A CSV file containing the training data present in the saved text file, which contains
+            the feature names and can be input directly when creating the classifier. Only
+            saved if save_file=True.
     """
 
     sub_directories = [files.path for files in os.scandir(path) if files.is_dir()]
 
-    times_list=[]
-    mag_list=[]
-    magerr_list=[]
-    source_class_list=[]
-    id_list=[]
-    stats_list = []
+    times_list, mag_list, magerr_list, id_list, source_class_list, stats_list = [], [], [], [], [], []
 
     k=0 #ID counter
     for i in range(len(sub_directories)):
         dir_name = sub_directories[i].split('/')[-1]
         filenames = [name for name in os.listdir(sub_directories[i])]
         progess_bar = bar.FillingSquaresBar('Loading '+dir_name+' lightcurves...', max=len(filenames)) 
         for j in range(len(filenames)):
@@ -476,23 +435,16 @@
             try:
                 lightcurve = np.loadtxt(sub_directories[i]+'/'+filenames[j])
                 time, mag, magerr = lightcurve[:,0], lightcurve[:,1], lightcurve[:,2]
             except:
                 print(); print('WARNING: File {} could not be loaded, skipping...'.format(filenames[j]))
                 continue
 
-            source_class = [dir_name]*len(time)
-            source_class_list.append(source_class)
-
-            id_num = [k]*len(time)
-            id_list.append(id_num)
-
-            times_list.append(time)
-            mag_list.append(mag)
-            magerr_list.append(magerr)
+            source_class_list.append([dir_name]*len(time)); id_list.append([k]*len(time))
+            times_list.append(time); mag_list.append(mag); magerr_list.append(magerr)
 
             stats, feature_names = extract_features.extract_all(time, mag, magerr, apply_weights=apply_weights, convert=convert, zp=zp, return_names=True)
             stats = [i for i in stats]
             stats = [dir_name] + [k] + stats
             stats_list.append(stats) 
             progess_bar.next()  
         progess_bar.finish()
@@ -505,82 +457,92 @@
         col1 = fits.Column(name='ID', format='E', array=np.hstack(id_list))
         col2 = fits.Column(name='time', format='D', array=np.hstack(times_list))
         col3 = fits.Column(name='mag', format='E', array=np.hstack(mag_list))
         col4 = fits.Column(name='magerr', format='E', array=np.hstack(magerr_list))
         cols = fits.ColDefs([col0, col1, col2, col3, col4])
         hdu = fits.BinTableHDU.from_columns(cols)
 
-        fname = Path('lightcurves_'+filename+'_.fits')
-        if fname.exists(): #To avoid error if file already exists
+        fname = Path('lightcurves_'+filename+'.fits') if filename is not None else Path('lightcurves.fits')
+
+        if fname.exists(): #To avoid error if the file already exists
             fname.unlink()
         hdu.writeto(path+str(fname), overwrite=True)
 
-        np.savetxt(path+'temporary_feats.txt',np.array(stats_list).astype(str),fmt='%s')
-        with open(path+'temporary_feats.txt', 'r') as infile, open(path+'all_features_'+filename+'.txt', 'w') as outfile:    
+        np.savetxt(path+'__temporary_feats__.txt', np.array(stats_list).astype(str), fmt='%s')
+        _file_ = path+'all_features_'+filename+'.txt' if filename is not None else path+'all_features.txt'
+
+        with open(path+'__temporary_feats__.txt', 'r') as infile, open(_file_, 'w') as outfile:    
             outfile.write('# ' + ', '.join(feature_names) + '\n')
             data = infile.read()
             data = data.replace("'", "")
             data = data.replace(",", "")
             data = data.replace("[", "")
             data = data.replace("]", "")
             outfile.write(data)
-        os.remove(path+'temporary_feats.txt')
+        os.remove(path+'__temporary_feats__.txt')
 
     data = np.array(stats_list)
-    data_x = data[:,2:].astype('float')
-    data_y = data[:,0].astype(str)
-    print(data_x.shape, len(feature_names))
-    df = DataFrame(data_x, columns=feature_names)
-    df['label'] = data_y
-    df.to_csv(path+'MicroLIA_Training_Set.csv', index=False)
-    print("Complete! Files saved in: {}".format(path))
+    data_x, data_y = data[:,2:].astype('float'), data[:,0].astype(str)
+
+    if save_file:
+        df = DataFrame(data_x, columns=feature_names)
+        df['label'] = data_y
+
+        if filename is None:
+            df.to_csv(path+'MicroLIA_Training_Set.csv', index=False)
+        else:
+            df.to_csv(path+'MicroLIA_Training_Set_'+filename+'.csv', index=False)
+
+        print("Complete! Files saved in: {}".format(path))
 
     return data_x, data_y
 
 def plot(hdu, ID=None, label=None, savefig=False):
     """
     Plots simulated lightcurve, extracted from the 
     lightcurves.fits file that is saved upon training set
-    creation
+    creation.
 
-    Args:
+    Parameters:
+    ----------
         hdu (fits file) : The loaded lightcurves.fits file.
         ID (int, optional): The ID of the lightcurve to be plotted.
             This input is overwritten if label is also input. Defaults to None.
         label (str, optional): The class label of the lightcuve class
             to be plotted, the lightcurve will be chosen randomly among
             the class sample.
         savefig (bool): If True the figure will be saved to the
             working directory. Defaults to False, which will plot
             the figure instead.
 
-        Returns:
-            AxesImage
+    Returns:
+    --------
+        AxesImage
     """
 
     classes = np.unique(np.array(hdu[1].data['Class']))
 
     if ID is not None:
         index = np.where(hdu[1].data['ID'] == ID)[0]
+        
     if label is not None:
         index = np.where(hdu[1].data['Class'] == label)[0]
         index = np.random.choice(index)
         index = np.where(hdu[1].data['ID'] == hdu[1].data['ID'][index])[0]
         if len(index) == 0:
             raise ValueError('Could not find input class label, options are: {}'.format(classes))
     else:
         print('Plotting random lightcurve...')
         index = np.random.choice(np.arange(len(hdu[1].data['Class'])))
         index = np.where(hdu[1].data['ID'] == hdu[1].data['ID'][index])[0]
 
     time, mag, magerr = hdu[1].data['time'][index], hdu[1].data['mag'][index], hdu[1].data['magerr'][index]
     plt.errorbar(time, mag, magerr, fmt='ro--')
     plt.gca().invert_yaxis()
-    plt.xlabel('Time (days)')
-    plt.ylabel('Mag')
+    plt.xlabel('Time (days)'); plt.ylabel('Mag')
     plt.title(str(hdu[1].data['Class'][index[0]])+' || ID: '+str(int(hdu[1].data['ID'][index[0]])))
 
     if savefig:
         plt.savefig(str(hdu[1].data['Class'][index[0]])+'_ID_'+str(int(hdu[1].data['ID'][index[0]])), bbox_inches='tight', dpi=300)
         plt.clf()
     else:
         plt.show()
```

### Comparing `MicroLIA-2.2.6/MicroLIA.egg-info/PKG-INFO` & `MicroLIA-2.2.7/MicroLIA.egg-info/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: MicroLIA
-Version: 2.2.6
+Version: 2.2.7
 Summary: Machine learning classifier for microlensing
 Home-page: https://github.com/Professor-G/MicroLIA
 Author: Daniel Godines
 Author-email: danielgodinez123@gmail.com
 License: GPL-3.0
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
```

### Comparing `MicroLIA-2.2.6/MicroLIA.egg-info/SOURCES.txt` & `MicroLIA-2.2.7/MicroLIA.egg-info/SOURCES.txt`

 * *Files 24% similar despite different names*

```diff
@@ -19,8 +19,12 @@
 MicroLIA.egg-info/SOURCES.txt
 MicroLIA.egg-info/dependency_links.txt
 MicroLIA.egg-info/requires.txt
 MicroLIA.egg-info/top_level.txt
 MicroLIA/data/Miras_vo.xml
 MicroLIA/data/__init__.py
 MicroLIA/data/Sesar2010/RRLyr_ugriz_templates.tar.gz
-MicroLIA/data/Sesar2010/__init__.py
+MicroLIA/data/Sesar2010/__init__.py
+MicroLIA/test/__init__.py
+MicroLIA/test/test_classifier.py
+MicroLIA/test/test_features.py
+MicroLIA/test/test_ogle_lc.dat
```

### Comparing `MicroLIA-2.2.6/PKG-INFO` & `MicroLIA-2.2.7/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: MicroLIA
-Version: 2.2.6
+Version: 2.2.7
 Summary: Machine learning classifier for microlensing
 Home-page: https://github.com/Professor-G/MicroLIA
 Author: Daniel Godines
 Author-email: danielgodinez123@gmail.com
 License: GPL-3.0
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
```

### Comparing `MicroLIA-2.2.6/README.md` & `MicroLIA-2.2.7/README.md`

 * *Files 26% similar despite different names*

```diff
@@ -1,22 +1,38 @@
 [![Documentation Status](https://readthedocs.org/projects/microlia/badge/?version=latest)](https://microlia.readthedocs.io/en/latest/?badge=latest)
 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.2541465.svg)](https://doi.org/10.5281/zenodo.2541465)
 [![GPLv3 License](https://img.shields.io/badge/License-GPL%20v3-yellow.svg)](https://opensource.org/licenses/LGPL-3.0)
 [![arXiv](https://img.shields.io/badge/arXiv-2004.14347-b31b1b.svg)](https://arxiv.org/abs/2004.14347)
 
-# LIA: Lens Identification Algorithm
-LIA is an open-source program for detecting microlensing events in wide-field surveys — it’s currently adapted for single lens detection only. 
+# MicroLIA: MicroLensing Identification Algorithm
+MicroLIA is an open-source program for detecting microlensing events in wide-field surveys — it’s currently adapted for single lens detection only. 
 <img src="https://user-images.githubusercontent.com/19847448/51231407-4cce2a80-1918-11e9-8c4b-aaafeddbd335.jpg" width="900" height="500">
 
 # Installation
 
 ```
     $ pip install MicroLIA
 ```
 
+# Version 2
+
+As of version 2.2.7, MicroLIA provides the following new features and improvements:
+
+* New time-series features (74 total). To enhance the analysis, we now take the derivative of the lightcurve and re-compute the features in this derivative space, for a grand total of 148 metrics.
+* Lightcurve features can now be calculated by taking into account the flux/mag errors, thus allowing for proper weighting of data points.
+* We include a feature selection procedure so as to identify the metrics that carry useful information given the training set.
+* The short-period variables are now simulated using real RR-Lyrae templates.
+* The training set can now be generated using your own directory of lightcurves, no limit on the amount of classes.
+* After a training set is generated a csv file is saved which can be directly input when creating the classifier; in addition, the training set module contains a plot function to visualize the generated lightcurves.
+* The ensemble engine hyperparameters can now be optimized using Bayesian analysis. 
+* We added data imputation techniques to better handle undefined values in the training data.
+* We include a CNN model for image classification purposes, including a data augmentation routine and an optimization procedure for identifying the proper augmentations to perform given the training set images.
+* Built-in class methods are now available to visualize the engine parameters and performance, as well as to save and load models post-processing.
+
+
 # [Documentation](https://microlia.readthedocs.io/en/latest/?)
 
 For technical details and an example of how to implement MicroLIA for a microlensing search, check out our [Documentation](https://microlia.readthedocs.io/en/latest/?).
 
 
 # Additional Filtering: pyLIMA
 
@@ -35,13 +51,13 @@
 * test_features
 * test_classifier
 
 If both test scripts work you are good to go!
 
 # Citation
 
-If you use LIA in publication, we would appreciate citations to the paper, [Godines et al. 2019.](https://arxiv.org/abs/2004.14347)
+If you use MicroLIA in publication, we would appreciate citations to the paper, [Godines et al. 2019.](https://ui.adsabs.harvard.edu/abs/2019A%26C....2800298G/abstract)
 
  
 # How to Contribute?
 
-Want to contribute? Bug detections? Comments? Suggestions? Please email us : danielgodinez123@gmail.com, etibachelet@gmail.com, rstreet@lcogt.net, claudiatrevino2002@gmail.com.
+Want to contribute? Bug detections? Comments? Suggestions? Please email us : danielgodinez123@gmail.com, etibachelet@gmail.com, rstreet@lcogt.net
```

### Comparing `MicroLIA-2.2.6/setup.py` & `MicroLIA-2.2.7/setup.py`

 * *Files 18% similar despite different names*

```diff
@@ -2,18 +2,17 @@
 """
 Created on Fri Aug 3 13:30:11 2018
 
 @author: danielgodinez
 """
 from setuptools import setup, find_packages, Extension
 
-
 setup(
     name="MicroLIA",
-    version="2.2.6",
+    version="2.2.7",
     author="Daniel Godines",
     author_email="danielgodinez123@gmail.com",
     description="Machine learning classifier for microlensing",
     license='GPL-3.0',
     url = "https://github.com/Professor-G/MicroLIA",
     classifiers=[
 		'Development Status :: 5 - Production/Stable',
@@ -26,10 +25,11 @@
     install_requires = ['numpy','scikit-learn', 'scikit-optimize', 'astropy','scipy','peakutils',
         'progress', 'matplotlib', 'optuna', 'boruta', 'BorutaShap', 'xgboost', 'scikit-plot',
         'tensorflow', 'pandas', 'dill', 'opencv-python', 'imbalanced-learn', 'gatspy', 'astroML'],
     python_requires='>=3.7,<4',
     include_package_data=True,
     test_suite="nose.collector",
     package_data={
-        'MicroLIA': ['data/Miras_vo.xml', 'data/Sesar2010/*']
+        'MicroLIA': ['data/Miras_vo.xml', 'data/Sesar2010/*', 'test/test_model/*', 'test/test_classifier.py', 
+            'test/test_features.py', 'test/MicroLIA_Training_Set.csv', 'test/test_ogle_lc.dat']
     },
 )
```

