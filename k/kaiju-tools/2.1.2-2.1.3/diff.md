# Comparing `tmp/kaiju_tools-2.1.2-py3-none-any.whl.zip` & `tmp/kaiju_tools-2.1.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,55 +1,55 @@
-Zip file size: 96942 bytes, number of entries: 53
--rw-r--r--  2.0 unx      231 b- defN 23-Jun-22 14:41 kaiju_tools/__init__.py
--rw-r--r--  2.0 unx    15027 b- defN 23-Jun-22 14:41 kaiju_tools/annotations.py
--rw-r--r--  2.0 unx    37350 b- defN 23-Jun-22 14:41 kaiju_tools/app.py
--rw-r--r--  2.0 unx     4699 b- defN 23-Jun-22 14:41 kaiju_tools/cache.py
--rw-r--r--  2.0 unx     5430 b- defN 23-Jun-22 14:41 kaiju_tools/class_registry.py
--rw-r--r--  2.0 unx    12475 b- defN 23-Jun-22 14:41 kaiju_tools/encoding.py
--rw-r--r--  2.0 unx     5310 b- defN 23-Jun-22 14:41 kaiju_tools/exceptions.py
--rw-r--r--  2.0 unx     8706 b- defN 23-Jun-22 14:41 kaiju_tools/functions.py
--rw-r--r--  2.0 unx    11388 b- defN 23-Jun-22 14:41 kaiju_tools/http.py
--rw-r--r--  2.0 unx    10411 b- defN 23-Jun-22 14:41 kaiju_tools/interfaces.py
--rw-r--r--  2.0 unx    10067 b- defN 23-Jun-22 14:41 kaiju_tools/jsonschema.py
--rw-r--r--  2.0 unx     7548 b- defN 23-Jun-22 14:41 kaiju_tools/locks.py
--rw-r--r--  2.0 unx    10446 b- defN 23-Jun-22 14:41 kaiju_tools/logging.py
--rw-r--r--  2.0 unx      210 b- defN 23-Jun-22 14:41 kaiju_tools/loop.py
--rw-r--r--  2.0 unx     7822 b- defN 23-Jun-22 14:41 kaiju_tools/mapping.py
--rw-r--r--  2.0 unx    34431 b- defN 23-Jun-22 14:41 kaiju_tools/rpc.py
--rw-r--r--  2.0 unx     4416 b- defN 23-Jun-22 14:41 kaiju_tools/rpc_client_gen.py
--rw-r--r--  2.0 unx       95 b- defN 23-Jun-22 14:41 kaiju_tools/serialization.py
--rw-r--r--  2.0 unx      702 b- defN 23-Jun-22 14:41 kaiju_tools/services.py
--rw-r--r--  2.0 unx    16658 b- defN 23-Jun-22 14:41 kaiju_tools/sessions.py
--rw-r--r--  2.0 unx     7216 b- defN 23-Jun-22 14:41 kaiju_tools/streams.py
--rw-r--r--  2.0 unx    14337 b- defN 23-Jun-22 14:41 kaiju_tools/templates.py
--rw-r--r--  2.0 unx    12410 b- defN 23-Jun-22 14:41 kaiju_tools/types.py
--rw-r--r--  2.0 unx      276 b- defN 23-Jun-22 14:41 kaiju_tools/docker/__init__.py
--rw-r--r--  2.0 unx     9782 b- defN 23-Jun-22 14:41 kaiju_tools/docker/containers.py
--rw-r--r--  2.0 unx     7723 b- defN 23-Jun-22 14:41 kaiju_tools/docker/images.py
--rw-r--r--  2.0 unx      103 b- defN 23-Jun-22 14:41 kaiju_tools/docker/services.py
--rw-r--r--  2.0 unx    11216 b- defN 23-Jun-22 14:41 kaiju_tools/docker/stack.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-22 14:41 kaiju_tools/docker/tests/__init__.py
--rw-r--r--  2.0 unx     1625 b- defN 23-Jun-22 14:41 kaiju_tools/docker/tests/fixtures.py
--rw-r--r--  2.0 unx      575 b- defN 23-Jun-22 14:41 kaiju_tools/docker/tests/test_containers.py
--rw-r--r--  2.0 unx      359 b- defN 23-Jun-22 14:41 kaiju_tools/docker/tests/test_images.py
--rw-r--r--  2.0 unx      371 b- defN 23-Jun-22 14:41 kaiju_tools/docker/tests/test_stack.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-22 14:41 kaiju_tools/tests/__init__.py
--rw-r--r--  2.0 unx    18531 b- defN 23-Jun-22 14:41 kaiju_tools/tests/fixtures.py
--rw-r--r--  2.0 unx     9209 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_annotation_parser.py
--rw-r--r--  2.0 unx     1469 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_cache.py
--rw-r--r--  2.0 unx     1436 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_class_registry.py
--rw-r--r--  2.0 unx      552 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_configurator.py
--rw-r--r--  2.0 unx     2849 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_http.py
--rw-r--r--  2.0 unx     2097 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_locks.py
--rw-r--r--  2.0 unx     3407 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_mapping.py
--rw-r--r--  2.0 unx     9174 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_rpc.py
--rw-r--r--  2.0 unx     1555 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_scheduler.py
--rw-r--r--  2.0 unx     2800 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_serializers.py
--rw-r--r--  2.0 unx     2207 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_services.py
--rw-r--r--  2.0 unx     3213 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_streams.py
--rw-r--r--  2.0 unx     1692 b- defN 23-Jun-22 14:41 kaiju_tools/tests/test_templates.py
--rw-rw-rw-  2.0 unx      610 b- defN 23-Jun-22 14:41 kaiju_tools-2.1.2.dist-info/LICENSE
--rw-r--r--  2.0 unx     3360 b- defN 23-Jun-22 14:41 kaiju_tools-2.1.2.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-22 14:41 kaiju_tools-2.1.2.dist-info/WHEEL
--rw-r--r--  2.0 unx       12 b- defN 23-Jun-22 14:41 kaiju_tools-2.1.2.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     4510 b- defN 23-Jun-22 14:41 kaiju_tools-2.1.2.dist-info/RECORD
-53 files, 338190 bytes uncompressed, 89788 bytes compressed:  73.5%
+Zip file size: 98143 bytes, number of entries: 53
+-rw-r--r--  2.0 unx      231 b- defN 23-Jun-26 12:56 kaiju_tools/__init__.py
+-rw-r--r--  2.0 unx    15027 b- defN 23-Jun-26 12:56 kaiju_tools/annotations.py
+-rw-r--r--  2.0 unx    37350 b- defN 23-Jun-26 12:56 kaiju_tools/app.py
+-rw-r--r--  2.0 unx     4699 b- defN 23-Jun-26 12:56 kaiju_tools/cache.py
+-rw-r--r--  2.0 unx     5430 b- defN 23-Jun-26 12:56 kaiju_tools/class_registry.py
+-rw-r--r--  2.0 unx    12475 b- defN 23-Jun-26 12:56 kaiju_tools/encoding.py
+-rw-r--r--  2.0 unx     5310 b- defN 23-Jun-26 12:56 kaiju_tools/exceptions.py
+-rw-r--r--  2.0 unx     8706 b- defN 23-Jun-26 12:56 kaiju_tools/functions.py
+-rw-r--r--  2.0 unx    11388 b- defN 23-Jun-26 12:56 kaiju_tools/http.py
+-rw-r--r--  2.0 unx    10681 b- defN 23-Jun-26 12:56 kaiju_tools/interfaces.py
+-rw-r--r--  2.0 unx    10179 b- defN 23-Jun-26 12:56 kaiju_tools/jsonschema.py
+-rw-r--r--  2.0 unx     7548 b- defN 23-Jun-26 12:56 kaiju_tools/locks.py
+-rw-r--r--  2.0 unx    10446 b- defN 23-Jun-26 12:56 kaiju_tools/logging.py
+-rw-r--r--  2.0 unx      210 b- defN 23-Jun-26 12:56 kaiju_tools/loop.py
+-rw-r--r--  2.0 unx     7839 b- defN 23-Jun-26 12:56 kaiju_tools/mapping.py
+-rw-r--r--  2.0 unx    34389 b- defN 23-Jun-26 12:56 kaiju_tools/rpc.py
+-rw-r--r--  2.0 unx     4416 b- defN 23-Jun-26 12:56 kaiju_tools/rpc_client_gen.py
+-rw-r--r--  2.0 unx       95 b- defN 23-Jun-26 12:56 kaiju_tools/serialization.py
+-rw-r--r--  2.0 unx      702 b- defN 23-Jun-26 12:56 kaiju_tools/services.py
+-rw-r--r--  2.0 unx    16671 b- defN 23-Jun-26 12:56 kaiju_tools/sessions.py
+-rw-r--r--  2.0 unx     7313 b- defN 23-Jun-26 12:56 kaiju_tools/streams.py
+-rw-r--r--  2.0 unx    14417 b- defN 23-Jun-26 12:56 kaiju_tools/templates.py
+-rw-r--r--  2.0 unx    12410 b- defN 23-Jun-26 12:56 kaiju_tools/types.py
+-rw-r--r--  2.0 unx      103 b- defN 23-Jun-26 12:56 kaiju_tools/docker/__init__.py
+-rw-r--r--  2.0 unx     9790 b- defN 23-Jun-26 12:56 kaiju_tools/docker/containers.py
+-rw-r--r--  2.0 unx     7723 b- defN 23-Jun-26 12:56 kaiju_tools/docker/images.py
+-rw-r--r--  2.0 unx    11216 b- defN 23-Jun-26 12:56 kaiju_tools/docker/stack.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-26 12:56 kaiju_tools/docker/tests/__init__.py
+-rw-r--r--  2.0 unx     1306 b- defN 23-Jun-26 12:56 kaiju_tools/docker/tests/fixtures.py
+-rw-r--r--  2.0 unx      575 b- defN 23-Jun-26 12:56 kaiju_tools/docker/tests/test_containers.py
+-rw-r--r--  2.0 unx      359 b- defN 23-Jun-26 12:56 kaiju_tools/docker/tests/test_images.py
+-rw-r--r--  2.0 unx      371 b- defN 23-Jun-26 12:56 kaiju_tools/docker/tests/test_stack.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-26 12:56 kaiju_tools/tests/__init__.py
+-rw-r--r--  2.0 unx    19574 b- defN 23-Jun-26 12:56 kaiju_tools/tests/fixtures.py
+-rw-r--r--  2.0 unx     9209 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_annotation_parser.py
+-rw-r--r--  2.0 unx     1469 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_cache.py
+-rw-r--r--  2.0 unx     1436 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_class_registry.py
+-rw-r--r--  2.0 unx      552 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_configurator.py
+-rw-r--r--  2.0 unx     3801 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_data_store.py
+-rw-r--r--  2.0 unx     2849 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_http.py
+-rw-r--r--  2.0 unx     2097 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_locks.py
+-rw-r--r--  2.0 unx     3457 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_mapping.py
+-rw-r--r--  2.0 unx     9192 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_rpc.py
+-rw-r--r--  2.0 unx     1554 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_scheduler.py
+-rw-r--r--  2.0 unx     2800 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_serializers.py
+-rw-r--r--  2.0 unx     2207 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_services.py
+-rw-r--r--  2.0 unx     3213 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_streams.py
+-rw-r--r--  2.0 unx     1692 b- defN 23-Jun-26 12:56 kaiju_tools/tests/test_templates.py
+-rw-rw-rw-  2.0 unx      610 b- defN 23-Jun-26 12:57 kaiju_tools-2.1.3.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3360 b- defN 23-Jun-26 12:57 kaiju_tools-2.1.3.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-26 12:57 kaiju_tools-2.1.3.dist-info/WHEEL
+-rw-r--r--  2.0 unx       12 b- defN 23-Jun-26 12:57 kaiju_tools-2.1.3.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4517 b- defN 23-Jun-26 12:57 kaiju_tools-2.1.3.dist-info/RECORD
+53 files, 343068 bytes uncompressed, 90977 bytes compressed:  73.5%
```

## zipnote {}

```diff
@@ -72,17 +72,14 @@
 
 Filename: kaiju_tools/docker/containers.py
 Comment: 
 
 Filename: kaiju_tools/docker/images.py
 Comment: 
 
-Filename: kaiju_tools/docker/services.py
-Comment: 
-
 Filename: kaiju_tools/docker/stack.py
 Comment: 
 
 Filename: kaiju_tools/docker/tests/__init__.py
 Comment: 
 
 Filename: kaiju_tools/docker/tests/fixtures.py
@@ -111,14 +108,17 @@
 
 Filename: kaiju_tools/tests/test_class_registry.py
 Comment: 
 
 Filename: kaiju_tools/tests/test_configurator.py
 Comment: 
 
+Filename: kaiju_tools/tests/test_data_store.py
+Comment: 
+
 Filename: kaiju_tools/tests/test_http.py
 Comment: 
 
 Filename: kaiju_tools/tests/test_locks.py
 Comment: 
 
 Filename: kaiju_tools/tests/test_mapping.py
@@ -138,23 +138,23 @@
 
 Filename: kaiju_tools/tests/test_streams.py
 Comment: 
 
 Filename: kaiju_tools/tests/test_templates.py
 Comment: 
 
-Filename: kaiju_tools-2.1.2.dist-info/LICENSE
+Filename: kaiju_tools-2.1.3.dist-info/LICENSE
 Comment: 
 
-Filename: kaiju_tools-2.1.2.dist-info/METADATA
+Filename: kaiju_tools-2.1.3.dist-info/METADATA
 Comment: 
 
-Filename: kaiju_tools-2.1.2.dist-info/WHEEL
+Filename: kaiju_tools-2.1.3.dist-info/WHEEL
 Comment: 
 
-Filename: kaiju_tools-2.1.2.dist-info/top_level.txt
+Filename: kaiju_tools-2.1.3.dist-info/top_level.txt
 Comment: 
 
-Filename: kaiju_tools-2.1.2.dist-info/RECORD
+Filename: kaiju_tools-2.1.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## kaiju_tools/__init__.py

```diff
@@ -1,8 +1,8 @@
 from kaiju_tools.interfaces import *
 from kaiju_tools.types import *
 from kaiju_tools.app import *
 from kaiju_tools.encoding import Serializable
 
-__version__ = '2.1.2'
+__version__ = '2.1.3'
 __python_version__ = '3.8'
 __author__ = 'antonnidhoggr@me.com'
```

## kaiju_tools/interfaces.py

```diff
@@ -1,13 +1,15 @@
 import abc
 import logging
 import uuid
 from contextvars import ContextVar  # noqa: pycharm
 from typing import (
     Any,
+    AsyncGenerator,
+    List,
     Dict,
     Collection,
     Literal,
     Union,
     TypeVar,
     Hashable,
     FrozenSet,
@@ -35,14 +37,15 @@
     'AuthenticationInterface',
     'Locks',
     'RPCServer',
     'RPCClient',
     'ServiceManagerInterface',
     'App',
     'TokenLoginInterface',
+    '_Session',
 ]
 
 
 class App(Application):
     """Web application interface."""
 
     id: str
@@ -179,15 +182,15 @@
 
     @abc.abstractmethod
     async def delete(self, id: Hashable, columns: _Columns = None, _connection=None) -> _Row:
         ...
 
     @abc.abstractmethod
     async def m_delete(
-        self, id: Collection[Hashable] = None, conditions=None, columns: _Columns = None, _connection=None
+        self, id: Collection[Hashable] = None, conditions: dict = None, columns: _Columns = None, _connection=None
     ) -> Collection[_Row]:
         ...
 
     @abc.abstractmethod
     async def create(
         self,
         data: dict,
@@ -213,18 +216,24 @@
 
     @abc.abstractmethod
     async def update(self, id: Hashable, data, columns: _Columns = '*', _connection=None) -> _Row:
         ...
 
     @abc.abstractmethod
     async def m_update(
-        self, id: Collection[Hashable], data, conditions=None, columns: _Columns = '*', _connection=None
+        self, id: Collection[Hashable], data, conditions: dict = None, columns: _Columns = '*', _connection=None
     ) -> Collection[_Row]:
         ...
 
+    @abc.abstractmethod
+    async def iter(
+        self, conditions: dict = None, sort=None, offset: int = 0, limit: int = 10, columns: _Columns = '*'
+    ) -> AsyncGenerator[List[dict], None]:
+        ...
+
 
 _User = TypeVar('_User')
 
 
 class UserInterface(Generic[_User], abc.ABC):
     """User login interface."""
```

## kaiju_tools/jsonschema.py

```diff
@@ -81,14 +81,15 @@
 
     type = 'boolean'
 
 
 Enumerated = JSONSchemaObject  # compatibility, the base object has enum
 
 
+# noinspection PyPep8Naming
 class String(JSONSchemaObject):
     """Text/string data type."""
 
     type = 'string'
     format_: str = None
 
     STRING_FORMATS = frozenset(
@@ -173,14 +174,15 @@
         """Initialize."""
         super().__init__(enum=[None])
 
 
 Null = _Null()
 
 
+# noinspection PyPep8Naming
 class Number(JSONSchemaObject):
     """Numeric data type (use it for both float or integer params)."""
 
     type = 'number'
     __slots__ = ('multipleOf', 'minimum', 'exclusiveMinimum', 'maximum', 'exclusiveMaximum')
 
     def __init__(
@@ -211,14 +213,15 @@
 class Integer(Number):
     """Integer type."""
 
     type = 'integer'
     __slots__ = tuple()
 
 
+# noinspection PyPep8Naming
 class Array(JSONSchemaObject):
     """Array, list, set or tuple definition (depends on params)."""
 
     type = 'array'
     __slots__ = ('items', 'prefixItems', 'contains', 'additionalItems', 'uniqueItems', 'minItems', 'maxItems')
 
     def __init__(
@@ -253,14 +256,15 @@
             data, ('items', 'prefixItems', 'contains', 'additionalItems', 'uniqueItems', 'minItems', 'maxItems')
         )
         for key in ('prefixItems',):
             self._unpack_items(data, key)
         return data
 
 
+# noinspection PyPep8Naming
 class Object(JSONSchemaObject):
     """JSON object (dictionary) definition."""
 
     type = 'object'
     __slots__ = (
         'properties',
         'propertyNames',
```

## kaiju_tools/mapping.py

```diff
@@ -198,15 +198,15 @@
         __obj1 = __obj2
     return __obj1
 
 
 def _filter_field(obj, keys, default):
     for n, key in enumerate(keys):
         if isinstance(obj, dict):
-            return {key: _filter_field(obj.get(key, default), keys[n + 1 :], default)}
+            return {key: _filter_field(obj.get(key, default), keys[n + 1 :], default)}  # noqa: linter?
         elif isinstance(obj, Collection) and not isinstance(obj, str):
             return [_filter_field(o, keys[n:], default) for o in obj]
     return obj
 
 
 def filter_fields(__obj: dict, fields: Iterable[str], *, default=None, delimiter: str = '.') -> dict:
     """Filter dict keys from a specified set of fields.
```

## kaiju_tools/rpc.py

```diff
@@ -222,22 +222,22 @@
     f: Callable
     signature: FunctionAnnotation
     service_name: str
     permission: Scope
     validator: Callable
 
 
-class JSONRPCServer(ContextableService, AbstractRPCCompatible, RPCServer):
+class JSONRPCServer(ContextableService, PublicInterface, RPCServer):
     """A simple JSON RPC interface with method execution and management tasks."""
 
     service_name = 'rpc'
     _permission_levels = {
-        AbstractRPCCompatible.PermissionKeys.GLOBAL_SYSTEM_PERMISSION: Scope.SYSTEM,
-        AbstractRPCCompatible.PermissionKeys.GLOBAL_USER_PERMISSION: Scope.USER,
-        AbstractRPCCompatible.PermissionKeys.GLOBAL_GUEST_PERMISSION: Scope.GUEST,
+        PublicInterface.PermissionKeys.GLOBAL_SYSTEM_PERMISSION: Scope.SYSTEM,
+        PublicInterface.PermissionKeys.GLOBAL_USER_PERMISSION: Scope.USER,
+        PublicInterface.PermissionKeys.GLOBAL_GUEST_PERMISSION: Scope.GUEST,
     }
 
     def __init__(
         self,
         app,
         *,
         session_service: SessionInterface = None,
@@ -370,25 +370,25 @@
             }
             for route, method in self._methods.items()
             if session and method['permission'].value >= session.scope.value and fnmatch(route, pattern)
         ]
         routes.sort(key=lambda o: o['route'])
         return {'api': 'jsonrpc', 'version': JSONRPC, 'spec': 'https://www.jsonrpc.org/specification', 'routes': routes}
 
-    def register_service(self, service_name: str, service: AbstractRPCCompatible) -> None:
+    def register_service(self, service_name: str, service: PublicInterface) -> None:
         """Register an RPC compatible service and its methods."""
-        if not isinstance(service, AbstractRPCCompatible):
+        if not isinstance(service, PublicInterface):
             raise TypeError('Service must be rpc compatible.')
         permissions = service.permissions
         validators = service.validators
         for route, f in service.routes.items():
             full_name = f'{service_name}.{route}'
             if self._route_blacklisted(full_name):
                 continue
-            route_perm = AbstractRPCCompatible.PermissionKeys.GLOBAL_SYSTEM_PERMISSION
+            route_perm = PublicInterface.PermissionKeys.GLOBAL_SYSTEM_PERMISSION
             for pattern, perm in permissions.items():
                 if fnmatch(route, pattern):
                     route_perm = perm
             if route_perm.value <= self._blacklist_scope:  # noqa
                 continue
             try:
                 annotation = AnnotationParser.parse_method(type(service), route, f)
```

## kaiju_tools/sessions.py

```diff
@@ -17,15 +17,15 @@
     TokenInterface,
     PublicInterface,
     SessionInterface,
     AuthenticationInterface,
     TokenLoginInterface,
     RPCClient,
     _Session,
-)  # noqa
+)
 from kaiju_tools.app import ContextableService, Scheduler
 from kaiju_tools.types import Session
 from kaiju_tools.exceptions import NotFound, NotAuthorized
 
 __all__ = [
     'SessionService',
     'AuthType',
@@ -54,15 +54,15 @@
 
     service_name = 'sessions'
     session_cls = Session
 
     def __init__(
         self,
         app,
-        store_service: DataStore = None,
+        session_store: DataStore = None,
         cache_service: Cache = None,
         session_idle_timeout: int = 24 * 3600,
         exp_renew_interval: int = 3600,
         salt: str = 'SALT',
         shared: bool = False,
         logger=None,
     ):
@@ -75,15 +75,15 @@
         :param salt: salt for user agent hashing, change it to invalidate all current sessions
         :param logger:
         """
         super().__init__(app, logger=logger)
         self.ns = self.app.namespace_shared if shared else self.app.namespace
         self.ns = self.ns / '_session'
         self._cache = cache_service
-        self._store = store_service
+        self._store = session_store
         self.session_idle_timeout = session_idle_timeout
         self.exp_renew_interval = exp_renew_interval
         self.salt = salt.encode('utf-8')
 
     async def init(self):
         self._cache = self.discover_service(self._cache, cls=Cache)
         self._store = self.discover_service(self._store, cls=DataStore)
@@ -378,15 +378,15 @@
             raise NotAuthorized('Unsupported auth method')
         token_info = await self._tokens.refresh(refresh)
         if not token_info:
             raise NotAuthorized('Invalid credentials')
         return token_info
 
 
-class TokenClientService(ContextableService, abc.ABC):
+class TokenClientService(ContextableService, TokenLoginInterface, abc.ABC):
     """Token client."""
 
     def __init__(self, *args, rpc_client: RPCClient, scheduler: Scheduler = None, username: str, password: str, **kws):
         super().__init__(*args, **kws)
         self._client = rpc_client
         self._username = username
         self._password = password
```

## kaiju_tools/streams.py

```diff
@@ -66,15 +66,15 @@
         self._encoder = serializers[self.content_type]()
 
     async def init(self):
         self._closing = False
         self._unlocked.set()
         self._idle.set()
         self._rpc = self.discover_service(self._rpc, cls=JSONRPCServer)
-        self._locks = self.discover_service(self._rpc, cls=Locks)
+        self._locks = self.discover_service(self._locks, cls=Locks)
         self._sessions = self.discover_service(self._sessions, cls=SessionInterface, required=False)
         self._transport = self.discover_service(self._transport, cls=self.get_transport_cls())
         self._scheduler = self.discover_service(self._scheduler, cls=Scheduler)
         self._auth = self.discover_service(self._auth, cls=AuthenticationInterface, required=False)
         self._loop = asyncio.create_task(self._read(), name=f'{self.service_name}.{self.topic}._read')
         self._lock_task = self._scheduler.schedule_task(
             self._check_lock, interval=self.lock_check_interval, name=f'{self.service_name}._check_lock'
@@ -127,25 +127,26 @@
     async def _read(self) -> None:
         """Read from a stream."""
         self.logger.info('Starting')
         while not self._closing:
             await self._unlocked.wait()
             try:
                 batch = await self._read_batch()
+                self._idle.clear()
+                if self.max_parallel_batches:
+                    async with self._counter.acquire():
+                        if batch:
+                            await self._process_batch(batch)
+                else:
+                    if batch:
+                        await self._process_batch(batch)
             except Exception as exc:
                 self.logger.error('Read error', exc_info=exc, topic=self._key)
-                continue
-
-            self._idle.clear()
-            if self.max_parallel_batches:
-                async with self._counter.acquire():
-                    await self._process_batch(batch)
-            else:
-                await self._process_batch(batch)
-            self._idle.set()
+            finally:
+                self._idle.set()
 
     async def _check_lock(self) -> None:
         """Check for existing shared lock and lock / unlock if needed."""
         existing = await self._locks.m_exists([self._lock_key])
         if self._lock_key in existing:
             if not self.locked:
                 self._unlocked.clear()
```

## kaiju_tools/templates.py

```diff
@@ -36,14 +36,15 @@
     'ge': lambda args: isinstance(args[0], Real) and isinstance(args[1], Real) and args[0] >= args[1],
     'le': lambda args: isinstance(args[0], Real) and isinstance(args[1], Real) and args[0] <= args[1],
     'eq': lambda args: args[0] == args[1],
     'ne': lambda args: args[0] != args[1],
     'has': lambda args: isinstance(args[0], Container) and args[1] in args[0],
     'in': lambda args: isinstance(args[1], Container) and args[0] in args[1],
     'match': lambda args: fnmatch(str(args[0]), str(args[1])),
+    'like': lambda args: fnmatch(str(args[0]), str(args[1]).replace('%', '*')),
 }
 # << comparison_functions
 
 
 # >> functions
 TEMPLATE_FUNCTIONS = {
     'true': lambda args: True,
```

## kaiju_tools/docker/__init__.py

```diff
@@ -1,12 +1,3 @@
-"""
-Docker python api and classes.
-
-Docker SDK python bindings are required for everything except compose services.
-
-containers.py - single containers management
-fixtures.py - pytest fixtures
-images.py - image building
-stack.py - compose file api
-"""
-
-from .services import *
+from .images import DockerImage
+from .containers import DockerContainer
+from .stack import DockerStack
```

## kaiju_tools/docker/containers.py

```diff
@@ -1,15 +1,15 @@
 """Docker container management."""
 
 import uuid
 from time import sleep
 from typing import Awaitable, Union
 
-import docker  # type: ignore
-from docker.errors import NotFound  # type: ignore
+import docker  # noqa: tests only
+from docker.errors import NotFound  # noqa: tests only
 
 from kaiju_tools.app import ContextableService
 from kaiju_tools.functions import async_run_in_thread
 from kaiju_tools.docker.images import DockerImage
 
 __all__ = ['DockerContainer']
 
@@ -45,15 +45,15 @@
     way to do it since it usually takes time to start and health check containers).
     """
 
     image_class = DockerImage  #: wraps dict or str `image` param in __init__
 
     def __init__(
         self,
-        image: Union[str, image_class._Dict, image_class],
+        image: Union[str, image_class.Image, image_class],
         name: str = None,
         command: str = None,
         ports: dict = None,
         env: dict = None,
         healthcheck: dict = None,
         sleep_interval=0,
         remove_on_exit=False,
```

## kaiju_tools/docker/images.py

```diff
@@ -42,15 +42,15 @@
 
     DOCKERFILE = './Dockerfile'
     NAMESPACE = 'systems.elemento'
     REPOSITORY = 'docker.io'
 
     _tempfile_prefix = '_docker_image'
 
-    class _Dict:
+    class Image:
         """Used for type hinting in docker container class."""
 
         tag: str
         version: str
         dockerfile: str
         labels: dict
         namespace: str
```

## kaiju_tools/docker/tests/fixtures.py

```diff
@@ -1,23 +1,14 @@
-"""
-Various test fixtures.
-
-You can use `docker_container` and `per_session_docker_container` to implement your own container
-fixtures for unit tests. See `DockerContainer` class for arguments description.
-
-You also can use `docker_stack` and `per_session_docker_stack` for your custom docker-compose stacks
-fixtures. See `DockerStack` class for arguments description.
-"""
-
 import uuid
 
-import pytest
+import pytest  # noqa: pycharm
 
-from kaiju_tools.tests.fixtures import *
-from ..services import *
+from ..images import DockerImage
+from ..containers import DockerContainer
+from ..stack import DockerStack
 
 
 @pytest.fixture
 def sample_dockerfile():
     return """
     FROM alpine:latest
     CMD echo test
@@ -34,16 +25,16 @@
     """
 
 
 @pytest.fixture
 def sample_image(sample_dockerfile, application, logger):
     tag = str(uuid.uuid4())
     return DockerImage.from_string(
-        sample_dockerfile, tag=tag, remove_on_exit=True, always_build=True, pull=True,
-        app=application(), logger=logger)
+        sample_dockerfile, tag=tag, remove_on_exit=True, always_build=True, pull=True, app=application(), logger=logger
+    )
 
 
 @pytest.fixture
 def sample_container(sample_dockerfile, application, logger):
     return DockerContainer(
         image={
             'dockerfile_str': sample_dockerfile,
@@ -51,14 +42,14 @@
             'remove_on_exit': True,
             'always_build': True,
             'pull': False,
         },
         name='pytest-sample-container',
         remove_on_exit=True,
         app=application(),
-        logger=logger
+        logger=logger,
     )
 
 
 @pytest.fixture
 def sample_stack(sample_compose_file, application, logger):
     return DockerStack.from_string(sample_compose_file, name=None, app=application(), logger=logger)
```

## kaiju_tools/tests/fixtures.py

```diff
@@ -1,13 +1,13 @@
 import asyncio
 import logging
 import uuid
 from datetime import datetime
 from time import time
-from typing import cast, Dict, List, FrozenSet, Optional, Collection, Hashable, Type
+from typing import cast, Dict, List, FrozenSet, Optional, Collection, Hashable, Type, AsyncGenerator, Union
 
 import pytest  # noqa: pycharm
 import pytest_asyncio
 
 import kaiju_tools.jsonschema as js
 from kaiju_tools.exceptions import ValidationError, NotFound
 from kaiju_tools.app import (
@@ -106,28 +106,38 @@
 def scheduler(app) -> Scheduler:
     service = Scheduler(app=app, refresh_rate=0.1)
     app.services.add_service(service)
     return service
 
 
 class _MockDataStore(Service, DataStore):
-    def __init__(self, *args, primary_key: str = 'id', **kws):
+    def __init__(self, *args, primary_key: Union[str, List[str]] = 'id', **kws):
         super().__init__(*args, **kws)
         self.primary_key = primary_key
         self._ext = {}
 
+    def _get_primary_key(self, row: dict):
+        if type(self.primary_key) is str:
+            return row[self.primary_key]
+        else:
+            return tuple(row[key] for key in self.primary_key)
+
     @staticmethod
-    def _filter_columns(row: dict, columns):
+    def _filter_columns(row: dict, columns) -> Optional[dict]:
         if not columns:
             return
         elif columns == '*':
             return row
         else:
             return {key: row[key] for key in row if key in columns}
 
+    @staticmethod
+    def _check_condition(row: dict, conditions: Optional[Condition]) -> bool:
+        return conditions(row) if conditions else True
+
     async def get(self, id: Hashable, columns: _Columns = '*', _connection=None) -> _Row:
         await asyncio.sleep(0)
         try:
             row = self._ext[id]
         except KeyError:
             raise NotFound
         else:
@@ -161,15 +171,15 @@
     ) -> Collection[_Row]:
         await asyncio.sleep(0)
         if conditions:
             conditions = Condition(conditions)
         rows = []
         keys = id if id else tuple(self._ext.keys())
         for key in keys:
-            if key in self._ext and (conditions is None or conditions(key)):
+            if key in self._ext and self._check_condition(self._ext[key], conditions):
                 row = self._ext.pop(key)
                 rows.append(self._filter_columns(row, columns))
         if columns:
             return rows
 
     async def create(
         self,
@@ -177,15 +187,15 @@
         columns: _Columns = '*',
         _connection=None,
         on_conflict: str = None,
         on_conflict_keys: Collection = None,
         on_conflict_values=None,
     ) -> _Row:
         await asyncio.sleep(0)
-        self._ext[data[self.primary_key]] = data
+        self._ext[self._get_primary_key(data)] = data
         if columns:
             return self._filter_columns(data, columns)
 
     async def m_create(
         self,
         data: Collection,
         columns: _Columns = '*',
@@ -193,15 +203,15 @@
         on_conflict: str = None,
         on_conflict_keys: Collection = None,
         on_conflict_values: dict = None,
     ) -> Collection[_Row]:
         await asyncio.sleep(0)
         rows = []
         for row in data:
-            self._ext[row[self.primary_key]] = row
+            self._ext[self._get_primary_key(row)] = row
             rows.append(self._filter_columns(row, columns))
         if columns:
             return rows
 
     async def update(self, id: Hashable, data, columns: _Columns = '*', _connection=None) -> _Row:
         try:
             self._ext[id].update(data)
@@ -216,20 +226,33 @@
     ) -> Collection[_Row]:
         if conditions:
             conditions = Condition(conditions)
         rows = []
         keys = id if id else tuple(self._ext.keys())
         for key in keys:
             if key in self._ext and (conditions is None or conditions(key)):
-                self._ext[id].update(data)
-                row = self._ext[id]
+                self._ext[key].update(data)
+                row = self._ext[key]
                 rows.append(self._filter_columns(row, columns))
         if columns:
             return rows
 
+    async def iter(
+        self, conditions: dict = None, sort=None, offset: int = 0, limit: int = 10, columns: _Columns = '*'
+    ) -> AsyncGenerator[List[dict], None]:
+        if conditions:
+            conditions = Condition(conditions)
+        rows = [
+            self._filter_columns(row, columns) for row in self._ext.values() if self._check_condition(row, conditions)
+        ][offset:]
+        for _offset in range(0, (len(rows) // limit) + 1):
+            chunk = rows[_offset * limit : (_offset + 1) * limit]
+            if chunk:
+                yield chunk
+
 
 @pytest.fixture
 def mock_data_store(app) -> _MockDataStore:
     service = _MockDataStore(app=app)
     app.services.add_service(service)
     return service
 
@@ -279,15 +302,15 @@
     service = _MockCacheService(app=app, transport=_MockCacheService.MockTransport(app))
     app.services.add_service(service)
     return service
 
 
 @pytest.fixture
 def mock_sessions(app, mock_cache, mock_data_store) -> SessionService:
-    service = SessionService(app=app, cache_service=mock_cache, store_service=mock_data_store)
+    service = SessionService(app=app, cache_service=mock_cache, session_store=mock_data_store)
     app.services.add_service(service)
     return service
 
 
 @pytest_asyncio.fixture
 async def mock_session(mock_sessions) -> Session:
     _session = Session(
@@ -330,15 +353,15 @@
 
     async def refresh(self, token: str, /) -> Optional[TokenInterface.TokenInfo]:
         if token == self.refresh_token:
             return TokenInterface.TokenInfo(access=self.token, refresh=self.refresh_token)
 
 
 @pytest.fixture
-def mock_tokens(app, mock_session) -> TokenInterface:
+def mock_tokens(app, mock_session) -> TokenInterface:  # noqa: pycharm
     service = _MockTokenService(app=app, session=mock_session)
     app.services.add_service(service)
     return service
 
 
 class _MockUserService(Service, UserInterface):
     def __init__(self, *args, session: Session, **kws):
@@ -349,15 +372,15 @@
 
     async def auth(self, username: str, password: str) -> Optional[_User]:
         if username == self.username and password == self.password:
             return TokenInterface.TokenClaims(id=self.session.user_id, permissions=self.session.permissions)
 
 
 @pytest.fixture
-def mock_users(app, mock_session) -> _MockUserService:
+def mock_users(app, mock_session) -> _MockUserService:  # noqa: pycharm
     service = _MockUserService(app=app, session=mock_session)
     app.services.add_service(service)
     return service
 
 
 @pytest.fixture
 def mock_auth(app, mock_sessions, mock_users, mock_tokens) -> AuthenticationService:
```

## kaiju_tools/tests/test_mapping.py

```diff
@@ -1,8 +1,9 @@
 import pytest  # noqa: pytest
+from typing import cast
 
 from kaiju_tools.mapping import *
 
 
 @pytest.fixture
 def test_mapping():
     def _test_mapping(**kws):
@@ -88,14 +89,15 @@
     _o = filter_fields(obj, ['come.get.some', 'come.get.empty'])
     logger.debug(_o)
     assert _o['come']['get']['some'] is True
     assert 'another' not in _o['come']['get']
     assert _o['come']['get']['empty'] is None
 
     obj = test_list(some=True, another=False)
+    obj = cast(dict, obj)
     _o = filter_fields(obj, ['come.get.some', 'come.get.empty'])
     logger.debug(_o)
     for o in _o:
         assert o['come']['get']['some'] is True
         assert 'another' not in o['come']['get']
         assert o['come']['get']['empty'] is None
```

## kaiju_tools/tests/test_rpc.py

```diff
@@ -67,15 +67,15 @@
         headers, response = await _rpc.call(req, req_headers)
         assert type(response) is RPCResponse
         assert response.result is True
 
     async def test_local_callback(self, _rpc: JSONRPCServer, mock_session):
         counter = 0
 
-        async def _do_callback(mock_session, headers, response):
+        async def _do_callback(mock_session, headers, response):  # noqa: expected
             nonlocal counter
             counter += response.result
 
         req = {'method': 'do.echo', 'params': {'data': 1}}
         headers = {JSONRPCHeaders.SESSION_ID_HEADER: mock_session.id}
         await _rpc.call(req, headers, callback=_do_callback, nowait=True)
         await asyncio.sleep(0.1)
```

## kaiju_tools/tests/test_scheduler.py

```diff
@@ -20,16 +20,16 @@
         async with scheduler.app.services:
             await asyncio.sleep(0.15)
             assert self.counter == 2, 'both tasks must be completed'
 
     async def test_scheduler_repeat(self, scheduler):
         scheduler.schedule_task(self._call, interval=0.1, name='task_1')
         async with scheduler.app.services:
-            await asyncio.sleep(0.4)
-            assert self.counter == 3, 'must repeat task'
+            await asyncio.sleep(0.5)
+            assert self.counter > 1, 'must repeat task'
 
     async def test_scheduler_policy_wait(self, scheduler):
         scheduler.schedule_task(self._call, params={'t': 0.1}, interval=0.1, policy=scheduler.ExecPolicy.WAIT)
         async with scheduler.app.services:
             await asyncio.sleep(0.35)
             assert self.counter == 1, 'must wait, i.e. only one increment must happen'
```

## Comparing `kaiju_tools-2.1.2.dist-info/LICENSE` & `kaiju_tools-2.1.3.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `kaiju_tools-2.1.2.dist-info/METADATA` & `kaiju_tools-2.1.3.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: kaiju-tools
-Version: 2.1.2
+Version: 2.1.3
 Summary: Base classes and services for a backend application.
 Home-page: https://gitlab.com/kaiju-python/kaiju-tools
 Author: antonnidhoggr@me.com
 Author-email: antonnidhoggr@me.com
 License: Apache Software License 2.0
 Classifier: Development Status :: 3 - Alpha
 Classifier: License :: OSI Approved :: Apache Software License
```

## Comparing `kaiju_tools-2.1.2.dist-info/RECORD` & `kaiju_tools-2.1.3.dist-info/RECORD`

 * *Files 15% similar despite different names*

```diff
@@ -1,53 +1,53 @@
-kaiju_tools/__init__.py,sha256=nCLkaPFqQYQ_knkOYClKffgt0QpgzgDCZrib7Z4ZfHA,231
+kaiju_tools/__init__.py,sha256=ROufm5ZIDJQlL28zW22ctiaFOjCb7sZl1gIfiJt5qVo,231
 kaiju_tools/annotations.py,sha256=47ioFnGcZDvDElnCVRFlzkCU_A6a2UfWz_M8dfKBmpM,15027
 kaiju_tools/app.py,sha256=MwsaUs2cy2bJGUJ8Hrr648_1txYGHxamNT4mRzJ7Upc,37350
 kaiju_tools/cache.py,sha256=pzlK_GEYfp0dus4uZDov4cd5d7I9wbdS6Y4QQSo9vlo,4699
 kaiju_tools/class_registry.py,sha256=0duhDIB_za-SPLkxI7mK6NsjGodw99i-ldoOGFSI5Q4,5430
 kaiju_tools/encoding.py,sha256=r0Jx4U5VLTCVswZC83lFDp5za1BY1jFJAm88w3rGEyg,12475
 kaiju_tools/exceptions.py,sha256=_z9yJd2zJv32Z76bDnlVCtBSN9b0FRWRsfJGf4xcB94,5310
 kaiju_tools/functions.py,sha256=ZeyIGCUqrYcNpBZ_dF530I7KB3f4lfT52TATAWfb8Xg,8706
 kaiju_tools/http.py,sha256=Ld9ETI13WjMtucqEOEmxGq3XxbYdVfbfazy3JurpN_E,11388
-kaiju_tools/interfaces.py,sha256=RnCSmy__6YbXZL01BtREzxlvu5qUHO3DsCNgF8qUMCE,10411
-kaiju_tools/jsonschema.py,sha256=cKn8bZ9pXZXgTgcj4hG9H8EWuHS7Q2QQmcN4k5eQMc4,10067
+kaiju_tools/interfaces.py,sha256=pH53GxZDJ-FKNjla4GmhnS37l5B7lMN5aWg8Y3X09Vw,10681
+kaiju_tools/jsonschema.py,sha256=AnNKjAfGWjgRLw4w8PYffh1WehLNjJrQ7lPsgjUjocY,10179
 kaiju_tools/locks.py,sha256=OGtfkqwECCMM1JK8Dtm2vOAsKJz4OK2NpH1SMQ30xeE,7548
 kaiju_tools/logging.py,sha256=ZG-ImBLpOvzB9MrSopVBlgNiCckO9QdXh7V_6iBGRGk,10446
 kaiju_tools/loop.py,sha256=DhiJ9jftB43RkeoTvOGKdwBbRFr4gj1Rz6uTLTYyF_U,210
-kaiju_tools/mapping.py,sha256=1ilBdLrpTEkGkMm6Ogv1L8lcHofRSelavhJnuiZraOM,7822
-kaiju_tools/rpc.py,sha256=zDbqkK3ofZ_jbYkX-ZHcCCMHGYwTWWbfH2WZhzOhksY,34431
+kaiju_tools/mapping.py,sha256=Z81ktH2IHLBw05KTvegA8mqch9vJMFwqZ4LnAKz8LiY,7839
+kaiju_tools/rpc.py,sha256=pM0aSiyVeTEZXUwG7qxS37mn2nVC5eN8KKifWW6N-FA,34389
 kaiju_tools/rpc_client_gen.py,sha256=8k31kUdwK2T4Zpwb-OBlNAoMK7k_2FDoX1LjhciD2yg,4416
 kaiju_tools/serialization.py,sha256=_TPV7HTUua5EEeUYEHCdqj_HHo2VdKpe2RusbeVIp8g,95
 kaiju_tools/services.py,sha256=hh7nSgw6cN59menn7LgeQ0R9gFmMQOrt1FLi22Rdhq8,702
-kaiju_tools/sessions.py,sha256=HcxcyX1gONcHXdTTfD53sI3OXTtB8Vb4Na9Av4UFi7w,16658
-kaiju_tools/streams.py,sha256=QG_V_Hv6C4ZT5gs-kT99XlifeoKSO1YsC3S27EKhonM,7216
-kaiju_tools/templates.py,sha256=DAwXGLYN7flm5hS4fKWpt5cJZuXK1x5YYgiflTvJKuU,14337
+kaiju_tools/sessions.py,sha256=wLUuauGg_6h2AFp3KLcN0r7V7cv1oZ9By5AHLEyEpBg,16671
+kaiju_tools/streams.py,sha256=EIj_-npyYfFGwFuNYe0JyTGAYZB7NI5o3OCU_rb4mY8,7313
+kaiju_tools/templates.py,sha256=GgvxXrGGuHe3X5gUxwTfartqLMhloFVj9bXwH0kWkOo,14417
 kaiju_tools/types.py,sha256=9WE-S_6V63fO1y8E9F9NFjJEhayF6fUzEjjseyyquLU,12410
-kaiju_tools/docker/__init__.py,sha256=OAZ6r-UPPssXFhgcw2Xa0AW9N8ToR45ZVX6jQWpv3k0,276
-kaiju_tools/docker/containers.py,sha256=Vx-uMI7lHrQWRQAj2UFcjuVdVX3C7F43IJRoDebgrTY,9782
-kaiju_tools/docker/images.py,sha256=ZDzc2rQ9kL1ydWSco0r9JAIgHq-BVT1HmkDhXjzf1F4,7723
-kaiju_tools/docker/services.py,sha256=cS3Xl3EMOWv0y_WRCi5GKFYXFrcpkievTVSyFUt0p4I,103
+kaiju_tools/docker/__init__.py,sha256=cS3Xl3EMOWv0y_WRCi5GKFYXFrcpkievTVSyFUt0p4I,103
+kaiju_tools/docker/containers.py,sha256=LvvRYWRmsJCtZ-Gzp1jblxPKE-0Ixwwvyyo7x3mDqOs,9790
+kaiju_tools/docker/images.py,sha256=-fZlI1yePkvPT60ww-i8Z5viJjqIiz1imIk6aPWmrE8,7723
 kaiju_tools/docker/stack.py,sha256=dtoS3veOln42dG-um9d1datTwMJIUkR8vWPgVySYB1Y,11216
 kaiju_tools/docker/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-kaiju_tools/docker/tests/fixtures.py,sha256=0bx6BE7id5Rz52y3nEVXx0ZNjzPuDe_T9C6Jzq4iHaU,1625
+kaiju_tools/docker/tests/fixtures.py,sha256=Y8qdiezKbnuZedZs-D0aUB7NakHqRyHDpfgDTunc9xA,1306
 kaiju_tools/docker/tests/test_containers.py,sha256=Yugtil6wQs2DGp6W0lNJM0ZoihzG5d95z0u5StGIfJ0,575
 kaiju_tools/docker/tests/test_images.py,sha256=XDJ1Z3XQSQswiJxDO_QtKmw4NymJpXhSdvHtxCGg8rE,359
 kaiju_tools/docker/tests/test_stack.py,sha256=qa6UbjCBiVmAORKyWTs9HaArZF0ZLBDZSzGJlc3Bjhs,371
 kaiju_tools/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-kaiju_tools/tests/fixtures.py,sha256=1qWxT4_wC7CgOzmmzn96QZpHLg-Fbt1GaUDz2ng609k,18531
+kaiju_tools/tests/fixtures.py,sha256=Crhjbla2wYIjOuIKG4ZKpGOVukn05cjY_xS0t3aMoDI,19574
 kaiju_tools/tests/test_annotation_parser.py,sha256=jCQ5DR_EJEcyH5L5YzhKGw01_UlUxeiSd2i6zJUqhOU,9209
 kaiju_tools/tests/test_cache.py,sha256=Ko4Lx4thNU4IQK575xRAws7XVaAjLG0i_nMVFvn1kBg,1469
 kaiju_tools/tests/test_class_registry.py,sha256=P-XQ4nbAgH6TMBHoIEKpAdlMd1FL9tM9zm4f7L7Mpaw,1436
 kaiju_tools/tests/test_configurator.py,sha256=BwOmU6H4szzWDpK0JNq1b7Q1mm-yWGwAZ3O200MNLJc,552
+kaiju_tools/tests/test_data_store.py,sha256=niVKVoeF_vWzNL4tNWx8ndMxy50X8P2Mffsi8SMVAPw,3801
 kaiju_tools/tests/test_http.py,sha256=2gnS9pVZPCcf8imAjHm8b2TBXKCJdWLpzP0L3BwOvg8,2849
 kaiju_tools/tests/test_locks.py,sha256=-6h3amJnhWe5mf6uP1r2-laiaiXGMNfFpzThmyZfBlw,2097
-kaiju_tools/tests/test_mapping.py,sha256=V2821EkkXrzvQ5qKPHYADPRNmTrOa2LaNJv8y6rdar4,3407
-kaiju_tools/tests/test_rpc.py,sha256=_SEQNib-2fO-T_wgJlDUsUuUpPJ4RrUsZnULwjxX0jQ,9174
-kaiju_tools/tests/test_scheduler.py,sha256=jeOmW44btxdyeeORs_fPnK2Qzj1kENkFpLxJz5Zkkl4,1555
+kaiju_tools/tests/test_mapping.py,sha256=tv60gtNz-89RBFw3vYuBD3QWi49FYkYvoOMgRQW74zY,3457
+kaiju_tools/tests/test_rpc.py,sha256=E_tzQJtoJHcfBJCZhoE9dcoFgkSbAGaM06z5ETnUL9I,9192
+kaiju_tools/tests/test_scheduler.py,sha256=XA2kHgGUDr_E2XpAQAt4eaWY_rJ1cMxo_AnlntM6r9Y,1554
 kaiju_tools/tests/test_serializers.py,sha256=VcQkjaZe8gjjg4Thyf-cEXp8uHgntPcZKc0jURg66qo,2800
 kaiju_tools/tests/test_services.py,sha256=cCZecNOXsY-j91l07_rG3rfKpXQiu6DeMqBCrbaBsuY,2207
 kaiju_tools/tests/test_streams.py,sha256=WEVy4ctD3znw-qmZgM_j90mVPdoRcpXOKs3dIYi7A5U,3213
 kaiju_tools/tests/test_templates.py,sha256=CoQdRatGZhGzPl_y4MYXPTQMA9c_wn0ieVITQaamrL4,1692
-kaiju_tools-2.1.2.dist-info/LICENSE,sha256=XIlN2qA8UqpBDA-PteoYP4hTU0qBW0G9PRB__khO2zc,610
-kaiju_tools-2.1.2.dist-info/METADATA,sha256=-pXqeazEOvYFbZYJpufo3t7CtbF2gk9rtCv_3W4IjIY,3360
-kaiju_tools-2.1.2.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-kaiju_tools-2.1.2.dist-info/top_level.txt,sha256=DIgXUScFnJtRLiRWfjo547JK4rMuTIJoioMPRe1Jn6Y,12
-kaiju_tools-2.1.2.dist-info/RECORD,,
+kaiju_tools-2.1.3.dist-info/LICENSE,sha256=XIlN2qA8UqpBDA-PteoYP4hTU0qBW0G9PRB__khO2zc,610
+kaiju_tools-2.1.3.dist-info/METADATA,sha256=cjikWuTF5xxLArkz4CMypOqe7dkseFfFGPokLYGtFDU,3360
+kaiju_tools-2.1.3.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+kaiju_tools-2.1.3.dist-info/top_level.txt,sha256=DIgXUScFnJtRLiRWfjo547JK4rMuTIJoioMPRe1Jn6Y,12
+kaiju_tools-2.1.3.dist-info/RECORD,,
```

